{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/stanzheng/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "When did The Knights Templar are founded to protect Christian     pilgrims in Jerusalem.\n",
      "When did Alfonso VI of Castile captures the Moorish Muslim city of Toledo, Spain.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "question_one = 'Connected devices, such as sensors, actuators, embedded devices, smart appliances, and wearable devices, connect to AWS IoT over HTTPS, WebSockets, or secure MQTT. Included in AWS IoT is a Device Gateway that allows secure, low-latency, low-overhead, bi-directional communication between connected devices and your cloud and mobile applications.\n",
    "\n",
    "'\n",
    "question_two = 'Alfonso VI of Castile captures the Moorish Muslim city of Toledo, Spain.'\n",
    "\n",
    "def modify(inputStr):\n",
    "\n",
    "    tokens = nltk.PunktSentenceTokenizer().tokenize(inputStr)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    auxiliary_verbs = [i for i, w in enumerate(tagged) if w[1] == 'VBP']\n",
    "    if auxiliary_verbs:\n",
    "        tagged.insert(0, tagged.pop(auxiliary_verbs[0]))\n",
    "    else:\n",
    "        tagged.insert(0, ('did', 'VBD'))\n",
    "    tagged.insert(0, ('When', 'WRB'))\n",
    "\n",
    "    return ' '.join([t[0] for t in tagged])\n",
    "\n",
    "question_one = modify(question_one)\n",
    "question_two = modify(question_two)\n",
    "\n",
    "print(question_one)\n",
    "print(question_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "html_doc = requests.get(\"https://aws.amazon.com/batch/faqs/\").text\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q: What is AWS Batch?',\n",
       " 'AWS Batch is a set of batch management capabilities that enables developers, scientists, and engineers to easily and efficiently run hundreds of thousands of batch computing jobs on AWS. AWS Batch dynamically provisions the optimal quantity and type of compute resources (e.g., CPU or memory optimized instances) based on the volume and specific resource requirements of the batch jobs submitted. With AWS Batch, there is no need to install and manage batch computing software or server clusters, allowing you to instead focus on analyzing results and solving problems. AWS Batch plans, schedules, and executes your batch computing workloads using Amazon EC2 and Spot Instances.',\n",
       " 'Q: What is Batch Computing? Batch computing is the execution of a series of programs (\"jobs\") on one or more computers without manual intervention. Input parameters are pre-defined through scripts, command-line arguments, control files, or job control language. A given batch job may depend on the completion of preceding jobs, or on the availability of certain inputs, making the sequencing and scheduling of multiple jobs important, and incompatible with interactive processing.',\n",
       " 'Q: What are the benefits of batch computing?',\n",
       " 'Q: Why should I use AWS Batch? AWS Batch handles job execution and compute resource management, allowing you to focus on developing applications or analyzing results instead of setting up and managing infrastructure. If you are considering running or moving batch workloads to AWS, you should consider using AWS Batch.',\n",
       " 'Q: What use cases is AWS Batch optimized for? AWS Batch is optimized for batch computing and applications that scale through the execution of multiple jobs in parallel. Deep learning, genomics analysis, financial risk models, Monte Carlo simulations, animation rendering, media transcoding, image processing, and engineering simulations are all excellent examples of batch computing applications. ',\n",
       " 'Q: What are the key features of AWS Batch? AWS Batch manages compute environments and job queues, allowing you to easily run thousands of jobs of any scale using Amazon EC2 and EC2 Spot. You simply define and submit your batch jobs to a queue. In response, AWS Batch chooses where to run the jobs, launching additional AWS capacity if needed. AWS Batch carefully monitors the progress of your jobs. When capacity is no longer needed, AWS Batch will remove it. AWS Batch also provides the ability to submit jobs that are part of a pipeline or workflow, enabling you to express any interdependencies that exist between them as you submit jobs.',\n",
       " 'Q: What types of batch jobs does AWS Batch support? AWS Batch supports any job that can executed as a Docker container. Jobs specify their memory requirements and number of vCPUs. \\xa0',\n",
       " 'Q: What is a Compute Resource? An AWS Batch Compute Resource is an EC2 instance.',\n",
       " 'Q: What is a Compute Environment? An AWS Batch Compute Environment is a collection of compute resources on which jobs are executed. AWS Batch supports two types of Compute Environments; Managed Compute Environments which are provisioned and managed by AWS and Unmanaged Compute Environments which are managed by customers. Unmanaged Compute Environments provide a mechanism to leverage specialized resources such as Dedicated Hosts, larger storage configurations, and Amazon EFS.',\n",
       " 'Q: What is a Job Definition? A Job Definition describes the job to be executed, parameters, environmental variables, compute requirements, and other information that is used to optimize the execution of a job.\\xa0Job Definitions are defined in advance of submitting a job and can be shared with others.',\n",
       " 'Q: What is the Amazon ECS Agent and how is it used by AWS Batch? AWS Batch uses Amazon ECS to execute containerized jobs and therefore requires the ECS Agent to be installed on compute resources within your AWS Batch Compute Environments. The ECS Agent is pre-installed in Managed Compute Environments.',\n",
       " 'Q: How does AWS Batch make it easier to use EC2 Spot? AWS Batch Compute Environments can be comprised of EC2 Spot instances. When creating a Managed Compute Environment, simplify specify that you would like to use EC2 Spot and provide a percentage of On Demand pricing that you would like to bid and AWS Batch will take care of the rest. Unmanaged Compute Environments can also include Spot instances that you launch, including those launched by EC2 Spot Fleet.',\n",
       " 'Q. What is the pricing for AWS Batch? There is no additional charge for AWS Batch. You only pay for the AWS Resources (e.g. EC2 Instances) you create to store and run your batch jobs. ',\n",
       " 'Q. How do I get started? Follow the Getting Started Guide in our documentation to get started.  ',\n",
       " 'Q. What do I need to provision to get started? There is no need to manually launch your own compute resources in order to get started. The AWS Batch web console will guide you through the process of creating your first Compute Environment and Job Queue so that you can submit your first job. Resources within your compute environment will scale up as additional jobs are ready to run and scale down as the number of runnable jobs decreases. ',\n",
       " 'Amazon Web Services is Hiring.',\n",
       " 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.',\n",
       " '\\xa0',\n",
       " 'Amazon Web Services is an Equal Opportunity Employer.',\n",
       " '\\xa0',\n",
       " '\\xa0']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.get_text() for i in soup.select(\".aws-text-box p\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "FAQS = \"https://aws.amazon.com/faqs/\"\n",
    "html_doc = requests.get(FAQS).text\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "FAQ_LIST = soup.select(\".aws-text-box a[href^='/']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"https://aws.amazon.com/\"\n",
    "urls = {i['href']:'{}{}'.format(root, i['href']) for i in FAQ_LIST}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from itertools import zip_longest\n",
    "\n",
    "QA = {}\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "for k, u in urls.items():\n",
    "    html_doc = requests.get(u).text\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    results = [i.get_text() for i in soup.select(\".aws-text-box p\")]\n",
    "    QA[k] = list(grouper(results, 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['/ec2/faqs/', '/windows/faq/', '/ecr/faqs/', '/ecs/faqs/', '/vpc/faqs/', '/batch/faqs/', '/elasticbeanstalk/faqs/', '/lambda/faqs/', '/autoscaling/faqs/', '/elasticloadbalancing/faqs/', '/efs/faq/', '/snowball/faqs/', '/snowball-edge/faqs/', '/snowmobile/faqs/', '/rds/aurora/faqs/', '/redshift/faqs/', '/dms/faqs/', '/application-discovery/faqs/', '/server-migration-service/faqs/', '/codecommit/faqs/', '/codebuild/faqs/', '/codedeploy/faqs/', '/codepipeline/faqs/', '/xray/faqs/', '/cloudwatch/faqs/', '/ec2/systems-manager/faqs/', '/cloudtrail/faqs/', '/config/faq/', '/managed-services/faqs/', '/servicecatalog/faqs/', '/premiumsupport/ta-faqs/', '/console/faqs/', '/lex/faqs/', '/polly/faqs/', '/rekognition/faqs/', '/amazon-ai1/faqs/', '/athena/faqs/', '/elasticsearch-service/faqs/', '/kinesis/streams/faqs/', '/cloud-directory/faqs/', '/inspector/faqs/', '/certificate-manager/faqs/', '/directoryservice/faqs/', '/iam/faqs/', '/kms/faqs/', '/organizations/faqs/', '/shield/faqs/', '/waf/faq/', '/mobile/faqs/', '/api-gateway/faqs/', '/cognito/faqs/', '/pinpoint/faqs/', '/device-farm/faq/', '/mobileanalytics/faqs/', '/step-functions/faqs/', '/appstream/faqs/', '/workdocs/faqs/', '/workmail/faqs/', '/workspaces/faqs/', '/appstream2/faqs/', '/iot/faqs/', '/iot-platform/faqs/', '/greengrass/faqs/', '/iotbutton/faq/', '/connect/faqs/', '/lumberyard/faq/', '/gamelift/faq/'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = range(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Q: Why is this necessary?',\n",
       " 'Given how fast AWS continues to grow, we will start to run low on IDs for certain resources in 2018. In order to enable the long-term, uninterrupted creation of new resources, we need to introduce a longer ID format. All Amazon EC2 resource IDs will change to the longer format in July 2018.')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA['/ec2/faqs/'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

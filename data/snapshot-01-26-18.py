# coding: utf-8
{'/ec2/faqs/': [('Q: What is changing?', 'Starting in July 2018, all newly created Amazon EC2 resources will receive longer format IDs. The new format will only apply to newly created resources; your existing resources won’t be affected. Instances and volumes already use this ID format. From January 2018 through the end of June 2018, customers will have the ability to opt-in to use longer IDs. During this time, you can choose which ID format resources are assigned and update your management tools and scripts to add support for the longer format.'), ('Q: Why is this necessary?', 'Given how fast AWS continues to grow, we will start to run low on IDs for certain resources in 2018. In order to enable the long-term, uninterrupted creation of new resources, we need to introduce a longer ID format. All Amazon EC2 resource IDs will change to the longer format in July 2018.'), ('Q:\xa0 I already opted in for longer IDs last year. Why do I need to opt-in again?', 'In 2016, we moved to the longer ID format for Amazon EC2 instances, reservations, volumes, and snapshots only. This opt-in changes the ID format for all remaining EC2 resource types.'), ('Q: What will the new identifier format look like?', 'The new identifier format will follow the pattern of the current identifier format, but it will be longer. The new format will be -<17 characters>, e.g. “vpc-1234567890abcdef0” for VPCs or “subnet-1234567890abcdef0” for subnets.'), ('Q: Which IDs are changing?', ' Q: How does this impact me?'), ('There is a good chance that you won’t need to make any system changes to handle the new format. If you only use the console to manage AWS resources, you might not be impacted at all, but you should still update your settings to use the longer ID format as soon as possible. If you interact with AWS resources via APIs, SDKs, or the AWS CLI, you might be impacted, depending on whether your software makes assumptions about the ID format when validating or persisting resource IDs. If this is the case, you might need to update your systems to handle the new format.', 'Some failure modes could include:'), ('Q: Will this affect existing resources?', 'No. Only resources that are created after you opt-in to the longer format will be affected. Once a resource has been assigned an ID (long or short), that ID will never change. Each ID is unique and will never be reused. Any resource created with the old ID format will always retain its shorter ID. Any resource created with the new format will retain its longer ID, even if you opt back out.'), ('Q: When will this happen?', 'In January 2018, longer IDs will be available for opt-in via APIs and the EC2 Console. From January 2018 through the end of June 2018, all accounts can opt-in and out of longer IDs as needed for testing. Starting in July 1, 2018, the option to switch formats will no longer be available, and newly created EC2 resources to receive longer IDs.'), ('Q: Why is there an opt-in period?', 'We want to give you as much time as possible to test your systems with the new format. This transition time offers maximum flexibility to test and update your systems incrementally and will help minimize interrupts as you add support for the new format, if necessary.'), ('Q: What is Amazon Elastic Compute Cloud (Amazon EC2)?', 'Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides resizable compute capacity in the cloud. It is designed to make web-scale computing easier for developers.'), ('Q: What can I do with Amazon EC2?', 'Just as Amazon Simple Storage Service (Amazon S3) enables storage in the cloud, Amazon EC2 enables “compute” in the cloud. Amazon EC2’s simple web service interface allows you to obtain and configure capacity with minimal friction. It provides you with complete control of your computing resources and lets you run on Amazon’s proven computing environment. Amazon EC2 reduces the time required to obtain and boot new server instances to minutes, allowing you to quickly scale capacity, both up and down, as your computing requirements change. Amazon EC2 changes the economics of computing by allowing you to pay only for capacity that you actually use.'), ('Q: How can I get started with Amazon EC2?', 'To sign up for Amazon EC2, click the “Sign up for This Web Service” button on the Amazon EC2 detail page. You must have an Amazon Web Services account to access this service; if you do not already have one, you will be prompted to create one when you begin the Amazon EC2 sign-up process. After signing up, please refer to the Amazon EC2 documentation, which includes our Getting Started Guide.'), ('Q: Why am I asked to verify my phone number when signing up for Amazon EC2?', 'Amazon EC2 registration requires you to have a valid phone number and email address on file with AWS in case we ever need to contact you. Verifying your phone number takes only a couple of minutes and involves receiving a phone call during the registration process and entering a PIN number using the phone key pad.'), ('Q: What can developers now do that they could not before?', 'Until now, small developers did not have the capital to acquire massive compute resources and ensure they had the capacity they needed to handle unexpected spikes in load. Amazon EC2 enables any developer to leverage Amazon’s own benefits of massive scale with no up-front investment or performance compromises. Developers are now free to innovate knowing that no matter how successful their businesses become, it will be inexpensive and simple to ensure they have the compute capacity they need to meet their business requirements.'), ('The “Elastic” nature of the service allows developers to instantly scale to meet spikes in traffic or demand. When computing requirements unexpectedly change (up or down), Amazon EC2 can instantly respond, meaning that developers have the ability to control how many resources are in use at any given point in time. In contrast, traditional hosting services generally provide a fixed number of resources for a fixed amount of time, meaning that users have a limited ability to easily respond when their usage is rapidly changing, unpredictable, or is known to experience large peaks at various intervals.', 'Q: How do I run systems in the Amazon EC2 environment?'), ('Once you have set up your account and select or create your AMIs, you are ready to boot your instance. You can start your AMI on any number of On-Demand instances by using the RunInstances API call. You simply need to indicate how many instances you wish to launch. If you wish to run more than 20 On-Demand instances, complete the Amazon EC2 instance request form.', 'If Amazon EC2 is able to fulfill your request, RunInstances will return success, and we will start launching your instances. You can check on the status of your instances using the DescribeInstances API call. You can also programmatically terminate any number of your instances using the TerminateInstances API call.'), ('If you have a running instance using an Amazon EBS boot partition, you can also use the StopInstances API call to release the compute resources but preserve the data on the boot partition. You can use the StartInstances API when you are ready to restart the associated instance with the Amazon EBS boot partition.', 'In addition, you have the option to use Spot Instances to reduce your computing costs when you have flexibility in when your applications can run. Read more about Spot Instances for a more detailed explanation on how Spot Instances work.'), ('If you prefer, you can also perform all these actions from the AWS Management Console or through the command line using our command line tools, which have been implemented with this web service API.', 'Q: What is the difference between using the local instance store and Amazon Elastic Block Store (Amazon EBS) for the root device?'), ('When you launch your Amazon EC2 instances you have the ability to store your root device data on Amazon EBS or the local instance store. By using Amazon EBS, data on the root device will persist independently from the lifetime of the instance. This enables you to stop and restart the instance at a subsequent time, which is similar to shutting down your laptop and restarting it when you need it again.', 'Alternatively, the local instance store only persists during the life of the instance. This is an inexpensive way to launch instances where data is not stored to the root device. For example, some customers use this option to run large web sites where each instance is a clone to handle web traffic.'), ('Q: How quickly will systems be running?', 'It typically takes less than 10 minutes from the issue of the RunInstances call to the point where all requested instances begin their boot sequences. This time is dependant on a number of factors including: the size of your AMI, the number of instances you are launching, and how recently you have launched that AMI. Images launched for the first time may take slightly longer to boot.'), ('Q: How do I load and store my systems with Amazon EC2?', 'Amazon EC2 allows you to set up and configure everything about your instances from your operating system up to your applications. An Amazon Machine Image (AMI) is simply a packaged-up environment that includes all the necessary bits to set up and boot your instance. Your AMIs are your unit of deployment. You might have just one AMI or you might compose your system out of several building block AMIs (e.g., webservers, appservers, and databases). Amazon EC2 provides a number of tools to make creating an AMI easy. Once you create a custom AMI, you will need to bundle it. If you are bundling an image with a root device backed by Amazon EBS, you can simply use the bundle command in the AWS Management Console. If you are bundling an image with a boot partition on the instance store, then you will need to use the AMI Tools to upload it to Amazon S3. Amazon EC2 uses Amazon EBS and Amazon S3 to provide reliable, scalable storage of your AMIs so that we can boot them when you ask us to do so.'), ('Or, if you want, you don’t have to set up your own AMI from scratch. You can choose from a number of globally available AMIs that provide useful instances. For example, if you just want a simple Linux server, you can choose one of the standard Linux distribution AMIs.', 'Q: How do I access my systems?'), ('The RunInstances call that initiates execution of your application stack will return a set of DNS names, one for each system that is being booted. This name can be used to access the system exactly as you would if it were in your own data center. You own that machine while your operating system stack is executing on it.', 'Q: Is Amazon EC2 used in conjunction with Amazon S3?'), ('Yes, Amazon EC2 is used jointly with Amazon S3 for instances with root devices backed by local instance storage. By using Amazon S3, developers have access to the same highly scalable, reliable, fast, inexpensive data storage infrastructure that Amazon uses to run its own global network of web sites. In order to execute systems in the Amazon EC2 environment, developers use the tools provided to load their AMIs into Amazon S3 and to move them between Amazon S3 and Amazon EC2. See How do I load and store my systems with Amazon EC2?\xa0for more information about AMIs.', 'We expect developers to find the combination of Amazon EC2 and Amazon S3 to be very useful. Amazon EC2 provides cheap, scalable compute in the cloud while Amazon S3 allows users to store their data reliably.'), ('Q: How many instances can I run in Amazon EC2?', 'You are limited to running up to a total of 20 On-Demand instances across the instance family, purchasing 20 Reserved Instances, and requesting Spot Instances per your dynamic Spot limit per region. New AWS accounts may start with limits that are lower than the limits described here. Certain instance types are further limited per region as follows: '), ('Note that cc2.8xlarge, cg1.4xlarge, hs1.8xlarge, cr1.8xlarge, G2, D2, and I2 instances are not available in all regions.', 'If you need more instances, complete the Amazon EC2 instance request form with your use case and your instance increase will be considered. Limit increases are tied to the region they were requested for.'), ('Q: Are there any limitations in sending email from Amazon EC2 instances?', 'Yes. In order to maintain the quality of Amazon EC2 addresses for sending email, we enforce default limits on the amount of email that can be sent from EC2 accounts. If you wish to send larger amounts of email from EC2, you can apply to have these limits removed from your account by filling out this form.'), ('Q: How quickly can I scale my capacity both up and down?', 'Amazon EC2 provides a truly elastic computing environment. Amazon EC2 enables you to increase or decrease capacity within minutes, not hours or days. You can commission one, hundreds or even thousands of server instances simultaneously. When you need more instances, you simply call RunInstances, and Amazon EC2 will typically set up your new instances in a matter of minutes. Of course, because this is all controlled with web service APIs, your application can automatically scale itself up and down depending on its needs.'), ('Q: What operating system environments are supported?', 'Amazon EC2 currently supports a variety of operating systems including: Amazon Linux, Ubuntu, Windows Server, Red Hat Enterprise Linux, SUSE Linux Enterprise Server, Fedora, Debian, CentOS, Gentoo Linux, Oracle Linux, and FreeBSD. We are looking for ways to expand it to other platforms.'), ('Q: Does Amazon EC2 use ECC memory?', 'In our experience, ECC memory is necessary for server infrastructure, and all the hardware underlying Amazon EC2 uses ECC memory.'), ('Q: How is this service different than a plain hosting service?', 'Traditional hosting services generally provide a pre-configured resource for a fixed amount of time and at a predetermined cost. Amazon EC2 differs fundamentally in the flexibility, control and significant cost savings it offers developers, allowing them to treat Amazon EC2 as their own personal data center with the benefit of Amazon.com’s robust infrastructure.'), ('When computing requirements unexpectedly change (up or down), Amazon EC2 can instantly respond, meaning that developers have the ability to control how many resources are in use at any given point in time. In contrast, traditional hosting services generally provide a fixed number of resources for a fixed amount of time, meaning that users have a limited ability to easily respond when their usage is rapidly changing, unpredictable, or is known to experience large peaks at various intervals.', 'Secondly, many hosting services don’t provide full control over the compute resources being provided. Using Amazon EC2, developers can choose not only to initiate or shut down instances at any time, they can completely customize the configuration of their instances to suit their needs – and change it at any time. Most hosting services cater more towards groups of users with similar system requirements, and so offer limited ability to change these.'), ('Finally, with Amazon EC2 developers enjoy the benefit of paying only for their actual resource consumption – and at very low rates. Most hosting services require users to pay a fixed, up-front fee irrespective of their actual computing power used, and so users risk overbuying resources to compensate for the inability to quickly scale up resources within a short time frame. ', ''), ('Q: How will I be charged and billed for my use of Amazon EC2?', 'You pay only for what you use. Displayed pricing is an hourly rate but depending on which instances you choose, you pay by the hour or second (minimum of 60 seconds) for each instance type. Partial instance-hours consumed are billed based on instance usage. Data transferred between AWS services in different regions will be charged as Internet Data Transfer on both sides of the transfer. Usage for other Amazon Web Services is billed separately from Amazon EC2.'), ('For EC2 pricing information, please visit the pricing section on the EC2 detail page.', 'Q: When does billing of my Amazon EC2 systems begin and end?'), ('Billing commences when Amazon EC2 initiates the boot sequence of an AMI instance. Billing ends when the instance terminates, which could occur through a web services command, by running "shutdown -h", or through instance failure. When you stop an instance, we shut it down but don\'t charge hourly usage for a stopped instance, or data transfer fees, but we do charge for the storage for any Amazon EBS volumes. To learn more, visit the AWS Documentation.', 'Q: What defines billable EC2 instance usage?'), ('Instance usages are billed for any time your instances are in a "running" state. If you no longer wish to be charged for your instance, you must "stop" or "terminate" the instance to avoid being billed for additional instance usage. Billing starts when an instance transitions into the running state.', 'Q: If I have two instances in different availability zones, how will I be charged for regional data transfer?'), ('Each instance is charged for its data in and data out at corresponding Data Transfer rates. Therefore, if data is transferred between these two instances, it is charged at "Data Transfer Out from EC2 to Another AWS Region" for the first instance and at "Data Transfer In from Another AWS Region" for the second instance. Please refer to this page\xa0for detailed data transfer', 'Q. If I have two instances in different regions, how will I be charged for data transfer?'), ('Each instance is charged for its data in and data out at Internet Data Transfer rates. Therefore, if data is transferred between these two instances, it is charged at Internet Data Transfer Out for the first instance and at Internet Data Transfer In for the second instance.', 'Q: How will my monthly bill show per-second versus per-hour?'), ('Although EC2 charges in your monthly bill will now be calculated based on a per second basis, for consistency, the monthly EC2 bill will show cumulative usage for each instance that ran in a given month in decimal hours. An example would be an instance running for 1 hour 10 minutes and 4 seconds would look like 1.1677. Below is an example of a detailed billing report. The two highlighted areas show how the new report will look based on decimal hours.', 'Q: Do your prices include taxes?'), ('Except as otherwise noted, our prices are exclusive of applicable taxes and duties, including VAT and applicable sales tax.\xa0For customers with a Japanese billing address, use of AWS services is subject to Japanese Consumption Tax. Learn more. ', ''), ('Q: What kind of hardware will my application stack run on?', 'Visit Amazon EC2 Pricing for a list of instances available by region.'), ('Q: How do I select the right instance type?', 'Amazon EC2 instances are grouped into 5 families: General Purpose, Compute Optimized, Memory Optimized, Storage Optimized and Accelerated Computing instances. General Purpose Instances have memory to CPU ratios suitable for most general purpose applications and come with fixed performance (M5, M4, M3) or burstable performance (T2); Compute Optimized instances (C5, C4, C3) have proportionally more CPU resources than memory (RAM) and are well suited for scale out compute-intensive applications and High Performance Computing (HPC) workloads; Memory Optimized Instances (X1e, X1, R4, R3) offer larger memory sizes for memory-intensive applications, including database and memory caching applications; Accelerating Computing instances (P3, P2, G3, F1) take advantage of the parallel processing capabilities of NVIDIA Tesla GPUs for high performance computing and machine/deep learning; GPU Graphics instances (G3) offer high-performance 3D graphics capabilities for applications using OpenGL and DirectX; F1 instances deliver Xilinx FPGA-based reconfigurable computing; Storage Optimized Instances (H1, I3, D2) that provide very high, low latency, I/O capacity using SSD-based local instance storage for I/O-intensive applications, with D2 or H1, the dense-storage and HDD-storage instances, provide local high storage density and sequential I/O performance for data warehousing, Hadoop and other data-intensive applications. When choosing instance types, you should consider the characteristics of your application with regards to resource utilization (i.e. CPU, Memory, Storage) and select the optimal instance family and instance size.'), ('Q: What is an “EC2 Compute Unit” and why did you introduce it?', 'Transitioning to a utility computing model fundamentally changes how developers have been trained to think about CPU resources. Instead of purchasing or leasing a particular processor to use for several months or years, you are renting capacity by the hour. Because Amazon EC2 is built on commodity hardware, over time there may be several different types of physical hardware underlying EC2 instances. Our goal is to provide a consistent amount of CPU capacity no matter what the actual underlying hardware.'), ('Amazon EC2 uses a variety of measures to provide each instance with a consistent and predictable amount of CPU capacity. In order to make it easy for developers to compare CPU capacity between different instance types, we have defined an Amazon EC2 Compute Unit. The amount of CPU that is allocated to a particular instance is expressed in terms of these EC2 Compute Units. We use several benchmarks and tests to manage the consistency and predictability of the performance from an EC2 Compute Unit. The EC2 Compute Unit (ECU) provides the relative measure of the integer processing power of an Amazon EC2 instance. Over time, we may add or substitute measures that go into the definition of an EC2 Compute Unit, if we find metrics that will give you a clearer picture of compute capacity.', 'Q: What is the regional availability of Amazon EC2 instance types? For a list of all instances and regional availability, visit Amazon EC2 Pricing. '), ('', 'Q: How do I prevent other people from viewing my systems?'), ('You have complete control over the visibility of your systems. The Amazon EC2 security systems allow you to place your running instances into arbitrary groups of your choice. Using the web services interface, you can then specify which groups may communicate with which other groups, and also which IP subnets on the Internet may talk to which groups. This allows you to control access to your instances in our highly dynamic environment. Of course, you should also secure your instance as you would any other server.', 'Q: Can I get a history of all EC2 API calls made on my account for security analysis and operational troubleshooting purposes?  '), ('Yes. To receive a history of all EC2 API calls (including VPC and EBS) made on your account, you simply turn on CloudTrail in the AWS Management Console.\xa0 For more information, visit the CloudTrail home page.\xa0', 'Q: Where can I find more information about security on AWS?'), ('For more information on security on AWS please refer to our Amazon Web Services: Overview of Security Processes white paper and to our Amazon EC2 running Windows Security Guide. ', ''), ('Q: Why am I limited to 5 Elastic IP addresses per region?', 'Public (IPV4) internet addresses are a scarce resource. There is only a limited amount of public IP space available, and Amazon EC2 is committed to helping use that space efficiently.'), ('By default, all accounts are limited to 5 Elastic IP addresses per region. If you need more the 5 Elastic IP addresses, we ask that you apply for your limit to be raised. We will ask you to think through your use case and help us understand your need for additional addresses. You can apply for more Elastic IP address here. Any increases will be specific to the region they have been requested for.', ''), ('Q: Why am I charged when my Elastic IP address is not associated with a running instance?', 'In order to help ensure our customers are efficiently using the Elastic IP addresses, we impose a small hourly charge for each address when it is not associated to a running instance.'), ('', 'Q: Do I need one Elastic IP address for every instance that I have running?'), ('No. You do not need an Elastic IP address for all your instances. By default, every instance comes with a private IP address and an internet routable public IP address. The private address is associated exclusively with the instance and is only returned to Amazon EC2 when the instance is stopped or terminated. The public address is associated exclusively with the instance until it is stopped, terminated or replaced with an Elastic IP address. These IP addresses should be adequate for many applications where you do not need a long lived internet routable end point. Compute clusters, web crawling, and backend services are all examples of applications that typically do not require Elastic IP addresses.', ''), ('Q: How long does it take to remap an Elastic IP address?', 'The remap process currently takes several minutes from when you instruct us to remap the Elastic IP until it fully propagates through our system.'), ('', 'Q: Can I configure the reverse DNS record for my Elastic IP address?'), ('Yes, you can configure the reverse DNS record of your Elastic IP address by filling out this form. Note that a corresponding forward DNS record pointing to that Elastic IP address must exist before we can create the reverse DNS record. ', ''), ('Q: How isolated are Availability Zones from one another?', 'Each Availability Zone runs on its own physically distinct, independent infrastructure, and is engineered to be highly reliable. Common points of failures like generators and cooling equipment are not shared across Availability Zones. Additionally, they are physically separate, such that even extremely uncommon disasters such as fires, tornados or flooding would only affect a single Availability Zone.'), ('Q: Is Amazon EC2 running in more than one region?', 'Yes.\xa0Please refer to Regional Products and Services for more details of our product and service availability by region.'), ('Q: How can I make sure that I am in the same Availability Zone as another developer?', 'We do not currently support the ability to coordinate launches into the same Availability Zone across AWS developer accounts. One Availability Zone name (for example, us-east-1a) in two AWS customer accounts may relate to different physical Availability Zones.'), ('Q: If I transfer data between Availability Zones using public IP addresses, will I be charged twice for Regional Data Transfer (once because it’s across zones, and a second time because I’m using public IP addresses)?', 'No. Regional Data Transfer rates apply if at least one of the following is true, but is only charged once for a given instance even if both are true:'), ('Q. What is the Nitro Hypervisor?', 'The launch of C5 instances introduced a new hypervisor for Amazon EC2, the Nitro Hypervisor. As a component of the Nitro system, the Nitro Hypervisor primarily provides CPU and memory isolation for EC2 instances. VPC networking and EBS storage resources are implemented by dedicated hardware components, Nitro Cards that are part of all current generation EC2 instance families. The Nitro Hypervisor is built on core Linux Kernel-based Virtual Machine (KVM) technology, but does not include general-purpose operating system components.'), ('Q. How does the Nitro Hypervisor benefit customers?', 'The Nitro Hypervisor provides consistent performance and increased compute and memory resources for EC2 virtualized instances by removing host system software components. It allows AWS to offer larger instance sizes (like c5.18xlarge) that provide practically all of the resources from the server to customers. Previously, C3 and C4 instances each eliminated software components by moving VPC and EBS functionality to hardware designed and built by AWS. This hardware enables the Nitro Hypervisor to be very small and uninvolved in data processing tasks for networking and storage.'), ('Q. Will all EC2 instances use the Nitro Hypervisor?', 'Eventually all new instance types will use the Nitro Hypervisor, but in the near term, some new instance types will use Xen depending on the requirements of the platform.'), ('Q. Will AWS continue to invest in its Xen-based hypervisor?', 'Yes. As AWS expands its global cloud infrastructure, EC2’s use of its Xen-based hypervisor will also continue to grow. Xen will remain a core component of EC2 instances for the foreseeable future. AWS is a founding member of the Xen Project since its establishment as a Linux Foundation Collaborative Project and remains an active participant on its Advisory Board. As AWS expands its global cloud infrastructure, EC2’s Xen-based hypervisor also continues to grow. Therefore EC2’s investment in Xen continues to grow, not shrink  Q. How many EBS volumes and Elastic Network Interfaces (ENIs) can be attached to instances running on the Nitro Hypervisor?'), ('Instances running on the Nitro Hypervisor support a maximum of 27 additional PCI devices for EBS volumes and VPC ENIs. Each EBS volume or VPC ENI uses a PCI device. For example, if you attach 3 additional network interfaces to an instance that uses the Nitro Hypervisor, you can attach up to 24 EBS volumes to that instance.', 'Q. Will the Nitro Hypervisor change the APIs used to interact with EC2 instances?'), ('No, all the public facing APIs for interacting with EC2 instances that run using the Nitro Hypervisor will remain the same. For example, the “hypervisor” field of the DescribeInstances response, which will continue to report “xen” for all EC2 instances, even those running under the Nitro Hypervisor. This field may be removed in a future revision of the EC2 API.', 'Q. Which AMIs are supported on instances that use the Nitro Hypervisor?'), ('EBS backed HVM AMIs with support for ENA networking and booting from NVMe storage can be used with instances that run under the Nitro Hypervisor. The latest Amazon Linux AMI and Windows AMIs provided by Amazon are supported, as are the latest AMI of Ubuntu, Debian, Red Hat Enterprise Linux, SUSE Enterprise Linux, CentOS, and FreeBSD.', 'Q. Will I notice any difference between instances using Xen hypervisor and those using the Nitro Hypervisor?'), ('Yes. For example, instances running under the Nitro Hypervisor boot from EBS volumes using an NVMe interface. Instances running under Xen boot from an emulated IDE hard drive, and switch to the Xen paravirtualized block device drivers.', 'Operating systems can identify when they are running under a hypervisor. Some software assumes that EC2 instances will run under the Xen hypervisor and rely on this detection. Operating systems will detect they are running under KVM when an instance uses the Nitro Hypervisor, so the process to identify EC2 instances should be used to identify EC2 instances that run under both hypervisors.'), ('All the features of EC2 such as Instance Metadata Service work the same way on instances running under both Xen and the Nitro Hypervisor. The majority of applications will function the same way under both Xen and the Nitro Hypervisor as long as the operating system has the needed support for ENA networking and NVMe storage.', 'Q. How are instance reboot and termination EC2 API requests implemented by the Nitro Hypervisor?'), ('The Nitro Hypervisor signals the operating system running in the instance that it should shut down cleanly by industry standard ACPI methods. For Linux instances, this requires that acpid be installed and functioning correctly. If acpid is not functioning in the instance, termination events will be delayed by multiple minutes and will then execute as a hard reset or power off.', 'Q. How do EBS volumes behave when accessed by NVMe interfaces?'), ('There are some important differences in how operating system NVMe drivers behave compared to Xen paravirtual (PV) block drivers.', 'First, the NVMe device names used by Linux based operating systems will be different than the parameters for EBS volume attachment requests and block device mapping entries such as /dev/xvda and /dev/xvdf. NVMe devices are enumerated by the operating system as /dev/nvme0n1, /dev/nvme1n1, and so on. The NVMe device names are not persistent mappings to volumes, therefore other methods like file system UUIDs or labels should be used when configuring the automatic mounting of file systems or other startup activities. When EBS volumes are accessed via the NVMe interface, the EBS volume ID is available via the controller serial number and the device name specified in EC2 API requests is provided by an NVMe vendor extension to the Identify Controller command. This enables backward compatible symbolic links to be created by a utility script. For more information see the EC2 documentation on device naming and NVMe based EBS volumes.'), ('Second, by default the NVMe drivers included in most operating systems implement an I/O timeout. If an I/O does not complete in an implementation specific amount of time, usually tens of seconds, the driver will attempt to cancel the I/O, retry it, or return an error to the component that issued the I/O. The Xen PV block device interface does not time out I/O, which can result in processes that cannot be terminated if it is waiting for I/O. The Linux NVMe driver behavior can be modified by specifying a higher value for the nvme.io timeout kernel module parameter.', 'Third, the NVMe interface can transfer much larger amounts of data per I/O, and in some cases may be able to support more outstanding I/O requests, compared to the Xen PV block interface. This can cause higher I/O latency if very large I/Os or a large number of I/O requests are issued to volumes designed to support throughput workloads like EBS Throughput Optimized HDD (st1) and Cold HDD (sc1) volumes. This I/O latency is normal for throughput optimized volumes in these scenarios, but may cause I/O timeouts in NVMe drivers. The I/O timeout can be adjusted in the Linux driver by specifying a larger value for the nvme_core.io_timeout kernel module parameter. '), ('', 'Q: What networking capabilities are included in this feature?'), ('We currently support enhanced networking capabilities using SR-IOV (Single Root I/O Virtualization). SR-IOV is a method of device virtualization that provides higher I/O performance and lower CPU utilization compared to traditional implementations. For supported Amazon EC2 instances, this feature provides higher packet per second (PPS) performance, lower inter-instance latencies, and very low network jitter.', 'Q: Why should I use Enhanced Networking?'), ('If your applications benefit from high packet-per-second performance and/or low latency networking, Enhanced Networking will provide significantly improved performance, consistence of performance and scalability.', 'Q: How can I enable Enhanced Networking on supported instances?'), ('In order to enable this feature, you must launch an HVM AMI with the appropriate drivers. M5, C5, H1, R4, X1, I3, P3, P2, G3, and m4.16xlarge instances provide the Elastic Network Adapter (ENA) interface (which uses the “ena” Linux driver) for Enhanced Networking. C3, C4, R3, I2, M4 (except m4.16xlarge) and D2 instances use Intel® 82599g Virtual Function Interface (which uses the “ixgbevf” Linux driver). Amazon Linux AMI includes both of these drivers by default. For AMIs that do not contain these drivers, you will need to download and install the appropriate drivers based on the instance types you plan to use. You can use Linux or Windows instructions to enable Enhanced Networking in AMIs that do not include the SR-IOV driver by default. Enhanced Networking is only supported in Amazon VPC. ', 'Q: Do I need to pay an additional fee to use Enhanced Networking?'), ('No, there is no additional fee for Enhanced Networking. To take advantage of Enhanced Networking you need to launch the appropriate AMI on a supported instance type in a VPC.', 'Q: Why is Enhanced Networking only supported in Amazon VPC?'), ('Amazon VPC allows us to deliver many advanced networking features to you that are not possible in EC2-Classic. Enhanced Networking is another example of a capability enabled by Amazon VPC.', 'Q: Which instance types support Enhanced Networking?'), ('Currently C3, C4, C5, D2, I3, I2, H1, M5, M4, X1 and R3 instances support Enhanced Networking. X1, P2, P3, G3, I3, R4 and m4.16xlarge instances provide the Elastic Network Adapter (ENA) interface for Enhanced Networking. C3, C4, R3, I2, M4 (except m4.16xlarge) and D2 instances, use Intel® 82599 Virtual Function Interface.', 'Q.\xa0Which instance types offer NVMe instance storage?'), ('High I/O instances use NVMe based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require millions of IOPS. Like Cluster instances, High I/O instances can be clustered via cluster placement groups for high bandwidth networking. ', ''), ('Q: What happens to my data when a system terminates?', 'The data stored on a local instance store will persist only as long as that instance is alive. However, data that is stored on an Amazon EBS volume will persist independently of the life of the instance. Therefore, we recommend that you use the local instance store for temporary data and, for data requiring a higher level of durability, we recommend using Amazon EBS volumes or backing up the data to Amazon S3. If you are using an Amazon EBS volume as a root partition, you will need to set the Delete On Terminate flag to "N" if you want your Amazon EBS volume to persist outside the life of the instance.'), ('Q: What kind of performance can I expect from Amazon EBS volumes?', "Amazon EBS provides four current generation volume types and are divided into two major categories: SSD-backed storage for transactional workloads and HDD-backed storage for throughput intensive workloads.\xa0These volume types differ in performance characteristics and price, allowing you to tailor your storage performance and cost to the needs of your applications. For more information on see the EBS product details page,\xa0and for additional information on performance, see the Amazon EC2 User Guide's EBS Performance section."), ('Q: What are Throughput Optimized HDD (st1) and Cold HDD (sc1) volume types?', 'ST1 volumes are backed by hard disk drives (HDDs) and are ideal for frequently accessed, throughput intensive workloads with large datasets and large I/O sizes, such as MapReduce, Kafka, log processing, data warehouse, and ETL workloads. These volumes deliver performance in terms of throughput, measured in MB/s, and include the ability to burst up to 250 MB/s per TB, with a baseline throughput of 40 MB/s per TB and a maximum throughput of 500 MB/s per volume. ST1 is designed to deliver the expected throughput performance 99% of the time and has enough I/O credits to support a full-volume scan at the burst rate.'), ('SC1 volumes are backed by hard disk drives (HDDs) and provides the lowest cost per GB of all EBS volume types. It is ideal for less frequently accessed workloads with large, cold datasets. Similar to st1, sc1 provides a burst model: these volumes can burst up to 80 MB/s per TB, with a baseline throughput of 12 MB/s per TB and a maximum throughput of 250 MB/s per volume. For infrequently accessed data, sc1 provides extremely inexpensive storage. SC1 is designed to deliver the expected throughput performance 99% of the time and has enough I/O credits to support a full-volume scan at the burst rate.', 'To maximize the performance of st1 and sc1, we recommend using\xa0EBS-optimized EC2 instances.'), ('Q: Which volume type should I choose?', 'Amazon EBS includes two major categories of storage: SSD-backed storage for transactional workloads (performance depends primarily on IOPS) and HDD-backed storage for throughput workloads (performance depends primarily on throughput, measured in MB/s). SSD-backed volumes are designed for transactional, IOPS-intensive database workloads, boot volumes, and workloads that require high IOPS. SSD-backed volumes include Provisioned IOPS SSD (io1) and General Purpose SSD (gp2). HDD-backed volumes are designed for throughput-intensive and big-data workloads, large I/O sizes, and sequential I/O patterns. HDD-backed volumes include Throughput Optimized HDD (st1) and Cold HDD (sc1). For more information on Amazon EBS see the EBS product details page.'), ('Q: Do you support multiple instances accessing a single volume?', 'While you are able to attach multiple volumes to a single instance, attaching multiple instances to one volume is not supported at this time.'), ('Q: Will I be able to access my EBS snapshots using the regular Amazon S3 APIs?', 'No, EBS snapshots are only available through the Amazon EC2 APIs.'), ('Q: Do volumes need to be un-mounted in order to take a snapshot? Does the snapshot need to complete before the volume can be used again?\xa0', 'No, snapshots can be done in real time while the volume is attached and in use. However, snapshots only capture data that has been written to your Amazon EBS volume, which might exclude any data that has been locally cached by your application or OS. In order to ensure consistent snapshots on volumes attached to an instance, we recommend cleanly detaching the volume, issuing the snapshot command, and then reattaching the volume. For Amazon EBS volumes that serve as root devices, we recommend shutting down the machine to take a clean snapshot.'), ('Q: Are snapshots versioned? Can I read an older snapshot to do a point-in-time recovery?', 'Each snapshot is given a unique identifier, and customers can create volumes based on any of their existing snapshots.'), ('Q: What charges apply when using Amazon EBS shared snapshots?', 'If you share a snapshot, you won’t be charged when other users make a copy of your snapshot. If you make a copy of another user’s shared volume, you will be charged normal EBS rates.'), ('Q: Can users of my Amazon EBS shared snapshots change any of my data?', 'Users who have permission to create volumes based on your shared snapshots will first make a copy of the snapshot into their account. Users can modify their own copies of the data, but the data on your original snapshot and any other volumes created by other users from your original snapshot will remain unmodified.'), ('Q: How can I discover Amazon EBS snapshots that have been shared with me?', 'You can find snapshots that have been shared with you by selecting “Private Snapshots” from the viewing dropdown in the Snapshots section of the AWS Management Console. This section will list both snapshots you own and snapshots that have been shared with you.'), ('Q: How can I find what Amazon EBS snapshots are shared globally?', 'You can find snapshots that have been shared globally by selecting “Public Snapshots” from the viewing dropdown in the Snapshots section of the AWS Management Console.'), ('Q: Do you offer encryption on Amazon EBS volumes and snapshots?', 'Yes. EBS offers seamless encryption of data volumes and snapshots. EBS encryption better enables you to meet security and encryption compliance requirements.'), ('Q: How can I find a list of Amazon Public Data Sets?', 'All information on Public Data Sets is available in our Public Data Sets Resource Center. You can also obtain a listing of Public Data Sets within the AWS Management Console by choosing “Amazon Snapshots” from the viewing dropdown in the Snapshots section. '), ('Q: Where can I learn more about EBS?', 'You can visit the Amazon EBS FAQ page. '), ('', 'Q. How do I access a file system from an Amazon EC2 instance?'), ('To access your file system, you mount the file system on an Amazon EC2 Linux-based instance using the standard Linux mount command and the file system’s DNS name. Once you’ve mounted, you can work with the files and directories in your file system just like you would with a local file system.', 'Amazon EFS uses the NFSv4.1 protocol. For a step-by-step example of how to access a file system from an Amazon EC2 instance, please see the Amazon EFS\xa0Getting Started\xa0guide.'), ('Q. What Amazon EC2 instance types and AMIs work with Amazon EFS?', 'Amazon EFS is compatible with all Amazon EC2 instance types and is accessible from Linux-based AMIs. You can mix and match the instance types connected to a single file system. For a step-by-step example of how to access a file system from an Amazon EC2 instance, please see the Amazon EFS\xa0Getting Started\xa0guide.'), ('Q. How do I load data into a file system?', 'You can load data into an Amazon EFS file system from your Amazon EC2 instances or from your on-premises datacenter servers.'), ('Amazon EFS file systems can be mounted on an Amazon EC2 instance, so any data that is accessible to an Amazon EC2 instance can also be read and written to Amazon EFS. To load data that is not currently stored on the Amazon cloud, you can use the same methods you use to transfer files to Amazon EC2 today, such as Secure Copy (SCP).', 'Amazon EFS file systems can also be mounted on an on-premises server, so any data that is accessible to an on-premises server can be read and written to Amazon EFS using standard Linux tools. For more information about accessing a file system from an on-premises server, please see the\xa0On-premises Access\xa0section of the Amazon EFS FAQ.'), ('For more information about moving data to the Amazon cloud, please see the\xa0Cloud Data Migration\xa0page.', 'Q. How do I access my file system from outside my VPC?'), ('Amazon EC2 instances within your VPC can access your file system directly, and Amazon EC2 Classic instances outside your VPC can mount a file system via\xa0ClassicLink.\xa0On-premises servers can mount your file systems via an\xa0AWS Direct Connect\xa0connection to your VPC.', 'Q. How many Amazon EC2 instances can connect to a file system?'), ('Amazon EFS supports one to thousands of Amazon EC2 instances connecting to a file system concurrently.', 'Q: Where can I learn more about EFS?'), ('You can visit the Amazon EFS FAQ page.', ''), ('Q: What is the minimum time interval granularity for the data that Amazon CloudWatch receives and aggregates?', 'Metrics are received and aggregated at 1 minute intervals.'), ('Q: Which operating systems does Amazon CloudWatch support?', 'Amazon CloudWatch receives and provides metrics for all Amazon EC2 instances and should work with any operating system currently supported by the Amazon EC2 service.'), ('Q: Will I lose the metrics data if I disable monitoring for an Amazon EC2 instance?', 'You can retrieve metrics data for any Amazon EC2 instance up to 2 weeks from the time you started to monitor it. After 2 weeks, metrics data for an Amazon EC2 instance will not be available if monitoring was disabled for that Amazon EC2 instance. If you want to archive metrics beyond 2 weeks you can do so by calling mon-get-stats command from the command line and storing the results in Amazon S3 or Amazon SimpleDB.'), ('Q: Can I access the metrics data for a terminated Amazon EC2 instance or a deleted Elastic Load Balancer?', 'Yes. Amazon CloudWatch stores metrics for terminated Amazon EC2 instances or deleted Elastic Load Balancers for 2 weeks.'), ('Q: Does the Amazon CloudWatch monitoring charge change depending on which type of Amazon EC2 instance I monitor?', 'No, the Amazon CloudWatch monitoring charge does not vary by Amazon EC2 instance type.'), ('Q: Why does the graphing of the same time window look different when I view in 5 minute and 1 minute periods?', 'If you view the same time window in a 5 minute period versus a 1 minute period, you may see that data points are displayed in different places on the graph. For the period you specify in your graph, Amazon CloudWatch will find all the available data points and calculates a single, aggregate point to represent the entire period. In the case of a 5 minute period, the single data point is placed at the beginning of the 5 minute time window. In the case of a 1 minute period, the single data point is placed at the 1 minute mark. We recommend using a 1 minute period for troubleshooting and other activities that require the most precise graphing of time periods. '), ('Q: Can I automatically scale my Amazon EC2 fleets?', ' Yes. Amazon EC2 Auto Scaling is a fully managed service designed to launch or terminate Amazon EC2 instances automatically to help ensure you have the correct number of Amazon EC2 instances available to handle the load for your application. EC2 Auto Scaling helps you maintain application availability through fleet management for EC2 instances, which detects and replaces unhealthy instances, and by scaling your Amazon EC2 capacity up or down automatically according to conditions you define. You can use EC2 Auto Scaling to automatically increase the number of Amazon EC2 instances during demand spikes to maintain performance and decrease capacity during lulls to reduce costs. For more information see the Amazon EC2 Auto Scaling FAQ.'), ('Q: What load balancing options does the Elastic Load Balancing service offer? ', 'Elastic Load Balancing offers two types of load balancers that both feature high availability, automatic scaling, and robust security. These include the Classic Load Balancer that routes traffic based on either application or network level information, and the Application Load Balancer that routes traffic based on advanced application level information that includes the content of the request.'), ('Q: When should I use the Classic Load Balancer and when should I use the Application Load Balancer?', 'The Classic Load Balancer is ideal for simple load balancing of traffic across multiple EC2 instances, while the Application Load Balancer is ideal for applications needing advanced routing capabilities, microservices, and container-based architectures. Please visit Elastic Load Balancing for more information. '), ('Q: What is a Reserved Instance?', 'A Reserved Instance (RI) is an EC2 offering that provides you with a significant discount on EC2 usage when you commit to a one-year or three-year term.'), ('Q: What are the differences between Standard RIs and Convertible RIs?', 'Standard RIs offer a significant discount on EC2 instance usage when you commit to a particular instance family. Convertible RIs offer you the option to change your instance configuration during the term, and still receive a discount on your EC2 usage. For more information on Convertible RIs, please click here.'), ('Q: Do RIs provide a capacity reservation?', 'Yes, when a Standard or Convertible RI is scoped to a specific Availability Zone (AZ), instance capacity matching the exact RI configuration is reserved for your use (these are referred to as “zonal RIs”). Zonal RIs give you additional confidence in your ability to launch instances when you need them.'), ('You can also choose to forego the capacity reservation and purchase Standard or Convertible RIs that are scoped to a region (referred to as “regional RIs”). Regional RIs automatically apply the discount to usage across Availability Zones and instance sizes in a region, making it easier for you to take advantage of the RI’s discounted rate. ', 'Q: When should I purchase a zonal RI?'), ('If you want to take advantage of the capacity reservation, then you should buy an RI in a specific Availability Zone.', 'Q: When should I purchase a regional RI?'), ('If you do not require the capacity reservation, then you should buy a regional RI. Regional RIs provide AZ and instance size flexibility, which offers broader applicability of the RI’s discounted rate.', 'Q: What are Availability Zone and instance size flexibility?'), ('Availability Zone and instance size flexibility make it easier for you to take advantage of your regional RI’s discounted rate. Availability Zone flexibility applies your RI’s discounted rate to usage in any Availability Zone in a region, while instance size flexibility applies your RI’s discounted rate to usage of any size within an instance family. Let’s say you own an m5.2xlarge Linux/Unix regional RI with default tenancy in US East (N.Virginia). Then this RI’s discounted rate can automatically apply to two m5.xlarge instances in us-east-1a or four m5.large instances in us-east-1b. ', 'Q: What types of RIs provide instance size flexibility?'), ('Linux/Unix regional RIs with the default tenancy provide instance size flexibility. Instance size flexibility is not available on RIs of other platforms such as Windows, Windows with SQL Standard, Windows with SQL Server Enterprise, Windows with SQL Server Web, RHEL, and SLES.', 'Q:\xa0Do I need to take any action to take advantage of Availability Zone and instance size flexibility?'), ('Regional RIs do not require any action to take advantage of Availability Zone and instance size flexibility.', 'Q: I own zonal RIs how do I assign them to a region?'), ('You can assign your Standard zonal RIs to a region by modifying the scope of the RI from a specific Availability Zone to a region from the EC2 management console or by using the ModifyReservedInstances API.\xa0', 'Q: How do I purchase an RI?'), ('To get started, you can purchase an RI from the EC2 Management Console or by using the AWS CLI. Simply specify the instance type, platform, tenancy, term, payment option, and region or Availability Zone.', 'Q: Can I purchase an RI for a running instance?'), ('Yes, AWS will automatically apply an RI’s discounted rate to any applicable instance usage from the time of purchase. Visit the Getting Started page to learn more.', 'Q: Can I control which instances are billed at the discounted rate?'), ('No. AWS automatically optimizes which instances are charged at the discounted rate to ensure you always pay the lowest amount. For information about billing, and how it applies to RIs, see Billing Benefits and Payment Options.', 'Q: How does instance size flexibility work?'), ('EC2 uses the scale shown below, to compare different sizes within an instance family. In the case of instance size flexibility on RIs, this scale is used to apply the discounted rate of RIs to the normalized usage of the instance family. For example, if you have an m5.2xlarge RI that is scoped to a region, then your discounted rate could apply towards the usage of 1 m5.2xlarge or 2 m5.xlarge instances.', 'Click here to learn more about how instance size flexibility of RIs applies to your EC2 usage. And click here to learn about how instance size flexibility of RIs is presented in the Cost and Usage Report.'), ('Q: Can I change my RI during its term?', 'Yes, you can modify the Availability Zone of the RI, change the scope of the RI from Availability Zone to region (and vice-versa), change the network platform from EC2-VPC to EC2-Classic (and vice versa) or modify instance sizes within the same instance family (on the Linux/Unix platform).'), ('Q: Can I change the instance type of my RI during its term?', 'Yes, Convertible RIs offer you the option to change the instance type, operating system, tenancy or payment option of your RI during its term. Please refer to the Convertible RI section of the FAQ for additional information.'), ('Q: What are the different payment options for RIs?', 'You can choose from three payment options when you purchase an RI. With the All Upfront option, you pay for the entire RI term with one upfront payment. With the Partial Upfront option, you make a low upfront payment and are then charged a discounted hourly rate for the instance for the duration of the RI term. The No Upfront option does not require any upfront payment and provides a discounted hourly rate for the duration of the term.'), ('Q: When are RIs activated?', 'The billing discount and capacity reservation (if applicable) is activated once your payment has successfully been authorized. You can view the status (pending | active | retired) of your RIs on the "Reserved Instances" page of the Amazon EC2 Console.'), ('Q: Do RIs apply to Spot instances or instances running on a Dedicated Host?', 'No, RIs do not apply to Spot instances or instances running on Dedicated Hosts. To lower the cost of using Dedicated Hosts, purchase Dedicated Host Reservations.'), ('Q: How do RIs work with Consolidated Billing?', 'Our system automatically optimizes which instances are charged at the discounted rate to ensure that the consolidated accounts always pay the lowest amount. If you own RIs that apply to an Availability Zone, then only the account which owns the RI will receive the capacity reservation. However, the discount will automatically apply to usage in any account across your consolidated billing family.'), ('Q: Can I get a discount on RI purchases?', 'Yes, EC2 provides tiered discounts on RI purchases. These discounts are determined based on the total list value (non-discounted price) for the active RIs you have per region. Your total list value is the sum of all expected payments for an RI within the term, including both the upfront and recurring hourly payments. The tier ranges and corresponding discounts are shown alongside.'), ('Q: Can you help me understand how volume discounts are applied to my RI purchases?', "Sure. Let's assume that you currently have $400,000 worth of active RIs in the US-east-1 region. Now, if you purchase RIs worth $150,000 in the same region, then the first $100,000 of this purchase would not receive a discount. However, the remaining $50,000 of this purchase would be discounted by 5 percent, so you would only be charged $47,500 for this portion of the purchase over the term based on your payment option."), ('To learn more, please visit the Understanding Reserved Instance Discount Pricing Tier portion of the Amazon EC2 User Guide.', 'Q: How do I calculate the list value of an RI?'), ('Here is a sample list value calculation for three-year Partial Upfront Reserved Instances:', 'Q: How are volume discounts calculated if I use Consolidated Billing?'), ('If you leverage Consolidated Billing, AWS will use the aggregate total list price of active RIs across all of your consolidated accounts to determine which volume discount tier to apply. Volume discount tiers are determined at the time of purchase, so you should activate Consolidated Billing prior to purchasing RIs to ensure that you benefit from the largest possible volume discount that your consolidated accounts are eligible to receive.', 'Q: Do Convertible RIs qualify for Volume Discounts?'), ('No, however the value of each Convertible RI that you purchase contributes to your volume discount tier standing.', 'Q: How do I determine which volume discount tier applies to me?'), ('To determine your current volume discount tier, please consult the Understanding Reserved Instance Discount Pricing Tiers portion of the Amazon EC2 User Guide.', 'Q: Will the cost of my RIs change, if my future volume qualifies me for other discount tiers?'), ('No. Volume discounts are determined at the time of purchase, therefore the cost of your RIs will continue to remain the same as you qualify for other discount tiers. Any new purchase will be discounted according to your eligible volume discount tier at the time of purchase.', 'Q: Do I need to take any action at the time of purchase to receive volume discounts?'), ('No, you will automatically receive volume discounts when you use the existing PurchaseReservedInstance API or EC2 Management Console interface to purchase RIs. If you purchase more than $10M worth of RIs contact us about receiving discounts beyond those that are automatically provided.', 'Q: What is a Convertible RI? A Convertible RI is a type of Reserved Instance with attributes that can be changed during the term.'), ('Q: When should I purchase a Convertible\xa0RI instead of a Standard RI? The Convertible\xa0RI is useful for customers who can commit to using EC2 instances for a three-year term in exchange for a significant discount on their EC2 usage, are uncertain about their instance needs in the future, or want to benefit from changes in price.', 'Q: What term length options are available on Convertible RIs? Like Standard RIs, Convertible RIs are available for purchase for a one-year or three-year term. \xa0'), ('Q: Can I exchange my Convertible\xa0RI to benefit from a Convertible\xa0RI matching a different instance type, operating system, tenancy, or payment option?  Yes, you can select a new instance type, operating system, tenancy, or payment option when you exchange your Convertible RIs.\xa0You also have the flexibility to exchange a portion of your Convertible RI or merge the value of multiple Convertible RIs in a single exchange. Click here to learn more about exchanging Convertible RIs.', "Q: Can I transfer a Convertible or Standard\xa0RI from one region to another? No, a\xa0RI is associated with a specific region, which is fixed for the duration of the reservation's term."), ('Q: How do I change the configuration of a Convertible RI? You can change the configuration of your Convertible\xa0RI using the EC2 Management Console or the GetReservedInstancesExchangeQuote API.\xa0You also have the flexibility to exchange a portion of your Convertible RI or merge the value of multiple Convertible RIs in a single exchange. Click here to learn more about exchanging Convertible RIs.', 'Q: Do I need to pay a fee when I exchange my Convertible RIs? No, you do not pay a fee when you exchange your RIs. However may need to pay a one-time true-up charge that accounts for differences in pricing between the Convertible\xa0RIs that you have and the Convertible\xa0RIs that you want.'), ('Q: How do Convertible\xa0RI exchanges work? When you exchange one Convertible\xa0RI for another, EC2 ensures that the total value of the Convertible\xa0RIs is maintained through a conversion. So, if you are converting your\xa0RI with a total value of $1000 for another RI, you will receive a quantity of Convertible RIs with a value that’s equal to or greater than $1000. You cannot convert your Convertible\xa0RI for Convertible RI(s) of a lesser total value.', 'Q: Can you define total value?  The total value is the sum of all expected payments that you’d make during the term for the RI.'), ('Q: Can you walk me through how the true-up cost is calculated for a conversion between two All Upfront Convertible RIs? Sure, let’s say you purchased an All Upfront Convertible\xa0RI for $1000 upfront, and halfway through the term you decide to change the attributes of the RI. Since you’re halfway through the\xa0RI term, you have $500 left of prorated value remaining on the RI. The All Upfront Convertible\xa0RI that you want to convert into costs $1,200 upfront today. Since you only have half of the term left on your existing Convertible RI, there is $600 of value remaining on the desired new Convertible RI. The true-up charge that you’ll pay will be the difference in upfront value between original and desired Convertible RIs, or $100 ($600 - $500).', 'Q: Can you walk me through a conversion between No Upfront Convertible RIs? Unlike conversions between Convertible RIs with an upfront value, since you’re converting between RIs without an upfront cost, there will not be a true-up charge. However, the amount you pay on an hourly basis before the exchange will need to be greater than or equal to the amount you pay on a total hourly basis after the exchange.'), ('For example, let’s say you purchased one No Upfront Convertible\xa0RI (A) with a $0.10/hr rate, and you decide to exchange Convertible\xa0RI A for another\xa0RI (B) that costs $0.06/hr. When you convert, you will receive two RIs of B because the amount that you pay on an hourly basis must be greater than or equal to the amount you’re paying for A on an hourly basis.', 'Q: Can I customize the number of instances that I receive as a result of a Convertible\xa0RI exchange? No, EC2 uses the value of the Convertible RIs you’re trading in to calculate the minimal number of Convertible RIs you’ll receive while ensuring the result of the exchange gives you Convertible RIs of equal or greater value.'), ('Q: Are there exchange limits for Convertible RIs? No, there are no exchange limits for Convertible RIs.', 'Q: Do I have the freedom to choose any instance type when I exchange my Convertible RIs? No, you can only exchange into Convertible RIs that are currently offered by AWS.'), ('Q: Can I upgrade the payment option associated with my Convertible RI? Yes, you can upgrade the payment option associated with your RI. For example, you can exchange your No Upfront RIs for Partial or All Upfront RIs to benefit from better pricing. You cannot change the payment option from All Upfront to No Upfront, and cannot change from Partial Upfront to No Upfront.', 'Q: Do Convertible RIs allow me to benefit from price reductions when they happen? Yes, you can exchange your RIs to benefit from lower pricing. For example, if the price of new Convertible\xa0RIs reduces by 10%, you can exchange your Convertible\xa0RIs and benefit from the 10% reduction in price. \xa0'), ('Q. What is the Reserved Instance Marketplace?', 'The Reserved Instance Marketplace is an online marketplace that provides AWS customers the flexibility to sell their Amazon Elastic Compute Cloud (Amazon EC2) Reserved Instances to other businesses and organizations. Customers can also browse the Reserved Instance Marketplace to find an even wider selection of Reserved Instance term lengths and pricing options sold by other AWS customers.'), ('Q. When can I list a Reserved Instance on the Reserved Instance Marketplace?', 'You can list a Reserved Instance when:'), ('Q. How will I register as a seller for the Reserved Instance Marketplace?', 'To register for the Reserved Instance Marketplace, you can enter the registration workflow by selling a Reserved Instance from the EC2 Management Console or setting up your profile from the "Account Settings" page on the AWS portal. No matter the route, you will need to complete the following steps:'), ('If you exceed $20,000 in sales of Reserved Instances, or plan to sell 50 or more Reserved Instances, you will need to provide tax information before you can list your Reserved Instances. Choose "Continue with Tax Interview". During the tax interview pipeline, you will be prompted to enter your company name, contact name, address, and Tax Identification Number using the TIMS workflow.\xa0', 'Additionally, if you plan to sell Reserved Instances worth more than $50,000 per year you will also need to file a limit increase.'), ('Q. How will I know when I can start selling on the Reserved Instance Marketplace?', 'You can start selling on the Reserved Instance Marketplace after you have added a bank account through the registration pipeline. Once activation is complete, you will receive a confirmation email. However, it is important to note that you will not be able to receive disbursements until we are able to receive verification from your bank, which may take up to two weeks, depending on the bank you use.'), ('Q. How do I list a Reserved Instance for sale?', 'To list a Reserved Instance, simply complete these steps in the Amazon EC2 Console:'), ('Q. Which Reserved Instances can I list for sale?', 'You can list any Reserved Instances that have been active for at least 30 days, and for which we have received payment. Typically, this means that you can list your reservations once they are in the active state. It is important to note that if you are an invoice customer, your Reserved Instance can be in the active state prior to AWS receiving payment. In this case, your Reserved Instance will not be listed until we have received your payment.'), ('Q. How are listed Reserved Instances displayed to buyers?', 'Reserved Instances (both third-party and those offered by AWS) that have been listed on the Reserved Instance Marketplace can be viewed in the "Reserved Instances" section of the Amazon EC2 Console. You can also use the DescribeReservedInstancesListings API call.'), ('The listed Reserved Instances are grouped based on the type, term remaining, upfront price, and hourly price. This makes it easier for buyers to find the right Reserved Instances to purchase.', 'Q. How much of my Reserved Instance term can I list?'), ('You can sell a Reserved Instance for the term remaining, rounded down to the nearest month. For example, if you had 9 months and 13 days remaining, you will list it for sale as a 9-month-term Reserved Instance.', 'Q. Can I remove my Reserved Instance after I’ve listed it for sale?'), ('Yes, you can remove your Reserved Instance listings at any point until a sale is pending (meaning a buyer has bought your Reserved Instance and confirmation of payment is pending).', 'Q. Which pricing dimensions can I set for the Reserved Instances I want to list?'), ('Using the Reserved Instance Marketplace, you can set an upfront price you’d be willing to accept. You cannot set the hourly price (which will remain the same as was set on the original Reserved Instance), and you will not receive any funds collected from payments associated with the hourly prices.', 'Q. Can I still use my reservation while it is listed on the Reserved Instance Marketplace?'), ('Yes, you will continue to receive the capacity and billing benefit of your reservation until it is sold. Once sold, any running instance that was being charged at the discounted rate will be charged at the On-Demand rate until and unless you purchase a new reservation, or terminate the instance.', 'Q. Can I resell a Reserved Instance that I purchased from the Reserved Instance Marketplace?'), ('Yes, you can resell Reserved Instances purchased from the Reserved Instance Marketplace just like any other Reserved Instance.', 'Q. Are there any restrictions when selling Reserved Instances?'), ('Yes, you must have a US bank account to sell Reserved Instances in the Reserved Instance Marketplace. Support for non-US bank accounts will be coming soon. Also, you may not sell Reserved Instances in the US GovCloud region.', 'Q. Can I sell Reserved Instances purchased from the public volume pricing tiers?'), ('No, this capability is not yet available.', 'Q. Is there a charge for selling Reserved Instances on the Reserved Instance Marketplace?'), ('Yes, AWS charges a service fee of 12% of the total upfront price of each Reserved Instance you sell in the Reserved Instance Marketplace.', 'Q. Can AWS sell subsets of my listed Reserved Instances?'), ('Yes, AWS may potentially sell a subset of the quantity of Reserved Instances that you have listed. For example, if you list 100 Reserved instances, we may only have a buyer interested in purchasing 50 of them. We will sell those 50 instances and continue to list your remaining 50 Reserved Instances until and unless you decide not to list them any longer.', "Q. How do buyers pay for Reserved Instances that they've purchased?"), ('Payment for completed Reserved Instance sales are done via ACH wire transfers to a US bank account.', 'Q. When will I receive my money?'), ('Once AWS has received funds from the customer that has bought your reservation, we will disburse funds via wire transfer to the bank account you specified when you registered for the Reserved Instance Marketplace.', 'Then, we will send you an email notification letting you know that we’ve wired you the funds. Typically, funds will appear in your account within 3-5 days of when your Reserved Instance was been sold.'), ('Q. If I sell my Reserved Instance in the Reserved Instance Marketplace, will I get refunded for the Premium Support I was charged too?', 'No, you will not receive a pro-rated refund for the upfront portion of the AWS Premium Support Fee.'), ('Q. Will I be notified about Reserved Instance Marketplace activities?', 'Yes, you will receive a single email once a day that details your Reserved Instance Marketplace activity whenever you create or cancel Reserved Instance listings, buyers purchase your listings, or AWS disburses funds to your bank account.'), ('Q. What information is exchanged between the buyer and seller to help with the transaction tax calculation?', 'The buyer’s city, state, zip+4, and country information will be provided to the seller via a disbursement report. This information will enable sellers to calculate any necessary transaction taxes they need to remit to the government (e.g., sales tax, value-added tax, etc.). The legal entity name of the seller will also be provided on the purchase invoice.'), ('Q. Are there any restrictions on the customers when purchasing third-party Reserved Instances?', 'Yes, you cannot purchase your own listed Reserved Instances, including those in any of your linked accounts (via Consolidated Billing).'), ('Q. Do I have to pay for Premium Support when purchasing Reserved Instances from the Reserved Instance Marketplace?', 'Yes, if you are a Premium Support customer, you will be charged for Premium Support when you purchase a Reserved Instance through the Reserved Instance Marketplace. '), ('Q. What is a Spot Instance?', 'Spot instances are spare EC2 capacity that can save you up 90% off of On-Demand prices that AWS can interrupt with a 2-minute notification. Spot uses the same underlying EC2 instances as On-Demand and Reserved Instances, and is best suited for fault-tolerant, flexible workloads. Spot instances provides an additional option for obtaining compute capacity and can be used along with On-Demand and Reserved Instances. '), ('Q. How is a Spot instance different than an On-Demand instance or Reserved Instance?', 'While running, Spot instances are exactly the same as On-Demand or Reserved instances. The main differences are that Spot instances typically offer a significant discount off the On-Demand prices, your instances can be interrupted by Amazon EC2 for capacity requirements with a 2-minute notification, and Spot prices adjust gradually based on long term supply and demand for spare EC2 capacity.  See here for more details on Spot instances. '), ('Q. How do I purchase and start up a Spot instance?', 'Spot instances can be launched using the same tools you use launch instances today, including AWS Management Console, Auto-Scaling Groups, Run Instances and Spot Fleet. In addition many AWS services support launching Spot instances such as EMR, ECS, Datapipeline, Cloudformation and Batch.  To start up a Spot instance, you simply need to choose a Launch Template and the number of instances you would like to request.  See here for more details on how to request Spot instances.'), ('Q. How many Spot instances can I request?', 'You can request Spot instances up to your Spot limit for each region. Note that customers new to AWS might start with a lower limit. To learn more about Spot instance limits, please refer to the Amazon EC2 User Guide.'), ('If you would like a higher limit, complete the Amazon EC2 instance request form with your use case and your instance increase will be considered. Limit increases are tied to the region they were requested for.', 'Q. What price will I pay for a Spot instance? '), ('You pay the Spot price that’s in effect at the beginning of each instance-hour for your running instance. If Spot price changes after you launch the instance, the new price is charged against the instance usage for the subsequent hour.', 'Q. What is a Spot capacity pool?'), ('A Spot capacity pool is a set of unused EC2 instances with the same instance type, operating system, Availability Zone, and network platform (EC2-Classic or EC2-VPC). Each spot capacity pool can have a different price based on supply and demand.', 'Q. What are the best practices to use Spot instances? '), ('We highly recommend using multiple Spot capacity pools to maximize the amount of Spot capacity available to you. EC2 provides built-in automation to find the most cost-effective capacity across multiple Spot capacity pools using Spot Fleet. For more information, please see Spot Best Practices.', 'Q. How can I determine the status of my Spot request?'), ('You can determine the status of your Spot request via Spot Request Status code and message. You can access Spot Request Status information on the Spot Instance page of the EC2 console of the AWS Management Console, API and CLI. For more information, please visit the\xa0Amazon EC2 Developer guide.', 'Q. Are Spot instances available for all instance families and sizes and in all regions?'), ('Spot instances are available in all public AWS regions. Spot is available for nearly all EC2 instance families and sizes, including the newest compute-optimized instances, accelerated graphics, FPGA and the new bare-metal instance types. A full list of instance types supported in each region are listed here. ', 'Q. Which operating systems are available as Spot instances?'), ('Linux/UNIX and Windows Server are available. Windows Server with SQL Server is not currently available.', 'Q. Can I use a Spot instance with a paid AMI for third-party software (such as IBM’s software packages)?'), ('Not at this time.', 'Q. When would my Spot instance get interrupted?'), ('Over the last 3 months, 92% of Spot instance interruptions were from a customer manually terminating the instance because the application had completed its work.', 'In the circumstance EC2 needs to reclaim your Spot instance it can be for two possible reasons, with the primary one being Amazon EC2 capacity requirements (e.g. On Demand or Reserved Instance usage). Secondarily, if you have chosen to set a “maximum Spot price” and the Spot price rises above this, your instance will be reclaimed with a two-minute notification. This parameter determines the maximum price you would be willing to pay for a Spot instance hour, and by default, is set at the On-Demand price. As before, you continue to pay the Spot market price, not your maximum price, at the time your instance was running, charged in per-second increments.'), ('Q. What happens to my Spot instance when it gets interrupted?', 'You can choose to have your Spot instances terminated, stopped or hibernated upon interruption. Stop and hibernate options are available for persistent Spot requests and Spot Fleets with the “maintain” option enabled. By default, your instances are terminated.'), ('Refer to Spot Hibernation to learn more about handling interruptions.', 'Q. What is the difference between Stop and Hibernate interruption behaviors?'), ('In the case of Hibernate, your instance gets hibernated and the RAM data persisted. In the case of Stop, your instance gets shutdown and RAM is cleared.  In both the cases, data from your EBS root volume and any attached EBS data volumes is persisted. Your private IP address remains the same, as does your elastic IP address (if applicable). The network layer behavior will be similar to that of EC2 Stop-Start workflow. Stop and Hibernate are available for Amazon EBS backed instances only. Local instance storage is not persisted. ', 'Q. What if my EBS root volume is not large enough to store memory state (RAM) for Hibernate?'), ('You should have sufficient space available on your EBS root volume to write data from memory. If the EBS root volume does not enough space, hibernation will fail and the instance will get shutdown instead. Ensure that your EBS volume is large enough to persist memory data before choosing the hibernate option.', 'Q. What is the benefit if Spot hibernates my instance on interruption?'), ('With hibernate, Spot instances will pause and resume around any interruptions so your workloads can pick up from exactly where they left off. You can use hibernation when your instance(s) need to retain instance state across shutdown-startup cycles, i.e. when your applications running on Spot depend on contextual, business, or session data stored in RAM.', 'Q. What do I need to do to enable hibernation for my Spot instances?'), ('Refer to Spot Hibernation to learn about enabling hibernation for your Spot instances. ', 'Q. Do I have to pay for hibernating my Spot instance?'), ('There is no additional charge for hibernating your instance beyond the EBS storage costs and any other EC2 resources you may be using. You are not charged instance usage fees once your instance is hibernated.', 'Q. Can I restart a stopped instance or resume a hibernated instance?'), ('No, you will not be able to re-start a stopped instance or resume a hibernated instance directly. Stop-start and hibernate-resume cycles are controlled by Amazon EC2. If an instance is stopped or hibernated by Spot, it will be restarted or resumed by Amazon EC2 when the capacity becomes available.', 'Q. Which instances and operating systems support hibernation?'), (' Spot Hibernation is currently supported for Amazon Linux AMIs, Ubuntu and Microsoft Windows operating systems running on any instance type across C3, C4, C5, M4, M5, R3, R4 instances with memory (RAM) size less than 100 GiB.', 'To review the list of supported OS versions, refer to Spot Hibernation.'), ('Q. How will I be charged if my Spot instance is interrupted?', 'If your Spot instance is terminated or stopped by Amazon EC2 in the first instance hour, you will not be charged for that usage. However, if you terminate the instance yourself, you will be charged to the nearest second. If the Spot instance is terminated or stopped by Amazon EC2 in any subsequent hour, you will be charged for your usage to the nearest second. If you are running on Windows and you terminate the instance yourself, you will be charged for an entire hour.'), ('Q. How am I charged if Spot price changes while my instance is running?\xa0', 'You will pay the price per instance-hour set at the beginning of each instance-hour for the entire hour, billed to the nearest second.'), ('Q. Where can I see my usage history for Spot instances and see how much I was billed?', 'The AWS Management Console makes a detailed billing report available which shows Spot instance start and termination/stop times for all instances. Customers can check the billing report against historical Spot prices via the API to verify that the Spot price they were billed is correct.   Q: Are Spot blocks (Fixed Duration Spot instances) ever interrupted?'), ('Spot blocks are designed not to be interrupted and will run continuously for the duration you select, independent of Spot market price. In rare situations, Spot blocks may be interrupted due to AWS capacity needs. In these cases, we will provide a two-minute warning before we terminate your instance (termination notice), and you will not be charged for the affected instance(s).', 'Q. What is a Spot fleet?'), ('A Spot Fleet allows you to automatically request and manage multiple Spot instances that provide the lowest price per unit of capacity for your cluster or application, like a batch processing job, a Hadoop workflow, or an HPC grid computing job. You can include the instance types that your application can use. You define a target capacity based on your application needs (in units including instances, vCPUs, memory, storage, or network throughput) and update the target capacity after the fleet is launched. Spot fleets enable you to launch and maintain the target capacity, and to automatically request resources to replace any that are disrupted or manually terminated.\xa0Learn more about Spot fleets. ', 'Q. Is there any additional charge for making Spot Fleet requests'), ('No, there is no additional charge for Spot Fleet requests.   Q. What limits apply to a Spot Fleet request?', 'Visit the Spot Fleet Limits section of the Amazon EC2 User Guide to learn about the limits that apply to your Spot Fleet request.   Q. What happens if my Spot Fleet request tries to launch Spot instances but exceeds my regional Spot request limit?'), ("If your Spot Fleet request exceeds your regional Spot instance request limit, individual Spot instance requests will fail with a Spot request limit exceeded request status. Your Spot Fleet request’s history will show any Spot request limit errors that the Fleet request received. Visit the Monitoring Your Spot Fleet section of the Amazon EC2 User Guide to learn how to describe your Spot Fleet request's history.   Q. Are Spot fleet requests guaranteed to be fulfilled?", 'No. Spot fleet requests allow you to place multiple Spot instance requests simultaneously, and are subject to the same availability and prices as a single Spot instance request. For example, if no resources are available for the instance types listed in your Spot Fleet request, we may be unable to fulfill your request partially or in full. We recommend you to include all the possible instance types and availability zones that are suitable for your workloads in the Spot Fleet.   Q. Can I submit a multi-Availability Zone Spot Fleet request?'), ('Yes, visit the Spot Fleet Examples section of the Amazon EC2 User Guide to learn how to submit a multi-Availability Zone Spot Fleet request.   Q. Can I submit a multi-region Spot Fleet request?', 'No, we do not support multi-region Fleet requests.  Q. How does Spot Fleet allocate resources across the various Spot instance pools specified in the launch specifications?'), ('The RequestSpotFleet API provides two allocation strategies: lowestPrice and diversified. The lowestPrice strategy allows you to provision your Spot Fleet resources in instance pools that provide the lowest price per unit of capacity at the time of the request. The diversified strategy allows you to provision your Spot Fleet resources across multiple Spot instance pools. This enables you to maintain your fleet’s target capacity and increase your application’s availability as Spot capacity fluctuates.', 'Running your application’s resources across diverse Spot instance pools also allows you to further reduce your fleet’s operating costs over time. Visit the Amazon EC2 User Guide to learn more.'), ('Q. Can I tag a Spot Fleet request?', 'You can request to launch Spot instances with tags via Spot Fleet. The Fleet by itself cannot be tagged.  Q. How can I see which Spot fleet owns my Spot instances?'), ('You can identify the Spot instances associated with your Spot Fleet by describing your fleet request. Fleet requests are available for 48 hours after all its Spot instances have been terminated. See the Amazon EC2 User Guide to learn how to describe your Spot Fleet request.  Q. Can I modify my Spot Fleet request?', 'Yes, you can modify the target capacity of your Spot Fleet request. You may need to cancel the request and submit a new one to change other request configuration parameters.  Q. Can I specify a different AMI for each instance type that I want to use?'), ('Yes, simply specify the AMI you’d like to use in each launch specification you provide in your Spot Fleet request.  Q. Can I use Spot Fleet with Elastic Load Balancing, Auto Scaling, or Elastic MapReduce?', 'You can use Auto Scaling features with Spot Fleet such as target tracking, health checks, cloudwatch metrics etc and can attach instances to your Elastic load balancers (both classic and application load balancers). Elastic MapReduce has a feature named “Instance fleets” that provides capabilities similar to Spot Fleet.  Q. Does a Spot Fleet request terminate Spot instances when they are no longer running in the lowest priced Spot pools and relaunch them in the lowest priced pools?'), ('No, Spot Fleet requests do not automatically terminate and re-launch instances while they are running. However, if you terminate a Spot instance, Spot Fleet will replenish it with a new Spot instance in the new lowest priced pool.  Q: Can I use stop or Hibernation interruption behaviors with Spot Fleet?', 'Yes, stop-start and hibernate-resume are supported with Spot Fleet with “maintain” fleet option enabled.'), ('\xa0', ''), ('', 'Q. How much compute power do Micro instances provide?'), ('Micro instances provide a small amount of consistent CPU resources and allow you to burst CPU capacity up to 2 ECUs when additional cycles are available. They are well suited for lower throughput applications and web sites that consume significant compute cycles periodically but very little CPU at other times for background processes, daemons, etc. Learn more about use of this instance type.', 'Q. How does a Micro instance compare in compute power to a Standard Small instance?'), ('At steady state, Micro instances receive a fraction of the compute resources that Small instances do. Therefore, if your application has compute-intensive or steady state needs we recommend using a Small instance (or larger, depending on your needs). However, Micro instances can periodically burst up to 2 ECUs (for short periods of time). This is double the number of ECUs available from a Standard Small instance. Therefore, if you have a relatively low throughput application or web site with an occasional need to consume significant compute cycles, we recommend using Micro instances.', 'Q. How can I tell if an application needs more CPU resources than a Micro instance is providing?'), ('The CloudWatch metric for CPU utilization will report 100% utilization if the instance bursts so much that it exceeds its available CPU resources during that CloudWatch monitored minute. CloudWatch reporting 100% CPU utilization is your signal that you should consider scaling – manually or via Auto Scaling – up to a larger instance type or scale out to multiple Micro instances.', 'Q. Are all features of Amazon EC2 available for Micro instances?'), ('Currently Amazon DevPay is not available for Micro instances. ', 'Q. When should I use Compute Optimized instances? '), ('Compute Optimized instances are designed for applications that benefit from high compute power. These applications include compute-intensive applications like high-performance web servers, high-performance computing (HPC), scientific modelling, distributed analytics and machine learning inference. ', 'Q. Can I launch C4 instances as Amazon EBS-optimized instances? '), ("Each C4 instance type is EBS-optimized by default. C4 instances 500 Mbps to 4,000 Mbps to EBS above and beyond the general-purpose network throughput provided to the instance. Since this feature is always enabled on C4 instances, launching a C4 instance explicitly as EBS-optimized will not affect the instance's behavior. ", 'Q. How can I use the processor state control feature available on the c4.8xlarge instance? '), ('The c4.8xlarge instance type provides the ability for an operating system to control processor C-states and P-states. This feature is currently available only on Linux instances. You may want to change C-state or P-state settings to increase processor performance consistency, reduce latency, or tune your instance for a specific workload. By default, Amazon Linux provides the highest-performance configuration that is optimal for most customer workloads; however, if your application would benefit from lower latency at the cost of higher single- or dual-core frequencies, or from lower-frequency sustained performance as opposed to bursty Turbo Boost frequencies, then you should consider experimenting with the C-state or P-state configuration options that are available to these instances. For additional information on this feature, see the Amazon EC2 User Guide section on Processor State Control. ', 'Q. Which instances are available within Compute Optimized instances category?'), ('C5 instances: C5 instances are the latest generation of EC2 Compute Optimized instances. C5 instances are based on Intel Xeon Platinum processors, part of the Intel Xeon Scalable (codenamed Skylake-SP) processor family, and are available in 6 sizes and offer up to 72 vCPUs and 144 GiB memory. C5 instances deliver 25% improvement in price/performance compared to C4 instances.', 'C4 instances: C4 instances are based on Intel Xeon E5-2666 v3 (codenamed Haswell) processors. C4 instances are available in 5 sizes and offer up to 36 vCPUs and 60 GiB memory.'), ('C3 instances: C3 instances are based on Intel Xeon E5-2680 v2 (codenamed Ivy Bridge) processors. C3 instances are available in 5 sizes and offer up to 32 vCPUs, 60 GiB memory and 640 GB of SSD storage.', 'Q. Should I move my workloads from C3 or C4 instances to C5 instances?'), ('The generational improvement in CPU performance and lower price of C5 instances, which combined result in a 25% price/performance improvement relative to C4 instances, benefit a broad spectrum of workloads that currently run on C3 or C4 instances. For floating point intensive applications, Intel AVX-512 enables significant improvements in delivered TFLOPS by effectively extracting data level parallelism. Customers looking for absolute performance for graphics rendering and HPC workloads that can be accelerated with GPUs or FPGAs should also evaluate other instance families in the Amazon EC2 portfolio that include those resources to find the ideal instance for their workload.', 'Q. Which operating systems/AMIs are supported on C5 Instances?'), ('EBS backed HVM AMIs with support for ENA networking and booting from NVMe-based storage can be used with C5 instances. The following AMIs are supported on C5:', 'Q. What are the storage options available to C5 customers?'), ('C5 instances use EBS volumes for storage, are EBS-optimized by default, and offer up to 9 Gbps throughput to both encrypted and unencrypted EBS volumes. C5 instances access EBS volumes via PCI attached NVM Express (NVMe) interfaces. NVMe is an efficient and scalable storage interface commonly used for flash based SSDs such as local NVMe storage provided with I3 instances. Though the NVMe interface may provide lower latency compared to Xen paravirtualized block devices, when used to access EBS volumes the volume type, size, and provisioned IOPS (if applicable) will determine the overall latency and throughput characteristics of the volume. When NVMe is used to provide EBS volumes, they are attached and detached by PCI hotplug.', 'Q. What network interface is supported on C5 instances?'), ('C5 instances use the Elastic Network Adapter (ENA) for networking and enable Enhanced Networking by default. With ENA, C5 instances can utilize up to 25 Gbps of network bandwidth.', 'Q. Which storage interface is supported on C5 instances?'), ('C5 instances will support only NVMe EBS device model. EBS volumes attached to C5 instances will appear as NVMe devices. NVMe is a modern storage interface that provides latency reduction and results in increased disk I/O and throughput.', 'Q. How many EBS volumes can be attached to C5 instances?'), ('C5 instances support a maximum for 27 EBS volumes for all Operating systems. The limit is shared with ENI attachments which can be found here http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html. For example: since every instance has at least 1 ENI, if you have 3 additional ENI attachments on the c4.2xlarge, you can attach 24 EBS volumes to that instance.', 'Q. What is the underlying hypervisor on C5 instances?'), ('C5 instances use a new EC2 hypervisor that is based on core KVM technology.', 'Q: Why does the total memory reported by Linux not match the advertised memory of the C5 instance type?'), ('In C5, portions of the total memory for an instance are reserved from use by the Operating System including areas used by the virtual BIOS for things like ACPI tables and for devices like the virtual video RAM.', 'Q: What are Accelerated Computing instances?'), ('Accelerated Computing instance family is a family of instances which use hardware accelerators, or co-processors, to perform some functions, such as floating-point number calculation and graphics processing, more efficiently than is possible in software running on CPUs. Amazon EC2 provides three types of Accelerated Computing instances –\xa0GPU compute instances for general-purpose computing, GPU graphics instances for graphics intensive applications, and FPGA programmable hardware compute instances for advanced scientific workloads.', 'Q. When should I use GPU Graphics and Compute instances?'), ('GPU instances work best for applications with massive parallelism such as workloads using thousands of threads. Graphics processing is an example with huge computational requirements, where each of the tasks is relatively small, the set of operations performed form a pipeline, and the throughput of this pipeline is more important than the latency of the individual operations. To be able build applications that exploit this level of parallelism, one needs GPU device specific knowledge by understanding how to program against various graphics APIs (DirectX, OpenGL) or GPU compute programming models (CUDA, OpenCL).', 'Q: How are P3 instances different from G3 instances?'), ('P3 instances are the next-generation of EC2 general-purpose GPU computing instances, powered by up to 8 of the latest-generation NVIDIA Tesla V100 GPUs. These new instances significantly improve performance and scalability, and add many new features, including new Streaming Multiprocessor (SM) architecture for machine learning (ML)/deep learning (DL) performance optimization, second-generation NVIDIA NVLink high-speed GPU interconnect, and highly tuned HBM2 memory for higher-efficiency.', 'G3 instances use NVIDIA Tesla M60 GPUs and provide a high-performance platform for graphics applications using DirectX or OpenGL. NVIDIA Tesla M60 GPUs support NVIDIA GRID Virtual Workstation features, and H.265 (HEVC) hardware encoding. Each M60 GPU in G3 instances supports 4 monitors with resolutions up to 4096x2160, and is licensed to use NVIDIA GRID Virtual Workstation for one Concurrent Connected User. Example applications of G3 instances include 3D visualizations, graphics-intensive remote workstation, 3D rendering, application streaming, video encoding, and other server-side graphics workloads.'), ('Q: What are the benefits of NVIDIA Volta GV100 GPUs?', 'The new NVIDIA Tesla V100 accelerator incorporates the powerful new Volta GV100 GPU. GV100 not only builds upon the advances of its predecessor, the Pascal GP100 GPU, it significantly improves performance and scalability, and adds many new features that improve programmability. These advances will supercharge HPC, data center, supercomputer, and deep learning systems and applications.'), ('Q: Who will benefit from P3 instances?', 'P3 instances with their high computational performance will benefit users in artificial intelligence (AI), machine learning (ML), deep learning (DL) and high performance computing (HPC) applications. Users includes data scientists, data architects, data analysts, scientific researchers, ML engineers, IT managers and software developers. Key industries include transportation, energy/oil & gas, financial services (banking, insurance), healthcare, pharmaceutical, sciences, IT, retail, manufacturing, high-tech, transportation, government, academia, among many others. '), ('Q: What are some key use cases of P3 instances?', 'P3 instance use GPUs to accelerate numerous deep learning systems and applications including autonomous vehicle platforms, speech, image, and text recognition systems, intelligent video analytics, molecular simulations, drug discovery, disease diagnosis, weather forecasting, big data analytics, financial modeling, robotics, factory automation, real-time language translation, online search optimizations, and personalized user recommendations, to name just a few. '), ('Q: Why should customers use GPU-powered Amazon P3 instances for AI/ML and HPC?', 'GPU-based compute instances provide greater throughput and performance because they are designed for massively parallel processing using thousands of specialized cores per GPU, versus CPUs offering sequential processing with a few cores. In addition, developers have built hundreds of GPU-optimized scientific HPC applications such as quantum chemistry, molecular dynamics, meteorology, among many others. Research indicates that over 70% of the most popular HPC applications provide built-in support for GPUs.'), ('Q: Will P3 instances support EC2 Classic networking and Amazon VPC?', 'P3 instances will support VPC only.'), ('Q. How are G3 instances different from P2 instances?', 'G3 instances use NVIDIA Tesla M60 GPUs and provide a high-performance platform for graphics applications using DirectX or OpenGL. NVIDIA Tesla M60 GPUs support NVIDIA GRID Virtual Workstation features, and H.265 (HEVC) hardware encoding. Each M60 GPU in G3 instances supports 4 monitors with resolutions up to 4096x2160, and is licensed to use NVIDIA GRID Virtual Workstation for one Concurrent Connected User. Example applications of G3 instances include 3D visualizations, graphics-intensive remote workstation, 3D rendering, application streaming, video encoding, and other server-side graphics workloads.'), ('P2 instances use NVIDIA Tesla K80 GPUs and are designed for general purpose GPU computing using the CUDA or OpenCL programming models. P2 instances provide customers with high bandwidth 25 Gbps networking, powerful single and double precision floating-point capabilities, and error-correcting code (ECC) memory, making them ideal for deep learning, high performance databases, computational fluid dynamics, computational finance, seismic analysis, molecular modeling, genomics, rendering, and other server-side GPU compute workloads.', 'Q: How are P3 instances different from G2 instances?'), ('P3 Instances are the next-generation of EC2 general-purpose GPU computing instances, powered by up to 8 of the latest-generation NVIDIA Volta GV100 GPUs. These new instances significantly improve performance and scalability and add many new features, including new Streaming Multiprocessor (SM) architecture, optimized for machine learning (ML)/deep learning (DL) performance, second-generation NVIDIA NVLink high-speed GPU interconnect, and highly tuned HBM2 memory for higher-efficiency.', 'P2 instances use NVIDIA Tesla K80 GPUs and are designed for general purpose GPU computing using the CUDA or OpenCL programming models. P2 instances provide customers with high bandwidth 25 Gbps networking, powerful single and double precision floating-point capabilities, and error-correcting code (ECC) memory.'), ('Q. What APIs and programming models are supported by GPU\xa0Graphics and Compute instances?', 'P3 instances support\xa0CUDA 9 and OpenCL, P2 instances support CUDA 8 and OpenCL 1.2 and G3 instances support DirectX 12, OpenGL 4.5, CUDA 8, and OpenCL 1.2.'), ('Q. Where do I get NVIDIA drivers for P3 and G3 instances?', 'There are two methods by which NVIDIA drivers may be obtained. There are listings on the AWS Marketplace\xa0which\xa0offer Amazon Linux AMIs and Windows Server AMIs with the NVIDIA drivers pre-installed. You may also launch 64-bit, HVM AMIs and install the drivers yourself. You must visit the NVIDIA driver website and search for the NVIDIA Tesla V100 for P3, NVIDIA Tesla K80 for P2, and NVIDIA Tesla M60 for G3 instances.'), ('Q. Which AMIs can I use with P3, P2 and G3 instances?', 'You can currently use Windows Server, SUSE Enterprise Linux, Ubuntu, and Amazon Linux AMIs on P2 and G3 instances. P3 instances only support HVM AMIs. If you want to launch AMIs with operating systems not listed here, contact AWS Customer Support with your request or reach out through EC2 Forums.'), ('Q. Does the use of G2 and G3 instances require third-party licenses?', 'Aside from the NVIDIA drivers and GRID SDK, the use of G2 and G3 instances does not necessarily require any third-party licenses. However, you are responsible for determining whether your content or technology used on G2 and G3 instances requires any additional licensing. For example, if you are streaming content you may need licenses for some or all of that content. If you are using third-party technology such as operating systems, audio and/or video encoders, and decoders from Microsoft, Thomson, Fraunhofer IIS, Sisvel S.p.A., MPEG-LA, and Coding Technologies, please consult these providers to determine if a license is required. For example, if you leverage the on-board h.264 video encoder on the NVIDIA GRID GPU you should reach out to MPEG-LA for guidance, and if you use mp3 technology you should contact Thomson for guidance.'), ('Q. Why am I not getting NVIDIA GRID features on G3 instances using the driver downloaded from NVIDIA website?', 'The NVIDIA Tesla M60 GPU used in G3 instances requires a special NVIDIA GRID driver to enable all advanced graphics features, and 4 monitors support with resolution up to 4096x2160. You need to use an AMI with NVIDIA GRID driver pre-installed, or download and install the NVIDIA GRID driver following the AWS documentation.'), ('Q. Why am I unable to see the GPU when using Microsoft Remote Desktop?', 'When using Remote Desktop, GPUs using the WDDM driver model are replaced with a non-accelerated Remote Desktop display driver. In order to access your GPU hardware, you need to utilize a different remote access tool, such as VNC.'), ('Q. What is Amazon EC2 F1?', 'Amazon EC2 F1 is a compute instance with programmable hardware you can use for application acceleration. The new F1 instance type provides a high performance, easy to access FPGA for developing and deploying custom hardware accelerations.'), ('Q. What are FPGAs and why do I need them?', 'FPGAs are programmable integrated circuits that you can configure using software. By using FPGAs you can accelerate your applications up to 30x when compared with servers that use CPUs alone. And, FPGAs are reprogrammable, so you get the flexibility to update and optimize your hardware acceleration without having to redesign the hardware.'), ('Q. How does F1 compare with traditional FPGA solutions?', 'F1 is an AWS instance with programmable hardware for application acceleration. With F1, you have access to FPGA hardware in a few simple clicks, reducing the time and cost of full-cycle FPGA development and scale deployment from months or years to days. While FPGA technology has been available for decades, adoption of application acceleration has struggled to be successful in both the development of accelerators and the business model of selling custom hardware for traditional enterprises, due to time and cost in development infrastructure, hardware design, and at-scale deployment. With this offering, customers avoid the undifferentiated heavy lifting associated with developing FPGAs in on-premises data centers.'), ('Q: What is an Amazon FPGA Image (AFI)?', 'The design that you create to program your FPGA is called an Amazon FPGA Image (AFI). AWS provides a service to register, manage, copy, query, and delete AFIs. After an AFI is created, it can be loaded on a running F1 instance. You can load multiple AFIs to the same F1 instance, and can switch between AFIs in runtime without reboot. This lets you quickly test and run multiple hardware accelerations in rapid sequence. You can also offer to other customers on the AWS Marketplace a combination of your FPGA acceleration and an AMI with custom software or AFI drivers.'), ('Q. How do I list my hardware acceleration on the AWS Marketplace?', 'You would develop your AFI and the software drivers/tools to use this AFI. You would then package these software tools/drivers into an Amazon Machine Image (AMI) in an encrypted format. AWS manages all AFIs in the encrypted format you provide to maintain the security of your code. To sell a product in the AWS Marketplace, you or your company must sign up to be an AWS Marketplace reseller, you would then submit your AMI ID and the AFI ID(s) intended to be packaged in a single product. AWS Marketplace will take care of cloning the AMI and AFI(s) to create a product, and associate a product code to these artifacts, such that any end-user subscribing to this product code would have access to this AMI and the AFI(s).'), ('Q. What is available with F1 instances?', 'For developers, AWS is providing a Hardware Development Kit (HDK) to help accelerate development cycles, a FPGA Developer AMI for development in the cloud, an SDK for AMIs running the F1 instance, and a set of APIs to register, manage, copy, query, and delete AFIs. Both developers and customers have access to the AWS Marketplace where AFIs can be listed and purchased for use in application accelerations.'), ('Q. Do I need to be a FPGA expert to use an F1 instance?', 'AWS customers subscribing to a F1-optimized AMI from AWS Marketplace do not need to know anything about FPGAs to take advantage of the accelerations provided by the F1 instance and the AWS Marketplace. Simply subscribe to an F1-optimized AMI from the AWS Marketplace with an acceleration that matches the workload. The AMI contains all the software necessary for using the FPGA acceleration. Customers need only write software to the specific API for that accelerator and start using the accelerator.'), ('Q. I’m a FPGA developer, how do I get started with F1 instances?', 'Developers can get started on the F1 instance by creating an AWS account and downloading the AWS Hardware Development Kit (HDK). The HDK includes documentation on F1, internal FPGA interfaces, and compiler scripts for generating AFI. Developers can start writing their FPGA code to the documented interfaces included in the HDK to create their acceleration function. Developers can launch AWS instances with the FPGA Developer AMI. This AMI includes the development tools needed to compile and simulate the FPGA code. The Developer AMI is best run on the latest C5, M5, or R4 instances. Developers should have experience in the programming languages used for creating FPGA code (i.e. Verilog or VHDL) and an understanding of the operation they wish to accelerate.'), ('Q. I’m not an FPGA developer, how do I get started with F1 instances?', 'Customers can get started with F1 instances by selecting an accelerator from the AWS Marketplace, provided by AWS Marketplace sellers, and launching an F1 instance with that AMI. The AMI includes all of the software and APIs for that accelerator. AWS manages programming the FPGA with the AFI for that accelerator. Customers do not need any FPGA experience or knowledge to use these accelerators. They can work completely at the software API level for that accelerator.'), ('Q. Does AWS provide a developer kit?', 'Yes. The Hardware Development Kit (HDK) includes simulation tools and simulation models for developers to simulate, debug, build, and register their acceleration code. The HDK includes code samples, compile scripts, debug interfaces, and many other tools you will need to develop the FPGA code for your F1 instances. You can use the HDK either in an AWS provided AMI, or in your on-premises development environment. These models and scripts are available publically with an AWS account.'), ('Q. Can I use the HDK in my on-premises development environment?', 'Yes. You can use the Hardware Development Kit HDK either in an AWS-provided AMI, or in your on-premises development environment.'), ('Q. Can I add an FPGA to any EC2 instance type?', 'No. F1 instances comes in two instance sizes f1.2xlarge and f1.16 xlarge.\xa0'), ('', 'Q. What is a Cluster Compute Instance?'), ('Cluster Compute Instances combine high compute resources with a high performance networking for High Performance Compute (HPC) applications and other demanding network-bound applications. Cluster Compute Instances provide similar functionality to other Amazon EC2 instances but have been specifically engineered to provide high performance networking.', 'Amazon EC2 cluster placement group functionality allows users to group Cluster Compute Instances in clusters – allowing applications to get the low-latency network performance necessary for tightly-coupled node-to-node communication typical of many HPC applications. Cluster Compute Instances also provide significantly increased network throughput both within the Amazon EC2 environment and to the Internet. As a result, these instances are also well suited for customer applications that need to perform network-intensive operations.'), ('Learn more about use of this instance type for HPC applications.', 'Q. What kind of network performance can I expect when I launch instances in cluster placement group?'), ('The bandwidth an EC2 instance can utilize in a cluster placement group depends on the instance type and its networking performance specification. When launched in a placement group, select EC2 instances can utilize up to 10 Gbps for single-flow and 25 Gbps for multi-flow traffic in each direction (full duplex). Network traffic outside a cluster placement group (e.g. to the Internet) is limited to 5 Gbps (full duplex).', 'Q. What is a Cluster GPU Instance?'), ('Cluster GPU Instances provide general-purpose graphics processing units (GPUs) with proportionally high CPU and increased network performance for applications benefiting from highly parallelized processing that can be accelerated by GPUs using the CUDA and OpenCL programming models. Common applications include modeling and simulation, rendering and media processing.', 'Cluster GPU Instances give customers with HPC workloads an option beyond Cluster Compute Instances to further customize their high performance clusters in the cloud for applications that can benefit from the parallel computing power of GPUs.'), ('Cluster GPU Instances use the same cluster placement group functionality as Cluster Compute Instances for grouping instances into clusters – allowing applications to get the low-latency, high bandwidth network performance required for tightly-coupled node-to-node communication typical of many HPC applications.', 'Learn more about HPC on AWS.'), ('Q. What is a High Memory Cluster Instance?', 'High Memory Cluster Instances provide customers with large amounts of memory and CPU capabilities per instance in addition to high network capabilities. These instance types are ideal for memory intensive workloads including in-memory analytics systems, graph analysis and many science and engineering applications'), ('High Memory Cluster Instances use the same cluster placement group functionality as Cluster Compute Instances for grouping instances into clusters – allowing applications to get the low-latency, high bandwidth network performance required for tightly-coupled node-to-node communication typical of many HPC and other network intensive applications.', 'Q. Does use of Cluster Compute and Cluster GPU Instances differ from other Amazon EC2 instance types?'), ('Cluster Compute and Cluster GPU Instances use differs from other Amazon EC2 instance types in two ways.', 'First, Cluster Compute and Cluster GPU Instances use Hardware Virtual Machine (HVM) based virtualization and run only Amazon Machine Images (AMIs) based on HVM virtualization. Paravirtual Machine (PVM) based AMIs used with other Amazon EC2 instance types cannot be used with Cluster Compute or Cluster GPU Instances.'), ('Second, in order to fully benefit from the available low latency, full bisection bandwidth between instances, Cluster Compute and Cluster GPU Instances must be launched into a cluster placement group through the Amazon EC2 API or AWS Management Console.', 'Q. What is a cluster placement group?'), ('A cluster placement group is a logical entity that enables creating a cluster of instances by launching instances as part of a group. The cluster of instances then provides low latency, full bisection 25 Gigabit Ethernet bandwidth connectivity between instances in the group. Cluster placement groups are created through the Amazon EC2 API or AWS Management Console.', 'Q. Are all features of Amazon EC2 available for Cluster Compute and Cluster GPU Instances?'), ('Currently, Amazon DevPay is not available for Cluster Compute or Cluster GPU Instances.', 'Q. Is there a limit on the number of Cluster Compute or Cluster GPU Instances I can use and/or the size of cluster I can create by launching Cluster Compute Instances or Cluster GPU into a cluster placement group? '), ('There is no limit specific for Cluster Compute Instances. For Cluster GPU Instances, you can launch 2 Instances on your own. If you need more capacity, please complete the Amazon EC2 instance request form (selecting the appropriate primary instance type).', 'Q. Are there any ways to optimize the likelihood that I receive the full number of instances I request for my cluster via a cluster placement group?'), ('We recommend that you launch the minimum number of instances required to participate in a cluster in a single launch. For very large clusters, you should launch multiple placement groups, e.g. two placement groups of 128 instances, and combine them to create a larger, 256 instance cluster.', 'Q. Can Cluster GPU and Cluster Compute Instances be launched into a single cluster placement group?'), ('While it may be possible to launch different cluster instance types into a single placement group, at this time we only support homogenous placement groups.', 'Q. If an instance in a cluster placement group is stopped then started again, will it maintain its presence in the cluster placement group?'), ('Yes. A stopped instance will be started as part of the cluster placement group it was in when it stopped. If capacity is not available for it to start within its cluster placement group, the start will fail. ', ''), ('Q. What is a High I/O instance?', 'High I/O instances use NVMe based local instance storage to deliver very high, low latency, I/O capacity to applications, and are optimized for applications that require millions of IOPS. Like Cluster instances, High I/O instances can be clustered via cluster placement groups for high bandwidth networking. '), ('Q. Are all features of Amazon EC2 available for High I/O instances?', 'High I/O instance support all Amazon EC2 features. I3 instances offer NVMe only storage, while previous generation I2 instances allow legacy blkfront storage access. Currently you can only purchase High I/O instances as On-Demand, Reserved Instances or as Spot instances. '), ('Q. Is there a limit on the number of High I/O instances I can use?', 'Currently, you can launch 2 i3.16xlarge instances by default. If you wish to run more than 2 On-Demand instances, please complete the Amazon EC2 instance request form.'), ('Q. How many IOPS can i3.16.xlarge instances deliver?', 'Using HVM AMIs, High I/O I3 instances can deliver up to 3.3 million IOPS measured at 100% random reads using 4KB block size, and up to 300,000 100% random write IOPs, measured at 4KB block sizes to applications across 8 x 1.9 TB NVMe devices.\xa0'), ('Q. What is the sequential throughput of i3 instances?', 'The maximum sequential throughput, measured at 128K block sizes is 16 GB/s read throughput and 6.4 GB/s write throughput.'), ('Q. AWS has other database and Big Data offerings. When or why should I use High I/O instances?', 'High I/O instances are ideal for applications that require access to millions of low latency IOPS, and can leverage data stores and architectures that manage data redundancy and availability. Example applications are: '), ('Q. Do High I/O instances provide any failover mechanisms or redundancy?', 'Like other Amazon EC2 instance types, instance storage on i3.16xlarge instances persists during the life of the instance. Customers are expected to build resilience into their applications. We recommend using databases and file systems that support redundancy and fault tolerance. Customers should back up data periodically to Amazon S3 for improved data durability. '), ('Q. Do High I/O instances support TRIM?', 'The TRIM command allows the operating system to inform SSDs which blocks of data are no longer considered in use and can be wiped internally. In the absence of TRIM, future write operations to the involved blocks can slow down significantly. I3 instances support TRIM. '), ('Q: What are the key use cases for Amazon EC2 M5 Instances?', 'M5 instances offer a good choice for running development and test environments, web, mobile and gaming applications, analytics applications, and business critical applications including ERP, HR, CRM, and collaboration apps. Customers who are interested in running their data intensive workloads (e.g. HPC, or SOLR clusters) on instances with a higher memory footprint will also find M5 to be a good fit. Workloads that heavily use single and double precision floating point operations and vector processing such as video processing workloads and need higher memory can benefit substantially from the AVX-512 instructions that M5 supports.'), ('Q: Why should customers choose EC2 M5 Instances over EC2 M4 Instances?', 'Compared with EC2 M4 Instances, the new EC2 M5 Instances deliver customers greater compute and storage performance, larger instance sizes for less cost, consistency and security. The biggest benefit of EC2 M5 Instances is based on its usage of the latest generation of Intel Xeon Scalable processors (aka Skylake), which deliver up to 14% improvement in price/performance compared to M4. With AVX-512 support in M5 vs. the older AVX2 in M4, customers will gain 2x higher performance in workloads requiring floating point operations. M5 instances offer up to 25 Gbps of network bandwidth and up to 10 Gbps of dedicated bandwidth to Amazon EBS. M5 instances also feature significantly higher networking and Amazon EBS performance on smaller instance sizes with EBS burst capability.'), ('Q: How does support for Intel AVX-512 benefit EC2 M5 Instance customers?', 'Intel Advanced Vector Extension 512 (AVX-512) is a set of new CPU instructions available on the latest Intel Xeon Scalable processor family, that can accelerate performance for workloads and usages such as scientific simulations, financial analytics, artificial intelligence, machine learning/deep learning, 3D modeling and analysis, image and video processing, cryptography and data compression, among others. Intel AVX-512 offers exceptional processing of encryption algorithms, helping to reduce the performance overhead for cryptography, which means EC2 M5 customers can deploy more secure data and services into distributed environments without compromising performance'), ('Q: What are the various storage options available to M5 customers?', 'M5 instances leverage EBS volumes for storage. There is currently no local storage option for M5 instances.'), ('Q: Which network interface is supported on M5 instances?', 'M5 instances support only ENA based Enhanced Networking. M5 instances will not support netback. With ENA, M5 instances can deliver up to 25 Gbps of network bandwidth between instances when launched within a Placement Group.'), ('Q. Which operating systems/AMIs are supported on M5 Instances?', 'EBS backed HVM AMIs with support for ENA networking and booting from NVMe-based storage can be used with M5 instances. The following AMIs are supported on M5:'), ('Q. What are the storage options available to M5 customers?', 'M5 instances use EBS volumes for storage, are EBS-optimized by default, and offer up to 10 Gbps throughput to both encrypted and unencrypted EBS volumes. M5 instances access EBS volumes via PCI attached NVM Express (NVMe) interfaces. NVMe is an efficient and scalable storage interface commonly used for flash based SSDs such as local NVMe storage provided with I3 instances. Though the NVMe interface may provide lower latency compared to Xen paravirtualized block devices, when used to access EBS volumes the volume type, size, and provisioned IOPS (if applicable) will determine the overall latency and throughput characteristics of the volume. When NVMe is used to provide EBS volumes, they are attached and detached by PCI hotplug.'), ('Q. How many EBS volumes can be attached to M5 instances?', 'M5 instances support a maximum for 27 EBS volumes for all Operating systems. The limit is shared with ENI attachments which can be found here http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html. For example: since every instance has at least 1 ENI, if you have 3 additional ENI attachments on the m4.2xlarge, you can attach 24 EBS volumes to that instance.'), ('Q. What is the underlying hypervisor on M5 instances?', 'M5 instances use a new lightweight Nitro Hypervisor that is based on core KVM technology.'), ('Q: Why does the total memory reported by Linux not match the advertised memory of the M5 instance type?', 'In M5, portions of the total memory for an instance are reserved from use by the operating system including areas used by the virtual BIOS for things like ACPI tables and for devices like the virtual video RAM.'), ('Q: How are Burstable Performance Instances different?', 'Amazon EC2 allows you to choose between Fixed Performance Instances (e.g. C, M and R instance families) and Burstable Performance Instances (e.g. T2). Burstable Performance Instances provide a baseline level of CPU performance with the ability to burst above the baseline.'), ('T2 instances’ baseline performance and ability to burst are governed by CPU Credits. Each T2 instance receives CPU Credits continuously, the rate of which depends on the instance size. T2 instances accrue CPU Credits when they are idle, and consume CPU credits when they are active. A CPU Credit provides the performance of a full CPU core for one minute.', '* For the t2.medium, single threaded applications can use 40% of 1 core, or if needed, multithreaded applications can use 20% each of 2 cores. '), ('**For the t2.large, single threaded applications can use 60% of 1 core, or if needed, multithreaded applications can use 30% each of 2 cores.', '*** For the t2.xlarge, single threaded applications can use 90% of 1 core, or if needed, multithreaded applications can use 45% each of 2 cores or 22.5% of all 4 cores.'), ('**** For the t2.large, single threaded applications can use all of 1 core, or if needed, multithreaded applications can use 67.5% each of 2 cores or 16.875% of all 8 cores.\xa0', 'Q. How do I choose the right Amazon Machine Image (AMI) for my T2 instances?'), ('You will want to verify that the minimum memory requirements of your operating system and applications are within the memory allocated for each T2 instance size (e.g. 512 MiB for t2.nano). Operating systems with Graphical User Interfaces (GUI) that consume significant memory and CPU, for example Microsoft Windows, might need a t2.micro or larger instance size for many use cases. You can find AMIs suitable for the t2.nano instance types on AWS Marketplace. Windows customers who do not need the GUI can use the Microsoft Windows Server 2012 R2 Core AMI.', 'Q: When should I choose a Burstable Performance Instance, such as T2?'), ('T2 instances provide a cost-effective platform for a broad range of general purpose production workloads. T2 Unlimited instances can sustain high CPU performance for as long as required. If your workloads consistently require CPU usage much higher than the baseline, consider a dedicated CPU instance family such as the M or C.', 'Q: How can I see the CPU Credit balance for each T2 instance?'), ('You can see the CPU Credit balance for each T2 instance in EC2 per-Instance metrics in Amazon CloudWatch. T2 instances have four metrics, CPUCreditUsage, CPUCreditBalance, CPUSurplusCreditBalance and CPUSurplusCreditsCharged. CPUCreditUsage indicates the amount of CPU Credits used. CPUCreditBalance indicates the balance of CPU Credits. CPUSurplusCredit Balance indicates credits used for bursting in the absence of earned credits. CPUSurplusCreditsCharged indicates credits that are charged when average usage exceeds the baseline.', 'Q: What happens to CPU performance if my T2 instance is running low on credits (CPU Credit balance is near zero)?'), ('If your T2 instance has a zero CPU Credit balance, performance will remain at baseline CPU performance. For example, the t2.micro provides baseline CPU performance of 10% of a physical CPU core. If your instance’s CPU Credit balance is approaching zero, CPU performance will be lowered to baseline performance over a 15-minute interval.', 'Q: Does my T2 instance credit balance persist at stop / start?'), ('No, a stopped instance does not retain its previously earned credit balance.', 'Q: Can T2 instances be purchased as Reserved Instances or Spot Instances? '), ('T2 instances can be purchased as On-Demand Instances, Reserved Instances or Spot Instances.', 'Q. What is a Dense-storage Instance?'), ('Dense-storage instances are designed for workloads that require high sequential read and write access to very large data sets, such as Hadoop distributed computing, massively parallel processing data warehousing, and log processing applications. The Dense-storage instances offer the best price/GB-storage and price/disk-throughput across other EC2 instances.', 'Q.\xa0How do Dense-storage and HDD-storage instances compare to High I/O instances?\xa0'), ('High I/O instances (I2) are targeted at workloads that demand low latency and high random I/O in addition to moderate storage density and provide the best price/IOPS across other EC2 instance types. Dense-storage instances (D2) and HDD-storage instances (H1) are optimized for applications that require high sequential read/write access and low cost storage for very large data sets and provide the best price/GB-storage and price/disk-throughput across other EC2 instances.', 'Q. How much disk throughput can Dense-storage and HDD-storage instances deliver? '), ('The largest current generation of Dense-storage instances, d2.8xlarge, can deliver up to 3.5 GBps read and 3.1 GBps write disk throughput with a 2 MiB block size. The largest H1 instances size, h1.16xlarge, can deliver up to 1.15 GBps read and write. To ensure the best disk throughput performance from your D2 instances on Linux, we recommend that you use the most recent version of the Amazon Linux AMI, or another Linux AMI with a kernel version of 3.8 or later that supports persistent grants - an extension to the Xen block ring protocol that significantly improves disk throughput and scalability. ', 'Q. Do Dense-storage and HDD-storage instances provide any failover mechanisms or redundancy? '), ('The primary data storage for Dense-storage instances is HDD-based instance storage. Like all instance storage, these storage volumes persist only for the life of the instance. Hence, we recommend that you build a degree of redundancy (e.g. RAID 1/5/6) or use file systems (e.g. HDFS and MapR-FS) that support redundancy and fault tolerance. You can also back up data periodically to more durable data storage solutions such as Amazon Simple Storage Service (S3) for additional data durability. Please refer to Amazon S3 for reference.', 'Q. How do Dense-storage and HDD-storage instances differ from Amazon EBS?'), ('Amazon EBS offers simple, elastic, reliable (replicated), and persistent block level storage for Amazon EC2 while abstracting the details of the underlying storage media in use. Amazon EC2 instance storage provides directly attached non-persistent, high performance storage building blocks that can be used for a variety of storage applications. Dense-storage instances are specifically targeted at customers who want high sequential read/write access to large data sets on local storage, e.g. for Hadoop distributed computing and massively parallel processing data warehousing.', 'Q. Can I launch H1 instances as Amazon EBS-optimized instances?'), ("Each H1 instance type is EBS-optimized by default. H1 instances offer 1,750 Mbps to 14,000 Mbps to EBS above and beyond the general-purpose network throughput provided to the instance. Since this feature is always enabled on H1 instances, launching a H1 instance explicitly as EBS-optimized will not affect the instance's behavior. ", 'Q. Can I launch D2 instances as Amazon EBS-optimized instances?'), ("Each D2 instance type is EBS-optimized by default. D2 instances 500 Mbps to 4,000 Mbps to EBS above and beyond the general-purpose network throughput provided to the instance. Since this feature is always enabled on D2 instances, launching a D2 instance explicitly as EBS-optimized will not affect the instance's behavior.", 'Q. Are HDD-storage instances offered in EC2 Classic?'), ("The current generation of HDD-storage instances (H1 instances) can only be launched in Amazon VPC. With Amazon VPC, you can leverage a number of features that are available only on the Amazon VPC platform – such as enabling enhanced networking, assigning multiple private IP addresses to your instances, or changing your instances' security groups. For more information about the benefits of using a VPC, see Amazon EC2 and Amazon Virtual Private Cloud (Amazon VPC).", 'Q. Are Dense-storage instances offered in EC2 Classic? '), ("The current generation of Dense-storage instances (D2 instances) can be launched in both EC2-Classic and Amazon VPC. However, by launching a Dense-storage instance into a VPC, you can leverage a number of features that are available only on the Amazon VPC platform – such as enabling enhanced networking, assigning multiple private IP addresses to your instances, or changing your instances' security groups. For more information about the benefits of using a VPC, see Amazon EC2 and Amazon Virtual Private Cloud (Amazon VPC). You can take steps to migrate your resources from EC2-Classic to Amazon VPC. For more information, see Migrating a Linux Instance from EC2-Classic to a VPC.", 'Q. When should I use Memory-optimized instances?'), ('Memory-optimized instances offer large memory size for memory intensive applications including in-memory applications, in-memory databases, in-memory analytics solutions, High Performance Computing (HPC), scientific computing, and other memory-intensive applications.', 'Q. When should I use X1 instances?'), ('X1 instances are ideal for running in-memory databases like SAP HANA, big data processing engines like Apache Spark or Presto, and high performance computing (HPC) applications. X1 instances are certified by SAP to run production environments of the next-generation Business Suite S/4HANA, Business Suite on HANA (SoH), Business Warehouse on HANA (BW), and Data Mart Solutions on HANA on the AWS cloud.', 'Q. When should I use X1e instances?'), ('X1e instances are ideal for running in-memory databases like SAP HANA, high-performance databases and other memory optimized enterprise applications. X1e instances offer twice the memory per vCPU compared to the X1 instances. The x1e.32xlarge instance is certified by SAP to run production environments of the next-generation Business Suite S/4HANA, Business Suite on HANA (SoH), Business Warehouse on HANA (BW), and Data Mart Solutions on HANA on the AWS Cloud.', 'Q. How do X1 and X1e instances differ?'), ('X1e instances offer 32GB of memory per vCPU whereas X1 instances offer 16GB of memory per vCPU. X1e instance sizes enable six instance configurations starting from 4 vCPUs and 122 GiB memory up to 128 vCPUs and 3,904 GiB of memory. X1 instances enable two instance configurations, 64 vCPUs with 976 GiB memory and 128 vCPUs with 1,952 GiB memory.', 'Q. What are the key specifications of Intel E7 (codenamed Haswell) processors that power X1 and X1e instances?'), ('The E7 processors have a high core count to support workloads that scale efficiently on large number of cores. The Intel E7 processors also feature high memory bandwidth and larger L3 caches to boost the performance of in-memory applications. In addition, the Intel E7 processor:', 'Q. Do X1 and X1e instances enable CPU power management state control'), ('Yes. You can configure C-states and P-states on x1e.32xlarge, x1e.16xlarge, x1e.8xlarge, x1.32xlarge and x1.16xlarge instances. You can use C-states to enable higher turbo frequencies (as much as 3.1 GHz with one or two core turbo). You can also use P-states to lower performance variability by pinning all cores at P1 or higher P states, which is similar to disabling Turbo, and running consistently at the base CPU clock speed.', 'Q: What operating systems are supported on X1 and X1e instances?'), ('X1 and X1e instances provide high number of vCPUs, which might cause launch issues in some Linux operating systems that have a lower vCPU limit. We strongly recommend that you use the latest AMIs when you launch these instances.\xa0', 'AMI support for SAP HANA workloads include: SUSE Linux 12, SUSE Linux 12 SP1, SLES for SAP 12 SP1, SLES for SAP 12 SP2, and RHEL 7.2 for SAP HANA.\xa0'), ('x1e.32xlarge will also support Windows Server 2012 R2 and 2012 RTM.\xa0 x1e.xlarge, x1e.2xlarge, x1e.4xlarge, x1e.8xlarge, x1e.16xlarge and x1.32xlarge will also support Windows Server 2012 R2, 2012 RTM and 2008 R2 64bit (Windows Server 2008 SP2 and older versions will not be supported) and x1.16xlarge will support Windows Server 2012 R2, 2012 RTM, 2008 R2 64bit, 2008 SP2 64bit, and 2003 R2 64bit (Windows Server 32bit versions will not be supported).', 'Q. What storage options are available for X1 customers?'), ('X1 instances offer SSD based instance store, which is ideal for temporary storage of information such as logs, buffers, caches, temporary tables, temporary computational data, and other temporary content. X1 instance store provides the best I/O performance when you use a Linux kernel that supports persistent grants, an extension to the Xen block ring protocol.', 'X1 instances are EBS-optimized by default and offer up to 14 Gbps of dedicated bandwidth to EBS volumes. EBS offers multiple volume types to support a wide variety of workloads. For more information see the EC2 User Guide.'), ('Q: What storage options are available for X1e customers?', 'X1e instances offer SSD based instance store, which is ideal for temporary storage of information such as logs, buffers, caches, temporary tables, temporary computational data, and other temporary content. X1e instance store provides the best I/O performance when you use a Linux kernel that supports persistent grants, an extension to the Xen block ring protocol.'), ('X1e instances enable dedicated throughput to Amazon Elastic Block Storage (EBS) starting from 500 Mbps (x1e.xlarge) up to 14 Gbps (x1e.32xlarge) and are EBS-optimized by default at no additional cost. For more information see the EC2 User Guide.', 'Q. How do I build cost-effective failover solution on X1 and X1e instances?'), ('You can design simple and cost-effective failover solutions on X1 instances using Amazon EC2 Auto Recovery, an Amazon EC2 feature that is designed to better manage failover upon instance impairment. You can enable Auto Recovery for X1 instances by creating an AWS CloudWatch alarm. Choose the “EC2 Status Check Failed (System)” metric and select the “Recover this instance” action. Instance recovery is subject to underlying limitations, including those reflected in the Instance Recovery Troubleshooting documentation. For more information visit Auto Recovery documentation and Creating Amazon CloudWatch Alarms respectively.', 'Q. Are there standard SAP HANA reference deployment frameworks available for the X1 instance and the AWS Cloud?'), ('You can use the AWS Quick Start reference HANA deployments to rapidly deploy all the necessary HANA building blocks on X1 instances following SAP’s recommendations for high performance and reliability. AWS Quick Starts are modular and customizable, so you can layer additional functionality on top or modify them for your own implementations. For additional information on deploying HANA on AWS, please refer to SAP HANA on AWS Cloud: Quick Start Reference Deployment Guide.', 'Q. Are there standard SAP HANA reference deployment frameworks available for the X1e instance and the AWS Cloud?'), ('You can use the AWS Quick Start reference HANA deployments to rapidly deploy all the necessary HANA building blocks on x1e.32xlarge instance following SAP’s recommendations for high performance and reliability. AWS Quick Starts are modular and customizable, so you can layer additional functionality on top or modify them for your own implementations. For additional information on deploying HANA on AWS, please refer to SAP HANA on AWS Cloud: Quick Start Reference Deployment Guide.', 'Q: Why don’t I see M1, C1, CC2, CG1 and HS1 instances on the pricing pages any more?'), ('These have been moved to the Previous Generation Instance page.', 'Q: Are these Previous Generation instances still being supported? '), ('Yes. Previous Generation instances are still fully supported.', 'Q: Can I still use/add more Previous Generation instances?'), ('Yes. Previous Generation instances are still available as On-Demand, Reserved Instances, and Spot Instance, from our APIs, CLI and EC2 Management Console interface.', 'Q: Are my Previous Generation instances going to be deleted?'), ('No. Your M1, C1, CC2, CG1 and HS1 instances are still fully functional and will not be deleted because of this change.', 'Q: Are Previous Generation instances being discontinued soon? '), ('Currently, there are no plans to end of life Previous Generation instances. However, with any rapidly evolving technology the latest generation will typically provide the best performance for the price and we encourage our customers to take advantage of technological advancements.', 'Q: Will my Previous Generation instances I purchased as a Reserved Instance be affected or changed? '), ('No. Your Reserved Instances will not change, and the Previous Generation instances are not going away.', 'Q. What is VM Import/Export?'), ('VM Import/Export enables customers to import Virtual Machine (VM) images in order to create Amazon EC2 instances. Customers can also export previously imported EC2 instances to create VMs. Customers can use VM Import/Export to leverage their previous investments in building VMs by migrating their VMs to Amazon EC2.', 'Q. What operating systems are supported?'), ('VM Import/Export currently supports Windows and Linux VMs, including Windows Server 2003, Windows Server 2003 R2, Windows Server 2008, Windows Server 2012 R1, Red Hat Enterprise Linux (RHEL) 5.1-6.5 (using Cloud Access), Centos 5.1-6.5, Ubuntu 12.04, 12.10, 13.04, 13.10, and Debian 6.0.0-6.0.8, 7.0.0-7.2.0. For more details on VM Import, including supported file formats, architectures, and operating system configurations, please see the VM Import/Export section of the\xa0Amazon EC2 User Guide.', 'Q. What virtual machine file formats are supported?'), ('You can import VMware ESX VMDK images, Citrix Xen VHD images, Microsoft Hyper-V VHD images and RAW images as Amazon EC2 instances. You can export EC2 instances to VMware ESX VMDK, VMware ESX OVA, Microsoft Hyper-V VHD or Citrix Xen VHD images. For a full list of support operating systems, please see What operating systems are supported?.', 'Q. What is VMDK?'), ('VMDK is a file format that specifies a virtual machine hard disk encapsulated within a single file. It is typically used by virtual IT infrastructures such as those sold by VMware, Inc.', 'Q. How do I prepare a VMDK file for import using the VMware vSphere client?'), ('The VMDK file can be prepared by calling File-Export-Export to OVF template in VMware vSphere Client. The resulting VMDK file is compressed to reduce the image size and is compatible with VM Import/Export. No special preparation is required if you are using the Amazon EC2 VM Import Connector vApp for VMware vCenter.', 'Q. What is VHD?'), ('VHD (Virtual Hard Disk) is a file format that that specifies a virtual machine hard disk encapsulated within a single file. The VHD image format is used by virtualization platforms such as Microsoft Hyper-V and Citrix Xen.', 'Q. How do I prepare a VHD file for import from Citrix Xen?'), ('Open Citrix XenCenter and select the virtual machine you want to export. Under the Tools menu, choose "Virtual Appliance Tools" and select "Export Appliance" to initiate the export task. When the export completes, you can locate the VHD image file in the destination directory you specified in the export dialog.', 'Q. How do I prepare a VHD file for import from Microsoft Hyper-V?'), ('Open the Hyper-V Manager and select the virtual machine you want to export. In the Actions pane for the virtual machine, select "Export" to initiate the export task. Once the export completes, you can locate the VHD image file in the destination directory you specified in the export dialog.', 'Q. Are there any other requirements when importing a VM into Amazon EC2?'), ('The virtual machine must be in a stopped state before generating the VMDK or VHD image. The VM cannot be in a paused or suspended state. We suggest that you export the virtual machine with only the boot volume attached. You can import additional disks using the ImportVolume command and attach them to the virtual machine using AttachVolume. Additionally, encrypted disks (e.g. Bit Locker) and encrypted image files are not supported. You are also responsible for ensuring that you have all necessary rights and licenses to import into AWS and run any software included in your VM image.', 'Q. Does the virtual machine need to be configured in any particular manner to enable import to Amazon EC2?'), ('Ensure Remote Desktop (RDP) or Secure Shell (SSH) is enabled for remote access and verify that your host firewall (Windows firewall, iptables, or similar), if configured, allows access to RDP or SSH. Otherwise, you will not be able to access your instance after the import is complete. Please also ensure that Windows VMs are configured to use strong passwords for all users including the administrator and that Linux VMs and configured with a public key for SSH access.', 'Q. How do I import a virtual machine to an Amazon EC2 instance?'), ('You can import your VM images using the Amazon EC2 API tools:', 'Alternatively, if you use the VMware vSphere virtualization platform, you can import your virtual machine to Amazon EC2 using a graphical user interface provided through AWS Management Portal for vCenter. Please refer to Getting Started Guide in AWS Management Portal for vCenter. AWS Management Portal for vCenter includes integrated support for VM Import. Once the portal is installed within vCenter, you can right-click on a VM and select “Migrate to EC2” to create an EC2 instance from the VM. The portal will handle exporting the VM from vCenter, uploading it to S3, and converting it into an EC2 instance for you, with no additional work required. You can also track the progress of your VM migrations within the portal.'), ('Q. How do I export an Amazon EC2 instance back to my on-premise virtualization environment?', 'You can export your Amazon EC2 instance using the Amazon EC2 CLI tools:'), ('Q. Are there any other requirements when exporting an EC2 instance using VM Import/Export?', 'You can export running or stopped EC2 instances that you previously imported using VM Import/Export. If the instance is running, it will be momentarily stopped to snapshot the boot volume. EBS data volumes cannot be exported. EC2 instances with more than one network interface cannot be exported.'), ('Q. Can I export Amazon EC2 instances that have one or more EBS data volumes attached?', 'Yes, but VM Import/Export will only export the boot volume of the EC2 instance.'), ('Q. What does it cost to import a virtual machine?', 'You will be charged standard Amazon S3 data transfer and storage fees for uploading and storing your VM image file. Once your VM is imported, standard Amazon EC2 instance hour and EBS service fees apply. If you no longer wish to store your VM image file in S3 after the import process completes, use the ec2-delete-disk-image command line tool to delete your disk image from Amazon S3.'), ('Q. What does it cost to export a virtual machine?', 'You will be charged standard Amazon S3 storage fees for storing your exported VM image file. You will also be charged standard S3 data transfer charges when you download the exported VM file to your on-premise virtualization environment. Finally, you will be charged standard EBS charges for storing a temporary snapshot of your EC2 instance. To minimize storage charges, delete the VM image file in S3 after downloading it to your virtualization environment.'), ('Q. When I import a VM of Windows Server 2003 or 2008, who is responsible for supplying the operating system license?', 'When you launch an imported VM using Microsoft Windows Server 2003 or 2008, you will be charged standard instance hour rates for Amazon EC2 running the appropriate Windows Server version, which includes the right to utilize that operating system within Amazon EC2. You are responsible for ensuring that all other installed software is properly licensed.'), ('So then, what happens to my on-premise Microsoft Windows license key when I import a VM of Windows Server 2003 or 2008? Since your on-premise Microsoft Windows license key that was associated with that VM is not used when running your imported VM as an EC2 instance, you can reuse it for another VM within your on-premise environment.', 'Q. Can I continue to use the AWS-provided Microsoft Windows license key after exporting an EC2 instance back to my on-premise virtualization environment?'), ('No. After an EC2 instance has been exported, the license key utilized in the EC2 instance is no longer available. You will need to reactivate and specify a new license key for the exported VM after it is launched in your on-premise virtualization platform.', 'Q. When I import a VM with Red Hat Enterprise Linux (RHEL), who is responsible for supplying the operating system license?'), ('When you import Red Hat Enterprise Linux (RHEL) VM images, you can use license portability for your RHEL instances. With license portability, you are responsible for maintaining the RHEL licenses for imported instances, which you can do using Cloud Access subscriptions for Red Hat Enterprise Linux. Please contact Red Hat to learn more about Cloud Access and to verify your eligibility.', 'Q. How long does it take to import a virtual machine?'), ('The length of time to import a virtual machine depends on the size of the disk image and your network connection speed. As an example, a 10 GB Windows Server 2008 SP2 VMDK image takes approximately 2 hours to import when it’s transferred over a 10 Mbps network connection. If you have a slower network connection or a large disk to upload, your import may take significantly longer.', 'Q. In which Amazon EC2 regions can I use VM Import/Export?'), ('Visit the Region Table page to see product service availability by region. ', 'Q. How many simultaneous import or export tasks can I have?'), ('Each account can have up to five active import tasks and five export tasks per region.', 'Q. Can I run imported virtual machines in Amazon Virtual Private Cloud (VPC)?'), ('Yes, you can launch imported virtual machines within Amazon VPC.', 'Q. Can I use the AWS Management Console with VM Import/Export?'), ('No. VM Import/Export commands are available via EC2 CLI and API. You can also use the AWS Management Portal for vCenter to import VMs into Amazon EC2. Once imported, the resulting instances are available for use via the AWS Management Console.', ''), ('Q. Can I use my existing Windows Server license with EC2?', 'Yes you can. After you’ve imported your own Windows Server machine images using the ImportImage tool, you can launch instances from these machine images on EC2 Dedicated Hosts and effectively manage instances and report usage. Microsoft typically requires that you track usage of your licenses against physical resources such as sockets and cores and Dedicated Hosts helps you to do this. Visit the Dedicated Hosts detail page for more information on how to use your own Windows Server licenses on Amazon EC2 Dedicated Hosts. '), ('Q. What software licenses can I bring to the Windows environment?', 'Specific software license terms vary from vendor to vendor. Therefore, we recommend that you check the licensing terms of your software vendor to determine if your existing licenses are authorized for use in Amazon EC2. '), ('Q. How am I billed for my use of Amazon EC2 running IBM?', 'You pay only for what you use and there is no minimum fee. Pricing is per instance-hour consumed for each instance type. Partial instance-hours consumed are billed as full hours. Data transfer for Amazon EC2 running IBM is billed and tiered separately from Amazon EC2. There is no Data Transfer charge between two Amazon Web Services within the same region (i.e. between Amazon EC2 US West and another AWS service in the US West). Data transferred between AWS services in different regions will be charged as Internet Data Transfer on both sides of the transfer.  For Amazon EC2 running IBM pricing information, please visit the pricing section on the Amazon EC2 running IBM detail page.'), ('Q. Can I use Amazon DevPay with Amazon EC2 running IBM?', 'No, you cannot use DevPay to bundle products on top of Amazon EC2 running IBM at this time. '), (' Q. How do I use this service?', 'The service provides an NTP endpoint at a link-local IP address (169.254.169.123) accessible from any instance running in a VPC. Instructions for configuring NTP clients are available for Linux and Windows.'), (' Q. What are the key benefits of using this service?', ' A consistent and accurate reference time source is crucial for many applications and services. The Amazon Time Sync Service provides a time reference that can be securely accessed from an instance without requiring VPC configuration changes and updates. It is built on Amazon’s proven network infrastructure and uses redundant reference time sources to ensure high accuracy and availability.'), (' Q. Which instance types are supported for this service?', 'All instances running in a VPC can access the service.  '), ('Q. What does your Amazon EC2 Service Level Agreement guarantee?', 'Our SLA guarantees a Monthly Uptime Percentage of at least 99.99% for Amazon EC2 and Amazon EBS within a Region.'), ('Q. How do I know if I qualify for a SLA Service Credit?', 'You are eligible for a SLA credit for either Amazon EC2 or Amazon EBS (whichever was Unavailable, or both if both were Unavailable) if the Region that you are operating in has an Monthly Uptime Percentage of less than 99.95% during any monthly billing cycle. For full details on all of the terms and conditions of the SLA, as well as details on how to submit a claim, please see http://aws.amazon.com/ec2/sla/ '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/windows/faq/': [("The use of Microsoft software is subject to Microsoft's terms. You are responsible for complying with Microsoft licensing. This document is only a guide for your convenience and you are not entitled to rely on its descriptions and it does not constitute legal advice. If you have questions about your licensing or rights to Microsoft software, please consult your legal team, Microsoft, or your Microsoft reseller. This page was last updated on March 30, 2017 and is up to date with current Microsoft Product Terms.", 'What is the relationship between Microsoft and Amazon Web Services?'), ('Is Microsoft software supported on AWS?', 'Does AWS Support open a support case with Microsoft on my behalf if I have a problem?'), ('How does AWS work with Microsoft to resolve customer issues?', 'What types of Microsoft software can I run on AWS?  '), ('What are my licensing options for Microsoft software on Amazon EC2?', 'What is BYOL?'), ('What is License Mobility?', 'How do I know if a specific Microsoft product is eligible for License Mobility?'), ('Do I need to pay for Software Assurance and License Mobility to use my Microsoft licenses in AWS?', "If I bring my own license, can I relicense AWS's Microsoft media or do I need to bring in my own media (a.k.a. “bits”)?"), ('After I import my Microsoft media, do I need to activate my media against my own key management server (KMS)?', 'How do I know what type of offering to use if I’m bringing my own license?'), ('How do I import my own licensed machine image into AWS?', "I’ve read in my licensing terms that certain licenses must be used on infrastructure that's dedicated for my use. How does Amazon EC2 allow me to meet this requirement if I’m using my own licenses?"), ('I’ve read in my licensing terms that a license cannot move to another region or physical machine for at least 90 days. How does Amazon EC2 help me meet this requirement if I’m using my own licenses?', 'When can I bring my own license using EC2 instances with default tenancy?'), ('What is VM Import/Export?', "What is EC2's default tenancy?"), ('What is dedicated infrastructure?', 'What are Amazon EC2 Dedicated Hosts?'), ('What are Amazon EC2 Dedicated Instances?', "What's the difference between Dedicated Hosts and Dedicated Instances?"), ('Does AWS recommend an EC2 purchasing option if I’m looking to use my own licenses? ', 'What are my options for bringing development licenses to AWS?'), ('\xa0', 'Can I buy Windows Server from AWS?'), ('Can I bring my own Windows Server licenses and use them in EC2?', 'What are Amazon EC2 Dedicated Hosts?'), ('Do Microsoft licensing terms allow software without license mobility benefits or active Software Assurance to be deployed on Dedicated Hosts or Dedicated Instances? How can I confirm this?\xa0', 'How do I import and use my own Windows Server license?'), ("How do I track usage if I'm bringing my own licenses?", 'Do I need to have Software Assurance on Windows Server on AWS?'), ('Does License Mobility work with Windows Server?', 'How can I use my own Windows Server license on EC2 instances with default tenancy?'), ('What is included when I buy Windows Server instances from AWS?', 'Can I relicense license-included, EC2 Windows Server instances to use my own licenses, pointing at my own KMS server?  '), ('Can I buy SQL Server from AWS?', 'Can I bring in my own SQL Server licenses for use on AWS?'), ('Can I use License Mobility with SQL Server?', 'Do I have to pay for failover SQL Servers for disaster recovery?'), ('How do I know how many SQL Server licenses to bring in?', 'What are the use cases for SQL Server Web Edition?'), ('How do I determine the right core factor to license with?', "How do I track usage if I'm bringing my own licenses? "), ('Can SQL Server Developer be used on AWS?', ' Are SQL CALS required on AWS?'), (' \xa0', 'Can I bring Microsoft Developer Network (MSDN) licenses to AWS?'), ('Can I buy MSDN from AWS?', 'Can I use MSDN on AWS instances with a default tenancy?'), ('Can I use by existing MSDN licenses on dedicated infrastructure?', 'Does License Mobility work with MSDN?  '), ('Can I buy Windows Client from AWS?', 'Can I bring in my own Windows Client licenses for use on AWS?'), ('Can I use License Mobility with Windows Client?  ', 'Can I bring in my own Office licenses for use on AWS?'), ('Can I use License Mobility with Microsoft Office?  ', 'Can I buy other Microsoft products from AWS?'), ('Can I bring in my own licenses for use on AWS?', 'Can I use License Mobility?'), ('How can I obtain additional Remote Desktop Services licenses?', '\xa0'), ('Can I use my own Service Provider License Agreement (SPLA)?', 'What are Self Hosting rights?'), ('Can Microsoft BizSpark licenses be used on AWS?  ', 'How frequently does AWS patch Windows AMIs? '), ('What happens with previously published AMIs? ', "How do I know I'm launching the latest AWS published AMI?  "), ('What’s new in Windows Server 2016?', 'How is AWS supporting Windows Server 2016?'), ('Can you elaborate on some of the differences between Windows Server 2016 and Nano Server?', 'How is the EC2 Console experience different for Nano Server?'), ('Can I create my own images from Windows Server 2016 and Nano Server instances?', 'Are there any other significant changes regarding Windows Server 2016 AMIs?'), ('How can I run Windows containers?', 'Now that there’s a Windows 2016 with Containers AMI, are there plans for Amazon EC2 Container Service (ECS) to support Windows containers?'), ('What will it cost to run Windows Server 2016?', 'Which EC2 instance types work best with Windows Server 2016?'), ('Can I bring my own license (BYOL) for Windows Server 2016?', 'How can I upgrade my Windows Server instance to Windows Server 2016?'), ('What AWS regions support Windows Server 2016?\xa0', 'What editions of Windows Server 2012 R2 are available in AMIs? '), ('Will it cost more to run Windows Server 2012 R2? ', 'Which AWS regions are supported? '), ('Which Amazon EC2 instance types are supported? ', 'What languages are available? '), ('How do I deploy my applications running Windows Server 2012 R2 to AWS? ', 'Which SQL Server version/edition and languages are available with Windows Server 2012 R2 AMIs? '), ('Windows Server 2012 R2 has two file systems: NTFS and ReFS. Which one should I use? ', 'Can I create a Storage Space using an EBS volume? '), ('How do I switch to the new Windows Server Start screen? ', 'On previously published Windows Server AMIs I followed the steps as documented here to enable enhanced networking. Do I still need to do this for Windows Server 2012 R2 AMIs?  '), ('On what date will Microsoft end extended support for Windows Server 2003?', 'Can I run my existing Windows Server 2003 instances after the end of extended support?'), ('Can I launch new Windows Server 2003 instances after the end of extended support?', 'Will I be able to create and launch instances from custom Windows Server 2003 AMIs after the end of extended support?'), ('Will I be able to publicly access Windows Server 2003 AMIs from the AWS Console and AWS Marketplace?', 'Will AWS support Microsoft Windows Server 2003 after July 14, 2015?'), ('Will I be able to import new Windows Server 2003 virtual machines after the end of extended support?', 'Will Amazon EC2 continue to provide updated Windows Server 2003 and Windows Server 2003 R2 AMIs?'), ('Can I build custom AMIs that contain updates provided by Microsoft through a custom support agreement?', 'Will AWS support Microsoft applications, such as Microsoft SQL Server 2005, running on Windows Server 2003 after the end of extended support?'), ('Does AWS support in-place operating system upgrades for my Windows Server 2003 instances?', 'Will my scripted references to existing Windows Server 2003 AMIs continue to work after the end of extended support?'), ('How can I keep up-to-date with Windows Server 2003 security related information?  ', ''), ('Does AWS offer SharePoint instances? ', 'How can I run SharePoint on AWS?'), ('What is Microsoft License Mobility?', 'What if I do not have Software Assurance on the Licenses?'), ('How do SharePoint licenses on AWS work?', 'How do I use an SQL Instance with SharePoint on AWS?  '), ('What is the AWS Management Pack for Microsoft System Center? ', 'Which AWS resources can I monitor using the AWS Management Pack? '), ('Which versions of System Center Operations Manager can I use?', 'Can I monitor AWS resources that are in different AWS regions? '), ('Can I monitor AWS resources that are in Amazon Virtual Private Cloud (VPC)? ', 'Can I monitor AWS resources from multiple AWS accounts? '), ('Can I monitor applications running within Amazon EC2 instances? ', 'Can I use IAM credentials instead of AWS root account credentials to monitor AWS resources? '), ('Can I use my on-premises Operations Manager for the AWS Management Pack? ', 'Where can I find more information about the AWS Management Pack? '), ('Can I use my existing System Center Licenses?  ', 'What is AWS Systems Manager for Microsoft System Center Virtual Machine Manager?'), ('What can I do with Systems Manager for SCVMM?', 'Which versions of SCVMM can be used with Systems Manager for SCVMM?'), ('Where do I download Systems Manager for SCVMM?', 'How much does Systems Manager for SCVMM cost?'), ('How is this different from the AWS Management Pack for Microsoft System Center?  ', 'What is the AWS Diagnostics for Microsoft Windows Server? '), ('When should I use this tool? ', 'What data will be collected? '), ('What are some of the analysis rules? ', 'How much does the AWS Diagnostics for Microsoft Windows Server cost? '), ('My EC2 Windows Server just crashed. Can I use this tool to collect log files from the EBS boot volume for that instance? ', 'Where can I find more information about the AWS Diagnostic Tool for Microsoft Windows Server?  '), ('Will customers have to recreate their environment using other technologies in order to receive support from AWS or Microsoft?', 'Is AWS SVVP Validated?'), ('Without SVVP Validation, are Microsoft products fully supported in the AWS environment? ', 'Back to top'), ('What is the relationship between Microsoft and Amazon Web Services?', 'Amazon Web Services and Microsoft have worked together for many years, starting with AWS launching Windows Server based instances in 2008. AWS is a Gold Certified member of the Microsoft Partner Network and licensed to sell Microsoft software under the Services Provider License Agreement (SPLA). AWS is also an authorized license mobility partner. Over the years, AWS and Microsoft have collaborated to make Windows and its associated workloads available in the AWS cloud. Microsoft and AWS have mutual customers running Windows workloads on AWS today, including Dole Foods, Hess Corporation, and Lionsgate. In addition, AWS has released Microsoft-specific technologies that allow users to manage and optimize Windows applications in AWS – such as AWS tools for Windows PowerShell, AWS Management Pack for Microsoft System Center, and AWS Diagnostics for Microsoft Windows Server. '), (' Is Microsoft software supported on AWS?', 'AWS supports Microsoft software running on AWS. AWS customers have successfully deployed every Microsoft application available in the AWS cloud, including (but not limited to) Microsoft Office, Windows Server, SQL Server, Exchange, SharePoint, Skype for Business, Dynamics, and Remote Desktop Services.'), ('AWS is a member of the Microsoft Partner Network, licensed to resell Microsoft software via the SPLA, and a Microsoft Gold Certified Hosting Partner. AWS is an authorized license mobility partner. AWS also has an active Premier Support agreement with Microsoft.  ', 'Does AWS open a support case with Microsoft on my behalf when I have a problem?'), ('Customer issues with AWS services should be submitted to AWS. \xa0Issues with Microsoft applications running on an AWS instance should be submitted to Microsoft support. \xa0AWS Support does not submit support cases to Microsoft on behalf of AWS customers with individual customer issues. \xa0In some cases AWS will engage with the customer and Microsoft on open Microsoft support tickets to help drive resolution.', 'How does AWS work with Microsoft to resolve customer issues?'), ('If you have an existing Microsoft Support agreement, you can contact Microsoft Support directly, under that agreement. Also, if Microsoft determines that they need to perform infrastructure level debugging, you or Microsoft Support can contact AWS Support to help resolve the issue.', ' What types of Microsoft software can I run on AWS?'), ('You can run many types of Microsoft software on AWS, including but not limited to Microsoft Office, Windows Server, SQL Server, Exchange, SharePoint, Lync, Skype for Business, Microsoft Dynamics products, System Center, BizTalk, and Remote Desktop Services. You can pay for Windows Server and SQL Server licenses directly from AWS to run on Amazon EC2 or Amazon RDS instances. AWS customers have the flexibility of bringing on-premises Microsoft volume licenses and deploying them on Amazon EC2 or Amazon RDS instances.\xa0Licenses that are eligible for license mobility and covered by active Software Assurance can be deployed on AWS multi-tenant environments.\xa0Licenses that are not eligible for license mobility or that do not have active Software Assurance can be deployed on Amazon EC2 Dedicated Hosts or Amazon EC2 Dedicated Instances.', 'Back to top'), ('What are my licensing options for Microsoft software on Amazon EC2?', 'On Amazon EC2, you can choose to run instances that include the relevant license fees in their cost (“license included”) or to utilize license you have already purchased from Microsoft. For Microsoft software, EC2 allows you to pay for instances that include Windows Server and SQL Server licenses. For all other Microsoft software, customers can bring their own license, subject to Microsoft’s terms.  '), ('What is BYOL?', 'BYOL, or “bring your own license,” is the process you can use to deploy software that you’ve previously licensed on physically dedicated AWS hardware. If you BYOL, you do not pay for instances with licensing included in the cost. Instead you pay the same rate as EC2 instances with Amazon Linux pricing. When you BYOL, you are responsible for managing your own licenses, but Amazon EC2 has features that help you maintain license compliance throughout the lifecycle of your licenses, such as Instance Affinity and targeted placement available through Amazon EC2 Dedicated Hosts.  '), ('\xa0', 'What is License Mobility?'), ('License Mobility is a benefit available to Microsoft Volume Licensing customers with eligible server applications covered by active Microsoft Software Assurance (SA). License Mobility allows customers to move eligible Microsoft software to third party cloud providers such as AWS for use on EC2 instances with default tenancy. It is important to note that you may not need license mobility if you are using your own licenses on EC2 Dedicated Hosts or EC2 Dedicated Instances For additional details, see the Microsoft License Mobility page on the AWS site.  ', 'How do I know if a specific Microsoft product is eligible for License Mobility?'), ('This information is included in the Microsoft Product Terms. Each product has an individual Software Assurance section that indicates License Mobility eligibility. ', '\xa0'), ('Do I need to pay for Software Assurance and License Mobility to use my Microsoft licenses in AWS?', 'No, if you are bringing your own licenses into EC2 Dedicated Hosts or EC2 Dedicated Instances then Software Assurance is not required subject to Microsoft’s terms. If you are moving licensed software onto EC2 instances with a default tenancy, Software Assurance is required. You need to have Software Assurance in order to participate in License Mobility.  '), ('\xa0', "If I bring my own license, can I relicense AWS's Microsoft media or do I need to bring in my own media (a.k.a. “bring your own bits”)?"), ('No, you must import and license your own media. To get started, you can use the ImportImage\xa0API (from AWS CLI or AWS Tool for Windows PowerShell) to import your own media (VHD, VMDK, OVA). If you are importing from VMware vCenter, you can also use AWS Server Migration Service. After the media has been imported, you will see your images in the “My AMIs” console, or you can describe these images using the DescribeImages API.  ', 'After I import my Microsoft media, do I need to activate my media against my own key management server (KMS)?'), ('Yes, when you launch an instance of your own image, your OS will prompt you to activate the image against your KMS.  ', '\xa0'), ('How do I know what type of offering to use if I’m bringing my own license?', 'Please read your licensing terms and conditions and select the AWS model that meets your needs. Generally speaking, there are various products and each have differing levels of BYOL support:'), ('Under your agreements with Microsoft, you may have a special case to use your licenses in a way that is different than described in the BYOL Licensing Scenario table. If your agreements permit a special case where you have additional rights to use your licenses, please contact your account manager or AWS customer support. For additional questions about Microsoft licensing terms contact Microsoft or your Microsoft reseller.  ', 'How do I import my own licensed machine image into AWS?'), ('In order to BYOL of Microsoft software into AWS, you need to use the ImportImage tool made available by the EC2 VM Import/Export service. Do not use the ImportInstance tool as it does not support Microsoft BYOL scenarios.  ', "I've read in my licensing terms that certain licenses must be used on infrastructure that’s dedicated for my use. How does Amazon EC2 allow me to meet this requirement if I’m using my own licenses?"), ('Amazon EC2 offers two purchasing options that provide you with dedicated infrastructure: Dedicated Hosts and Dedicated Instances. It is important to note that all BYOL scenarios are supported through the use of Dedicated Hosts, while only certain scenarios are supported by Dedicated Instances. Also, if you bring existing licenses to Dedicated Hosts or Dedicated Instances, then you are using hardware that is fully dedicated to your use and the outsourcing language within the Microsoft Product Terms applies.', 'For BYOL license scenarios that are server bound (e.g., Windows Server, SQL Server) and require you to license against the number of sockets or physical cores on a dedicated server, you should use Dedicated Hosts.'), ('For licensing scenarios that are VM, CAL, or user bound and do not require you to license against the number of sockets or physical cores on a dedicated server but require you to run on dedicated infrastructure (e.g., Windows Desktop, SQL Server, Remote Desktop Services, Microsoft Office, and MSDN) you can use Dedicated Instances.', 'For more information on Dedicated Hosts, visit the Dedicated Hosts detail page.'), ('For more information on Dedicated Instances, visit the Dedicated Instances detail page.  ', "I've read in my licensing terms that a license cannot move to another region or physical machine for at least 90 days. How does Amazon EC2 help me meet this requirement if I’m using my own licenses?"), ('Instance Affinity (only available through the use of Amazon EC2 Dedicated Hosts) and Dedicated Host targeting helps you to monitor this requirement. When you enable Affinity between an instance and a Dedicated Host, that particular instance will only run on a specific Dedicated Host. Using Dedicated Host targeting, you can launch instances onto a specific Dedicated Host, giving you full control over how your licenses are used. For more information on these features, visit the Dedicated Hosts detail page.  ', 'When can I bring my own license using EC2 instances with default tenancy?'), ('License Mobility through Software Assurance allows customers to bring eligible Microsoft software licenses into AWS for use on EC2 instances with default tenancy. The AWS License Mobility Page is a great place to start the process. If you are planning to take advantage of License Mobility in AWS, you will need to fill out the appropriate License Mobility forms. With License Mobility, you can use these images on EC2 Windows Server license-included instances running on EC2 instances with default tenancy. Windows Server licenses must be purchased from AWS in this scenario.  ', 'What is VM Import/Export?'), ('VM Import/Export enables you to easily import virtual machine images from your existing environment to Amazon EC2 instances. This service allows you to leverage your existing investments in the virtual machines that you have built to meet your IT security, configuration management, and compliance requirements by bringing those virtual machines into Amazon EC2 as ready-to-use instances. If you are planning to use your own Microsoft licenses, use the ImportImage tool made available by the VM Import/Export service to import your own Microsoft media.', 'The VM Import/Export service is available at no additional charge beyond standard usage charges for Amazon EC2 and Amazon S3.  '), ("What is EC2's default tenancy?", 'EC2 Dedicated instances and EC2 Dedicated Hosts provide instance capacity on physical servers that are fully dedicated for your use. Alternatively, EC2 offers instances with a tenancy of ‘default’ which run on physical servers that may host multiple isolated instances from different customers.  '), ('What is dedicated infrastructure?', 'Dedicated infrastructure provides servers that are physically isolated for use by a single customer. Amazon EC2 has two dedicated infrastructure options: Dedicated Hosts and Dedicated Instances. If you bring existing licenses to Dedicated Hosts or Dedicated Instances, then you are using hardware that is fully dedicated to your use. In that case, the outsourcing language within the Microsoft Product Terms applies. When you want to use instances on a Dedicated Host, launch instances with a tenancy of ‘host’. When you want to use Dedicated Instances, launch instances with a tenancy of ‘dedicated’.  '), ('What are Amazon EC2 Dedicated Hosts?', 'A Dedicated Host is a physical EC2 server fully dedicated to your use. With Dedicated Hosts, you have more control over instance placement and gain visibility into the number of sockets and cores installed on a host. You can use these features to leverage your own per-socket or per-core software licenses, including Windows Server and SQL Server, and SUSE Enterprise Server. Software Assurance is not required when you bring licenses to a Dedicated Host. Visit the Dedicated Host detail page for more information.  '), ('\xa0', 'What are Amazon EC2 Dedicated Instances?'), ('Dedicated instances are Amazon EC2 instances that run on hardware that is dedicated to a single customer. For more information on Dedicated Instances, visit the Dedicated Instance page.  ', 'What’s the difference between Dedicated Hosts and Dedicated Instances?'), ('Both offerings provide instances that are dedicated to your use. However, Dedicated Hosts provide additional control over your instances and visibility into Host level resources and tooling that allows you to manage software that consumes licenses on a per-core or per-socket basis, such as Windows Server and SQL Server. In addition, AWS Config will keep a record of how your instances use these Dedicated Host resources which will allow you to create your own license usage reports.  ', 'Does AWS recommend an EC2 purchasing model if I’m looking to use my own licenses? '), ('In order to take full advantage of EC2 it is recommended that customers first consider bringing eligible licenses through License Mobility. Default tenancy EC2 allows customers to scale capacity up and down according to changing needs. This allows customers to pay only for what they use. SQL is the most common product brought to AWS through License Mobility.', 'Amazon EC2 Dedicated Hosts are ideal for products that are not eligible for License Mobility or for which active Software Assurance is not in place. Dedicated Hosts are most cost effective when the host is highly utilized and in a steady, non-variable state. A Dedicated Host will support all BYOL scenarios outlined in this FAQ and provide customers with more control and visibility over how their instances are placed, which is useful for minimizing risk and licensing costs in a BYOL scenario. Additionally, Dedicated Hosts support per-socket, per-core, VM, and CAL based licenses. Windows is the most common product brought to Dedicated Hosts.'), ('What are my options for bringing development licenses to AWS? ', 'AWS customers have two options for bringing Microsoft developer products to AWS for use on test, development, and non-production workloads.'), ('Microsoft Development Network (MSDN) subscription licenses can be brought to Amazon EC2 Dedicated Hosts or Amazon EC2 Dedicated Instances. Microsoft does not allow the use of MSDN on multi-tenant AWS servers.', 'SQL Developer 2016 edition is available as a free download from Microsoft. Once downloaded from Microsoft, AWS customers can bring and install SQL Developer 2016 on Amazon EC2 instances. Dedicated infrastructure is not required for SQL Developer. \xa0'), ('Back to top', 'Can I buy Windows Server from AWS?'), ('Yes, you can deploy Windows Server on AWS by purchasing Amazon Machine Images (AMIs) with Windows Server pre-installed. If you buy Windows instances from AWS, whether your instances have a tenancy of dedicated or default, the Windows Server license is included in the cost.  With EC2 license-included instances, EC2 manages licensing compliance and you only pay for what you use. It is not necessary to pay for Software Assurance and you have the flexibility to upgrade your software when it is made available without additional cost. Furthermore, there is no need to buy additional Windows Server CALs as access for an unlimited number of end users is included in the price. Two Remote Desktop connections are also included for administration purposes. If you require more than two Remote Desktop connections, or need those remote connections for purposes other than administration, you may need to purchase and bring additional Remote Desktop Services CALs.  ', 'Can I bring my own Windows Server licenses and use them in EC2?'), ('Yes you can. After you’ve imported your own Windows Server machine images using the ImportImage tool, you need to launch instances from these machine images on EC2 Dedicated Hosts in order to effectively manage instances and report usage. Microsoft typically requires that you track usage of your licenses against physical resources such as sockets and cores and Dedicated Hosts helps you to do this. Visit the Dedicated Hosts detail page for more information on how to use your own Windows Server licenses on Amazon EC2 Dedicated Hosts.  ', 'What are Amazon EC2 Dedicated Hosts?'), ('A Dedicated Host is a physical EC2 server fully dedicated for your use. With Dedicated Hosts, you have more control over instance placement and gain visibility into the number of sockets and cores installed on a host. You can use these features to bring in your own software licenses bound to VMs, sockets, or cores, including Windows Server, SQL Server, and SUSE Enterprise Server. Software Assurance is not required when bring licenses to a Dedicated Host. For more information on Dedicated Hosts, visit the Dedicated Hosts detail page.', 'Do Microsoft licensing terms allow software without license mobility benefits or active Software Assurance to be deployed on Dedicated Hosts or Dedicated Instances? How can I confirm this?'), ('The Microsoft Product Terms, which govern the use of all on-premise Microsoft software, provide the following statement in the “Universal License Terms” section. Outsourcing Software Management Customer may install and use licensed copies of the software on Servers and other devices that are under the day-to-day management and control of third parties, provided all such Servers and other devices are and remain fully dedicated to Customer’s use. Customer is responsible for all of the obligations under its volume licensing agreement regardless of the physical location of the hardware upon which the software is used.', 'How do I import and use my own Windows Server license?'), ('You can bring in your own licensed copy of Windows Server media using the ImageImport tool made available by the EC2 VM Import/Export service. Once these images are imported, you can find them under the “my AMIs” section in the AWS Management Console or by using the DescribeImages API. You can then launch instances from your BYOL machine images onto Dedicated Hosts.', 'Visit this link for more information on how to bring your own machine images into AWS.'), ('Keep in mind that when you choose to bring in your existing Windows Server licenses, you cannot utilize Windows Server AMIs that you purchase from AWS through license-included instances. You must bring in your own licenses using your own software media.  ', '\xa0'), ('How do I track usage if I’m bringing my own licenses?', 'Using AWS Config as the data source and Dedicated Hosts as the platform to run BYOL instances, you can track BYOL usage against physical resources such as sockets and cores. Before you begin launching BYOL instances onto your Dedicated Hosts, ensure AWS Config has been enabled to record Dedicated Host changes. AWS Config keeps track of the configuration changes that occur on a Dedicated Host, including the instances and corresponding IDs of AMIs that ran on a Dedicated Host. These changes are paired with Host level data, such as the Host ID and the number of sockets and physical cores installed on a Dedicated Host. AWS Config will also keep track of instance tags. We recommend that you tag your instances with a meaningful identifier if you would like a human-readable way to identify BYOL instances in the AWS Config output. Visit this page for more information on AWS Config.'), ('How do I determine the number of licenses of Windows Server to bring in?', 'Visit the Dedicated Hosts detail page for information on the number of instances available per Dedicated Host. On this page you will also find the number of sockets and cores installed on each EC2 Dedicated Host. The instance, socket, and core counts vary by the instance type configuration of the Dedicated Host. '), ('\xa0', 'Do I need to have Software Assurance on Windows Server on AWS?'), ('No, if you are using Dedicated Hosts to use your own Windows Server licenses, you do not need to have Software Assurance (SA). Also, if you purchase Windows Server instances from AWS, then there is no need for you to have Software Assurance to cover those Windows Server licenses.  ', 'Does License Mobility work with Windows Server?'), ('No, as specified in the Microsoft Product Terms, Windows Server, Windows client, and Microsoft Office are not eligible for License Mobility. Since License Mobility enables the use of licenses on EC2 instances with a default tenancy, License Mobility is not required for licenses used on EC2 Dedicated Hosts. If you choose to use Dedicated Hosts for BYOL scenarios, then you can bring in your own licenses for Windows Server, Windows client, and Microsoft Office without the need for License Mobility.  ', 'How can I use my own Windows Server license on EC2 instances with a default tenancy?'), ('You should use your own Windows Server licenses on Dedicated Hosts and you can do this by running instances with a tenancy of ‘host’. You should not use your own Windows Server license on EC2 instances with a default tenancy unless you have approval from Microsoft to do so. If you have negotiated custom terms with Microsoft and have this permission, please contact AWS support or reach out to your account manager.  ', 'What is included when I buy Windows Server instances from AWS?'), ('AWS manages the licensing for you; all you need to do is pay for the instances you use. There is also no need to buy additional Windows Server CALs, as access is included in the price. Each instance comes with two remote connections for admin purposes only. If you require more than two connections, or need those connections for purposes other than admin, you may have to bring in additional Remote Desktop Services CALs for use on AWS.  ', 'Can I relicense license-included, EC2 Windows Server instances to use my own licenses, pointing at my own KMS server?'), ('No, you cannot relicense existing Windows Server EC2 instances or migrate existing Windows Server EC2 instances over to BYOL VMs. However, if you need to migrate from license-included to BYOL and have applications or OS configurations that need to be migrated, we suggest that you reach out to our partners, such as CloudEndure or AppZero, who may be able to assist with these types of migrations. ', '\xa0'), ('Back to top', 'Can I buy SQL Server from AWS?'), ('Yes, you can buy instances with SQL Server licenses included from AWS to run on either Amazon EC2 or Amazon Relational Database Service (RDS). SQL Server Web Edition, Standard Edition, and Enterprise Edition are available for you to license on both Amazon EC2 and Amazon RDS.', ' Can I bring in my own SQL Server licenses for use on AWS?'), ('Yes, you can bring in your own licenses (BYOL) on EC2 Dedicated Hosts, EC2 Dedicated Instances with license included Windows Server, or EC2 instances with a default tenancy with License Mobility.', ' Can I use License Mobility with SQL Server?'), ('Yes, license Mobility is a benefit available to Microsoft Volume Licensing customers with eligible server applications (including SQL Server) covered by active Microsoft Software Assurance (SA) contracts. License Mobility allows customers to move eligible Microsoft software to third party cloud providers such as AWS for the end use on EC2 instances with a default tenancy. It is important to note that you may not need license mobility if you are using your own licenses on EC2 Dedicated Hosts or EC2 Dedicated Instances. For additional details, see the Microsoft License Mobility page on the AWS site. Qualifying customers with Software Assurance can bring in their own licenses of SQL Server for use on Amazon EC2 and Amazon RDS instances with a default tenancy.', ' Do I have to pay for failover SQL Servers for disaster recovery?'), ('There are various factors to consider when licensing disaster recovery for SQL Server. The information below pertains only to the SQL Server licenses and not the Windows Server licenses. In all cases you must license Windows Server. For more information on SQL and failover server scenarios, visit this Microsoft SQL Server licensing guide. ', '\xa0'), (' How do I know how many SQL Server licenses to bring in?', 'If you are licensing SQL Server under Microsoft’s License Mobility through Software Assurance, the number of licenses required varies based on the instance type, version of SQL Server, and the Microsoft licensing model you choose. To assist you with your virtual core licensing calculations under the Microsoft Product Terms, we provide a table here that shows the number of virtual representations of hardware threads based on instance type.'), ('If you are using Dedicated Hosts, EC2 provides you with the number of physical cores installed on the Dedicated Host. Using this information, you can calculate the number of SQL Server licenses that you need to bring in. For additional information, we recommend referencing Microsoft documentation, such as the licensing guide for SQL server 2014 (see here).', 'What are the use cases for SQL Server Web Edition?'), ('The Microsoft Product Terms state that SQL Server Web may be used to support public and Internet accessible web pages, web sites, web applications and web services. SQL Server Web may not be used to support line of business applications (e.g., Customer Relationship Management, Enterprise Resource Management and other similar applications). For addition information on use cases for SQL Server Web, please consult Microsoft or your Microsoft reseller. ', ' How do I determine the right core factor to license with?'), ('You can determine the core count per server by dividing the number of physical cores on the Dedicated Host by the socket count. This information can be found on the Dedicated Host detail page. You can find the processor types on the EC2 Instance Type detail page.', ' How do I track usage if I’m bringing my own licenses?'), ('Using AWS Config as the data source you can track configuration changes against physical resources such as sockets and cores. Before you begin launching BYOL instances onto AWS, ensure AWS Config has been enabled to record any changes. AWS Config keeps track of the changes that occur, including the instances and corresponding AMI IDs that ran. These changes are paired with Host level data, such as the Host ID and the number of sockets and physical cores installed. AWS Config will also keep track of instance tags. We recommend that you tag your instances with a meaningful identifier if you would like a human-readable way to identify BYOL instances in your AWS Config logs. Visit this page for more information on AWS Config.', '\xa0'), ('Can SQL Server 2016 Developer edition be used on AWS? ', 'Yes. SQL Developer 2016 edition is available as a free download from Microsoft. SQL Developer 2016 is eligible for use in non-production, development, and test workloads. Once downloaded from Microsoft, AWS customers can bring and install SQL Developer 2016 on Amazon EC2 instances. Dedicated infrastructure is not required for SQL Developer.'), ('\xa0', 'Are SQL CALS required on AWS? '), ('Customers using SQL Server on Amazon EC2 or Amazon RDS license included instances do not require client access licenses (CALs) for SQL Server. An unlimited number of end users can access SQL Server on a license included instance.', 'Customers bringing their own SQL Server licenses to AWS through license mobility or bring your own licenses (BYOL), will follow the licensing rules they have in place on-premises. If the customer purchased SQL Server under the Server/CAL model, they would still require CALs to meet Microsoft licensing requirements, but these CALs would remain on-premises and enable end user access SQL Server running on AWS  \xa0'), ('\xa0', 'Back to top'), ('Can I bring Microsoft Developer Network (MSDN) licenses to AWS?  ', 'Yes, you can bring your MSDN licenses to Amazon EC2 Dedicated Hosts or Amazon EC2 Dedicated Instances. Microsoft does not allow the use of MSDN on multi-tenant AWS servers. Amazon EC2 Dedicated Hosts or Amazon EC2 Dedicated Instances are fully dedicated to the use of one end customer and satisfy the “Outsourcing Software Management” section of the Microsoft Product Terms which state: “Customer may install and use licensed copies of the software on Servers and other devices that are under the day-to-day management and control of third parties, provided all such Servers and other devices are and remain fully dedicated to Customer’s use. Customer is responsible for all of the obligations under its volume licensing agreement regardless of the physical location of the hardware upon which the software is used.” '), (' Can I buy MSDN from AWS?  ', 'No, AWS does not sell MSDN licenses.'), (' Can I use MSDN on AWS instances with a default tenancy?  ', 'No, Microsoft does not allow MSDN licenses to be utilized on AWS instances with a default tenancy.'), (' Can I use my existing MSDN licenses on EC2 Dedicated Hosts or EC2 Dedicated Instances?  ', 'Yes, you can use these licenses on either Dedicated Hosts or Dedicated Instances.'), (' Does License Mobility work with MSDN?  ', 'No, MSDN is not included in Microsoft’s License Mobility program.'), ('Back to top', 'Can I buy Windows Client from AWS?'), ('No. AWS does not sell any Windows Client operating system licenses on any of our services.', ' Can I bring in my own Windows Client licenses for use on AWS?'), ('Yes. If you use Dedicated Instances or Dedicated Hosts, then you can bring in your own Windows Client licenses for use on AWS. You may require Software Assurance or Virtual Desktop Access (VDA) in order to utilize the Windows client operating systems such as Windows 7 or Windows 8 on AWS. We recommend you read this Microsoft licensing brief for more information.', ' Can I use License Mobility with Windows Client?'), ('No, as specified in the Microsoft Product Terms, License Mobility does not apply to Windows Client, Windows Server, or Microsoft Office. Since License Mobility enables the use of specific licenses on EC2 instances with a default tenancy, License Mobility is not required to deploy licenses on EC2 Dedicated Hosts or EC2 Dedicated Instances. If you choose to use Dedicated Hosts and BYOL, then you can bring in your own licenses for Windows Client, Windows Server, and Microsoft Office without needing License Mobility.', 'Back to top'), ('Can I bring in my own Office licenses for use on AWS?', 'Yes, you can BYOL of Microsoft Office for use on EC2 Dedicated Hosts or EC2 Dedicated Instances. If you bring existing licenses to EC2 Dedicated Hosts or EC2 Dedicated Instances, then you are using hardware that is fully dedicated to your use. In that case, the outsourcing language within the Microsoft Product Terms applies. This allows you to bring in Office licenses for use on your own Windows client licenses.'), (' Can I use License Mobility with Microsoft Office?', 'No, Microsoft does not include Microsoft Office in Microsoft’s License Mobility program.'), ('Back to top', 'Can I buy other Microsoft products from AWS?'), ('No. AWS sells only Windows Server and SQL Server licenses today for use on Amazon EC2.', ' Can I bring in my own licenses for use on AWS?'), ('Yes. We have many customers that have successfully brought in and deployed licenses on AWS. These deployments include, but are not limited to, Exchange, SharePoint, Lync, Remote Desktop Services, Office, Dynamics products, BizTalk, and System Center.', 'Customers can choose to use shared EC2 instances and utilize License Mobility or they can purchase EC2 Dedicated Hosts and utilize physically dedicated hardware.'), (' Can I use License Mobility?', 'Yes. License Mobility is a benefit available to Microsoft Volume Licensing customers with eligible server applications covered by active Microsoft Software Assurance (SA). License Mobility allows customers to move eligible Microsoft software to third party cloud providers such as AWS for the end use on EC2 instances with a default tenancy. It is important to note that you may not need license mobility if you are using your own licenses on EC2 Dedicated Hosts or EC2 Dedicated Instances. For additional details, see the Microsoft License Mobility page on the AWS site. Qualifying customers with Software Assurance can bring in their own licenses of user based products as long as they comply with the terms of the License Mobility program.'), ('\xa0', 'How can I obtain additional Remote Desktop Services licenses?'), ('Amazon EC2 instances come with two Remote Desktop Services (aka Terminal Services) licenses for administration purposes. If additional Remote Desktop Services licenses are needed, they should be purchased from Microsoft or a Microsoft license reseller. Remote Desktop Services licenses purchased with Software Assurance have license mobility benefits and can be brought to AWS multi-tenant environments. If the licenses do not have Software Assurance, they must be deployed on dedicated hosts or dedicated instances.  If you are providing this is a service to a third party (not internal use), then the Service Provider License Agreement (SPLA)could be used to license Remote Desktop Services. Under this model, you would deploy your service on AWS and rent remote desktop licenses for your end users on a monthly basis. Information on SPLA can be found at:\xa0 https://www.microsoft.com/en-us/CloudandHosting/Licensing_Get_started_with_SPLA.aspx  ', '\xa0'), ('\xa0', '\xa0'), ('\xa0', '\xa0'), ('Back to top', 'Can I use my own SPLA?'), ('We have many customers and partners that have their own SPLA and utilize AWS. AWS customers can use their SPLA in scenarios where they are offering software services to a third party. Customers that have a SPLA with Microsoft are governed by the Services Provider Use Rights (SPUR). The SPUR describes exactly how customers can outsource their infrastructure to AWS. Products licensed by user can be deployed on multi-tenant AWS and licensed on a monthly basis under the customer’s SPLA. Unless deployed on dedicated infrastructure, products that are licensed by core or processor (Windows Server, SQL Server) are licensed with AWS license included instances. ', 'What are Self Hosting rights?'), ('ISVs can choose to utilize self-hosting rights with Microsoft as part of their Enterprise Agreement (EA). This allows them to take advantage of pricing that they have negotiated with Microsoft under their EA. Microsoft requires that customers not mix self-hosting rights and SPLA for each application. If you have a solution that is licensed under the self-hosting benefit and you wish to bring it to AWS, you can deploy this on EC2 default tenancy. In this scenario, you would still be required to purchase a Windows license-included instance. Dedicated Hosts are not required for SQL (or other included self-hosting products) due to AWS’s status as a license mobility partner.\xa0', 'Can Microsoft BizSpark licenses be used on AWS?'), ('No, at this time new BizSpark licenses cannot be used on AWS. We encourage startups to try AWS Activate, with benefits including usage credits, support, training and more.', 'Back to top'), ('How frequently does AWS patch Windows AMIs?', 'AWS provides updated, fully patched Windows AMIs within 5 business days of Microsoft’s patch Tuesday (second Tuesday of each month).  '), ('What happens with previously published AMIs?', 'AWS deprecates previously published Windows and SQL Server AMIs within 10 business days after a new set of AMIs is published.  '), ("How do I know I'm launching the latest AWS published AMI?", 'When publishing new Windows AMIs, AWS follows a consistent naming scheme. For example, Windows_Server-2012-R2_RTM-English-64Bit-Base-2014.05.20. Look for the date stamp in the AMI name. You find the date stamp (last 8 digits) at the end of the AMI name. '), ('Back to top', 'What’s new in Windows Server 2016?'), ('Windows Server 2016 is Microsoft’s newest release of Windows Server. Windows Server 2016 comes loaded with a variety of powerful new features including support for Docker and Windows Containers. The release also features a Nano Server deployment option that boots faster than the Standard Edition and uses a fraction of the disk space. By running Windows Server 2016 on Amazon EC2, users can leverage the performance and elasticity of AWS to get up and running on this new release.', 'How is AWS supporting Windows Server 2016?'), ('AWS is releasing several new AMIs, including Windows Server 2016, Nano Server, Windows Server 2016 with Containers and Windows Server 2016 with SQL Server 2016.', 'How is Nano Server different from Windows Server 2016?'), ('Nano Server is optimized to run cloud-hosted applications and containers. Compared to Windows Server 2016, it starts faster, requires fewer updates, consumes far less disk space, presents less surface area for security threats, and only runs 64-bit applications, tools, and agents. Nano Server has no graphical user interface – all administration is done remotely via PowerShell or WMI. ', 'How is the EC2 Console experience different for Nano Server?'), ('For Nano Server, Get Instance Screenshot and System Log views are supported, however given Nano Server is headless, Connect via RDP is not. Instead, users can administer a running Nano Server instance via PowerShell remoting, via PowerShell CIM\xa0sessions over WinRM, or via Windows Remote Management.', 'Can I create my own images from Windows Server 2016 and Nano Server instances?'), ('Yes, you can create customized AMIs from Windows Server 2016 and Nano Server instances. As a best practice, AWS recommends generalizing an image by running sysprep when creating a new Windows AMI, and this continues to be true for Windows Server 2016. However, sysprep is not included in Nano Server, meaning image generalization is not available when creating a Windows AMI from Nano Server. Alternately, users can customize a Nano Server instance post-launch by using Run Command, which enables configuration via remote command execution.', 'Are there any other significant changes regarding Windows Server 2016 AMIs?'), ('Windows Server 2016 and Nano Server AMIs feature an all-new version of the SSM agent that replaces the functionality previously supported by the EC2Config service, thereby eliminating the need for EC2Config. With these enhancements, SSM agent now supports a number of advanced settings and launch-time configurations. More details on the new SSM agent in Windows Server 2016 and Nano Server can be found in the User Guide.', 'How can I run Windows containers?'), ('Launch an instance with the new Windows Server 2016 with Containers AMI. You can find a sample walkthrough in the AWS Blog. ', 'Now that there’s a Windows 2016 with Containers AMI, are there plans for Amazon EC2 Container Service (ECS) to support Windows containers?'), ('Yes. Amazon EC2 Container Service (ECS) will support Windows containers by the end of 2016. Please sign up here to receive more information.', 'What will it cost to run Windows Server 2016?'), ('Windows Server 2016 instances are billed under standard Windows EC2 pricing.', 'Which EC2 instance types work best with Windows Server 2016?'), ('Microsoft recommends a minimum of 2GB RAM – visit the EC2 Instance Types page to see which instances fit best for your application.', 'Can I bring my own license (BYOL) for Windows Server 2016?'), ('You can bring your own license to AWS EC2 Dedicated Hosts, subject to your licensing terms with Microsoft. Use VM Import to create a Windows Server 2016 AMI from your own copy of Windows Server 2016.', 'Can I upgrade my Windows Server instance to Windows Server 2016?'), ('Yes, you can upgrade Windows instances to Windows Server 2016. Visit this page for more details.', 'What AWS regions support Windows Server 2016?'), ('Windows Server 2016 is available in all AWS regions.\xa0', 'What editions of Windows Server 2012 R2 are available in AMIs?'), ('We will be releasing AMIs with Windows Server 2012 R2 Standard Edition. For details on the differences between the Windows Server Editions, please refer to the Microsoft documentation.  ', 'Will it cost more to run Windows Server 2012 R2?'), ('No. Both On-Demand and Reserved instance pricing for Windows Server 2012 R2 is the same as the pricing for earlier versions of Windows Server available on Amazon EC2. You can view the current pricing for Amazon EC2 instances here: http://aws.amazon.com/ec2/pricing.  ', 'Which AWS regions are supported?'), ('Windows Server 2012 R2 is available in all AWS regions.  ', 'Which Amazon EC2 instance types are supported?'), ('At this time, all Amazon EC2 instance types are supported.  ', 'What languages are available?'), ('We support 19 languages with the Windows Server 2012 R2 AMIs. Current list of supported languages: Brazilian Portuguese, Chinese Simplified, Chinese Traditional, Czech, Dutch, English, French, German, Hungarian, Italian, Japanese, Korean, Polish, Russian, Spanish, Swedish, and Turkish.  ', 'How do I deploy my applications running Windows Server 2012 R2 to AWS?'), ('You can use AWS Elastic Beanstalk to deploy and manage your applications on Windows Server 2012 R2 in the AWS cloud. Additionally, you can deploy directly to Amazon EC2 instances launched from the EC2 console or the AWS Marketplace. Also, you can use the AWS Toolkit for Visual Studio to get your application deployed and running in a few clicks.  ', 'Which SQL Server version/edition and languages are available with Windows Server 2012 R2 AMIs?'), ('The following SQL Server languages, version and editions are available with Windows Server 2012 R2 AMI: English, Japanese and Brazilian Portuguese: SQL Server 2014 (Enterprise (English only), Express, Standard and Web editions).  ', 'Windows Server 2012 R2 has two file systems: NTFS and ReFS. Which one should I use?'), ('ReFS was designed for file sharing workloads like sharing content or streaming videos. Windows applications like SQL Server support NTFS and will not install on a ReFS volume.  ', 'Can I create a Storage Space using an EBS volume?'), ('Yes. EBS volumes can be used to setup a Storage Pool. The volumes can be formatted as NTFS or ReFS depending upon your application*.  ', 'How do I switch to the new Windows Server Start screen?'), ('Move your mouse to the lower left corner, wait for the Start screen and then click to switch into the Start screen.  ', 'On previously published Windows Server AMIs I followed the steps as documented here to enable enhanced networking. Do I still need to do this for Windows Server 2012 R2 AMIs?'), ('No, you don’t need to do this for the new Windows Server 2012 R2 AMIs. The AMIs provide built-in support for enhanced networking via SR-IOV on R3, C3 and I2 instances.', 'Back to top'), ('On what date will Microsoft end extended support for Windows Server 2003?', 'Microsoft extended support for Windows Server 2003 ends on July 14, 2015*.  '), ('', 'Can I run my existing Windows Server 2003 instances after the end of extended support? '), ('Yes. You can run Windows Server 2003 and Windows Server 2003 R2 instances on Amazon EC2 after Microsoft extended support ends on July 14, 2015* including instances that are running at that time.  ', 'Can I launch new Windows Server 2003 instances after the end of extended support? '), ('You can launch new Windows Server 2003 instances on existing Amazon EC2 instance families after the end of extended support*.  ', 'Will I be able to create and launch instances from custom Windows Server 2003 AMIs after the end of extended support?'), ('Yes. You will be able to create custom Windows Server 2003 AMIs and launch instances from those AMIs after July 14, 2015*.  ', 'Will I be able to publicly access Windows Server 2003 AMIs from the AWS Console and AWS Marketplace?'), ('Windows Server 2003 AMIs will continue to be published and updated through the August AMI release schedule, and will be removed from the Amazon EC2 quick launch and Marketplace on September 15th, 2015. After September 15th, you will still be able to search for the published AMIs by following the instructions on this page.  ', 'Will AWS support Microsoft Windows Server 2003 after July 14, 2015? '), ('Without the ability to receive updates or debugging assistance from Microsoft, our ability to fully resolve issues related to Windows Server 2003 will be restricted to addressing issues which do not require an OS patch. AWS will continue to offer assistance troubleshooting issues with running Windows Server 2003 on Amazon EC2.  ', 'Will I be able to import new Windows Server 2003 virtual machines after the end of extended support? '), ('Yes. You can use VM Import to import Windows Server 2003 based VMs after July 14th, 2015.  ', 'Will Amazon EC2 continue to provide updated Windows Server 2003 and Windows Server 2003 R2 AMIs?'), ('AWS is unable to provide security and software updates to Windows Server 2003 after extended support ends on July 14th 2015. If Microsoft provides security and software updates to the general public for Windows Server 2003 after July 14, 2015, we will provide them to you via an updated AMI.  ', 'Can I build custom AMIs that contain updates provided by Microsoft through a custom support agreement? '), ('Yes. AWS customers can create and launch custom AMIs for their own use, including if those AMIs contain updates resulting from a custom support agreement. AWS customers may not redistribute any custom support updates, however.  ', 'Will AWS support Microsoft applications, such as Microsoft SQL Server 2005, running on Windows Server 2003 after the end of extended support? '), ('AWS will continue to offer assistance troubleshooting applications that are still within the Microsoft extended support phase. There is no change in the way applications running on Windows Server are supported. However if the issue requires a patch or OS-level troubleshooting support from Microsoft, the AWS support team may not be able to fully resolve your issue. Please visit the AWS Support page for more details.  ', 'Does AWS support in-place OS upgrades for my Windows Server 2003 instances?'), ('Yes, for details on how to perform OS Upgrades on your Amazon EC2 instances, please visit the following page for more details.  ', 'Will my scripted references to existing Windows Server 2003 AMIs continue to work after the end of extended support?'), ('On September 15, 2015, the AWS-published Windows Server 2003 AMIs will be removed from the quick start in the instance launch wizard but will still be accessible by following the instructions on this page. The AMI IDs of your custom AMIs will not be changed.  ', 'How can I keep up-to-date with Windows Server 2003 security related information?'), ('We encourage you to visit the AWS Security Center to learn about security in the AWS cloud. You can also subscribe to our Security Bulletin RSS Feed to keep abreast of security announcements.  ', "* Following July 14, 2015, Microsoft's extended support for Microsoft Windows Server 2003 will end. Because of this, instances running Windows Server 2003 may have a higher risk of failure, security issues, incompatibility, or non-functionality. AWS will continue to offer you use of Windows Server 2003 within Amazon EC2, with an understanding that there may be an increasing number of issues that cannot be diagnosed or resolved, and therefore there is a risk that your Windows Server 2003 instances will lose their functionality entirely. "), ('Back to top', 'Does AWS offer SharePoint instances?'), ('No, AWS does not offer SharePoint instances at this time.  ', 'How can I run SharePoint on AWS?'), ('You can run SharePoint on AWS by deploying eligible licenses with active Software Assurance through Microsoft’s License Mobility program. Learn more at http://aws.amazon.com/windows/resources/licensemobility/. SharePoint can also be deployed on AWS EC2 Dedicated Hosts without Software Assurance.  ', 'What is Microsoft License Mobility?'), ('Microsoft License Mobility through Software Assurance allows Microsoft customers to move current on-premises Microsoft Server application workloads to Amazon Web Services (AWS), without any additional Microsoft software license fees. This benefit is available to Microsoft Volume Licensing (VL) customers with eligible server applications covered by active Microsoft Software Assurance (SA) contracts. Learn more at http://aws.amazon.com/windows/resources/licensemobility/.  ', 'What if I do not have Software Assurance on the Licenses?'), ('Please contact your Microsoft Large Account Reseller (LAR) for options on how to purchased and/or add Software Assurance to existing licenses.  ', 'How do SharePoint licenses on AWS work?'), ('One SharePoint license can be assigned to one AWS instance (no max/min size).  ', 'How do I use an SQL Instance with SharePoint on AWS?'), ('Customers can run their existing SQL licenses per the License Mobility program or they can run on an AWS SQL instance. For more information on SQL instances running on Amazon EC2, including pricing, please visit http://aws.amazon.com/windows/products/ec2. ', 'Back to top'), ('What is the AWS Management Pack for Microsoft System Center? ', 'The AWS Management Pack is an extension to Microsoft System Center Operations Manager that enables you to view and monitor your AWS resources directly in the Operations Manager console. This way, you get a single pane of glass to view and monitor your resources, whether they are on-premises or in the AWS cloud.  '), ('Which AWS resources can I monitor using the AWS Management Pack? ', 'You can monitor following AWS resources using the AWS Management Pack: '), ('● Amazon EC2 instances (Microsoft Windows and Linux) ● Amazon Elastic Block Store (EBS) volumes ● Elastic Load Balancing ● AWS CloudFormation stacks ● AWS Beanstalk applications', 'All the default Amazon CloudWatch metrics for these resources—and any Amazon CloudWatch alarms associated with them—are surfaced as performance counters and alerts in Operations Manager.'), (' Which versions of System Center Operations Manager can I use? ', 'The AWS Management Pack is available for “System Center 2012 – Operations Manager” and “System Center Operations Manager 2007 R2”.  '), ('Can I monitor AWS resources that are in different AWS regions? ', 'Yes. The management pack gives you a consolidated view of your resources across multiple regions and Availability Zones.  '), ('Can I monitor AWS resources that are in Amazon Virtual Private Cloud (VPC)? ', 'Yes. The management pack gives you a consolidated view of your resources running in Amazon VPC and Amazon EC2.  '), ('Can I monitor AWS resources from multiple AWS accounts? ', 'Yes. You can configure the management pack to monitor AWS resources from multiple AWS accounts. Resources from multiple AWS accounts are monitored separately instead of being consolidated in a single view.  '), ('Can I monitor applications running within Amazon EC2 instances? ', 'Yes, provided that (a) the Amazon EC2 instances are running Operations Manager Agent, and (b) the application-specific management packs are imported in Operations Manager. This applies to Amazon EC2 instances running Microsoft Windows as well as Linux. '), ('Can I use IAM credentials instead of AWS root account credentials to monitor AWS resources?', 'Yes. You can configure the AWS Management Pack to use the access key ID and secret access key of a locked-down IAM user instead of using the credentials of a fully-privileged AWS root account.  '), ('Can I use my on-premises Operations Manager for the AWS Management Pack?', 'Yes. You can choose to run Operations Manager either on-premises or in the AWS cloud.  '), ('Where can I find more information about the AWS Management Pack?', 'A comprehensive guide detailing deploying, using, customizing, and troubleshooting the AWS Management Pack is available here.  '), ('Can I use my existing System Center Licenses?', 'Yes, through Microsoft License Mobility. '), ('Back to top', 'What is AWS Systems Manager for Microsoft System Center Virtual Machine Manager?'), ('AWS Systems Manager for Microsoft SCVMM is a software add-in that lets you administer your AWS resources using SCVMM. You can monitor and manage your EC2 for Windows instances in the AWS Cloud, as well as on-premises virtual machines—from a single console.  ', 'What can I do with Systems Manager for SCVMM?'), ('You can list and view EC2 for Windows instances in any region. You can also start, stop, reboot, and terminate instances, as well as connect via RDP.  ', 'Which versions of SCVMM can be used with Systems Manager for SCVMM?'), ('You can use AWS Systems Manager with SCVMM 2012 SP1 and later.  ', 'Where do I download Systems Manager for SCVMM?'), ('You can download the add-in here.  ', 'How much does Systems Manager for SCVMM cost?'), ('There is no additional cost to download, install or use Systems Manager for SCVMM.  ', 'How is this different from the AWS Management Pack for Microsoft System Center?'), ('The AWS Management Pack is used for monitoring and reporting on the performance of EC2 for Windows instances, whereas AWS Systems Manager lets you start, stop, reboot and terminate instances. ', 'Back to top'), ('What is the AWS Diagnostics for Microsoft Windows Server?', 'AWS Diagnostics for Microsoft Windows Server is a standalone executable that can be run on an EC2 Windows Server instance for diagnosis and troubleshooting as well as proactively checking for possible issues. The tool includes a data collector module that collects debug information and packages it in a zip file. It also includes an analyzer module that can analyze the log files collected by the data collector module and parse them based on predefined rule.  '), ('When should I use this tool?', 'If you ever run into issues with your EC2 Windows Server instance and want to do a preliminary check to eliminate some of the known problems, this tool will be a great starting point. It will also relieve the pain point of trying to collect a bunch of different log files manually, especially when you are working with our technical support.  '), ('What data will be collected?', 'Here’s a sample list of data that will be collected. For a comprehensive list, please refer to the user manual'), ('What are some of the analysis rules?', 'Here’s a sample list of analysis rules. For a comprehensive list, please refer to the user manual'), ('How much does the AWS Diagnostics for Microsoft Windows Server cost?', 'There is no additional charge for AWS Diagnostics for Microsoft Windows Server.  '), ('My EC2 Windows Server just crashed. Can I use this tool to collect log files from the EBS boot volume for that instance?', 'Yes. In order to do that you will have to detach the volume from the crashed instance and attach it to an instance on which the tool is running. The tool will then parse through the directory structure of the attached EBS volume that you select and will collect the necessary information.  '), ('Where can I find more information about the AWS Diagnostic Tool for Microsoft Windows Server?', 'A comprehensive guide for AWS Diagnostic Tool for Microsoft Windows Server is available here. '), ('Back to top', 'Will customers have to recreate their environment using other technologies in order to receive support from AWS or Microsoft?'), ('No. Customers can receive support running Microsoft workloads on AWS from both AWS and Microsoft under the customer’s support agreements with AWS or Microsoft without having to recreate their environment using other technologies. In the very rare case a problem could not be duplicated, AWS would work with the customer to recreate the issue in a Microsoft validated environment.  ', 'Is AWS SVVP Validated?'), ('AWS does not need to be SVVP validated for customers to be fully supported running Microsoft workloads on AWS. As Microsoft explains: “SVVP does not apply to vendors that are hosting Windows Server or other Microsoft products through the Microsoft Service Provider License Agreement Program (SPLA). Support for SPLA customers is provided under the SPLA agreement by the SPLA hoster.” (see http://www.windowsservercatalog.com/svvp.aspx).  ', 'Without SVVP Validation, are Microsoft products fully supported in the AWS environment?'), ('Yes. SVVP validation is not applicable to SPLA providers. Support for SPLA customers is provided under the SPLA agreement by AWS. AWS is fully committed to supporting our customers running Microsoft workloads on AWS.', 'Back to top'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/ecr/faqs/': [('Q: What is Amazon\xa0Elastic Container Registry (ECR)? Amazon\xa0Elastic Container Registry (ECR) is a fully-managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images. Amazon ECR is integrated with Amazon\xa0Elastic Container Service (ECS), simplifying your development to production workflow. Amazon ECR eliminates the need to operate your own container repositories or worry about scaling the underlying infrastructure. Amazon ECR hosts your images in a highly available and scalable architecture, allowing you to reliably deploy containers for your applications. Integration with AWS Identity and Access Management (IAM) provides resource-level control of each repository.', 'Q: Why should I use Amazon ECR? Amazon ECR eliminates the need to operate and scale the infrastructure required to power your container registry. Amazon ECR uses Amazon S3 for storage to make your container images highly available and accessible, allowing you to reliably deploy new containers for your applications. Amazon ECR transfers your container images over HTTPS and automatically encrypts your images at rest. You can configure policies to manage permissions for each repository and restrict access to IAM users, roles, or other AWS accounts. Amazon ECR integrates with Amazon ECS and the Docker CLI, allowing you to simplify your development and production workflows. You can easily push your container images to Amazon ECR using the Docker CLI from your development machine, and Amazon ECS can pull them directly for production deployments.'), ('Q: What is the pricing for Amazon ECR? With Amazon ECR, there are no upfront fees or commitments. You pay only for the amount of data you store in your repositories and data transferred to the Internet. Please see our Pricing page for more details. ', 'Q: Is Amazon ECR a global service? Amazon ECR is a regional service and is designed to give you flexibility in how images are deployed. You have the ability to push/pull images to the same region where your Docker cluster runs for the best performance. You can also access Amazon ECR anywhere that Docker runs such as desktops and on-premises environments. Pulling images between regions or out to the internet will have additional latency and data transfer costs.'), ('Q: Can Amazon ECR host public container images? Amazon ECR currently supports private images. However, using IAM resource-based permissions, you can configure policies for each repository to allow access to IAM users, roles, or other AWS accounts.', 'Q: What compliance capabilities can I enable on Amazon ECR? You can use AWS CloudTrail on Amazon ECR to provide a history of all API actions such as who pulled an image and when tags were moved between images. Administrators can also find which EC2 instances pulled which images.'), ('Q: How do I get started using Amazon ECR? The best way to get started with Amazon ECR is to use the Docker CLI to push and pull and your first image. Visit our Getting Started page for more information.', 'Q: Can I access Amazon ECR inside a VPC? To use Amazon ECR within a VPC, your instances must be able to communicate with the Internet. You can do this with Amazon VPC NAT Gateway.'), ('Q: What’s the best way to manage my repositories and images? Amazon ECR provides a command line interface and APIs to create, monitor, and delete repositories and set repository permissions. You can perform the same actions in the Amazon ECR Management Console, which can be accessed via the “Repositories” section of the Amazon ECS Console. Amazon ECR also integrates with the Docker CLI allowing you to push, pull, and tag images on your development machine.', 'Q: Does Amazon ECR replicate images across regions? No. Amazon ECR is designed to give you flexibility in where you store and how you deploy your images. You can create deployment pipelines that build images, push them to Amazon ECR in selected regions, and then deploy the images to your Docker cluster. '), ('Q: Can I use Amazon ECR within local and on-premises environments? Yes. You can access Amazon ECR anywhere that Docker runs such as desktops and on-premises environments.', 'Q:\xa0Does Amazon ECR provide an Amazon Linux container image? Yes. Amazon ECR provides Amazon Linux container images, and detailed steps can be found on the forums. Customers can use these container images to run workloads in their Linux-based Docker environment. The container image has a minimal set of packages and is able to install the full set of Amazon Linux AMI packages. Similar to the Amazon Linux AMI in EC2, Amazon Linux container images will get ongoing updates from Amazon in the form of security updates, rolling releases, and package updates.'), ('Q: Does Amazon ECR work with Amazon ECS? Yes. Amazon ECR is integrated with Amazon ECS allowing you to easily store, run, and manage container images for applications running on Amazon ECS. All you need to do is specify the Amazon ECR repository in your Task Definition and Amazon ECS will retrieve the appropriate images for your applications.', 'Q: Does Amazon ECR work with AWS Elastic Beanstalk? Yes. AWS Elastic Beanstalk supports Amazon ECR for both single and multi-container Docker environments allowing you to easily deploy container images stored in Amazon ECR with AWS Elastic Beanstalk. All you need to do is specify the Amazon ECR repository in your Dockerrun.aws.json configuration and attach the AmazonEC2ContainerRegistryReadOnly policy to your container instance role. '), ('Q: What version of Docker Engine does Amazon ECR support? Amazon ECR currently supports Docker Engine 1.7.0 and up.', 'Q: What version of the Docker Registry API does Amazon ECR support? Amazon ECR supports the Docker Registry V2 API specification.'), ('Q: Will Amazon ECR automatically build images from a Dockerfile?  No. However, Amazon ECR integrates with a number of popular CI/CD solutions to provide this capability. See the Amazon ECR Partners Page for more information.', 'Q: Does Amazon ECR support federated access? Yes. Amazon ECR is integrated with AWS Identity and Access Management, which supports identity federation for delegated access to the AWS Management Console or AWS APIs.'), (' Q: What version of the Docker Image Manifest specification does Amazon ECR support? Amazon ECR supports the Docker Image Manifest V2, Schema 2 format. In order to maintain backwards compatibility with Schema 1 images, Amazon ECR will continue to accept images uploaded in the Schema 1 format. Additionally, Amazon ECR can down-translate from a Schema 2 to a Schema 1 image when pulling with an older version of Docker Engine (1.9 and below).', 'Q: Does Amazon ECR support the Open Container Initiative (OCI) format? Yes. Amazon ECR is compatible with the Open Container Initiative (OCI) image specification letting you push and pull OCI images. Amazon ECR can also translate between Docker Image Manifest V2, Schema 2 images and OCI images on pull. '), ('Q: How does Amazon ECR help ensure that container images are secure? Amazon ECR automatically encrypts images at rest using S3 server side encryption and transfers your container images over HTTPS. You can configure policies to manage permissions and control access to your images using AWS Identity and Access Management (IAM) users and roles without having to manage credentials directly on your EC2 instances.', 'Q: How can I use AWS Identity and Access Management for permissions? You can use IAM resource-based policies to control and monitor who and what (e.g., EC2 instances) can access your container images as well as how, when, and where they can access them. To get started, use the Management Console to create resource-based policies for your repositories. Alternatively, you can use sample policies and attach them to your repositories via the Amazon ECR CLI. '), ('Q: Can I share my images across AWS accounts? Yes. Here is an example of how to create and set a policy for cross-account image sharing.', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/ecs/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/vpc/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/batch/faqs/': [('Q: What is AWS Batch?', 'AWS Batch is a set of batch management capabilities that enables developers, scientists, and engineers to easily and efficiently run hundreds of thousands of batch computing jobs on AWS. AWS Batch dynamically provisions the optimal quantity and type of compute resources (e.g., CPU or memory optimized instances) based on the volume and specific resource requirements of the batch jobs submitted. With AWS Batch, there is no need to install and manage batch computing software or server clusters, allowing you to instead focus on analyzing results and solving problems. AWS Batch plans, schedules, and executes your batch computing workloads using Amazon EC2 and Spot Instances.'), ('Q: What is Batch Computing? Batch computing is the execution of a series of programs ("jobs") on one or more computers without manual intervention. Input parameters are pre-defined through scripts, command-line arguments, control files, or job control language. A given batch job may depend on the completion of preceding jobs, or on the availability of certain inputs, making the sequencing and scheduling of multiple jobs important, and incompatible with interactive processing.', 'Q: What are the benefits of batch computing?'), ('Q: Why should I use AWS Batch? AWS Batch handles job execution and compute resource management, allowing you to focus on developing applications or analyzing results instead of setting up and managing infrastructure. If you are considering running or moving batch workloads to AWS, you should consider using AWS Batch.', 'Q: What use cases is AWS Batch optimized for? AWS Batch is optimized for batch computing and applications that scale through the execution of multiple jobs in parallel. Deep learning, genomics analysis, financial risk models, Monte Carlo simulations, animation rendering, media transcoding, image processing, and engineering simulations are all excellent examples of batch computing applications. '), ('Q: What are the key features of AWS Batch? AWS Batch manages compute environments and job queues, allowing you to easily run thousands of jobs of any scale using Amazon EC2 and EC2 Spot. You simply define and submit your batch jobs to a queue. In response, AWS Batch chooses where to run the jobs, launching additional AWS capacity if needed. AWS Batch carefully monitors the progress of your jobs. When capacity is no longer needed, AWS Batch will remove it. AWS Batch also provides the ability to submit jobs that are part of a pipeline or workflow, enabling you to express any interdependencies that exist between them as you submit jobs.', 'Q: What types of batch jobs does AWS Batch support? AWS Batch supports any job that can executed as a Docker container. Jobs specify their memory requirements and number of vCPUs. \xa0'), ('Q: What is a Compute Resource? An AWS Batch Compute Resource is an EC2 instance.', 'Q: What is a Compute Environment? An AWS Batch Compute Environment is a collection of compute resources on which jobs are executed. AWS Batch supports two types of Compute Environments; Managed Compute Environments which are provisioned and managed by AWS and Unmanaged Compute Environments which are managed by customers. Unmanaged Compute Environments provide a mechanism to leverage specialized resources such as Dedicated Hosts, larger storage configurations, and Amazon EFS.'), ('Q: What is a Job Definition? A Job Definition describes the job to be executed, parameters, environmental variables, compute requirements, and other information that is used to optimize the execution of a job.\xa0Job Definitions are defined in advance of submitting a job and can be shared with others.', 'Q: What is the Amazon ECS Agent and how is it used by AWS Batch? AWS Batch uses Amazon ECS to execute containerized jobs and therefore requires the ECS Agent to be installed on compute resources within your AWS Batch Compute Environments. The ECS Agent is pre-installed in Managed Compute Environments.'), ('Q: How does AWS Batch make it easier to use EC2 Spot? AWS Batch Compute Environments can be comprised of EC2 Spot instances. When creating a Managed Compute Environment, simplify specify that you would like to use EC2 Spot and provide a percentage of On Demand pricing that you would like to bid and AWS Batch will take care of the rest. Unmanaged Compute Environments can also include Spot instances that you launch, including those launched by EC2 Spot Fleet.', 'Q. What is the pricing for AWS Batch? There is no additional charge for AWS Batch. You only pay for the AWS Resources (e.g. EC2 Instances) you create to store and run your batch jobs. '), ('Q. How do I get started? Follow the Getting Started Guide in our documentation to get started.  ', 'Q. What do I need to provision to get started? There is no need to manually launch your own compute resources in order to get started. The AWS Batch web console will guide you through the process of creating your first Compute Environment and Job Queue so that you can submit your first job. Resources within your compute environment will scale up as additional jobs are ready to run and scale down as the number of runnable jobs decreases. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/elasticbeanstalk/faqs/': [('Q: What is AWS Elastic Beanstalk? AWS Elastic Beanstalk makes it even easier for developers to quickly deploy and manage applications in the AWS Cloud. Developers simply upload their application, and Elastic Beanstalk automatically handles the deployment details of capacity provisioning, load balancing, auto-scaling, and application health monitoring.', 'Q: Who should use AWS Elastic Beanstalk? Those who want to deploy and manage their applications within minutes in the AWS Cloud. You don’t need experience with cloud computing to get started. AWS Elastic Beanstalk supports Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker\xa0web applications.'), ('Q: Which languages and development stacks does AWS Elastic Beanstalk support? AWS Elastic Beanstalk supports the following languages and development stacks:', 'See Supported Platforms for a complete, up-to-date list of supported language and development stacks. '), ('Q: Will AWS Elastic Beanstalk support other languages? Yes. AWS Elastic Beanstalk is designed so that it can be extended to support multiple development stacks and programming languages in the future. AWS is working with solution providers on the APIs and capabilities needed to create additional Elastic Beanstalk offerings.', 'Q: What can developers now do with AWS Elastic Beanstalk that they could not before? AWS Elastic Beanstalk automates the details of capacity provisioning, load balancing, auto scaling, and application deployment, creating an environment that runs a version of your application. You can simply upload your deployable code (e.g., WAR file), and AWS Elastic Beanstalk does the rest. The AWS Toolkit for Visual Studio and the AWS Toolkit for Eclipse allow you to deploy your application to AWS Elastic Beanstalk and manage it without leaving your IDE. Once your application is running, Elastic Beanstalk automates management tasks–such as monitoring, application version deployment, a basic health check–and facilitates log file access. By using Elastic Beanstalk, developers can focus on developing their application and are freed from deployment-oriented tasks, such as provisioning servers, setting up load balancing, or managing scaling.'), ('Q: How is AWS Elastic Beanstalk different from existing application containers or platform-as-a-service solutions? Most existing application containers or platform-as-a-service solutions, while reducing the amount of programming required, significantly diminish developers’ flexibility and control. Developers are forced to live with all the decisions predetermined by the vendor–with little to no opportunity to take back control over various parts of their application’s infrastructure. However, with AWS Elastic Beanstalk, developers retain full control over the AWS resources powering their application. If developers decide they want to manage some (or all) of the elements of their infrastructure, they can do so seamlessly by using Elastic Beanstalk’s management capabilities.', 'Q: What elements of my application can I control when using AWS Elastic Beanstalk? With AWS Elastic Beanstalk, you can:'), ('Q: What are the Cloud resources powering my AWS Elastic Beanstalk application? AWS Elastic Beanstalk uses proven AWS features and services, such as Amazon EC2, Amazon RDS, Elastic Load Balancing, Auto Scaling, Amazon S3, and Amazon SNS, to create an environment that runs your application. The current version of AWS Elastic Beanstalk uses the Amazon Linux AMI or the Windows Server 2012 R2 AMI.', 'Q: What kinds of applications are supported by AWS Elastic Beanstalk? AWS Elastic Beanstalk supports Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker, and is ideal for web applications. However, due to Elastic Beanstalk’s open architecture, non-web applications can also be deployed using Elastic Beanstalk. We expect to support additional application types and programming languages in the future. See Supported Platforms to learn more. '), ('Q: Which operating systems does AWS Elastic Beanstalk use? AWS Elastic Beanstalk runs on the Amazon Linux AMI and the Windows Server 2012 R2 AMI. Both AMIs are supported and maintained by Amazon Web Services and are designed to provide a stable, secure, and high-performance execution environment for Amazon EC2 Cloud computing.', 'Q: How quickly will my application start running? It typically takes a few minutes to create the AWS resources to run your application, measured from the time you upload your application version (e.g., WAR file, ASP.NET files, Node.js files, PHP files, Python files, or Ruby files) to when it is fully deployed and accessible to your users. This time is dependent on a number of factors, including the size of your deployable code and the number of application servers you are deploying.'), ('Q: How quickly will my application get updated? Deploying new application versions to existing resources (e.g., environments) happens much faster (typically under a minute) and is mostly dependent on the size of the new application version. ', 'Q: How quickly can my application scale up and down? AWS Elastic Beanstalk provides a truly elastic environment using Auto Scaling. Your application can be configured to automatically scale tens or even hundreds of times based on thresholds, such as CPU utilization or network bandwidth. These thresholds can be easily configured for your specific application using the Elastic Beanstalk console. With Elastic Beanstalk, you don’t have to worry if you will be able to scale quickly to handle peaks in traffic or users, nor if you will be forced to pay for resources that you don’t need.'), ('Q: Can I have multiple versions of my application running at the same time? Yes. AWS Elastic Beanstalk is designed to support multiple running environments, such as one for integration testing, one for pre-production, and one for production. Each environment is independently configured and runs on its own separate AWS resources. Elastic Beanstalk also stores and tracks application versions over time, so an existing environment can be easily rolled back to a prior version or a new environment can be launched using an older version to try and reproduce a customer problem.', 'Q: How many applications can I run with AWS Elastic Beanstalk? You can create up to 75 applications and 1,000 application versions. By default, you can run up to 200 environments across all of your applications. If you are also using AWS outside of AWS Elastic Beanstalk, you may not be able to create 10 environments since other limits may be hit sooner. For example, the default AWS account limits allow you to launch up to 20 EC2 instances and create up to 10 elastic load balancers. If you need more resources, complete the AWS Elastic Beanstalk request form, and your request will be promptly evaluated.'), ('Q: Can I use AWS Elastic Beanstalk to deploy applications that must be highly available? Yes. To do this, you edit your environment configuration settings, select 2 or more instances for Auto Scaling minimum, and set Multiple Availability Zones to “Any 2”. AWS Availability Zones are designed to be physically distinct, fail independently, and be reliable.', 'Q: What happens if my application stops responding to requests? AWS Elastic Beanstalk applications are protected against failures in the underlying infrastructure. If an Amazon EC2 instance fails for any reason, AWS Elastic Beanstalk will use Auto Scaling to automatically launch a new instance. Elastic Beanstalk can also detect if your application is not responding on the custom URL even though the underlying infrastructure appears healthy, and will log that as an environment event (e.g., a bad version was deployed) so you can take appropriate action.'), ('Q: Which AWS Regions is AWS Elastic Beanstalk available in?', 'Please refer to Regional Products and Services for details of Elastic Beanstalk availability by Region.'), ('Q: How do I access AWS Elastic Beanstalk? You can use the AWS Management Console, the AWS Elastic Beanstalk command line interface (CLI), the AWS Toolkit for Visual Studio, the AWS Toolkit for Eclipse, the AWS Elastic Beanstalk API, or AWS SDKs. ', 'Q: Can I use an integrated development environment, like Eclipse or Microsoft Visual Studio? Yes. You can use Eclipse and Visual Studio to deploy your application to AWS Elastic Beanstalk. You can use the AWS Toolkit for Eclipse for Java applications and the AWS Toolkit for Visual Studio for .NET applications. The toolkits allow you to develop your application, deploy it to Elastic Beanstalk, and even test it out without having to switch your focus away from your IDE.'), ('\xa0', 'Q: How do I sign up for AWS Elastic Beanstalk?'), ('To sign up for AWS Elastic Beanstalk, choose the Sign Up Now button on the Elastic Beanstalk detail page. You must have an Amazon Web Services account to access this service; if you do not already have one, you will be prompted to create one when you begin the Elastic Beanstalk process. After signing up, please refer to the AWS Elastic Beanstalk Getting Started Guide.', 'Q: Why am I asked to verify my phone number when signing up for AWS Elastic Beanstalk?'), ('AWS Elastic Beanstalk registration requires you to have a valid phone number and email address on file with AWS in case we ever need to contact you. Verifying your phone number takes only a few minutes and involves receiving an automated phone call during the registration process and entering a PIN number using the phone key pad.', 'Q: How do I get started after I have signed up?'), ('The best way to get started with AWS Elastic Beanstalk is to work through the AWS Elastic Beanstalk Getting Started Guide, part of our technical documentation. Within a few minutes, you will be able to deploy and use a sample application or upload your own application.', 'Q: Is there a sample application that I can use to check out AWS Elastic Beanstalk?'), ('Yes. AWS Elastic Beanstalk includes a sample application that you can use to test drive the offering and explore its functionality.', 'Q: Does AWS Elastic Beanstalk store anything in Amazon S3?'), ('Yes. AWS Elastic Beanstalk stores your application files and, optionally, server log files in Amazon S3. If you are using the AWS Management Console, the AWS Toolkit for Visual Studio, or AWS Toolkit for Eclipse, an Amazon S3 bucket will be created in your account for you and the files you upload will be automatically copied from your local client to Amazon S3. Optionally, you may configure Elastic Beanstalk to copy your server log files every hour to Amazon S3. You do this by editing the environment configuration settings.', 'Q: Can I use Amazon S3 to store application data, like images?'), ("Yes. You can use Amazon S3 for application storage. The easiest way to do this is by including the AWS SDK as part of your application’s deployable file. For example, you can include the AWS SDK for Java as part of your application's WAR file.", 'Q: What database solutions can I use with AWS Elastic Beanstalk?'), ('AWS Elastic Beanstalk does not restrict you to any specific data persistence technology. You can choose to use Amazon Relational Database Service (Amazon RDS) or Amazon DynamoDB, or use Microsoft SQL Server, Oracle, or other relational databases running on Amazon EC2.', 'Q: How do I set up a database for use with AWS Elastic Beanstalk?'), ('Elastic Beanstalk can automatically provision an Amazon RDS DB instance. The information about connectivity to the DB instance is exposed to your application by environment variables. To learn more about how to configure RDS DB instances for your environment, see the Elastic Beanstalk Developer Guide.', 'Q: Does this mean I need to modify the application code when moving from test to production?'), ('Not with AWS Elastic Beanstalk. With Elastic Beanstalk, you can specify the connection information in the environment configuration. By extracting the connection string from the application code, you can easily configure different Elastic Beanstalk environments to use different databases.', 'Q: How do I make my application private?'), ('By default, your application is available publicly at myapp.elasticbeanstalk.com for anyone to access. You can use Amazon VPC to provision a private, isolated section of your application in a virtual network that you define. This virtual network can be made private through specific security group rules, network ACLs, and custom route tables. You can also easily control what other incoming traffic, such as SSH, is delivered or not to your application servers by changing the EC2 security group settings.', 'Q: Can I run my application inside a Virtual Private Cloud (VPC)?'), ('Yes, you can run your applications in a VPC. For more details, see the AWS Elastic Beanstalk Developer Guide.', 'Q: Where can I find more information about security and running applications on AWS?'), ('For more information about security on AWS, please refer to our Amazon Web Services: Overview of Security Processes document and visit our Security Center.', 'Q: Is it possible to use Identity & Access Management (IAM) with AWS Elastic Beanstalk?'), ('Yes. IAM users with the appropriate permissions can now interact with AWS Elastic Beanstalk.', 'Q: Why should I use IAM with AWS Elastic Beanstalk?'), ('IAM allows you to manage users and groups in a centralized manner. You can control which IAM users have access to AWS Elastic Beanstalk, and limit permissions to read-only access to Elastic Beanstalk for operators who should not be able to perform actions against Elastic Beanstalk resources. All user activity within your account will be aggregated under a single AWS bill.', 'Q: How do I create IAM users?'), ('You can use the IAM console, IAM command line interface (CLI), or IAM API to provision IAM users. By default, IAM users have no access to AWS services until permissions are granted.', 'Q: How do I grant an IAM user access to AWS Elastic Beanstalk?'), ('You can grant IAM users access to services by using policies. To simplify the process of granting access to AWS Elastic Beanstalk, you can use one of the policy templates in the IAM console to help you get started. Elastic Beanstalk offers two templates: a read-only access template and a full-access template. The read-only template grants read access to Elastic Beanstalk resources. The full-access template grants full access to all Elastic Beanstalk operations, as well as permissions to manage dependent resources, such as Elastic Load Balancing, Auto Scaling, and Amazon S3. You can also use the AWS Policy Generator to create custom policies. For more details, see the AWS Elastic Beanstalk Developer Guide.', 'Q: Can I restrict access to specific AWS Elastic Beanstalk resources?'), ('Yes. You can allow or deny permissions to specific AWS Elastic Beanstalk resources, such as applications, application versions, and environments.', 'Q: Who gets billed for the AWS resources that an IAM user creates?'), ('All resources created by IAM users under a root account are owned and billed to the root account.', 'Q: Who has access to an AWS Elastic Beanstalk environment launched by an IAM user?'), ('The root account has full access to all AWS Elastic Beanstalk environments launched by any IAM user under that account. If you use the Elastic Beanstalk template to grant read-only access to an IAM user, that user will be able to view all applications, application versions, environments, and any associated resources in that account. If you use the Elastic Beanstalk template to grant full access to an IAM user, that user will be able to create, modify, and terminate any Elastic Beanstalk resources under that account.', 'Q: Can an IAM user access the AWS Elastic Beanstalk console?'), ('Yes. An IAM user can access the AWS Elastic Beanstalk console using their username and password.', 'Q: Can an IAM user call the AWS Elastic Beanstalk API?'), ('Yes. An IAM user can use their access key and secret key to perform operations using the Elastic Beanstalk API.', 'Q: Can an IAM user use the AWS Elastic Beanstalk command line interface?'), ('Yes. An IAM user can use their access key and secret key to perform operations using the AWS Elastic Beanstalk command line interface (CLI).', 'Q: How can I keep the underlying platform of the environment running my application automatically up-to-date?'), ('You can opt-in to having your AWS Elastic Beanstalk environments automatically updated to the latest version of the underlying platform running your application during a specified maintenance window. Elastic Beanstalk regularly releases new versions of supported platforms (Java, PHP, Ruby, Node.js, Python, .NET, Go, and Docker) with operating system, web and application server, and language and framework updates.', 'Q: How can I get started with managed platform updates?'), ('To let Elastic Beanstalk automatically manage your platform updates, you must enable managed platform updates in the Configuration tab of the Elastic Beanstalk console or use the EB CLI or API. After you have enabled the feature, you can configure which types of updates to allow and when updates can occur.', 'Q: What kinds of platform version updates will managed platform updates apply?'), ('AWS Elastic Beanstalk can automatically perform platform updates for new patch and minor platform versions. Elastic Beanstalk will not automatically perform major platform version updates (e.g., Java 7 Tomcat 7 to Java 8 Tomcat 8) because they include backwards incompatible changes and require additional testing. In these cases, you must manually initiate the update.', 'Q: How does AWS Elastic Beanstalk distinguish between “major,” “minor,” and “patch” version releases?'), ('AWS Elastic Beanstalk platforms are versioned using this pattern: MAJOR.MINOR.PATCH (e.g., 2.0.0). Each portion is incremented as follows:', 'Q: When and how can I perform major version updates?'), ('You can perform major version updates at any time using the AWS Elastic Beanstalk management console, API, or CLI. You have the following options to perform a major version update:', 'Q: How does Elastic Beanstalk apply managed platform updates?'), ('The updates are applied using an immutable deployment mechanism that ensures that no changes are made to the existing environment until a parallel fleet of Amazon EC2 instances, with the updates installed, is ready to be swapped with the existing instances, which are then terminated. In addition, if the Elastic Beanstalk health system detects any issues during the update, traffic is redirected to the existing fleet of instances, ensuring minimal impact to end users of your application.', 'Q: Will my application be available during the maintenance windows?'), ('Since managed platform updates use an immutable deployment mechanism to perform the updates, your application will be available during the maintenance window and consumers of your application will not be impacted by the update.', 'Q: What does it cost to use managed platform updates?'), ('There is no additional charge for the managed platform updates feature. You simply pay for the additional EC2 instances necessary to perform the update for the duration of the update.', 'Q: What is a maintenance window?'), ('A maintenance window is a weekly two-hour-long time slot during which AWS Elastic Beanstalk will initiate platform updates if managed platform updates is enabled and a new version of the platform is available. For example, if you select a maintenance window that begins every Sunday at 2 AM, AWS Elastic Beanstalk will initiate the platform update sometime between 2-4 AM every Sunday. It is important to note that, depending on the configuration of your applications, updates could complete outside of the maintenance window.', 'The maintenance window is set on a per-environment basis, providing you the option to set different maintenance windows for your various application components or applications. This allows environment updates to be staggered if you do not want multiple pieces of your application to be updated at the same time. If you enable managed platform updates but do not specify a maintenance window, a default weekly 2-hour window will be assigned for your environment. If you want to change when maintenance is performed on your behalf, you can do so by modifying the managed update configuration in the AWS Management Console or by using the UpdateEnvironment API.'), ('Q: How will I be notified of the availability of new platform versions?', 'You will be notified about the availability of new platform versions through the AWS Management Console, forum announcements, and release notes.'), ('Q: Where can I find details of changes between platform versions?', 'Details on changes between platform versions can be found on the AWS Elastic Beanstalk Release Notes page.'), ('Q: What operations can I perform on the environment while a managed update is in progress?', 'The only action available to you while a managed platform update is in-progress is ‘abort’. This will allow you to stop the update immediately and roll back to the previous version.'), ('Q: Which platform version will my environment be updated to if there are multiple new versions released in between maintenance windows?', 'Your environment will always be updated to the latest version available based on the level (minor plus patch or patch only) you have selected.'), ('Q: Where can I find details of all the managed platform updates that have been performed on my environment?', 'Details for every managed platform update are available on the events page and are tagged with an event type of “MAINTENANCE.”'), ('Q: How often are platform version updates released?', 'The number of version releases in a given year varies based on the frequency and content of releases and patches from the language/framework’s vendor or core team, and the outcome of a thorough vetting of these releases and patches by our platform engineering team.'), ('Q: How much does AWS Elastic Beanstalk cost?', 'There is no additional charge for AWS Elastic Beanstalk–you pay only for the AWS resources actually used to store and run your application. New AWS customers who are eligible for the AWS Free Tier may deploy an application that runs within the Free Tier using the default settings of Elastic Beanstalk.'), ('Q: How much do the AWS resources powering my application on AWS Elastic Beanstalk cost?', 'You pay only for what you use, and there is no minimum fee for the use of any AWS resources. For Amazon EC2 pricing information, please visit the pricing section on the EC2 detail page. For Amazon S3 pricing information, please visit the pricing section on the S3 detail page. You can use the AWS simple calculator to estimate your bill for different application sizes.'), ('Q: How do I check how many AWS resources have been used by my application and access my bill?', 'You can view your charges for the current billing period at any time on the Amazon Web Services web site by logging into your Amazon Web Services account and choosing Account Activity under Your Web Services Account.'), ('Q: Does AWS Support cover AWS Elastic Beanstalk?', 'Yes. AWS Support covers issues related to your use of AWS Elastic Beanstalk. For further details and pricing, see the AWS Support page.'), ('Q: What other support options are available?', 'You can tap into the breadth of existing AWS community knowledge to help you with your development through the AWS Elastic Beanstalk discussion forum.\xa0'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/lambda/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/autoscaling/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/elasticloadbalancing/faqs/': [('Q: How do I decide which load balancer to select for my application?', 'Elastic Load Balancing supports three types of load balancers. You can select the appropriate load balancer based on your application needs. If you need flexible application management and TLS termination then we recommend you to use Application Load Balancer. If extreme performance and static IP is needed for your application then we recommend you to use Network Load Balancer. If your application is built within the EC2 Classic network then you should use Classic Load Balancer.'), ('Q: Can I privately access Elastic Load Balancing APIs from my Amazon Virtual Private Cloud (VPC) without using public IPs?', 'Yes, you can privately access Elastic Load Balancing APIs from your Amazon Virtual Private Cloud (VPC) by creating VPC Endpoints. With VPC Endpoints, the routing between the VPC and Elastic Load Balancing APIs is handled by the AWS network without the need for an Internet gateway, NAT gateway, or VPN connection. The latest generation of VPC Endpoints used by Elastic Load Balancing are powered by AWS PrivateLink, an AWS technology enabling the private connectivity between AWS services using Elastic Network Interfaces (ENI) with private IPs in your VPCs. To learn more about AWS PrivateLink, visit the AWS PrivateLink documentation. \xa0'), ('Q: Which operating systems does an Application Load Balancer support? An Application Load Balancer supports targets with any operating system currently supported by the Amazon EC2 service.', 'Q: Which protocols does an Application Load Balancer support? An Application Load Balancer supports load balancing of applications using HTTP and HTTPS (Secure HTTP) protocols.'), ('Q: Is HTTP/2 Supported on an Application Load Balancer? Yes. HTTP/2 support is enabled natively on an Application Load Balancer. Clients that support HTTP/2 can connect to an Application Load Balancer over TLS.', 'Q: What TCP ports can I use to load balance? You can perform load balancing for the following TCP ports: 1-65535'), ('Q: Is WebSockets supported on an Application Load Balancer? Yes. WebSockets and Secure WebSockets support is available natively and ready for use on an Application Load Balancer.', 'Q: Is Request tracing supported on an Application Load Balancer? Yes. Request tracing is enabled by default on your Application Load Balancer.'), ('Q: Will my existing load balancers (Classic Load Balancers) have the same features and benefits of an Application Load Balancer?  While there is some overlap, we do not plan to maintain feature parity between the two types of load balancers. Application Load Balancers are the foundation of our application layer load-balancing platform for the future.', 'Q: Can I configure my Amazon EC2 instances to accept traffic only from my Application Load Balancers? Yes.'), ('Q: Can I configure a security group for the front-end of an Application Load Balancer? Yes.', 'Q: Can I use the existing APIs that I use with my Classic Load Balancer with an Application Load Balancer?  No. Application Load Balancers require a new set of APIs.'), ('Q: How do I manage both Application and Classic Load Balancers simultaneously?\xa0 The ELB Console will allow you to manage Application and Classic Load Balancers from the same interface. If you are using the CLI or an SDK, you will use a different ‘service’ for Application Load Balancers. For example, in the CLI you will describe your Classic Load Balancers using `aws elb describe-load-balancers` and your Application Load Balancers using `aws elbv2 describe-load-balancers`.', 'Q: Can I convert my Classic Load Balancer to an Application Load Balancer (and vice versa)? No, you cannot convert one load balancer type into another.'), ('Q: How do I migrate to an Application Load Balancer? Attach the same back-end instances to both a Classic Load Balancer and an Application Load Balancer simultaneously. This allows you to migrate traffic from one endpoint to another without altering their existing stack. Be sure to test the behavior of the application on the new platform before changing DNS to point to the Application Load Balancer.', 'Q: Can I use an Application Load Balancer as a Layer-4 load balancer? No. If you need Layer-4 features, you should use Network Load Balancer.'), ('Q: Can I use a single Application Load Balancer for handling HTTP and HTTPS requests? Yes, you can add listeners for HTTP port 80 and HTTPS port 443 to a single Application Load Balancer.   Q: Can I get a history of Application Load Balancing API calls made on my account for security analysis and operational troubleshooting purposes? Yes. To receive a history of Application Load Balancing API calls made on your account, use AWS CloudTrail.', 'Q: Does an Application Load Balancer support HTTPS termination? Yes, you can terminate HTTPS connection on the Application Load Balancer. You must install an SSL certificate on your load balancer. The load balancer uses this certificate to terminate the connection and then decrypt requests from clients before sending them to targets.'), ('Q: What are the steps to get a SSL certificate? You can either use AWS Certificate Manager to provision an SSL/TLS certificate or you can obtain the certificate from other sources by creating the certificate request, getting the certificate request signed by a CA, and then uploading the certificate either using AWS Certification Manager or the\xa0AWS Identity and Access Management (IAM) service.', 'Q: How does an Application Load Balancer integrate with AWS Certificate Manager (ACM)? An Application Load Balancer is integrated with AWS Certificate Management (ACM). Integration with ACM makes it very simple to bind a certificate to the load balancer thereby making the entire SSL offload process very easy. Purchasing, uploading, and renewing SSL/TLS certificates is a time-consuming manual and complex process. With ACM integration with Application Load Balancer, this whole process has been shortened to simply requesting a trusted SSL/TLS certificate and selecting the ACM certificate to provision it with the load balancer.'), ('Q: Is back-end server authentication supported with an Application Load Balancer? No, only encryption is supported to the back-ends with an Application Load Balancer.', 'Q: How can I enable Server Name Indication (SNI) for my Application Load Balancer? SNI is automatically enabled when you associate more than one TLS certificate with the same secure listener on a load balancer. Similarly, SNI mode for a secure listener is automatically disabled when you have only one certificate associated to a secure listener.'), ('Q: Can I associate multiple certificates for the same domain to a secure listener? Yes, you can associate multiple certificates for the same domain to a secure listener. For example, you can asoociate (a) ECDSA and RSA certificates (b) Certificates with different key sizes (e.g. 2K and 4K) for SSL/TLS certificates (c) Single-Domain, Multi-Domain (SAN) and Wildcard certificates ', 'Q: Is IPv6 supported with an Application Load Balancer? Yes, IPv6 is supported with an Application Load Balancer. '), ('Q: How do you set up rules on an Application Load Balancer? You can configure rules for each of your listeners you configure for the load balancer. The rules include a condition and a corresponding action if the condition is satisfied. The condition will be a path URL path of a service (e.g. /img) and action is forward. Once you have set this up, the load balancer will use the rules to determine the service to which the request must be routed.', 'Q: Are there limits on the resources for an Application Load Balancer? Your AWS account has these limits for an Application Load Balancer.'), ('Q. How can I protect my web applications behind a load balancer from web attacks? You can integrate your Application Load Balancer with AWS WAF, a web application firewall that helps protect web applications from attacks by allowing you to configure rules based on IP addresses, HTTP headers, and custom URI strings. Using these rules, AWS WAF can block, allow, or monitor (count) web requests for your web application. Please see AWS WAF Developer Guide for more information.', 'Q: Can I load balance to any arbitrary IP address? You can use any IP address from the load balancer’s VPC CIDR for targets within load balancer’s VPC and any IP address from RFC 1918 ranges (10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0/16) or RFC 6598 range (100.64.0.0/10) for targets located outside the load balancer’s VPC (for example, targets in Peered VPC, EC2-Classic and on-premises locations reachable over AWS Direct Connect or VPN connection).'), ('Q: How can I load balance applications distributed across a VPC and on-premises location? There are various ways to achieve hybrid load balancing. If an application runs on targets distributed between a VPC and an on-premises location, you can add them to the same target group using their IP addresses. To migrate to AWS without impacting your application, gradually add VPC targets to the target group and remove on-premises targets from the target group. If you have two different applications such that the targets for one application are in a VPC and the targets for other applications are in on-premises location, you can put the VPC targets in one target group and the on-premises targets in another target group and use content based routing to route traffic to each target group. You can also use separate load balancers for VPC and on-premises targets and use DNS weighting to achieve weighted load balancing between VPC and on-premises targets. ', "Q: How can I load balance to EC2-Classic instances? You cannot load balance to EC2-Classic Instances when registering their Instance IDs as targets. However if you link these EC2-Classic instances to the load balancer's VPC using ClassicLink and use the private IPs of these EC2-Classic instances as targets, then you can load balance to the EC2-Classic instances. If you are using EC2 Classic instances today with a Classic Load Balancer, you can easily migrate to an Application Load Balancer. "), ('Q: How does Application Load Balancer pricing work? You are charged for each hour or partial hour that an Application Load Balancer is running and the number of Load Balancer Capacity Units (LCU) used per hour.', 'Q: What is a Load Balancer Capacity Unit (LCU)? An LCU is a new metric for determining how you pay for an Application Load Balancer. An LCU defines the maximum resource consumed in any one of the dimensions (new connections, active connections, bandwidth and rule evaluations) the Application Load Balancer processes your traffic.'), ('Q: Will I be billed on Classic Load Balancers by LCU? No, Classic Load Balancers will continue to be billed for bandwidth and hourly usage.', 'Q: How do I know the number of LCUs an Application Load Balancer is using? We expose the usage of all four dimensions that constitute an LCU via CloudWatch.'), ('Q: Will I be billed on all the dimensions in an LCU? No. The number of LCUs per hour will be determined based on maximum resource consumed amongst the four dimensions that constitutes a LCU.', 'Q: Will I be billed on partial LCUs? Yes.'), ('Q: Is a free tier offered on an Application Load Balancer for new AWS accounts? Yes. For new AWS accounts, a free tier for an Application Load Balancer offers 750 hours and 15 LCUs. This free tier offer is only available to new AWS customers, and is available for 12 months following your AWS sign-up date. ', 'Q: Can I use a combination of Application Load Balancer and Classic Load Balancer as part of my free tier? Yes. You can use both Classic and Application Load Balancers for 15GB and 15 LCUs respectively. The 750 load balancer hours are shared between both Classic and Application Load Balancers.'), ('Q: What are rule evaluations? Rule evaluations are defined as the product of number of rules processed and the request rate averaged over an hour.', 'Q: How does the LCU billing work with different certificate types and key sizes? Certificate key size affects only the number of new connections per second in the LCU computation for billing. The following table lists the value of this dimension for different key sizes for RSA and ECDSA certificates.\xa0'), ('Q: Can I create a TCP (Layer 4) listener for my Network Load Balancer?', 'Yes. Network Load Balancers support only TCP (Layer 4) listeners.'), ('Q: What are the key features available with the Network Load Balancer?', 'Network Load Balancer provides TCP (Layer 4) load balancing. It is architected to handle millions of requests/sec, sudden volatile traffic patterns and provides extremely low latencies. In addition Network Load Balancer also preserves the source IP of the clients, provides stable IP support and Zonal isolation. It also supports long-running connections that are very useful for WebSocket type applications.'), ('Q: How does Network Load Balancer compare to what I get with the TCP listener on a Classic Load Balancer?', 'Network Load Balancer preserves the source IP of the client which in the Classic Load Balancer is not preserved. Customers can use proxy protocol with Classic Load Balancer to get the source IP. Network Load Balancer automatically provides a static IP per Availability Zone to the load balancer and also enables assigning an Elastic IP to the load balancer per Availability Zone. This is not supported with Classic Load Balancer. Classic Load Balancer provides SSL termination that is not available with Network Load Balancer. '), ('Q: How do I migrate to a Network Load Balancer from Classic Load Balancer?', 'Attach the same back-end targets to both a Classic Load Balancer and a Network Load Balancer simultaneously. This allows you to migrate traffic from one endpoint to another without altering their existing stack. Be sure to test the behavior of the application on the new platform before changing DNS to point to the Network Load Balancer.'), ('Q: Are there limits on the resources for my Network Load Balancer?', 'Yes, please refer to Network Load Balancer limits documentation for more information.'), ('Q: Can I use the AWS Management Console to set up my Network Load Balancer?', 'Yes, you can use the AWS Management Console, AWS CLI, or the API to set up a Network Load Balancer.'), ('Q: Can I use the existing API for Classic Load Balancers for my Network Load Balancers?', 'No. To create a Classic Load Balancer, use the 2012-06-01 API. To create a Network Load Balancer or an Application Load Balancer, use the 2015-12-01 API.'), ('Q: Can I create my Network Load Balancer in a single Availability Zone?', 'Yes, you can create your Network Load Balancer in a single availability zone by providing a single subnet when you create the load balancer.'), ('Q: Does Network Load Balancer support DNS regional and zonal fail-over?', 'Yes, you can use Amazon Route 53 health checking and DNS failover features to enhance the availability of the applications running behind Network Load Balancers. Using Route 53 DNS failover, you can run applications in multiple AWS Availability zones and designate alternate load balancers for failover across regions. In the event that you have your Network Load Balancer configured for multi-AZ, if there are no healthy EC2 instances registered with the load balancer for that Availability Zone or if the load balancer nodes in a given zone are unhealthy, then R-53 will fail away to alternate load balancer nodes in other healthy availability zones.'), ('Q: Can I have a Network Load Balancer with a mix of ELB-provided IPs and Elastic IPs or assigned private IPs?', 'No. A Network Load Balancer’s addresses must be completely controlled by you, or completely controlled by ELB. This is to ensure that when using Elastic IPs with a Network Load Balancer, all addresses known to your clients do not change.'), ('Q: Can I assign more than one EIP to my NLB in each subnet?', 'No. For each associated subnet that a NLB is in, the NLB can only support a single public/internet facing IP address'), ('Q: If I remove/delete a Network Load Balancer what will happen to the Elastic IP addresses that were associated with it?', 'The Elastic IP Addresses that were associated with your load balancer will be returned to your allocated pool and made available for future use.'), ('Q: Does NLB support internal load balancers?', 'NLB can be set-up as an internet-facing load balancer or an internal load balancer similar to what is possible with Application Load Balancer and Classic Load Balancer.'), ('Q: Can the internal Network Load balancer support more than one private IP in each subnet?', 'No. For each associated subnet that a load balancer is in, the NLB can only support a single private IP.'), ('Q: Can I set up Websockets with my Network Load Balancer?', 'Yes, configure TCP listeners that route the traffic to the targets that implement WebSockets protocol (https://tools.ietf.org/html/rfc6455 ). Because WebSockets is a layer 7 protocol and Network Load Balancer is operating at layer 4, no special handling exists in Network Load Balancer for WebSockets or other higher level protocols.'), ('Q: Can I load balance to any arbitrary IP address?', 'You can use any IP address from the load balancer’s VPC CIDR for targets within load balancer’s VPC and any IP address from RFC 1918 ranges (10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0/16) or RFC 6598 range (100.64.0.0/10) for targets located outside the load balancer’s VPC (EC2-Classic and on-premises locations reachable over AWS Direct Connect).'), ('Q: What benefit will I get by targeting containers behind a load balancer with IP addresses instead of instance IDs?', 'Each container on an instance can now have its own security group and does not need to share security rules with other containers. You can attach security groups to an ENI and each ENI on an instance can have a different security group. You can map a container to the IP address of a particular ENI to associate security group(s) per container. Load balancing using IP addresses also allows multiple containers running on an instance use the same port (say port 80). The ability to use the same port across containers allows containers on an instance to communicate with each other through well-known ports instead of random ports.'), ('Q: How can I load balance applications distributed across a VPC and on-premises location?', 'There are various ways to achieve hybrid load balancing. If an application runs on targets distributed between a VPC and an on-premises location, you can add them to the same target group using their IP addresses. To migrate to AWS without impacting your application, gradually add VPC targets to the target group and remove on-premises targets from the target group.You can also use separate load balancers for VPC and on-premises targets and use DNS weighting to achieve weighted load balancing between VPC and on-premises targets.'), ('Q: How can I load balance to EC2-Classic instances?', "You cannot load balance to EC2-Classic Instances when registering their Instance IDs as targets. However if you link these EC2-Classic instances to the load balancer's VPC using ClassicLink and use the private IPs of these EC2-Classic instances as targets, then you can load balance to the EC2-Classic instances. If you are using EC2 Classic instances today with a Classic Load Balancer, you can easily migrate to a Network Load Balancer."), ('Q:How does Network Load Balancer pricing work?', 'You are charged for each hour or partial hour that a Network Load Balancer is running and the number of Load Balancer Capacity Units (LCU) used by Network Load Balancer per hour.'), ('Q: What is a Load Balancer Capacity Unit (LCU)?', 'An LCU is a new metric for determining how you pay for a Network Load Balancer. An LCU defines the maximum resource consumed in any one of the dimensions (new connections/flows, active connections/flows, and bandwidth) the Network Load Balancer processes your traffic.'), ('Q: Is new connections/flows per sec same as requests/sec?', 'No. Multiple requests can be sent in a single connection.'), ('Q: Will I be billed on Classic Load Balancers by LCU?', 'No. Classic Load Balancers will continue to be billed for bandwidth and hourly charge'), ('Q: How do I know the number of LCUs a Network Load Balancer is using?', 'We will expose the usage of all three dimensions that constitutes a LCU via Amazon CloudWatch.'), ('Q: Will I be billed on all the dimensions in an LCU?', 'No. The number of LCUs per hour will be determined based on maximum resource consumed amongst the three dimensions that constitutes a LCU.'), ('Q: Will I be billed on partial LCUs?', 'Yes.'), ('Q: Is a free tier offered on a Network Load Balancer for new AWS accounts?', 'Yes. For new AWS accounts, a free tier for a Network Load Balancer offers 750 hours and 15 LCUs. This free tier offer is only available to new AWS customers, and is available for 12 months following your AWS sign-up date.'), ('Q: Can I use a combination of Network Load Balancer, Application Load Balancer and Classic Load Balancer as part of my free tier?', 'Yes. You can use Application and Network each for 15 LCUs and Classic for 15 GB respectively. The 750 load balancer hours are shared between Application, Network and Classic Load Balancers.'), ('', 'Q: Which operating systems does the Classic Load Balancer support?'), ('The Classic Load Balancer supports Amazon EC2 instances with any operating system currently supported by the Amazon EC2 service.', 'Q: Which protocols does the Classic Load Balancer support? The Classic Load Balancer supports load balancing of applications using HTTP, HTTPS (Secure HTTP), SSL (Secure TCP) and TCP protocols.'), ('Q: What TCP ports can I load balance? You can perform load balancing for the following TCP ports:', 'Q: Does the Classic Load Balancer support IPv6 traffic? Yes. Each Classic Load Balancer has an associated IPv4, IPv6, and dualstack (both IPv4 and IPv6) DNS name. IPv6 is not supported in VPC. You can use an Application Load Balancer for native IPv6 support in VPC.'), ('Q: Can I configure my Amazon EC2 instances to only accept traffic from Classic Load Balancers? Yes.', 'Q: Can I configure a security group for the front-end of Classic Load Balancers? If you are using Amazon Virtual Private Cloud, you can configure security groups for the front-end of your Classic Load Balancers.'), ('Q: Can I use a single Classic Load Balancer for handling HTTP and HTTPS requests? Yes, you can map HTTP port 80 and HTTPS port 443 to a single Classic Load Balancer.', 'Q: How many connections will my load balanced Amazon EC2 instances need to accept from each Classic Load Balancer? Classic Load Balancers do not cap the number of connections that they can attempt to establish with your load balanced Amazon EC2 instances. You can expect this number to scale with the number of concurrent HTTP, HTTPS, or SSL requests or the number of concurrent TCP connections that the Classic load balancers receive.'), ('Q: Can I load balance Amazon EC2 instances launched using a Paid AMI? You can load balance Amazon EC2 instances launched using a paid AMI from AWS Marketplace. However, Classic Load Balancers do not support instances launched using a paid AMI from Amazon DevPay site. ', 'Q: Can I use Classic Load Balancers in Amazon Virtual Private Cloud? Yes -- see the Elastic Load Balancing web page. '), ('Q: Can I get a history of Classic Load Balancer API calls made on my account for security analysis and operational troubleshooting purposes? Yes. To receive a history of Classic Load Balancer API calls made on your account, simply turn on CloudTrail in the AWS Management Console.', 'Q: Do Classic Load Balancers support SSL termination? Yes you can terminate SSL on Classic Load Balancers. You must install an SSL certificate on each load balancer. The load balancers use this certificate to terminate the connection and then decrypt requests from clients before sending them to the back-end instances.  Q: What are the steps to get a SSL certificate? You can either use AWS Certificate Manager to provision a SSL/TLS certificate or you can obtain the certificate from other sources by creating the certificate request, getting the certificate request signed by a CA, and then uploading the certificate using the AWS Identity and Access Management (IAM) service.  Q: How do Classic Load Balancers integrate with AWS Certificate Manager (ACM)? Classic Load Balancers are now integrated with AWS Certificate Management (ACM). Integration with ACM makes it very simple to bind a certificate to each load balancer thereby making the entire SSL offload process very easy. Typically purchasing, uploading, and renewing SSL/TLS certificates is a time-consuming manual and complex process. With ACM integrated with Classic Load Balancers, this whole process has been shortened to simply requesting a trusted SSL/TLS certificate and selecting the ACM certificate to provision it with each load balancer. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/efs/faq/': [('General', 'Data Protection and Availability'), ('Scale and Performance', 'Access Control'), ('Encryption', 'On-premises Access'), ('EFS File Sync', 'Compatibility'), ('Pricing and Billing', 'Q. What is Amazon Elastic File System?'), ('Amazon EFS is a fully-managed service that makes it easy to set up and scale file storage in the Amazon cloud. With a few clicks in the AWS Management Console, you can create file systems that are accessible to Amazon EC2 instances via a file system interface (using standard operating system file I/O APIs) and that support full file system access semantics (such as strong consistency and file locking).', 'Amazon EFS file systems can automatically scale from gigabytes to petabytes of data without needing to provision storage. Tens, hundreds, or even thousands of Amazon EC2 instances can access an Amazon EFS file system at the same time, and Amazon EFS provides consistent performance to each Amazon EC2 instance. Amazon EFS is designed to be highly durable and highly available. With Amazon EFS, there is no minimum fee or setup costs, and you pay only for the storage you use.'), ('\xa0', 'Q. What use cases is Amazon EFS intended for?'), ('Amazon EFS is designed to provide performance for a broad spectrum of workloads and applications, including Big Data and analytics, media processing workflows, content management, web serving, and home directories.', '\xa0'), ('Q. When should I use Amazon EFS vs. Amazon Simple Storage Service (S3) vs. Amazon Elastic Block Store (EBS)?', 'Amazon Web Services (AWS) offers cloud storage services to support a wide range of storage workloads.'), ('Amazon EFS is a file storage service for use with Amazon EC2. Amazon EFS provides a file system interface, file system access semantics (such as strong consistency and file locking), and concurrently-accessible storage for up to thousands of Amazon EC2 instances. ', 'Amazon EBS is a block level storage service for use with Amazon EC2. Amazon EBS can deliver performance for workloads that require the lowest-latency access to data from a single EC2 instance.'), ('Amazon S3 is an object storage service. Amazon S3 makes data available through an Internet API that can be accessed anywhere.', '\xa0'), ('Q. What regions is Amazon EFS currently available in? ', 'Please refer to\xa0Regional Products and Services\xa0for details of Amazon EFS service availability by region.'), ('\xa0', 'Q. How do I get started using Amazon EFS?'), ('To use Amazon EFS, you must have an Amazon Web Services account. If you do not already have an AWS account, you can create one by clicking the “Try the Free Tier” button on the Amazon EFS detail page.', 'Once you have created an AWS account, please refer to the Amazon EFS Getting Started guide to begin using Amazon EFS. You can create a file system via the AWS Management Console, the AWS Command Line Interface (AWS CLI), and Amazon EFS API (and various language-specific SDKs).'), ('\xa0', 'Q. How do I access a file system from an Amazon EC2 instance?'), ('To access your file system, you mount the file system on an Amazon EC2 Linux-based instance using the standard Linux mount command and the file system’s DNS name. Once you’ve mounted, you can work with the files and directories in your file system just like you would with a local file system.', 'Amazon EFS uses the NFSv4.1 protocol. For a step-by-step example of how to access a file system from an Amazon EC2 instance, please see the Amazon EFS Getting Started guide.'), ('\xa0', 'Q. What Amazon EC2 instance types and AMIs work with Amazon EFS?'), ('Amazon EFS is compatible with all Linux-based AMIs for Amazon EC2. You can mix and match the instance types connected to a single file system. For a step-by-step example of how to access a file system from an Amazon EC2 instance, please see the Amazon EFS Getting Started guide.', '\xa0'), ('Q. How do I manage a file system?', 'Amazon EFS is a fully-managed service, so all of the file storage infrastructure is managed for you. When you use Amazon EFS, you avoid the complexity of deploying and maintaining complex file system infrastructure. An Amazon EFS file system grows and shrinks automatically as you add and remove files, so you do not need to manage storage procurement or provisioning.'), ('You can administer a file system via the AWS Management Console, the AWS command-line interface (CLI), or the Amazon EFS API (and various language-specific SDKs). The Console, API, and SDK provide the ability to create and delete file systems, configure how file systems are accessed, create and edit file system tags, and display detailed information about file systems.', '\xa0'), ('Q. How do I load data into a file system?', 'There are a number of methods for loading existing file system data into Amazon EFS, whether your existing file system data is located in AWS or in your on-premises servers.'), ('Amazon EFS file systems can be mounted on an Amazon EC2 instance, so any data that is accessible to an Amazon EC2 instance can also be read and written to Amazon EFS. To load file data that is not currently stored in AWS, you can use EFS File Sync to copy data directly to Amazon EFS.', 'For on-premises file systems, EFS File Sync provides a fast and simple way to securely sync existing file systems into Amazon EFS. EFS File Sync works over any network connection, including with AWS Direct Connect. AWS Direct Connect provides a high bandwidth and lower latency dedicated network connection, over which you can mount your EFS filesystems. You can also use standard Linux copy tools to move data files to Amazon EFS.'), ('For more information about accessing a file system from an on-premises server, please see the On-premises Access section of this FAQ.', 'For more information about moving data to the Amazon cloud, please see the Cloud Data Migration page.'), ('Q. How is Amazon EFS designed to provide high durability and availability?', 'Every file system object (i.e. directory, file, and link) is redundantly stored across multiple Availability Zones. In addition, a file system can be accessed concurrently from all Availability Zones in the region where it is located, which means that you can architect your application to failover from one AZ to other AZs in the region in order to ensure the highest level of application availability. Mount targets themselves are designed to be highly available.'), ('Q. How do I back up a file system?', 'Amazon EFS is designed to be highly durable. Using the EFS-to-EFS Backup solution, you can schedule automatic incremental backups of your Amazon EFS file system. For more information, please see the Amazon EFS Walkthrough: Backup Solutions for Amazon EFS File Systems.'), ('Q. How do I access my file system from outside my VPC?', 'Amazon EC2 instances within your VPC can access your file system directly, and Amazon EC2 Classic instances outside your VPC can mount a file system via\xa0ClassicLink.\xa0On-premises servers can mount your file systems via an AWS Direct Connect connection to your VPC.'), ('Q. How much data can I store?', 'Amazon EFS file systems can store petabytes of data. Amazon EFS file systems are elastic, and automatically grow and shrink as you add and remove files. You do not provision file system size or specify a size up front and you pay only for the storage you use.'), ('\xa0', 'Q. How many Amazon EC2 instances can connect to a file system?'), ('Amazon EFS supports one to thousands of Amazon EC2 instances connecting to a file system concurrently.', '\xa0'), ('Q. How many file systems can I create?', 'By default, you can create up to 10 file systems per AWS account per region. You can request to increase your file system limit by visiting AWS Service Limits.'), ('\xa0', 'Q. How does Amazon EFS performance compare to that of other storage solutions?'), ('Amazon EFS file systems are distributed across an unconstrained number of storage servers, enabling file systems to grow elastically to petabyte-scale and allowing massively parallel access from Amazon EC2 instances to your data. Amazon EFS’s distributed design avoids the bottlenecks and constraints inherent to traditional file servers.', 'This distributed data storage design means that multi-threaded applications and applications that concurrently access data from multiple Amazon EC2 instances can drive substantial levels of aggregate throughput and IOPS. Big Data and analytics workloads, media processing workflows, content management and web serving are examples of these applications.'), ('The table below compares high-level performance and storage characteristics for Amazon’s file and block cloud storage offerings.', " Amazon EFS’s distributed nature enables high levels of availability, durability, and scalability. This distributed architecture results in a small latency overhead for each file operation. Due to this per-operation latency, overall throughput generally increases as the average I/O size increases, since the overhead is amortized over a larger amount of data. Amazon EFS's support for highly parallelized workloads (i.e. with consistent operations from multiple threads and multiple EC2 instances) enables high levels of aggregate throughput and IOPS."), ('Q. What’s the difference between “General Purpose” and “Max I/O” performance modes? Which one should I choose?', '“General Purpose” performance mode is appropriate for most file systems, and is the mode selected by default when you create a file system. “Max I/O” performance mode is optimized for applications where tens, hundreds, or thousands of EC2 instances are accessing the file system — it scales to higher levels of aggregate throughput and operations per second with a tradeoff of slightly higher latencies for file operations. For more information, please see the documentation on File System Performance.'), ('\xa0', 'Q. How much throughput can a file system support?'), ('The throughput available to a file system scales as a file system grows. Because file-based workloads are typically spiky – requiring high levels of throughput for periods of time and lower levels of throughput the rest of the time – Amazon EFS is designed to burst to allow high throughput levels for periods of time. All file systems deliver a consistent baseline performance of 50 MB/s per TB of storage, all file systems (regardless of size) can burst to 100 MB/s, and file systems larger than 1TB can burst to 100 MB/s per TB of storage. As you add data to your file system, the maximum throughput available to the file system scales linearly and automatically with your storage.', 'File system throughput is shared across all Amazon EC2 instances connected to a file system. For example, a 1TB file system that can burst to 100MB/s of throughput can drive 100MB/s from a single Amazon EC2 instance, or 10 Amazon EC2 instances can collectively drive 100MB/s. For more information, please see the documentation on File System Performance.'), ('Q. How do I control which Amazon EC2 instances can access my file system?', 'When you create a file system, you create endpoints in your VPC called “mount targets.” When mounting from an EC2 instance, your file system’s DNS name, which you provide in your mount command, resolves to a mount target’s IP address.\xa0Only resources that can access a mount target can access your file system. You can control the network traffic to and from your file system mount targets using VPC security groups.'), ('\xa0', 'Q. How do I control who can access my file system?'), ('You can control who can administer your file system using AWS Identity and Access Management (IAM). You can control access to files and directories with POSIX-compliant user and group-level permissions.', 'Q: What is Amazon EFS Encryption?'), ('Amazon EFS seamlessly offers encryption of EFS file systems. Data is transparently encrypted while being written, and transparently decrypted while being read, so you don’t have to modify your applications. Encryption keys are managed by the AWS Key Management Service (KMS), eliminating the need to build and maintain a secure key management infrastructure.', '\xa0'), ('Q: What is the AWS Key Management Service (KMS)?', 'AWS KMS is a managed service that makes it easy for you to create and control the encryption keys used to encrypt your data. AWS Key Management Service is integrated with AWS services including Amazon EFS, Amazon EBS, and Amazon S3, to make it simple to encrypt your data with encryption keys that you manage. AWS Key Management Service is also integrated with AWS CloudTrail to provide you with logs of all key usage to help meet your regulatory and compliance needs. To learn more about KMS, visit the AWS Key Management Service product page.'), ('\xa0', 'Q: How do I enable encryption for my Amazon EFS file system?'), ('You can enable encryption for your EFS file system in the EFS console, or by using the AWS CLI or SDKs. When creating a new file system in the EFS console, click “Create File System” and click the checkbox to enable encryption. For more details, see the user documentation on Encryption.', '\xa0'), ('Q: Does encryption impact Amazon EFS performance?', 'Encrypting your data has a minimal effect on I/O latency and throughput. '), ('Q. How do I access an EFS file system from servers in my on-premises datacenter?', 'To access EFS file systems from on-premises, you must have an AWS Direct Connect connection between your on-premises datacenter and your Amazon VPC. AWS Direct Connect establishes a private network connection between your on-premises datacenter and AWS. If you do not already have an AWS Direct Connect connection, you can create one by following the instructions in the AWS Direct Connect user guide.'), ('You mount an EFS file system on your on-premises Linux server using the standard Linux mount command for mounting a file system via the NFSv4.1 protocol.', 'For more information about accessing EFS file systems from on-premises servers via AWS Direct Connect, please see the documentation.'), ('\xa0', 'Q. What can I do by enabling access to my EFS file systems from my on-premises servers?'), ('You can mount your Amazon EFS file systems on your on-premises servers, and move file data to and from Amazon EFS using standard Linux tools and scripts. The ability to move file data to and from Amazon EFS file systems enables three use cases.', 'First, you can migrate data from on-premises datacenters to permanently reside in Amazon EFS file systems.'), ('Second, you can support cloud bursting workloads to offload your application processing to the cloud. You can move data from your on-premises servers into your EFS file systems, analyze it on a cluster of EC2 instances in your Amazon VPC, and store the results permanently in your EFS file systems or move the results back to your on-premises servers.', 'Third, you can periodically copy your on-premises file data to EFS to support backup and disaster recovery scenarios.'), ('\xa0', 'Q. Can I use an AWS VPN to access an EFS file system from on-premises?'), ('No, Amazon EFS does not support access over AWS VPN.', '\xa0'), ('Q. Can I access my Amazon EFS file system concurrently from my on-premises datacenter servers as well as Amazon EC2 instances?', 'Yes, you can access your Amazon EFS file system concurrently from servers in your on-premises datacenter as well as Amazon EC2 instances in your Amazon VPC. Amazon EFS provides the same file system access semantics, such as strong data consistency and file locking, across all EC2 instances and on-premises servers accessing a file system.'), ('\xa0', 'Q. What is the recommended best practice when moving file data to and from on-premises servers via AWS Direct Connect?'), ('Because of the propagation delay tied to data traveling over long distances, the network latency of a Direct Connect connection between your on-premises datacenter and your Amazon VPC can be tens of milliseconds. If your file operations are serialized, the latency of the Direct Connect connection directly impacts your read and write throughput; in essence, the volume of data you can read or write during a period of time is bounded by the amount of time it takes for each read and write operation to complete. To maximize your throughput, parallelize your file operations so that multiple reads and writes are processed by EFS concurrently. Standard tools like GNU parallel enable you to parallelize the copying of file data. For more information, see the online documentation.', '\xa0'), ('Q. How do I copy existing data from on-premises file storage to Amazon EFS?', 'There are a number of methods to copy existing on-premises data into Amazon EFS. EFS File Sync provides a fast and simple way to securely sync existing file systems into Amazon EFS, and works over any network, including AWS Direct Connect'), ('AWS Direct Connect provides a high bandwidth and lower latency dedicated network connection over which you can mount your Amazon EFS filesystems. Once mounted, you can use EFS File Sync to copy data into Amazon EFS up to 5x faster than standard Linux copy tools.', 'For more information on EFS File Sync, please see the EFS File Sync section of this FAQ.'), ('Q. What is EFS File Sync?', 'EFS File Sync provides a fast and simple way to securely move data from existing on-premises or in-cloud file systems into Amazon EFS file systems. EFS File Sync copies files and directories into Amazon EFS at speeds up to 5x faster than standard Linux copy tools, with simple setup and management in the AWS Console. When syncing on-premises or in-cloud file systems into Amazon EFS, EFS File Sync delivers fast parallel data transfer, encrypts data in transit, and ensures the integrity of the copied data.'), ('Visit our documentation site for EFS File Sync to learn about the technical details and get started.\xa0', '\xa0'), ('Q. How do I get started using EFS File Sync?', 'To use EFS File Sync, visit the Amazon EFS Console to download and deploy File Sync agent into your IT environment. Configure the source and destination file systems, start the sync task, and monitor progress through the console or using AWS CloudWatch. When your source file system is on-premises the agent is deployed in your data center, and when the source file system is in AWS the agent is deployed as an Amazon EC2 instance. Standard rates apply for this EC2 instance. For more information on getting started, read the documentation section.\xa0'), ('\xa0', 'Q. How is my data protected using EFS File Sync?'), ('All data transferred by EFS File Sync from the source file systems to the destination in Amazon EFS is encrypted via SSL/TLS.\xa0', '\xa0'), ('Q. Does EFS File Sync support copying data between AWS Regions?', 'Yes. You can deploy an EFS File Sync agent in one AWS Region, and sync to an EFS file system in another AWS Region. Your source file system can be either an EFS file system, or a file system shared from an EC2 instance. For more information on setting up EFS File Sync, read the documentation section.\xa0'), ('\xa0', 'Q. In what regions is EFS File Sync available?'), ('EFS File Sync is available in all regions where\xa0Amazon EFS is available.\xa0', 'Q. What interoperability and compatibility is there between existing AWS services and Amazon EFS?'), ('Amazon EFS is integrated with a number of other AWS services, including Amazon CloudWatch, AWS CloudFormation, AWS CloudTrail, AWS IAM, and AWS Tagging services.', 'Amazon CloudWatch allows you to monitor file system activity using metrics. AWS CloudFormation allows you to create and manage file systems using templates.'), ('AWS CloudTrail allows you to record all Amazon EFS API calls in log files.', 'AWS Identity and Access Management (IAM) allows you to control who can administer your file system. AWS Tagging services allows you to label your file systems with metadata that you define.'), ('\xa0', 'Q. What type of locking does Amazon EFS support?'), ('Locking in Amazon EFS follows the NFSv4.1 protocol for advisory locking, and enables your applications to use both whole file and byte range locks.', '\xa0'), ('Q. Are file system names global (like Amazon S3 bucket names)?', 'Every file system has an automatically generated ID number that is globally unique. You can tag your file system with a name, and these names do not need to be unique.'), ('Q. How much does Amazon EFS cost?', 'With Amazon EFS, you pay only for the amount of file system storage you use per month in GB. There is no minimum fee and no set-up costs. There are no additional costs for bandwidth or requests. For Amazon EFS pricing information, please visit the pricing section on the Amazon EFS Pricing page.'), ('\xa0', 'Q. How much does Amazon EFS File Sync cost?'), ('With Amazon EFS File Sync, you pay per-GB for data copied to Amazon EFS. For EFS File Sync pricing information, please visit the Amazon EFS File Sync Pricing page.', '\xa0'), ('Q. Do your prices include taxes?', 'Except as otherwise noted, our prices are exclusive of applicable taxes and duties, including VAT and applicable sales tax.\xa0For customers with a Japanese billing address, use of AWS services is subject to Japanese Consumption Tax. Learn more.'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/snowball/faqs/': [('Q. What is AWS Snowball?', 'AWS Snowball is a data transport solution that accelerates moving terabytes to petabytes of data into and out of AWS using storage appliances designed to be secure for physical transport. Using Snowball helps to eliminate challenges that can be encountered with large-scale data transfers including high network costs, long transfer times, and security concerns.'), ('Q. How does Snowball work? ', 'AWS Snowball uses secure appliances and the Snowball client to accelerate petabyte-scale data transfers into and out of AWS. You start by using the AWS Management Console to create one or more jobs to request one or multiple Snowball appliances (depending on how much data you need to transfer), and download and install the Snowball client. Once the appliance arrives, connect it to your local network, set the IP address either manually or with DHCP, and use the client to identify the directories you want to copy. The client will automatically encrypt and copy the data to the appliance and notify you when the transfer job is complete. When the transfer is complete and the appliance is ready to be returned, the E Ink shipping label will automatically update to indicate the correct AWS facility to ship to, and you can track the job status by using Amazon Simple Notification Service (Amazon SNS), text messages, or directly in the console. '), ('Q. Who should use Snowball? ', "Snowball is the right data transfer choice if you need to securely and quickly transfer terabytes to many petabytes of data to AWS. Snowball can also be the right choice if you don’t want to make expensive upgrades to your network infrastructure, if you frequently experience large backlogs of data, if you're located in a physically isolated environment, or if you're in an area where high-bandwidth Internet connections are not available or cost-prohibitive."), ('Q. How much data can I transfer using Snowball?', 'You can transfer virtually any amount of data with Snowball, from a few terabytes to many petabytes. You can typically transfer multiple TB of data to each Snowball appliance. You can transfer larger data sets by using multiple Snowballs, either in parallel, or one after another. For example, you can transfer 100 TB of data using two Snowballs in parallel, or you can transfer the data using two Snowballs one after another.'), ('Q. What is the Snowball client?  ', 'The Snowball client is software that you install on a local host computer and use to efficiently identify, compress, encrypt, and transfer data from the directories you specify to a Snowball. '), (' Q. How long does it take to transfer my data?', ' You can use the Snowball client to estimate the time it takes to transfer your data (refer to the user guide for more details). Data transfer speed is affected by a number of factors including local network speed, file size, and the speed at which data can be read from your local servers.'), (' The Snowball client will copy data to the Snowball as fast as conditions allow, (as little as a day to copy 48TB of data, depending on your local environment). End-to-end time to transfer the data into AWS is approximately a week, including the usual shipping and handling time in AWS data centers. You can copy twice that much data in the same amount of time by using two 48TB Snowballs in parallel, or you could copy 80TB of data in two and a half days on a single 80TB Snowball, which would increase your end-to-end time to about a week and a half.', 'Q. What are the specifications on the Snowball appliance?'), ('Check this Snowball documentation page for the complete list of hardware specs, including interfaces, thermal and power requirements, decibel output, and dimensions.', 'Q. How long can I have a Snowball for a specific job? '), ("For security purposes, data transfers must be completed within 90 days of a Snowball's preparation.", ' Q. What network interfaces does Snowball support?'), (' Snowball has 10Gbps network interfaces with RJ45, SFP+ copper, and SFP+ optical network ports.', 'Q. What is Snowball’s default shipping option? Can I choose expedited shipping?'), ('As a default, Snowball uses two-day shipping by UPS. You can choose expedited shipping if your jobs are time-sensitive.', 'Q. In what regions is Snowball available?'), ('Check the Regional Service Availability pages for the latest information. ', 'Snowball is available for use in all states in the USA. '), ('Please note that 50TB models are only available in the USA. ', 'Q. Can a Snowball be shipped to an alternate AWS region?'), ('No. Snowballs are designed to be requested and used within a single AWS region. It may not be requested from one region and returned to another. Snowball devices used for imports or exports from an AWS region in the EU may be used with any of the 28 EU countries.', 'Q. When should I consider using Snowball instead of the Internet? '), ("Snowball is a strong choice for data transfer if you need to securely and quickly transfer terabytes to many petabytes of data to AWS. Snowball can also be the right choice if you don’t want to make expensive upgrades to your network infrastructure, if you frequently experience large backlogs of data, if you're located in a physically isolated environment, or if you're in an area where high-speed Internet connections are not available or cost prohibitive. ", 'As a rule of thumb, if it takes more than one week to upload your data to AWS using the spare capacity of your existing Internet connection, then you should consider using Snowball. For example, following the guidelines in the table below, if you have a 100 Mb connection that you can solely dedicate to transferring your data and need to transfer 100 TB of data, it takes more than 100 days to complete data transfer over that connection. You can make the same transfer by using multiple Snowballs in about a week.'), ('Q. When should I consider using Snowball instead of AWS Direct Connect? ', 'AWS Direct Connect provides you with dedicated, fast connections from your premises to the AWS network. If you need to transfer large quantities of data to AWS on an ongoing basis, AWS Direct Connect might be the right choice.'), ('Snowball can be a strong alternative to Direct Connect if you need to transfer data in large batches or as a one-time transfer, potentially from distributed locations. For these workloads, Snowball can be a simpler, more cost-effective option than setting up a new Direct Connect connection to transfer your data and then terminating the connection upon completion. ', 'Q. When should I consider using Snowball instead of AWS Import/Export Disk? '), ('Snowball provides a faster, simpler, and more cost-effective experience for most use cases when compared to AWS Import/Export Disk.', 'With Snowball, you don’t need to purchase any hardware or write any code to transfer your data. Each Snowball appliance can transfer as much as 80 TB of data and you can use multiple appliances in parallel for larger workloads. Snowball uses tamper-resistant enclosures, 256-bit encryption, and an industry-standard Trusted Platform Module (TPM) that is designed to ensure both security and full chain of custody for your data, and also to reduce management overhead involved with transferring data into or out of AWS.'), ('You can create transfer jobs right from the AWS Management Console. When your transfer is complete and the appliance is ready to be returned, the E Ink shipping label will automatically update to indicate the correct AWS facility to ship to, and you can track the job status by using Amazon SNS, or text messages, or directly in the console. ', 'Q. Can I use Snowball to migrate data from one AWS region to another AWS region? '), (' No. Snowball is intended to serve as a data transport solution for moving high volumes of data into and out of a designated AWS region. For use cases that require data transfer between AWS regions, we recommend using S3 Cross-Region Replication as an alternative.', 'Q. Does Snowball encrypt my data?'), ('Snowball encrypts all data with 256-bit encryption. You manage your encryption keys by using the AWS Key Management Service (AWS KMS). Your keys are never sent to or stored on the appliance.', 'Q. Does AWS have a way to tell if the device was tampered with during transit?'), ('In addition to using a tamper-resistant enclosure, Snowball uses an industry-standard Trusted Platform Module (TPM) with a dedicated processor designed to detect any unauthorized modifications to the hardware, firmware, or software. AWS inspects every appliance for any signs of tampering and to verify that no changes were detected by the TPM. ', 'Q. What happens to the data on the appliance when it has been successfully transferred to AWS?  '), ('When the data transfer job has been processed and verified, AWS performs a software erasure of the Snowball appliance that follows the National Institute of Standards and Technology (NIST) guidelines for media sanitization.', 'Q. Is there a way to easily track my data transfer jobs?  '), ('Snowball uses an innovative, E Ink shipping label designed to ensure the appliance is automatically sent to the correct AWS facility and which also helps in tracking. When you have completed your data transfer job, you can track it by using Amazon SNS, text messages, and the console.', 'Q. Can I use AWS Snowball for data with Protected Health Information (PHI)? '), ('Yes. AWS Snowball is a HIPAA-eligible service. If you currently have a Business Associate Agreement (BAA) with AWS, you can begin using Snowball immediately to transfer data into your HIPAA accounts. ', 'Q: How do I get started with Snowball?'), ('To get started with Snowball, visit the Getting Started page.', 'Q: How do I transfer my data to the Snowball appliance?'), ("When you connect the Snowball appliance to your network and set the IP address using the E Ink display, you'll need to download three things from the AWS Management Console:", '1. Snowball client: The software tool that is used to transfer data from your on-premises storage to the Snowball appliance. For more information on the Snowball client, see the Tools page. '), ('2. Job manifest file: An encrypted metadata file that is used to uniquely identify your data transfer job.', '3. Job manifest unlock code: A 25-character code to unlock the job manifest file. '), ("When you have downloaded these files, you launch the Snowball client and provide the Snowball appliance's IP address, the manifest file path, and the unlock code. A sample Start command is below: ", 'snowball start -i {Snowball IP} -m path/to/the/job/manifest} -u {unlock code}'), ("After you launch the client and provide this information, the cilent is now connected to the Snowball appliance and is ready for use. Next you'll need to identify the file directories you want to transfer to the appliance and then wait for the transfer to complete. A sample Copy command is below:", 'snowball cp /path/to/data/on/source/storage/device/directories Snowball/bucketname'), ('Q: What do I do when the data has been transferred to the Snowball appliance? ', "When the data transfer job is complete, the Snowball appliance's E Ink display automatically updates the return shipping label to indicate the correct AWS facility to ship to. Just drop off the Snowball appliance at the nearest UPS shipping facility and you're all set. You can track the status of your transfer job by using Amazon SNS, or text messages, or directly in the AWS Management Console. "), ('Q: Can I import data from a Hadoop Distributed File System to Snowball?', 'Yes. You can copy data from a HDFS cluster to Snowball using the Snowball CLI. To learn more, please refer to the Snowball documentation.'), ('Q: What is the Snowball export feature?', 'Export is a feature of Snowball that enables customers to export terabytes to petabytes of data from Amazon Simple Storage Service (Amazon S3) to on-premises storage.\xa0'), ('Q: How do I get my data from AWS with export?', "To use Snowball Export simply sign in to the AWS Management Console, choose Snowball, and create an export job. As with an import job, you specify the region and buckets that you want to use. If you don't want to export all of the data from a particular bucket, you can specify a beginning and ending S3 key range sorted in UTF-8 binary order to indicate what data should be exported. The key range that you choose, and all keys between them, are exported. Details on using the console can be found here."), ('Q: How quickly can I access my exported data?', 'We typically start exporting your data within 24 hours of receiving your request, and exporting data can take as long as a week. Once the job is complete and the device is ready, we ship it to you using the shipping options selected when you created the job.'), ("Q: Can I pick up the Snowball from your data center so I don't have to wait for shipping?", "No. Although you can select one-day shipping, we do have to ship the Snowball to an address that you provide. We don't have a way for you to pick up a Snowball from our data center."), ('Q: Can I track the export data-writing progress while you prepare my Snowball?', 'Yes. You can\xa0see when we start provisioning a Snowball and get real-time updates as data is written to the device. As with import jobs, you can get notification when the provisioning is complete and when the device has been shipped.'), ('Q: Will AWS encrypt my data before copying it to the Snowball?', 'Yes. All data that is written is encrypted and the encryption keys for that data are never present on the Snowball.'), ('Q: How do I read my data from the Snowball when I receive the device?', 'Using the Snowball client, you can copy your data from the Snowball to local storage. The client decrypts your data when it reads it from the Snowball and writes the data to your local storage in the same format as the data was stored in Amazon S3.'), ('Q: How much data can I export?', 'There is almost no limit the amount of data you can export. If you want to export more data than can fit on one appliance, additional export jobs will be created automatically for you so that all of the data you select can be exported.'), ('Q: Can I retrieve data from more than one bucket?', 'Yes. You can select as many buckets as you want for export.'), ('Q: How are my Amazon S3 objects mapped to files when I copy them to my local storage?', 'Each key is copied to your device in a directory tree that starts with the bucket’s name. For example, if the key is “images/orange.jpg” and the bucket is "fruit” then the object is saved to /fruit/images/orange.jpg. Meta data associated with each object is not copied to your storage device.'), ('Q: Can I export data that is in the Amazon Glacier storage class?', 'No. Before Amazon Glacier data can be exported it needs to be restored to Amazon S3 using the S3 Lifecycle Restore feature.'), ('Q: Do I get a log of what was exported?', 'Yes. For each job, import or export, a log of the files that were copied and those that could not be copied is generated and available from the Snowball console.'), ('Q: What does it cost to export my data?', 'In addition to the Snowball Export fees detailed on our pricing page, you will also be charged all Amazon S3 and Amazon Glacier fees incurred to retrieve your data from those services.'), ('Q. How much does it cost to transfer data using Snowball? ', 'Each Snowball data transfer job costs a flat fee for device handling and import and export operations at AWS data centers. Snowball is free for use for 10 days at your site. The day that the device is received and the day that the device is shipped are not counted towards these 10 days. Beyond that, a Snowball device costs $15/day for each extra day that it is at your site. There is no cost for transferring data into AWS. Transferring data out of AWS costs are region specific, please see our pricing page for pricing details.'), ('The following example illustrates Snowball pricing for an 80 TB model.', 'Example:'), ('Assume you transfer 60 TB of data into AWS using one Snowball and you keep the Snowball for 14 days (receiving the Snowball from the shipper on day 1 and returning the Snowball to the shipper on day 14).', 'Service charge for this job:'), ('The service charge for this job is $250.', 'Extra day charge:'), ('Snowball is free for use for 10 days at your site. The day that the device is received and the day that the device is shipped are not counted toward these 10 days, meaning day 1 and day 14 are free in this case. There are 12 days between day 1 and day 14, and 10 out of 12 days are free. The remaining 2 days are 2 extra days used to transfer your data. The total extra day charge is:', '2 days x $15/day = $30'), ('Data transfer:', 'In this example, you transferred data into AWS, so the data transfer cost is free.'), ('Shipping:', 'Shipping charges are based on your shipment destination and the shipping option you choose (for example, overnight, or two-day).'), ('Q. How am I charged for Amazon S3 usage? ', 'Snowball will transfer data on your behalf from Snowball appliances to AWS services, such as Amazon S3. Standard AWS service charges apply. Data transferred in to AWS does not incur any data transfer fees, and Standard Amazon S3 pricing applies for data stored in S3. \xa0'), ('Q. Can I purchase a Snowball appliance? ', 'Snowballs are only available on a per-job pay-as-you-go basis, and are not available for purchase.'), ('Q. Does the Snowball service support API access?', 'Yes. The Snowball Job Management API provides programmatic access to the job creation and management features of a Snowball. It is a simple, standards-based REST web service interface, designed to work with any Internet development environment.'), ('Q. What can I do with the Snowball Job Management API?', 'The API allows partners and customers to build custom integrations to manage the process of requesting Snowballs and communicating job status. The API provides a simple web service interface that you can use to create, list, update, and cancel jobs from anywhere on the web. Using this web service, developers can easily build applications that manage Snowball job workflow. To learn more, please refer to Snowball documentation. '), ('Q. What is the S3 Adapter?', 'The S3 Adapter provides an S3-compatible interface to the Snowball client for reading and writing data on a Snowball.'), ('Q. What can I do with the S3 Adapter?', 'The S3 Adapter provides functions to communicate with Snowball, allowing customers to build tools to copy data from file and non-file sources. It includes interfaces to copy data to Snowball with the same encryption that is available through our Snowball command line tool. To learn more, please refer to Snowball documentation.'), ('Q. Why would I use the S3 Adapter rather than the Snowball Client?', 'The Snowball Client is a turnkey tool that makes it easy to copy file based data to Snowball. Customers who prefer a tighter integration can use the S3 Adapter to easily extend their existing applicaitons and workflows to seamlessly integrate with Snowball.'), ('Q. How is my data secured when I use the S3 Adapter?', 'The S3 Adapter writes data using the same advanced encryption mechanism that the Snowball Client provides.'), ('Q. Which programming languages does the Snowball S3 Adapter support?', 'The S3 Adapter communicates over REST which is language-agnostic.'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/snowball-edge/faqs/': [('Q. What is Snowball Edge?', 'Snowball Edge is a 100TB data transfer device with on-board storage and compute power for select AWS capabilities. In addition to transferring data to AWS, Snowball Edge can undertake local processing and edge-computing workloads. Features include an S3-compatible end-point on the device, a file interface with NFS support, a cluster mode where multiple Snowball Edge devices can act as a single, scalable, storage pool with increased durability, and the ability to run Lambda functions as data is copied to the device.'), ('Q. How does Snowball Edge work?', 'You start by requesting one or more Snowball Edge devices in the AWS Management Console based on how much data you need to transfer or process. The buckets and Lambda functions you select are automatically configured, encrypted and preinstalled on your devices before they are shipped to you. Once a device arrives, connect it to your local network and set the IP address either manually or automatically with DHCP. Then use the Snowball Edge client software, job manifest, and unlock code to verify the integrity of the Snowball Edge device and unlock it for use. The manifest and unlock code are uniquely generated and crypto-logically bound to a designated Snowball Edge to help ensure that both cannot be used with any other devices. Data copied to Snowball Edge is automatically encrypted and stored in the buckets you specify.'), ('All logistics and shipping is done by Amazon so when copying is complete and the device is ready to be returned, the E Ink shipping label will automatically update the return address to help ensure that the Snowball Edge device is delivered to the correct AWS facility. Once the device ships, you can receive tracking status via messages sent by Amazon Simple Notification Service (Amazon SNS), generated texts and emails, or directly from the console.', 'All of the management for your Snowball Edge resources can be performed in the AWS management console and these operations require no on-site system engineers.'), ('Q. Who should use Snowball Edge?', 'Snowball Edge is the optimal data transfer choice if you need to securely and quickly transfer terabytes to petabytes of data to AWS. You can use Snowball Edge if you have a large backlog of data to transfer or if you frequently collect data that needs to be transferred to AWS and your storage is in an area where high-bandwidth Internet connections are not available or cost-prohibitive. You can also use Snowball Edge to run edge computing workloads such as performing local analysis of your data using Lambda functions, backed by a Snowball Edge cluster with increased durability and an S3-compatible endpoint. You can streamline it into existing workflows leveraging built-in capabilities such as the NFS file interface and migrate files to the device while maintaining file metadata. Snowball Edge can operate in remote locations or harsh operating environments, such as factory floors, windmills, ships and hospitals. Snowball Edge is pre-configured and does not have to be connected to the internet, so processing and data collection can take place within isolated operating environments. Snowball Edge allows you to run the same software at the edge and access select AWS capabilities as you do when you have full connectivity to AWS.'), ('Q. Can I use Snowball Edge to migrate data from one AWS region to another AWS region?', 'No. Snowball Edge is intended to serve as a data transport solution for moving high volumes of data into and out of a designated AWS region. For use cases that require data transfer between AWS regions, we recommend using S3 Cross-Region Replication as an alternative.'), ('Q. How much data can I transfer using Snowball Edge?', 'You can transfer virtually any amount of data with Snowball Edge, from a few terabytes to many petabytes. You can transfer up to 100TB with a single Snowball Edge and transfer larger data sets with multiple devices, either in parallel, or sequentially. For example, you can transfer 1PB of data with 10 Snowball Edge devices.'), ('Q. How long does it take to transfer my data?', 'Data transfer speed is affected by a number of factors including local network speed, file size, and the speed at which data can be read from your local servers. The end-to-end time to transfer 100 TB of data into AWS with Snowball Edge is approximately a week, including the usual shipping and handling time in AWS data centers.'), ('Q. How long can I have a Snowball Edge for a specific job?', 'Snowball Edge devices must be returned within 360 days of the Snowball Edge’s preparation. '), ('Q. What are the specifications of the Snowball Edge?', 'Snowball Edge provides 100TB of storage in a ruggedized, rack mountable, shippable form factor. Additionally, it provides local compute capability that is approximately the equivalent of an EC2 m4.4xlarge instance that provides support for a number of additional functions. Check the Snowball Edge documentation page for a complete list of hardware specs, including network connections, thermal and power requirements, decibel output, and dimensions.'), ('Q. What network interfaces does Snowball Edge support?', 'Snowball Edge includes a 10GBase-T network connection, 10/25Gb SFP28 and 40Gb QSFP+ copper, and optical networking for fast data transfer rates. \xa0'), ('Q. What is Snowball Edge default shipping option? Can I choose expedited shipping?', 'As a default, Snowball Edge uses two-day shipping by UPS. You can choose expedited shipping if your jobs are time-sensitive. '), ('Q. In what regions is Snowball Edge available?', 'Check the Regional Service Availability pages for the latest information. '), ('We regret that we cannot provide the service at this time in all US states.', 'Q. Can a Snowball Edge be shipped to an alternate AWS region?'), ('No. Snowball Edge devices are designed to be requested and used within a single AWS region. It may not be requested from one region and returned to another. Snowball Edge devices used for imports or exports from an AWS region in the EU may be used with any of the 28 EU countries.', 'Q. Does Snowball Edge encrypt my data?'), ('Snowball Edge encrypts all data with 256-bit encryption. You manage your encryption keys by using the AWS Key Management Service (AWS KMS). Your keys are never stored on the device and all memory on a Snowball is erased when it is disconnected and to be returned to AWS.', 'Q. How does Snowball Edge physically secure my data?'), ('In addition to using a tamper-resistant enclosure, Snowball Edge uses industry-standard Trusted Platform Modules (TPM) designed to detect any unauthorized modifications to the hardware, firmware, or software. AWS visually and cryptographically inspects every device for any signs of tampering and to verify that no changes were detected by the TPM.', 'Q. How does Snowball Edge help digitally secure my data?'), ('Snowball Edge is designed with security in mind for the most sensitive data. All data is encrypted by keys provided by you through AWS Key Management Service (KMS). The keys are not permanently stored on the device and are erased after loss of power. Applications and Lambda functions run in a physically isolated environment and do not have access to storage. Lastly, after your data has been transferred to AWS, your data is erased from the device using standards defined by National Institute of Standards and Technology. Snowball Edge devices are hardened against attack and all configuration files are encrypted and signed with keys that are never present on the device.', 'Q. Is there a way to easily track my data transfer jobs?'), ('Snowball Edge uses an innovative, E Ink shipping label designed to ensure the device is automatically sent to the correct AWS facility. When you have completed your data transfer job, you can track it by using Amazon SNS generated text messages or emails, and the console.', 'Q: How do I transfer my data to the Snowball Edge?'), ('After you have connected and activated the Snowball Edge, you can transfer data from local sources to the device through the S3-compatible endpoint or the NFS file interface, both available on the device. You can also use the Snowball client to copy data. To learn more, please refer to the Snowball Edge documentation.', 'Q: What do I do when the data has been transferred to the Snowball Edge?'), ("When the data transfer job is complete, the E Ink display on the Snowball Edge automatically updates the return shipping label to indicate the correct AWS facility to ship to. Just drop off the Snowball Edge at the nearest UPS and you're all set. You can track the status of your transfer job through Amazon SNS generated text messages or emails, or directly in the AWS Management Console. ", 'Q: What does it cost to export my data?'), ('In addition to the Snowball Export job fees detailed on our pricing page, you will also be charged all fees incurred to retrieve your data from Amazon S3.', 'Q. What is the S3-compatible endpoint on Snowball Edge?'), ('The S3-compatible endpoint on Snowball Edge allows you to read and write data on the device using select S3 operations and client tools that support S3.', 'Q. What S3 operations are supported by the S3-compatible endpoint on Snowball Edge?'), ('The S3-compatible endpoint supports the Get, Head, Put, Delete, List, and MultipartUpload operations of Amazon S3. You can execute these operations on the Snowball Edge as if you are accessing an S3 web service endpoint. In addition, you can point client tools that support S3 to the Snowball Edge to read and write data.', 'Q. Why would I use the S3-compatible endpoint?'), ('The S3-compatible endpoint lets you transfer data programmatically using the S3 operations natively supported by the Snowball Edge. You can also seamlessly integrate Snowball Edge into your existing applications and workflows built for Amazon S3.', 'Q. How is my data secured when I use the S3-compatible endpoint?'), ('Data transferred via the S3-compatible endpoint is protected by the same advanced security mechanism on the Snowball Edge, which encrypts all data with 256-bit encryption. You manage your encryption keys using the AWS Key Management Service (AWS KMS). Your keys are never stored on the device and all memory on the Snowball Edge is erased when it is unplugged.', 'Q. Which programming languages does the S3-compatible endpoint support?'), ('The S3-compatible endpoint supports the REST interface which is language-agnostic. ', 'Q: What is the file interface on Snowball Edge?'), ('The file interface enables you to store and retrieve objects on Snowball Edge through standard file storage protocols. When the Snowball Edge is shipped back to AWS for data import, these objects will be ingested into Amazon S3, and can be accessed directly through S3 as normal. You can also access the objects as files, including the original file system metadata, through AWS Storage Gateway.', 'Q: How do I use the file interface on Snowball Edge?'), ('Once the Snowball Edge arrives at your site and has been unlocked, each of the S3 buckets is made available to your applications as an NFS export visible on the network to which the Snowball Edge is connected. You can use the local LCD display on the Snowball Edge to disable/enable the file interface. You can mount these NFS exports on your server, and your applications can read and write files as they would any other network shared file system. You can monitor the file interface status, and open a support channel through the LCD display.', 'Q: What use cases does the file interface on Snowball Edge enable?'), ('The file interface enables multiple use cases. It lets you ingest existing files into Amazon S3 as objects using a common file protocol (NFS), and preserves associated file metadata as object metadata. This offline bulk data transfer enables you to seed file data into S3, and use it for in-cloud workloads, such as Big Data processing. Alternatively, the transferred file data can be accessed from your sites for hybrid applications or workflows by using AWS Storage Gateway.', 'Q: What are the benefits of the file interface on Snowball Edge?'), ('The file interface on Snowball Edge enables your existing file-based applications, devices, and workflows to write data through standard file protocols, while also preserving metadata.', 'Q: What file protocols are supported?'), ('Snowball Edge supports clients connecting using NFS v3 and v4.1. Microsoft Windows clients that support NFS v3 can connect to Snowball Edge.', 'Q: How are files stored on Snowball Edge?'), ('Files are stored as objects in buckets on an AWS Snowball Edge appliance. File system metadata, such as permissions, ownership, and timestamps, is stored as user-defined object metadata. All data and metadata is encrypted when stored on the Snowball Edge.', 'Q: How do I configure the file interface on the Snowball Edge?'), ('You can use the local LCD display on the Snowball Edge to disable/enable the file interface, monitor the file interface status, and open a support channel.', 'Q: Can I use both the file interface and the Amazon S3 Adapter for Snowball to write to a bucket on an AWS Snowball Edge appliance?'), ('We recommend against writing to buckets on an AWS Snowball Edge appliance both directly and through the file interface. If you directly overwrite or update an object previously written by the file interface, it will result in undefined behavior when the object is accessed through the file interface. Concurrent modification of the same object (e.g. via the file interface and the Amazon S3 Adapter for Snowball) will lead to unpredictable results.', 'Q: Can I use both the file interface and the Amazon S3 Adapter for Snowball to read from the same bucket on an AWS Snowball Edge appliance?'), ('We recommend against using both the file interface and the Amazon Se Adapter for Snowball to read from the same bucket on an AWS Snowball Edge appliance. This may result in undefined behaviors.', 'Q: Should I use the file interface to load data into the Snowball Edge or the Amazon S3 Adapter for Snowball?'), ('You can use file interface when your existing workflow is file-based or you want to access objects in S3 as files using standard filesystem operations. You can use the Amazon S3 Adapter for Snowball when your application doesn’t require file system operations and can manage data transfer directly.', 'Q: How does the file interface on Snowball Edge compare with the AWS Storage Gateway?'), ('The file interface on Snowball Edge enables you to easily ingest data into S3 in an “off-line” mode. This is useful when you need to import sets of files that don’t need to be immediately available in S3, or from locations with insufficient bandwidth to transfer the data over the network.', 'AWS Storage Gateway enables you to put file data into S3 over the Internet or AWS Direct Connect, making your uploaded files instantly available.'), ('Q: Can I access files migrated via the file interface on Snowball Edge from Amazon EFS?', 'No. Files migrated via the file interface on Snowball Edge can be accessed directly as objects in S3 or as files through the AWS Storage Gateway. '), ('Q: What is the clustering feature in Snowball Edge?', ' The clustering feature in Snowball Edge allows you to aggregate many Snowball Edge devices together to create one logical storage pool with increased durability and capacity. '), ('Q: Why should I use the clustering feature in Snowball Edge?', 'Clustering Snowball Edge devices together creates a more durable, scalable, local storage pool. Snowball Edge clusters allow you to access large amounts of local storage capacity by using multiple Snowball Edge devices.'), ('Q: Can I use Snowball Edge in a clustered configuration to augment or replace my data storage solution on premises? ', ' Yes. The scalable storage that comes with Snowball Edge is designed to store your data safely and durably. '), ('Q: What are some scenarios for using the Snowball Edge clustering feature?', 'You can use the clustering feature in Snowball Edge when you need durable storage for your on premise locations. Some customers occasionally face situations where they need durable storage in remote sites where it is difficult to have large amounts of data storage. For example, in manufacturing there are companies who want to have a pool of storage for every factory location or in the military there are divisions that have shifting data storage requirements and need the flexibility to increase and decrease storage capacity for their ships.'), ('Q: How do I get started using a Snowball Edge cluster?', 'You can order a Snowball Edge cluster using the AWS Snowball API, AWS Console, AWS SDK or AWS CLI. Once you create a cluster, you will receive a cluster id (beginning with CID) which you will use to refer to any operations on this particular cluster job.'), ('Q: Is there a minimum size for my Snowball Edge cluster?', 'Yes, the minimum size of a Snowball Edge cluster is 5 nodes.'), ('Q: Is there a maximum size for my Snowball Edge cluster?', 'Yes, the maximum size of a Snowball Edge cluster is 10 nodes.'), ('Q: What is the usable space in a Snowball Edge cluster?', 'The total size of a Snowball Edge cluster is based on the number of nodes and usable capacity per node, which is 45TB.\xa0For example, in a 5 device cluster with 500TB of physical capacity, you will effectively realize usable space of 225TB. You can get the total used space and total available space in your cluster by typing the command below:'), ('snowballEdge status –i IP_PrimaryNode -m Path/to/manifest/file –u unlock_code', 'Q: Can I build a cluster from individually provisioned Snowball Edge devices?'), ('No. The only way to start using a cluster is to create a job of the type “AWS Snowball Edge cluster”.', 'Q: Once the Snowball Edge devices arrive at my location, how do I setup the cluster?'), ('Once the Snowball Edge devices have arrived at your location, you need to power them on, connect them to the same network, download the manifest file and unlock code, download the Snowball client and unlock the cluster.', 'Q: Do I interact with a specific node, which acts as an entry point to the Snowball Edge cluster?'), ('Yes. Each Snowball Edge cluster has one primary node and several secondary nodes. You can pick which device you want to be the primary node. All writes are done through the primary node, and reads can be done from any node.', 'Q: How do I unlock my Snowball Edge cluster?'), ('Note the IP address of any one of the Snowball Edge devices from the LCD screen. That device then acts as the primary node. To unlock the Snowball Edge cluster you will connect to the primary node using the client software and type the unlock command as shown below. Unlocking the primary node will unlock the cluster:', 'snowballEdge unlock –i Primary_IP_Address –s Secondary_1_IPAddress Secondary_2_IPAddress Secondary_3_IPAddress Secondary_4_IPAddress -m Path/to/manifest/file –u unlock_code'), ('Q: Do I need to unlock each node of my Snowball Edge cluster?', 'No. Each Snowball Edge cluster has a single cluster manifest file and an unlock code. You use the manifest file and the unlock code to unlock the primary node which then unlocks the secondary nodes automatically.'), ('Q: Can I unlock certain nodes of my Snowball Edge cluster before I receive all units or do I need to wait until I have all units in my possession?', 'We do not recommend you start your Snowball Edge cluster with less than the number of nodes that the cluster job is provisioned with since you may or may not be able to read and/or write durably to the cluster depending on the number of nodes.'), ('Q: How do I know what the total number of nodes are in my Snowball Edge cluster?', 'At any time, you can run the command below to learn more about the number of nodes that are available in your Snowball Edge cluster:'), ('snowballEdge status –i Primary_IP_Address -m Path/to/manifest/file –u unlock_code', 'Q: How do I know what data durability level my Snowball Edge cluster is operating at?'), ('The Snowball Edge cluster reports data durability level using the “snowballEdge status” command. You can get the status of the cluster by using the command below:', 'snowballEdge status –i Primary_IP_Address -m Path/to/manifest/file –u unlock_code'), ('\xa0', 'Here is a brief description of the different durability levels for a Snowball Edge cluster:'), ('HEALTHY: This level means that the Snowball Edge cluster is operating at full capacity.', 'REDUCED: This level means that the Snowball Edge cluster is operating at reduced capacity, as one or more appliances is unavailable. The cluster can still read and write data as normal, however we recommend that you check the power and network status of all your Snowball Edge appliances to ensure they are properly operating. If any Snowball Edge appliance(s) continues to be unresponsive then order a replacement(s).'), ('AT RISK: This level means that the Snowball Edge cluster is operating at severely reduced capacity, as one or more Snowball Edge appliance is unavailable. You cannot write data to the cluster while it is in this state, however you will be able to read data as normal. We recommend that you check the power and network status of all your Snowball Edge appliances to ensure they are properly operating. If any Snowball Edge appliance(s) continues to be unresponsive then order a replacement(s) and contact AWS support.', 'DATA UNAVAILABLE: This level means that the Snowball Edge cluster is not operating properly and some data will be unavailable. You cannot read or write data while the cluster is in this state. We recommend that you check the power and network status of all your Snowball Edge appliances to ensure they are properly operating. If any Snowball Edge appliance(s) continues to be unresponsive, contact AWS support immediately.'), (' Q: What are the different types of status that a particular device in a Snowball Edge cluster can be in?', ' Here is a brief description of the different types of states that a particular device in the Snowball Edge cluster can be in:'), (' AVAILABLE: This state means that the device is available for use in the cluster.', ' REMOVED: This state means that the device has been removed from the cluster.'), (' ', ' You can get the status of a particular node in a Snowball Edge cluster by using the command below:'), (' snowballEdge status –i Node_IP_Address -m Path/to/manifest/file –u unlock_code', 'Q: Is my Snowball Edge cluster expandable in size by adding nodes?'), ('You can add a new node to your Snowball Edge cluster if you have removed an unhealthy node from the cluster, or if you want to increase local storage. To add a new node, you need to order a replacement. Ordering a replacement node can be done from the console, from the AWS CLI, or from one of the AWS SDKs.', 'Q: Can I remove a node from my Snowball Edge cluster?'), ('You can remove a node from your Snowball Edge cluster if you intend to replace it. You may want to do this if one of your nodes is unhealthy, is not powering on or is defective. To remove a node, you can power it off and use the “snowballEdge removenode” command.', 'Q: How do I replace a secondary node in my Snowball Edge cluster?'), ('To order a replacement node in your Snowball Edge cluster, you can go the AWS Console page, and order a replacement device. Once you receive the device, you need to follow a few steps:', 'snowballEdge removenode –i IP_Primary –n Job_Id_of_Node_to_remove -m Path/to/manifest/file –u unlock_code'), ('snowballEdge addnode –i IP_Primary –a IP_node_to_be_added -m Path/to/manifest/file –u unlock_code', ' Q: How do I replace an unhealthy primary node in my Snowball Edge cluster?'), (' If your primary node stops working you can replace it using the instructions below:', ' snowballEdge unlock –i Primary_IP_Address –s Secondary_1_IPAddress –s Secondary_2_IPAddress –s Secondary_3_IPAddress –s Secondary_4_IPAddress -m Path/to/manifest/file –u unlock_code'), (' snowballEdge addnode –i IP_Primary –a IP_node_to_be_added -m Path/to/manifest/file –u unlock_code', 'Q: What happens if I remove more than one Snowball Edge device from my Snowball Edge cluster?'), (' You cannot remove more than one Snowball Edge device from a Snowball Edge cluster at any time. ', ' Q: Can I continue to use the Snowball Edge cluster while I am replacing a secondary Snowball Edge device?'), (' Yes. You can continue to use the Snowball Edge cluster even when you are replacing a Snowball Edge device. Until all the nodes show an AVAILABLE state, the cluster will run in a reduced durability mode. \xa0', ' '), (' Q: Can I continue to use the Snowball Edge cluster while I am replacing a primary Snowball Edge device?', ' Yes. If the primary node is unavailable, you will be able to read from any of the other nodes in the cluster. However, you will not be able to write to the Snowball Edge cluster until a primary node is restored. We recommend you immediately restart the cluster and choose a new primary node or order a replacement node if the device is not functional. '), ('Q: What will happen to stored data once I replace a node from my Snowball Edge cluster?', 'Once you replace a node, the Snowball Edge cluster will repartition the data amongst the remaining nodes so that it can still be used as durable storage.'), (' Q: Can I choose different job settings (Address, Shipping speed, Lambda functions, IAM roles, KMS keys, SNS notifications) in my replacement node than what was set when I ordered the Snowball Edge cluster?', ' No. Each replacement node is pre-configured to use the same job configurations that came with the Snowball Edge cluster.'), ('Q: Can I choose a different Lambda function in my replacement node?', ' Yes. You can choose a different Lambda function as long as it uses the same S3 bucket that was originally configured with the Snowball Edge cluster. '), (' Q: Can I use the same Snowball Edge cluster manifest key and unlock code as before after ordering a replacement node?', ' No. A new cluster manifest and unlock code is generated after your order a replacement device which must be used with any future operations of the Snowball Edge cluster. '), ('Q: What happens if one of my nodes is not available?', ' You can continue to use the Snowball Edge cluster even if it runs in a reduced durability level. Immediately order a replacement Snowball Edge device so that you can replace this node with a newer device. '), ('Q: What happens if two of my nodes are not available?', ' You can continue to use the Snowball Edge cluster but note that it will be running in a read-only mode and existing data on the cluster is at risk. Immediately order two replacement devices so that you can replace these nodes with newer Snowball Edge devices. '), ('Q: What happens if three or more of my nodes are not available?', ' You cannot use the Snowball Edge cluster anymore and existing data on the cluster is at risk. Contact AWS support immediately if three or more Snowball Edge devices are non-functional. '), (' Q: How long can I keep a Snowball Edge cluster on premise at my location?', ' The maximum duration a Snowball Edge cluster can be kept on premise at your location is 360 days from the day the order was created. After that, the certificates in the cluster expires and either all the Snowball Edge devices in the cluster must be returned or you should order new devices. '), (' Q: Can I pre-order replacement devices for my Snowball Edge cluster? ', ' Yes. To pre-order replacement devices, you need to create a Snowball Edge cluster job and then create a job to order replacement Snowball Edge devices. The replacement devices do not need to be connected to the original Snowball Edge cluster until one of the devices is unhealthy. Once a Snowball Edge device is unhealthy, you can remove the device and then add the replacement device. '), ('Q: Can a Snowball Edge cluster come preloaded with data from an existing S3 bucket?', ' No. However, you can place an order for two Snowball jobs – one cluster job and one export job. The Snowball Edge cluster will come empty from AWS but the export job can be a Snowball (or a Snowball Edge) device that can be used to import data into the Snowball Edge cluster. '), ('Q: Can I ingest data from the entire Snowball Edge cluster back to AWS using individual nodes of my cluster?', ' No. A Snowball Edge cluster can only be used for on premise storage and compute. It cannot be used to import data into AWS. To import data from your cluster, you will need to order additional AWS Snowball (or AWS Snowball Edge) devices and then connect them to the same network as the Snowball Edge cluster. You can then use the S3 adapter on the import device (Snowball or Snowball Edge) and the cluster to transfer data between them. Depending on the total amount of data used in the cluster, you may have to order multiple import devices to ship the data back to AWS. '), (' Q: Is there a single S3-comptabile end-point to connect to the Snowball Edge cluster?', ' No. Each node has a unique S3 endpoint for read operations. However, for write operations you can only use the primary node’s S3 endpoint. '), (' Q: Will the S3-comptabile end-point change if the node where it is running is disconnected?', ' Yes, if the primary node is disconnected then the IP address will change. The end-point will be the IP address of the new primary node that you have chosen.'), (' Q: Will the NFS end-point change if the node where it is running is disconnected?', ' Yes, if the primary node is disconnected then the NFS address will change. The end-point will be the IP address of the primary node that you have chosen.'), (' Q: When ingesting data into a cluster, does the network throughput of data transfer increase depending on the number of nodes?', ' No. All write operations must go through the primary node, so your ingest throughput will be limited to the throughput of a single node. However, throughput for read operations can be higher if you read from several devices in parallel. '), (' Q: Does compute capacity scale linearly when clustering is enabled? ', ' No. Clustering only increases the amount of durable storage that is available to you. The total amount of compute capacity available in a cluster is limited to only one node. '), (' Q: Where does the compute run in my Snowball Edge cluster?', ' Each cluster has a primary node where the compute runs. To identify which node is primary in your cluster, type the command below:'), (' snowballEdge status –i IP_of_any_node -m Path/to/manifest/file –u unlock_code', ' Q: Once a different node is chosen as the primary node, will my custom application state be maintained across instances?'), (' No. We recommend you build a stateless application or save all of your state on the NFS/S3 storage so that the data can be read from the persistent storage in case the primary node needs to be restarted. ', 'Q: Can I update my Lambda function in my Snowball Edge cluster while it is on premise? '), (' No. You cannot update your Lambda function on premise.', 'Q: What is AWS Greengrass?'), ('Snowball Edge comes with an embedded version of AWS Greengrass which allows you to execute Python-language AWS Lambda functions in response to S3 PUT object events.', 'Q: What AWS Greengrass features are available on Snowball Edge?'), (' Greengrass Core running on Snowball Edge enables you to deploy Python-based Lambda functions to Snowball Edge devices and trigger those Lambdas through MQTT messages. When you create a job for a Snowball Edge with at least one Lambda function pre-loaded, the Snowball Edge is provisioned as a Greengrass Core device by default. Whenever the Snowball Edge is connected to the internet, you can update, add, or remove Lambda functions on the device through the Greengrass console. You can even host Lambda functions that are triggered by MQTT messages other than an S3 PUT. Additionally, you can also update the associated Greengrass group in the Greengrass console and use the device in your group as any other Greengrass Core device.', 'Q: What are some possible use cases for Greengrass on Snowball Edge?'), (' Using Greengrass Core on Snowball Edge, you can write custom Lambda functions to provide local processing or pre-processing of data as it is written to the Snowball Edge device via S3 PUT operations and the S3-compatible endpoint available. You can also use the Snowball Edge as the core of your Greengrass group of IoT things. This allows you to do things like collect and analyze sensor data streams or compress images in-real time.', 'Q: How do I use Greengrass on Snowball Edge?'), (' Using the AWS Snowball Management Console or the Job Management API, you can map new or existing Lambda functions to pre-configured S3 buckets on a Snowball Edge device before it is shipped to you. Once the device arrives, unlock it and connect it to the internet so Greengrass in the cloud can send the Snowball Edge the certificates it needs to operate as the core of your Greengrass group.', 'Q: What happens if I use AWS Greengrass on a Snowball Edge cluster?'), (' You can use Greengrass on a Snowball Edge cluster just as you would with a single Snowball Edge, with each cluster node being its own unique AWS Greengrass core device.', 'Q: How many Lambda functions can there be for each job?'), (' At job creation, each Lambda function can be associated with a single S3 bucket on the Snowball Edge. Once you’ve received the device, unlocked it, and connected it to the internet, you can add, remove, or update Lambda functions as you see fit. If you allocated 128 MB of memory to each of your functions, you could have up to 7 Lambda functions at a time.', 'Q: Can I use Greengrass on Snowball Edge from any AWS Region?'), (' Currently, you must use Greengrass on a Snowball Edge in the regions are supported by the Greengrass service. For a list of Greengrass supported regions, see the Region Table. In regions that only support AWS Snowball Edge and not AWS Greengrass, you can still create jobs for Snowball Edge devices, however they won’t have access to the compute functionality.', 'Q. How much does it cost to use Snowball Edge?'), ('Each Snowball Edge job costs a flat fee of $300 for device handling and operations at AWS data centers. The $300 job fee includes 10 day of use at your site. The day that the device is received and the day that the device is shipped are not counted towards these 10 days. Beyond that, a Snowball Edge costs $30/day for each extra day that it is at your site. Data transferred into AWS does not incur any data transfer fees, and Standard Amazon S3 pricing applies for data stored. Exporting data starts at $0.03/GB. In addition, shipping charges are calculated based on standard carrier rates for the shipping location and shipping option (e.g. 2-day, overnight) you choose. The default shipping option is 2-day.', 'Pricing Example:'), ('The pricing example below illustrates what you can expect to pay for a 90TB data transfer into AWS using a single 100TB Snowball Edge device, where you kept the device for a total of 15 days (received the device on day 1 and returned the device on day 15).', 'The day the device is received and the day the device is shipped back to AWS are considered shipping days, and are not counted toward the 10 free days in this case. This means you had the device onsite for a total of 13 days, and 10 out of those days are free. Therefore you used 3 extra days to transfer your data.'), ('Service fee:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0 \xa0 \xa0 \xa0\xa0 \xa0 $300', 'Daily charges (3 days x $30/day): \xa0\xa0\xa0 $90'), ('Shipping charges:\xa0\xa0\xa0\xa0\xa0 \xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 \xa0\xa0 vary by distance', 'Data transfer cost: \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0\xa0\xa0\xa0 \xa0 $0'), ('Q. Am I charged for Amazon S3 usage if I use the S3-compatible endpoint on Snowball Edge?', "No, you don't incur additional charges for using the S3-compatible endpoint on Snowball Edge. If your Snowball Edge transfers data into Amazon S3, standard S3 request and storage charges will apply."), ('Q. Can I purchase a Snowball Edge device?', 'No. Snowball Edge devices are only available on a per-job pay-as-you-go basis, and are not available for purchase. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/snowmobile/faqs/': [('Q. What is AWS Snowmobile?', 'AWS Snowmobile is the first exabyte-scale data migration service that allows you to move very large datasets from on-premises to AWS. Each Snowmobile is a secure data truck with up to 100PB storage capacity that can be dispatched to your site and connected directly to your network backbone to perform high-speed data migration.You can quickly migrate an exabyte of data with ten Snowmobiles in parallel from a single location or multiple data centers. Snowmobile is operated by AWS as a managed service.'), ('Q. How does Snowmobile work? ', ' After you have placed your inquiry for a Snowmobile, AWS personnel will contact you to determine requirements for deploying a Snowmobile and schedule the job, and will drive the required Snowmobile equipment to your site and connect it to your local network so that you can use your high-speed local connection to quickly transfer data from your local storage appliances to the Snowmobile. After the data transfer is complete, the Snowmobile will be returned to a designated AWS region where your data will be uploaded into the AWS storage services you have selected, such as S3 or Glacier. Finally, AWS will work with you to validate that your data has been successfully uploaded.'), ('Q. Who should use a Snowmobile? ', 'Snowmobile enables customers to quickly migrate exabyte-scale datasets from on-premises to AWS in a secure, fast, and low-cost manner. Use cases include migrating 100’s of petabytes of data, such as video libraries, genomic sequences, seismic data, and financial records to run big data analytics on AWS or shutting down legacy data centers and moving all local data in exabytes to AWS. Before Snowmobile, migrating data at such scale would typically take years which was too slow for many customers. With Snowmobile, you can now request multiple data trucks each with up to 100PB capacity to be dispatched on-site, connected to your local high speed network backbone, and transfer your exabyte-scale datasets to AWS in as quickly as a few weeks, plus transport time.'), ('Q. What are the specifications of a Snowmobile?', 'Each Snowmobile comes with up to 100PB of storage capacity housed in a 45-foot long High Cube shipping container that measures 8 foot wide, 9.6 foot tall and has a curb weight of approximately 68,000 pounds. The ruggedized shipping container is tamper-resistant, water-resistant, temperature controlled, and GPS-tracked.'), ('Q. How should I choose between Snowmobile and Snowball?  ', ' To migrate large datasets of 10PB or more in a single location, you should use Snowmobile. For datasets less than 10PB or distributed in multiple locations, you should use Snowball. In addition, you should evaluate the amount of available bandwidth in your network backbone. If you have a high speed backbone with hundreds of Gb/s of spare throughput, then you can use Snowmobile to migrate the large datasets all at once. If you have limited bandwidth on your backbone, you should consider using multiple Snowballs to migrate the data incrementally. '), (' Q. How much data can I transfer to Snowmobile?', ' Each Snowmobile has a total capacity of up to 100 petabytes and multiple Snowmobiles can be used in parallel to transfer exabytes of data. '), ('Q. Are there environmental requirements to use a Snowmobile?', 'The Snowmobile needs physical access to your data center to allow for network connectivity. It comes with a removable connector rack with up to two kilometers of networking cable that can directly connect to the network backbone in your data center. The Snowmobile can be parked in a covered area at your data center or in an uncovered area that is adjacent to your data center and close enough to run the networking cable. The parking area needs to hold a standard 45-foot High Cube trailer with a minimum of 6’-0” (1.83m) of peripheral clearance. Snowmobile can operate at ambient temperatures up to 85F (29.4C) before an auxiliary chiller unit is required. AWS can provide the auxiliary chiller if needed based on the site survey findings.'), ('Q. How is a Snowmobile powered? ', 'A fully powered Snowmobile requires ~350KW. Snowmobile can be connected to available utility power sources at your location if sufficient capacity is available. Otherwise, AWS can dispatch a separate generator set along with the Snowmobile if your site permits such generator use. This generator set takes a similar amount of space as the Snowmobile which is parking for a vehicle approximately the same size as a 45-foot container trailer.'), ('Q. What is a Snowmobile job?', 'A Snowmobile job encapsulates the end-to-end data migration process using a Snowmobile. There are five main steps, including 1) Site Survey, where AWS personnel will work with you to understand your migration objectives, data center environment, and network configurations in order to determine a migration plan, 2) Site Preparation, where you (the customer) will identify and make available local resources such as parking space and power source for the Snowmobile, local security, network address, ports, and available rack positions to connect the Snowmobile with the local network backbone, 3) Dispatch and Setup, where AWS personnel will dispatch a Snowmobile to your site and configure it for you so it can be accessed securely as a network storage target, 4) Data Migration, where you will copy data from any number of sources within your data center to the Snowmobile, and 5) Return and Upload, where the Snowmobile is returned to an AWS region that you have designated where you data will be uploaded into the AWS storage services you have selected. Visit AWS Snowmobile to learn more.'), ('Q. How do I connect my data center to Snowmobile?', ' Each Snowmobile comes with a removable high-speed connector rack on wheels with two kilometers of ruggedized networking cable. The connector rack can be rolled to a location inside your data center and connected directly to your network backbone. This way, the Snowmobile will operate as a network storage target inside your network for you to perform high-speed data transfer. '), ('Q. How do I copy my data to a Snowmobile?', 'Once the Snowmobile is connected to your data center, it will appear as a network storage target. You can copy data from local storage devices to the Snowmobile using the same tools and in the same manner as data is copied to any network attached storage device with an NFS interface.'), ('Q. Can I connect to Snowmobile via an NFS endpoint?', 'Yes. The Snowmobile will appear as a standard NFS mount on your network that you can connect to via your existing tools and applications.'), ('Q. How do I get started with Snowmobile?', 'Please contact your sales team to request a Snowmobile.'), ('Q. How long does it take to transfer my data to a Snowmobile? ', 'The Snowmobile is designed to transfer data at a rate up to 1 Tb/s, which means you could fill a 100PB Snowmobile in less than 10 days. The actual transfer speed may vary depending on the available local network capacity at your site and the speed of your on-premises storage devices. AWS will provide a way for you to test your local network throughput and the copy speed from your data sources to properly size the Snowmobile job, before dispatching the Snowmobile.'), ('Q. What type of connections does Snowmobile provide? ', 'The Snowmobile comes with a removable connector rack that needs to be mounted on one of your data center racks where it can be connected directly to your high-speed network backbone. The connector racks provides multiple 40Gb/s interfaces that can transfer up to 1 Tb/s in aggregate.'), ('Q. After my data has been imported to AWS, what happens to the copy on Snowmobile? ', ' When the data import has been processed and verified, AWS performs a software erasure of the Snowmobile that follows the National Institute of Standards and Technology (NIST) guidelines for media sanitization (NIST 800-88). '), ('Q. How do I verify that my data has been successfully copied to Snowmobile? ', 'At the time your data is copied into the Snowmobile, a set of logs will be generated with checksums for each file transferred. These logs are available to you for verification. The logs are also used when data is imported from the Snowmobile to AWS to verify that all data has been transferred successfully.'), ('Q. Do I need to keep a local copy of my data while a copy is shipped back to AWS on a Snowmobile? ', ' You should always keep your source copy until AWS has worked with you to verify that the Snowmobile copy has been successfully uploaded to AWS. '), ('Q. Can I export data from AWS with Snowmobile? ', 'Snowmobile does not support data export. It is designed to let you quickly, easily, and securely migrate exabytes of data to AWS. When you need to export data from AWS, you can use AWS Snowball Edge to quickly export up to 100TB per appliance and run multiple export jobs in parallel as necessary. Visit the Snowball Edge FAQ to learn more.'), ('Q. How is Snowmobile designed to keep data secure digitally? ', 'Your data is encrypted with keys you provided before it is written to the Snowmobile. All data is encrypted with 256-bit encryption. You can manage your encryption keys with the AWS Key Management Service (AWS KMS). Your keys are never permanently stored on the Snowmobile, and are erased as soon as power is removed from the Snowmobile.'), ('Q. How is Snowmobile designed to keep data secure physically?', ' In addition to digital encryption, the Snowmobile is only operated by AWS personnel and physical access to the data container is controlled via secure access hardware controls. All data storage equipment is separated from the network access ports used to load or remove data.This way, physical access to the data container is not needed to operate the container after it has been set up. In addition, Snowmobile is protected by 24/7 video surveillance and alarm monitoring, GPS tracking, and may be escorted by a security vehicle during transit.'), ('Q. Can I still choose to encrypt my data before transferring to Snowmobile?', ' Yes. You can always encrypt your data before transferring it to the Snowmobile. '), ('Q: What AWS Regions are supported?', 'Snowmobile can be made available for use with AWS services in any AWS region. To discuss data transport needs specific for your region please follow up with AWS Sales.'), ('Q: How much does a Snowmobile job cost?', 'Snowmobile provides a practical solution to exabyte-scale data migration and is significantly faster and cheaper than any network-based solutions, which can take decades and millions of dollars of investment in networking and logistics. Snowmobile jobs cost $0.005/GB/month based on the amount of provisioned Snowmobile storage capacity and the end to end duration of the job, which starts when a Snowmobile departs an AWS data center for delivery to the time when data ingestion into AWS is complete. Please contact sales for an evaluation.'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/rds/aurora/faqs/': [('Q: What is Amazon Aurora?', 'Amazon Aurora is a relational database engine that combines the speed and reliability of high-end commercial databases with the simplicity and cost-effectiveness of open source databases. Amazon Aurora MySQL delivers up to five times the performance of MySQL without requiring any changes to most MySQL applications; similarly, Amazon Aurora PostgreSQL delivers up to three times the performance of PostgreSQL. Amazon RDS manages your Amazon Aurora databases, handling time-consuming tasks such as provisioning, patching, backup, recovery, failure detection and repair. You pay a simple monthly charge for each Amazon Aurora database instance you use. There are no upfront costs or long-term commitments required. '), ('Q: What does "MySQL compatible" mean?', 'It means that most of the code, applications, drivers and tools you already use today with your MySQL databases can be used with Aurora with little or no change. The Amazon Aurora database engine is designed to be wire-compatible with MySQL 5.6 using the InnoDB storage engine. Certain MySQL features like the MyISAM storage engine are not available with Amazon Aurora.'), ('Q: What does “PostgreSQL compatible” mean?', 'It means that most of the code, applications, drivers and tools you already use today with your PostgreSQL databases can be used with Aurora with little or no change. The Amazon Aurora database engine is designed to be wire-compatible with PostgreSQL 9.6, and supports the same set of PostgreSQL extensions that are supported with RDS for PostgreSQL 9.6, making it easy to move applications between the two engines. \xa0'), ('Q: How do I try Amazon Aurora?', 'To try Amazon Aurora, sign in to the AWS console, select RDS under the Database category, and choose Amazon Aurora as your database engine.'), ('Q: How much does Amazon Aurora cost? ', 'Please see our pricing page for current pricing information.'), ('Q. Amazon Aurora replicates each chunk of my database volume six ways across three Availability Zones. Does that mean that my effective storage price will be three or six times what is shown on the pricing page?', 'No. Amazon Aurora’s replication is bundled into the price. You are charged based on the storage your database consumes at the database layer, not the storage consumed in Amazon Aurora’s virtualized storage layer.'), ('Q. In which AWS regions is Amazon Aurora available?', 'Please see our pricing page for current information on regions and prices. '), ('Q: How can I migrate from MySQL to Amazon Aurora and vice versa?', 'You have several options. You can use the standard mysqldump utility to export data from MySQL and mysqlimport utility to import data to Amazon Aurora, and vice-versa. You can also use Amazon RDS’s DB Snapshot migration feature to migrate an RDS MySQL DB Snapshot to Amazon Aurora using the AWS Management Console. Migration completes for most customers in under an hour, though the duration depends on format and data set size. For more information see the Amazon Aurora Data Export and Import Guide.'), ('Q: How can I migrate from PostgreSQL to Amazon Aurora and vice versa?', 'You have several options. You can use the standard pg_dump utility to export data from PostgreSQL and pg_restore utility to import data to Amazon Aurora, and vice-versa. You can also use Amazon RDS’s DB Snapshot migration feature to migrate an RDS PostgreSQL 9.6 DB Snapshot to Amazon Aurora using the AWS Management Console. Migration completes for most customers in under an hour, though the duration depends on format and data set size. For more information see the Amazon Aurora Data Export and Import Guide.'), ('Q: Does Amazon Aurora participate in the AWS Free Tier?', 'Not at this time. The AWS Free Tier for Amazon RDS offers benefits for Micro DB Instances; Amazon Aurora does not currently offer Micro DB Instance support. Please see our pricing page for current pricing information.'), ('Q: What are IOs in Amazon Aurora and how are they calculated?', 'IOs are input/output operations performed by the Aurora database engine against its SSD-based virtualized storage layer. Every database page read operation counts as one IO. The Aurora database engine issues reads against the storage layer in order to fetch database pages not present in the buffer cache. Each database page is 16KB in Aurora MySQL and 8KB in Aurora PostgreSQL.'), ('Aurora was designed to eliminate unnecessary IO operations in order to reduce costs and to ensure resources are available for serving read/write traffic. Write IOs are only consumed when pushing transaction log records to the storage layer for the purpose of making writes durable. Write IOs are counted in 4KB units. For example, a transaction log record that is 1024 bytes will count as one IO operation. However, concurrent write operations whose transaction log is less than 4KB can be batched together by the Aurora database engine in order to optimize I/O consumption. Unlike traditional database engines Amazon Aurora never pushes modified database pages to the storage layer, resulting in further IO consumption savings.', 'You can see how many IOs your Aurora instance is consuming by going to the AWS Console. To find your IO consumption, go to the RDS section of the console, look at your list of instances, select your Aurora instances, then look for the “Billed read operations” and “Billed write operations” metrics in the monitoring section.'), ('Q: Do I need to change client drivers to use Amazon Aurora PostgreSQL?', 'No, Amazon Aurora will work with standard PostgreSQL database drivers.'), ('Q: What is Amazon Aurora Serverless?', 'At re:Invent 2017, we announced the preview for Amazon Aurora Serverless, a new configuration of the MySQL-compatible edition that can save you valuable time, effort and cost by automatically scaling database capacity up and down to match your application needs.'), ('Q: How can I get started with Amazon Aurora Serverless?', 'Amazon Aurora Serverless is now available in Preview for the MySQL-compatible edition of Amazon Aurora. You can sign up to request participation. We will announce general availability at a future date.'), ('Q: What does "five times the performance of MySQL" mean?', 'Amazon Aurora delivers significant increases over MySQL performance by tightly integrating the database engine with an SSD-based virtualized storage layer purpose-built for database workloads, reducing writes to the storage system, minimizing lock contention and eliminating delays created by database process threads. Our tests with SysBench on r3.8xlarge instances show that Amazon Aurora delivers over 500,000 SELECTs/sec and 100,000 UPDATEs/sec, five times higher than MySQL running the same benchmark on the same hardware. Detailed instructions on this benchmark and how to replicate it yourself are provided in the Amazon Aurora MySQL Performance Benchmarking Guide.'), ('Q: What does "three times the performance of PostgreSQL" mean?', 'Amazon Aurora delivers significant increases over PostgreSQL performance by tightly integrating the database engine with an SSD-based virtualized storage layer purpose-built for database workloads, reducing writes to the storage system, minimizing lock contention and eliminating delays created by database process threads. Our tests with SysBench on r4.16xlarge instances show that Amazon Aurora delivers SELECTs/sec and UPDATEs/sec over three times higher than PostgreSQL running the same benchmark on the same hardware. Detailed instructions on this benchmark and how to replicate it yourself are provided in the Amazon Aurora PostgreSQL Performance Benchmarking Guide. '), ('Q: How do I optimize my database workload for Amazon Aurora MySQL? ', 'Amazon Aurora is designed to be compatible with MySQL 5.6, so that existing MySQL applications and tools can run without requiring modification. However, one area where Amazon Aurora improves upon MySQL is with highly concurrent workloads. In order to maximize your workload’s throughput on Amazon Aurora, we recommend building your applications to drive a large number of concurrent queries and transactions.'), ('Q: How do I optimize my database workload for Amazon Aurora PostgreSQL?', 'Amazon Aurora is designed to be compatible with PostgreSQL 9.6, so that existing PostgreSQL applications and tools can run without requiring modification. However, one area where Amazon Aurora improves upon PostgreSQL is with highly concurrent workloads. In order to maximize your workload’s throughput on Amazon Aurora, we recommend building your applications to drive a large number of concurrent queries and transactions. '), ('Q: What are the minimum and maximum storage limits of an Amazon Aurora database?', 'The minimum storage is 10GB. Based on your database usage, your Amazon Aurora storage will automatically grow, up to 64 TB, in 10GB increments with no impact to database performance. There is no need to provision storage in advance.'), ('Q: How do I scale the compute resources associated with my Amazon Aurora DB Instance?', 'You can scale the compute resources allocated to your DB Instance in the AWS Management Console by selecting the desired DB Instance and clicking the Modify button. Memory and CPU resources are modified by changing your DB Instance class.'), ('When you modify your DB Instance class, your requested changes will be applied during your specified maintenance window. Alternatively, you can use the "Apply Immediately" flag to apply your scaling requests immediately. Both of these options will have an availability impact for a few minutes as the scaling operation is performed. Bear in mind that any other pending system changes will also be applied.', 'Q: How do I enable backups for my DB Instance?'), ('Automated backups are always enabled on Amazon Aurora DB Instances. Backups do not impact database performance.', 'Q: Can I take DB Snapshots and keep them around as long as I want?'), ('Yes, and there is no performance impact when taking snapshots. Note that restoring data from DB Snapshots requires creating a new DB Instance.', 'Q: If my database fails, what is my recovery path?'), ('Amazon Aurora automatically maintains 6 copies of your data across 3 Availability Zones and will automatically attempt to recover your database in a healthy AZ with no data loss. In the unlikely event your data is unavailable within Amazon Aurora storage, you can restore from a DB Snapshot or perform a point-in-time restore operation to a new instance. Note that the latest restorable time for a point-in-time restore operation can be up to 5 minutes in the past.', 'Q: What happens to my automated backups and DB Snapshots if I delete my DB Instance?'), ('You can choose to create a final DB Snapshot when deleting your DB Instance. If you do, you can use this DB Snapshot to restore the deleted DB Instance at a later date. Amazon Aurora retains this final user-created DB Snapshot along with all other manually created DB Snapshots after the DB Instance is deleted. Only DB Snapshots are retained after the DB Instance is deleted (i.e., automated backups created for point-in-time restore are not kept).', 'Q: Can I share my snapshots with another AWS account?'), ('Yes. Aurora gives you the ability to create snapshots of your databases, which you can use later to restore a database. You can share a snapshot with a different AWS account, and the owner of the recipient account can use your snapshot to restore a DB that contains your data. You can even choose to make your snapshots public – that is, anybody can restore a DB containing your (public) data. You can use this feature to share data between your various environments (production, dev/test, staging, etc.) that have different AWS accounts, as well as keep backups of all your data secure in a separate account in case your main AWS account is ever compromised.', 'Q: Will I be billed for shared snapshots?'), ('There is no charge for sharing snapshots between accounts. However, you may be charged for the snapshots themselves, as well as any databases you restore from shared snapshots. Learn more about Aurora pricing.', 'Q: Can I automatically share snapshots?'), ('We do not support sharing automatic DB snapshots. To share an automatic snapshot, you must manually create a copy of the snapshot, and then share the copy.', 'Q: How many accounts can I share snapshots with?'), ('You may share manual snapshots with up to 20 AWS account IDs. If you want to share the snapshot with more than 20 accounts, you can either share the snapshot as public, or contact support for increasing your quota.', 'Q: In which regions can I share my Aurora snapshots?'), ('You can share your Aurora snapshots in all AWS regions where Aurora is available.', 'Q. Can I share my Aurora snapshots across different regions?'), ('No. Your shared Aurora snapshots will only be accessible by accounts in the same region as the account that shares them.', 'Q: Can I share an encrypted Aurora snapshot?'), ('Yes, you can share encrypted Aurora snapshots.', 'Q: How does Amazon Aurora improve my database’s fault tolerance to disk failures?'), ('Amazon Aurora automatically divides your database volume into 10GB segments spread across many disks. Each 10GB chunk of your database volume is replicated six ways, across three Availability Zones. Amazon Aurora is designed to transparently handle the loss of up to two copies of data without affecting database write availability and up to three copies without affecting read availability. Amazon Aurora storage is also self-healing. Data blocks and disks are continuously scanned for errors and repaired automatically.', 'Q: How does Aurora improve recovery time after a database crash?'), ('Unlike other databases, after a database crash Amazon Aurora does not need to replay the redo log from the last database checkpoint (typically 5 minutes) and confirm that all changes have been applied, before making the database available for operations. This reduces database restart times to less than 60 seconds in most cases. Amazon Aurora moves the buffer cache out of the database process and makes it available immediately at restart time. This prevents you from having to throttle access until the cache is repopulated to avoid brownouts.', 'Q: What kind of replicas does Aurora support?'), ('Amazon Aurora MySQL and Amazon Aurora PostgreSQL support Amazon Aurora Replicas, which share the same underlying volume as the primary instance. Updates made by the primary are visible to all Amazon Aurora Replicas. With Amazon Aurora MySQL, you can also create MySQL Read Replicas based on MySQL’s binlog-based replication engine. In MySQL Read Replicas, data from your primary instance is replayed on your replica as transactions. For most use cases, including read scaling and high availability, we recommend using Amazon Aurora Replicas.', 'You have the flexibility to mix and match these two replica types based on your application needs:'), ('Q. Can I have cross-region replicas with Amazon Aurora?', 'Yes, with Aurora MySQL you can setup a cross-region Aurora Replica from the RDS console. The cross-region replication is based on single threaded MySQL binlog replication and the replication lag will be influenced by the change/apply rate and delays in network communication between the specific regions selected. Aurora PostgreSQL does not currently support cross-region replicas.'), ('Q. Can I create Aurora Read Replicas on the cross-region replica cluster? Yes, you can add Aurora Replicas on the cluster that will share the same underlying storage as the cross-region replica. The cross-region replica acts as the primary on the cluster and the Aurora Replicas on the cluster will typically lag behind the primary by 10s of milliseconds.', 'Q. Can I failover my application from my current primary to the cross-region replica? Yes, you can promote your cross-region replica to be the new primary from the RDS console. The promotion process typically takes a few minutes depending on your workload. The cross-region replication will stop once you initiate the promotion process.'), ('Q: Can I prioritize certain replicas as failover targets over others?', 'A: Yes. You can assign a promotion priority tier to each instance on your cluster. When the primary instance fails, Amazon RDS will promote the replica with the highest priority to primary. If there is contention between 2 or more replicas in the same priority tier, then Amazon RDS will promote the replica that is the same size as the primary instance. For more information on failover logic, read the Amazon Aurora User Guide.'), ('Q: Can I modify priority tiers for instances after they have been created?', 'A: You can modify the priority tier for an instance at any time. Simply modifying priority tiers will not trigger a failover.'), ('Q: Can I prevent certain replicas from being promoted to the primary instance?', 'A: You can assign lower priority tiers to replicas that you don’t want promoted to the primary instance. However, if the higher priority replicas on the cluster are unhealthy or unavailable for some reason, then Amazon RDS will promote the lower priority replica.'), ('Q: How can I improve upon the availability of a single Amazon Aurora database?', 'You can add Amazon Aurora Replicas. Amazon Aurora Replicas share the same underlying storage as the primary instance. Any Amazon Aurora Replica can be promoted to become primary without any data loss and therefore can be used for enhancing fault tolerance in the event of a primary DB Instance failure. To increase database availability, simply create 1 to 15 replicas, in any of 3 AZs, and Amazon RDS will automatically include them in failover primary selection in the event of a database outage.'), ('Q: What happens during failover and how long does it take?', 'Failover is automatically handled by Amazon Aurora so that your applications can resume database operations as quickly as possible without manual administrative intervention.'), ('Your application should retry database connections in the event of connection loss.', 'Q: If I have a primary database and an Amazon Aurora Replica actively taking read traffic and a failover occurs, what happens?'), ('Amazon RDS will automatically detect a problem with your primary instance and begin routing your read/write traffic to an Amazon Aurora Replica. On average, this failover will complete within 30 seconds. In addition, the read traffic that your Amazon Aurora Replicas were serving will be briefly interrupted.', 'Q: How far behind the primary will my replicas be?'), ('Since Amazon Aurora Replicas share the same data volume as the primary instance, there is virtually no replication lag. We typically observe lag times in the 10s of milliseconds. For MySQL Read Replicas, the replication lag can grow indefinitely based on change/apply rate as well as delays in network communication. However, under typical conditions, under a minute of replication lag is common.', 'Q: What is Amazon Aurora Multi-Master?'), ('At re:Invent 2017, we announced the preview for Amazon Aurora Multi-Master, a new feature of the Aurora MySQL-compatible edition that adds the ability to scale out write performance across multiple Availability Zones, allowing applications to direct read/write workloads to multiple instances in a database cluster and operate with higher availability.', 'Q: How can I get started with Amazon Aurora Multi-Master?'), ('Amazon Aurora Multi-Master is now available in Preview for the MySQL-compatible edition of Amazon Aurora. You can sign up to request participation. We will announce general availability at a future date. ', 'Q: Can I use Amazon Aurora in Amazon Virtual Private Cloud (Amazon VPC)?'), ('Yes, all Amazon Aurora DB Instances must be created in a VPC. With Amazon VPC, you can define a virtual network topology that closely resembles a traditional network that you might operate in your own datacenter. This gives you complete control over who can access your Amazon Aurora databases.', 'Q: Does Amazon Aurora encrypt my data in transit and at rest?'), ("Yes. Amazon Aurora uses SSL (AES-256) to secure the connection between the database instance and the application. Amazon Aurora allows you to encrypt your databases using keys you manage through AWS Key Management Service (KMS). On a database instance running with Amazon Aurora encryption, data stored at rest in the underlying storage is encrypted, as are its automated backups, snapshots, and replicas in the same cluster. Encryption and decryption are handled seamlessly. For more information about the use of KMS with Amazon Aurora, see the Amazon RDS User's Guide.", 'Q: Can I encrypt an existing unencrypted database?'), ('Currently, encrypting an existing unencrypted Aurora instance is not supported. To use Amazon Aurora encryption for an existing unencrypted database, create a new DB Instance with encryption enabled and migrate your data into it. ', 'Q: How do I access my Amazon Aurora database?'), ('Access to Amazon Aurora databases must be done through the database port entered on database creation. This is done to provide an additional layer of security for your data. Step by step instructions on how to connect to your Amazon Aurora database is provided in the Amazon Aurora Connectivity Guide.', 'Q: Can I use Amazon Aurora with applications that require HIPAA compliance?'), ('A: Yes, the MySQL- and PostgreSQL-compatible editions of Aurora are HIPAA-eligible, so you can use them to build HIPAA-compliant applications and store healthcare related information, including protected health information (PHI) under an executed Business Associate Agreement (BAA) with AWS. If you already have an executed BAA, no action is necessary to begin using these services in the account(s) covered by your BAA. If you do not have an executed BAA with AWS, or have any other questions about HIPAA-compliant applications on AWS, please contact us. ', 'Q: On which instance sizes will Performance Insights be available?'), ('All non-micro instance sizes. As RDS introduces new instance sizes, Performance Insights will be made available on those that have sufficient performance.', 'Q: When will Performance Insights be available for RDS for PostgreSQL, Aurora MySQL, RDS for MySQL, RDS for Oracle, RDS for SQL Server and RDS for MariaDB?'), ('Performance Insights will be initially available on Aurora PostgreSQL, followed soon after by Aurora MySQL. Additional engines will be added over time.', 'Q: How does Performance Insights show me the cause of performance problems?'), ('Performance problems appear in the Performance Insights section of the RDS console as spikes in the database load graph. One look at this graph can quickly tell you what type of resources your application has been spending time and resources on in the database. The console allows you to zoom in to any period within the retention time. By selecting the periods of high load, customers can display a list of SQL statements, ordered by overall contribution to load.', 'Q: How does Performance Insights know about load in my RDS DB instance?'), ('Performance Insights samples the state of all of the connected sessions in your DB instance every second. If a session is spending time in a database-related operation, Performance Insights records the sample time, the type of operation (I/O, CPU, locking, etc.), the current SQL statement and several other session attributes. Over periods of time, this sampled data is used to characterize how sessions are contributing to load in your database instance.', 'Q: Can performance data be queried from inside the RDS instance?'), ('No. The Performance Insights sampling process does not populate any tables in the database, nor does it present data to be retrieved from within the database via SQL.', 'Q: Can I see what is happening on my instance in real time?'), ('Yes. By default, Performance Insights displays a moving one hour window of performance data. The feature is designed to present the latest performance information within a few seconds of real time.', 'Q: How much does Performance Insights cost?'), ('Performance Insights includes 24 hours of retained data and console access. Performance Insights while in preview, offers a free tier that includes a trailing 24 hours of performance data retention. Pricing for longer term data rentention will be announced.', 'Q: How far back can I look at performance data stored in Performance Insights?'), ('You can see 24 hours of performance history. Options for longer retention will be announced at a future date.', 'Q: Can I turn off Performance Insights on new instances, even though it is enabled by default?'), ('Yes. The option for Performance Insights is selected by default in the AWS Console when you use the instance creation wizard. You can de-select the option in the wizard to prevent Performance Insights from being enabled, or you can disable Performance Insights in an enabled instance my modifying the instance.', 'Q: Does Performance Insights work on RDS database instances using encrypted storage?'), ('Yes. Performance Insights does not read the data you store in your database.', 'Q: What is DB load and why is it the primary measure used in Performance Insights to detect performance issues?'), ('DB load is a time series showing how much time a customer’s applications are spending in the database, and how they are spending that time. DB Load is measured in units of average active sessions (AAS). An active session is a connection (session) that has submitted work to the database engine and is waiting for a response from it. For example, if you submit a SQL statement to a database instance, that session is considered “active” during the time that the instance is processing that query. By counting the number of sessions that are active in an instance at a given moment, we can provide a metric which, averaged over time periods, can show how busy an instance is, and how much time sessions are spending waiting for the instance to respond; this is DB Load. Performance Insights counts active sessions and records each session’s attributes about every second using a lightweight sampling mechanism. The sampled data is encrypted and aggregated to a variety of granularities and served in the DB Load chart. Console users can select the timeframe they want to view.', 'Q: Do I have to do anything special to my database to enable Performance Insights?'), ('No. However, Performance Insights will work even better on some database engines when additional performance tracking is enabled. For instance, when the pg_stat_statement extension is enabled on RDS PostgreSQL or Aurora PostgreSQL, Performance Insights will use the PostgreSQL-native SQL identifier to identify the statement, and will be able to collect the full text of longer statements. In MySQL, enabling the Performance Schema will allow Performance Insights to collect much richer and deeper detail on wait events affecting the database.', 'Q: Will enabling Performance Insights affect my database performance?'), ('The Performance Insights agent is designed to stay out of the way of your database workloads. Performance Insights runs at a lower priority than the other processes on your instance, and monitors the health of the host and database. When Performance Insights detects heavy load or depleted resources, it backs off from the usual frequency of data gathering, still collecting data, but only when it is safe to do so. Database options, such as pg_stat_statement in RDS PostgreSQL and Aurora Postgres, and Performance Schema in MySQL may use some database resources and potentially affect performance. Whether enabling these options will affect a particular system depends on the application workload. AWS recommends testing any database options against your workload prior to enabling them on a production system.', 'Q: Should I keep using Enhanced Monitoring or just use Performance Insights?'), ('Customers using Enhanced Monitoring to monitor O/S metrics should continue to obtain that data via Enhanced Monitoring. In the months to come, that data, as well as an extensive colletion of database metrics, will also become available via the Performance Insights console and an API. At that point, customers will be able to obtain all performance data from Performance Insights. Enhanced Monitoring will remain available for those customers who prefer to use it, but we will encourage customers to standardize their database monitoring on Performance Insights.', 'Q: Is the data stored in Performance Insights encrypted?'), ('Yes. Performance Insights encrypts all potentially sensitive data using your own KMS key. Data is encrypted in flight and at rest. AWS personnel cannot access or see any potentially sensitive performance data. Only your users on your AWS account with full access to RDS can view Performance Insights. You can revoke RDS’s grant for your KMS key, which enables us to process and display your performance data, at any time.', 'Q: If I turn off Performance Insights, does AWS retain the data or is it deleted?'), ('Performance data retention free tier is restricted to one day. Disabling Performance Insights on an instance causes your performance data for that instance to be deleted.', 'Q: What happens to Performance Insights data retention when I stop my RDS database instance?'), ('Stopping an RDS instance that has Performance Insights enabled has no effect on retention or visibility of historical data for that instance. The period during which the instance was stopped will simply contain no data.', 'Q: How would I interface Performance Insights with my existing performance tools?'), ('In the future, Performance Insights will expose a publicly available API designed to enable customers and third parties to take advantage of the valuable data in Performance Insights.', 'Q: Is there any way for third party performance tools to integrate with Performance Insights?'), ('In the future, Performance Insights will expose a publicly available API designed to enable customers and third parties to take advantage of the valuable data in Performance Insights.', 'Q: Will Performance Insights be available in all AWS Regions RDS is?'), ('Yes. Performance Insights will initially be available in four regions: US East (N. Virginia, Ohio), US West (Oregon), and EU (Ireland). Over time, the feature will be made available in all reguions where RDS is supported.', 'Q: Can I turn on Performance Insights on existing instances or only on new ones?'), ('Yes, Performance Insights can be enabled on existing instances by modifying the instance to enable Performance Insights. It can be enabled on new instances by specifying that Performance Insights should be enabled when creating the instance.', 'Q: Does Performance Insights use any of the storage on my database instance?'), ('No, Performance Insights does not consume storage space on your RDS instances.', 'Q: How will Performance Insights be different, if at all, when running against different database engines?'), ('Performance Insights is designed to present a common approach, look and feel to tuning across all database engines in RDS. Because certain attributes like wait events and SQL identifiers vary by engine type, these will naturally vary in Performance Insights as well, when working with different database engines. One of the core tenets of Performance Insights is that existing concepts, identifiers, and attributes in a database engine should remain intact. Performance Insights will generally not re-interpret or rename wait events an other engine-specific attributes, but will present them faithfully as reported by the database engine.', 'Q: Does Performance Insights work on Multi-AZ instances and Read Replica instances?'), ('Yes. If an RDS database uses Multi-AZ and has Performance Insights enabled, then Performance Insights will remain enabled when and if that instance fails over to the other availability zone. Because Read Replicas are independent instances, customers can either enable or disable Performance Insights on those instances.', 'Q: Can I export my data from Performance Insights?'), ('In the future, Performance Insights will be adding functionality to export data.', 'Q: Can I re-import my data to Performance Insights later in order to do performance analysis?'), ('No. Performance Insights only shows data that has been collected directly from an instance. Data obtained via the Performance Insights will be available in the moths to come via an API and then analysis can be done using one of the analytics-oriented services in AWS, such as Amazon Athena, Amazon Redshift, Amazon Redshift Spectrum, and Amazon Quicksight. ', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/redshift/faqs/': [('Q: What is Amazon Redshift?  Amazon Redshift is a fast, fully managed data warehouse that makes it simple and cost-effective to analyze all your data using standard SQL and your existing Business Intelligence (BI) tools. It allows you to run complex analytic queries against petabytes of structured data, using sophisticated query optimization, columnar storage on high-performance local disks, and massively parallel query execution. Most results come back in seconds. With Redshift, you can start small for just $0.25 per hour with no commitments and scale out to petabytes of data for $1,000 per terabyte per year, less than a tenth the cost of traditional solutions. Amazon Redshift also includes Amazon Redshift Spectrum, allowing you to directly run SQL queries against exabytes of unstructured data in Amazon S3. No loading or transformation is required, and you can use open data formats,\xa0including Avro, CSV, Grok, ORC, Parquet, RCFile, RegexSerDe, SequenceFile, TextFile, and TSV. Redshift Spectrum automatically scales query compute capacity based on the data being retrieved, so queries against Amazon S3 run fast, regardless of data set size. ', 'Traditional data warehouses require significant time and resource to administer, especially for large datasets. In addition, the financial cost associated with building, maintaining, and growing self-managed, on-premise data warehouses is very high. As your data grows, you have to constantly trade-off what data to load into your data warehouse and what data to archive in storage so you can manage costs, keep ETL complexity low, and deliver good performance. Amazon Redshift not only significantly lowers the cost and operational overhead of a data warehouse, but with Redshift Spectrum, also makes it easy to analyze large amounts of data in its native format without requiring you to load the data. '), ('Amazon Redshift gives you fast querying capabilities over structured data using familiar SQL-based clients and business intelligence (BI) tools using standard ODBC and JDBC connections. Queries are distributed and parallelized across multiple physical resources. You can easily scale an Amazon Redshift data warehouse up or down with a few clicks in the AWS Management Console or with a single API call. Amazon Redshift automatically patches and backs up your data warehouse, storing the backups for a user-defined retention period. Amazon Redshift uses replication and continuous backups to enhance availability and improve data durability and can automatically recover from component and node failures. In addition, Amazon Redshift supports Amazon Virtual Private Cloud (Amazon VPC), SSL, AES-256 encryption and Hardware Security Modules (HSMs) to protect your data in transit and at rest.', 'As with all Amazon Web Services, there are no up-front investments required, and you pay only for the resources you use. Amazon Redshift lets you pay as you go. You can even try Amazon Redshift for free.'), ('Q: What is Amazon Redshift Spectrum?', 'Amazon Redshift Spectrum is a feature of Amazon Redshift that enables you to run queries against exabytes of unstructured data in Amazon S3, with no loading or ETL required. When you issue a query, it goes to the Amazon Redshift SQL endpoint, which generates and optimizes a query plan. Amazon Redshift determines what data is local and what is in Amazon S3, generates a plan to minimize the amount of Amazon S3 data that needs to be read, requests Redshift Spectrum workers out of a shared resource pool to read and process data from Amazon S3.'), ('Redshift Spectrum scales out to thousands of instances if needed, so queries run quickly regardless of data size. And, you can use the exact same SQL for Amazon S3 data as you do for your Amazon Redshift queries today and connect to the same Amazon Redshift endpoint using your same BI tools. Redshift Spectrum lets you separate storage and compute, allowing you to scale each independently. You can setup as many Amazon Redshift clusters as you need to query your Amazon S3 data lake, providing high availability and limitless concurrency. Redshift Spectrum gives you the freedom to store your data where you want, in the format you want, and have it available for processing when you need it.', 'Q: What does Amazon Redshift manage on my behalf?   Amazon Redshift manages the work needed to set up, operate, and scale a data warehouse, from provisioning the infrastructure capacity to automating ongoing administrative tasks such as backups, and patching. Amazon Redshift automatically monitors your nodes and drives to help you recover from failures.\xa0For Redshift Spectrum, Amazon Redshift manages all the computing infrastructure, load balancing, planning, scheduling and execution of your queries on data stored in Amazon S3.'), ('Q: How does the performance of Amazon Redshift compare to most traditional databases for data warehousing and analytics?  Amazon Redshift uses a variety of innovations to achieve up to ten times higher performance than traditional databases for data warehousing and analytics workloads:', "Q: How do I get started with Amazon Redshift?  You can sign up and get started within minutes from the Amazon Redshift detail page or via the AWS Management Console. If you don't already have an AWS account, you'll be prompted to create one."), ('To use Redshift Spectrum, you need to first store your data in Amazon S3. You can then define the metadata about that data in your Amazon Redshift cluster or register the metadata you may already have in your Hive metastore with your cluster. You can issue a CREATE EXTERNAL SCHEMA SQL command in your Amazon Redshift cluster to define or register a database in your catalog as an external schema within Amazon Redshift. You can then issue queries against Amazon S3 using the same SQL you use for local tables and any BI tool that supports Amazon Redshift today. The external database definition you create using Amazon Redshift SQL is registered in the same data catalog that Amazon Athena uses. You can optionally manage the external database definition from the Amazon Athena Catalog as well.\xa0', 'Visit our Getting Started\xa0page\xa0to see how to try Amazon Redshift for free.'), ('Q: In which AWS regions is Amazon Redshift available?', 'For information about Amazon Redshift regional availability, see the Region Table in the AWS Global Infrastructure page.'), ('Q: In which AWS regions is Redshift Spectrum available?', 'Amazon Redshift Spectrum is available in the following AWS Regions: US East (Northern Virginia), US East (Ohio), US West (Northern California), US West (Oregon), Canada (Central), EU (Frankfurt), EU (Ireland), EU (London), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), and Asia Pacific (Tokyo). '), ('Q: How do I create an Amazon Redshift data warehouse cluster?  You can easily create an Amazon Redshift data warehouse cluster by using the AWS Management Console or the Amazon Redshift APIs. You can start with a single node, 160GB data warehouse and scale all the way to a petabyte or more with a few clicks in the AWS Console or a single API call.', 'The single node configuration enables you to get started with Amazon Redshift quickly and cost-effectively and scale up to a multi-node configuration as your needs grow. The multi-node configuration requires a leader node that manages client connections and receives queries, and two compute nodes that store data and perform queries and computations. The leader node is provisioned for you automatically and you are not charged for it.'), ("Simply specify your preferred Availability Zone (optional), the number of nodes, node types, a master name and password, security groups, your preferences for backup retention, and other system settings. Once you've chosen your desired configuration, Amazon Redshift will provision the required resources and set up your data warehouse cluster.", 'Q: What does a leader node do?\xa0What does a compute node do?   A leader node receives queries from client applications, parses the queries and develops execution plans, which are an ordered set of steps to process these queries. The leader node then coordinates the parallel execution of these plans with the compute nodes, aggregates the intermediate results from these nodes and finally returns the results back to the client applications.'), ('Compute nodes execute the steps specified in the execution plans and transmit data among themselves to serve these queries. The intermediate results are sent back to the leader node for aggregation before being sent back to the client applications.', 'Q: What is the maximum storage capacity per compute node?\xa0What is the recommended amount of data per compute node for optimal performance?   You can create a cluster using either Dense Storage (DS) node types or Dense Compute (DC) node types. Dense Storage node types enable you to create very large data warehouses using hard disk drives (HDDs) for a very low price point. Dense Compute node types enable you to create very high performance data warehouses using fast CPUs, large amounts of RAM and solid-state disks (SSDs).'), ('Dense Storage (DS) node types are available in two sizes, Extra Large and Eight Extra Large. The Extra Large (XL) has 3 HDDs with a total of 2TB of magnetic storage, whereas Eight Extra Large (8XL) has 24 HDDs with a total of 16TB of magnetic storage. DS2.8XLarge has 36 Intel Xeon E5-2676 v3 (Haswell) virtual cores and 244GiB of RAM, and DS2.XL has 4 Intel Xeon E5-2676 v3 (Haswell) virtual cores and 31GiB of RAM. Please see our pricing page for more detail. You can get started with a single Extra Large node, 2TB data warehouse for $0.85 per hour and scale up to a petabyte or more. You can pay by the hour or use reserved instance pricing to lower your price to under $1,000 per TB per year.', 'Dense Compute (DC) node types are also available in two sizes. The Large has 160GB of SSD storage, 2 Intel Xeon E5-2670v2 (Ivy Bridge) virtual cores and 15GiB of RAM. The Eight Extra Large is sixteen times bigger with 2.56TB of SSD storage, 32 Intel Xeon E5-2670v2 virtual cores and 244GiB of RAM. You can get started with a single DC2.Large node for $0.25 per hour and scale all the way up to 128 8XL nodes with 326TB of SSD storage, 3,200 virtual cores and 24TiB of RAM.'), ("Amazon Redshift's MPP architecture means you can increase your performance by increasing the number of nodes in your data warehouse cluster. The optimal amount of data per compute node depends on your application characteristics and your query performance needs.", 'Q: How many nodes can I specify per Amazon Redshift data warehouse cluster?  An Amazon Redshift data warehouse cluster can contain from 1-128 compute nodes, depending on the node type. For details please see our documentation.'), ('Q: How do I access my running data warehouse cluster?  Once your data warehouse cluster is available, you can retrieve its endpoint and JDBC and ODBC connection string from the AWS Management Console or by using the Redshift APIs. You can then use this connection string with your favorite database tool, programming language, or Business Intelligence (BI) tool. You will need to authorize network requests to your running data warehouse cluster. For a detailed explanation please refer to our Getting Started Guide.', 'Q: When would I use Amazon Redshift vs. Amazon RDS?  Both Amazon Redshift and Amazon RDS enable you to run traditional relational databases in the cloud while offloading database administration. Customers use Amazon RDS databases both for online-transaction processing (OLTP) and for reporting and analysis. Amazon Redshift harnesses the scale and resources of multiple nodes and uses a variety of optimizations to provide order of magnitude improvements over traditional databases for analytic and reporting workloads against very large data sets. Amazon Redshift provides an excellent scale-out option as your data and query complexity grows or if you want to prevent your reporting and analytic processing from interfering with the performance of your OLTP workload.'), ('Q: When would I use Amazon Redshift vs. Amazon EMR?  You should use Amazon EMR if you use custom code to process and analyze extremely large datasets with big data processing frameworks such as Apache Spark, Hadoop, Presto, or Hbase. Amazon EMR gives you full control over the configuration of your clusters and the software you install on them.', 'Data warehouses like Amazon Redshift are designed for a different type of analytics altogether. Data warehouses are designed to pull together data from lots of different sources, like inventory, financial, and retail sales systems. In order to ensure that reporting is consistently accurate across the entire company, data warehouses store data in a highly structured fashion. This structure builds data consistency rules directly into the tables of the database.'), ('Amazon Redshift is the best service to use when you need to perform complex queries on massive collections of structured data and get superfast performance.', 'Q: Can Redshift Spectrum replace Amazon EMR?'), ('No. While Redshift Spectrum is great for running queries against data in Amazon Redshift and S3, it really isn’t a fit for the types of use cases that enterprises typically ask from processing frameworks like Amazon EMR. Amazon EMR goes far beyond just running SQL queries. Amazon EMR is a managed service that lets you process and analyze extremely large data sets using the latest versions of popular big data processing frameworks, such as Spark, Hadoop, and Presto, on fully customizable clusters. With Amazon EMR you can run a wide variety of scale-out data processing tasks for applications such as machine learning, graph analytics, data transformation, streaming data, and virtually anything you can code. You can also use Redshift Spectrum together with EMR. Amazon Redshift Spectrum uses the same approach to store table definitions as Amazon EMR. So, if you’re already using EMR to process a large data store, you can use Redshift Spectrum to query that data right at the same time without interfering with your Amazon EMR jobs.', 'Query services, data warehouses, and complex data processing frameworks all have their place, and they are used for different things. You just need to choose the right tool for the job.'), ('Q: When should I use Amazon Athena vs. Redshift Spectrum?', 'Amazon Athena is the simplest way to give any employee the ability to run ad-hoc queries on data in Amazon S3. Athena is serverless, so there is no infrastructure to setup or manage, and you can start analyzing your data immediately.'), ('If you have frequently accessed data, that needs to be stored in a consistent, highly structured format, then you should use a data warehouse like Amazon Redshift. This gives you the flexibility to store your structured, frequently accessed data in Amazon Redshift, and use Redshift Spectrum to extend your Amazon Redshift queries out to the entire universe of data in your Amazon S3 data lake. This gives you the freedom to store your data where you want, in the format you want, and have it available for processing when you need.', 'Q: Can I use Redshift Spectrum to query data that I process using Amazon EMR?'), ('Yes, Redshift Spectrum can support the same Apache Hive Metastore used by Amazon EMR to locate data and table definitions. If you’re using Amazon EMR and have a Hive Metastore already, you just have to configure your Amazon Redshift cluster to use it. You can then start querying that data right away along with your Amazon EMR jobs. ', 'Q: Why should I use Amazon Redshift instead of running my own MPP data warehouse cluster on Amazon EC2?  Amazon Redshift automatically handles many of the time-consuming tasks associated with managing your own data warehouse including:'), ('Back to top » ', 'Q: How will I be charged and billed for my use of Amazon Redshift?  You pay only for what you use, and there are no minimum or setup fees. You are billed based on:'), ('For Amazon Redshift pricing information, please visit the Amazon Redshift pricing page.', 'Q: When does billing of my Amazon Redshift data warehouse clusters begin and end?  Billing commences for a data warehouse cluster as soon as the data warehouse cluster is available. Billing continues until the data warehouse cluster terminates, which would occur upon deletion or in the event of instance failure.'), ('Q: What defines billable Amazon Redshift instance hours?  Node usage hours are billed for each hour your data warehouse cluster is running in an available state. If you no longer wish to be charged for your data warehouse cluster, you must terminate it to avoid being billed for additional node hours. Partial node hours consumed are billed as full hours. ', 'Q: Do your prices include taxes?'), ('Except as otherwise noted, our prices are exclusive of applicable taxes and duties, including VAT and applicable sales tax.\xa0For customers with a Japanese billing address, use of AWS services is subject to Japanese Consumption Tax. Learn more.', 'Back to top »'), ('Q: How do I load data into my Amazon Redshift data warehouse?  You can load data into Amazon Redshift from a range of data sources including Amazon S3, Amazon DynamoDB, Amazon EMR,\xa0AWS Data Pipeline and or any SSH-enabled host on Amazon EC2 or on-premises. Amazon Redshift attempts to load your data in parallel into each compute node to maximize the rate at which you can ingest data into your data warehouse cluster. For more details on loading data into Amazon Redshift please view our Getting Started Guide.', "Q: Can I load data using SQL ‘INSERT' statements?  Yes, clients can connect to Amazon Redshift using ODBC or JDBC and issue 'insert' SQL commands to insert the data. Please note this is slower than using S3 or DynamoDB since those methods load data in parallel to each compute node while SQL insert statements load via the single leader node."), ('Q: How do I load data from my existing Amazon RDS, Amazon EMR, Amazon DynamoDB, and Amazon EC2 data sources to Amazon Redshift?  You can use our COPY command to load data in parallel directly to Amazon Redshift from Amazon EMR, Amazon DynamoDB, or any SSH-enabled host.\xa0Redshift Spectrum also enables you to load data from Amazon S3 into your cluster with a simple INSERT INTO command. This could enable you to load data from various formats such as Parquet and RC into your cluster. Note that if you use this approach, you will accrue Redshift Spectrum charges for the data scanned from Amazon S3.', 'In addition, many ETL companies have certified Amazon Redshift for use with their tools, and a number are offering free trials to help you get started loading your data. AWS Data Pipeline provides a high performance, reliable, fault tolerant solution to load data from a variety of AWS data sources. You can use AWS Data Pipeline to specify the data source, desired data transformations, and then execute a pre-written import script to load your data into Amazon Redshift. Also, AWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy to prepare and load data for analytics. You can create and run an AWS Glue ETL job with a few clicks in the AWS Management Console.'), ('Q: I have a lot of data for initial loading into Amazon Redshift. Transferring via the Internet would take a long time. How do I load this data?  You can use AWS Import/Export to transfer the data to Amazon S3 using portable storage devices. In addition, you can use AWS Direct Connect to establish a private network connection between your network or datacenter and AWS. You can choose 1Gbit/sec or 10Gbit/sec connection ports to transfer your data. ', 'Back to top » '), ('Q: How does Amazon Redshift keep my data secure?  Amazon Redshift encrypts and keeps your data secure in transit and at rest using industry-standard encryption techniques. To keep data secure in transit, Amazon Redshift supports SSL-enabled connections between your client application and your Redshift data warehouse cluster. To keep your data secure at rest, Amazon Redshift encrypts each block using hardware-accelerated AES-256 as it is written to disk. This takes place at a low level in the I/O subsystem, which encrypts everything written to disk, including intermediate query results. The blocks are backed up as is, which means that backups are encrypted as well. By default, Amazon Redshift takes care of key management but you can choose to manage your keys using your own hardware security modules (HSMs)\xa0or manage your keys through AWS Key Management Service.', 'Redshift Spectrum supports Amazon S3’s Server Side Encryption (SSE) using your account’s default key managed used by the AWS Key Management Service (KMS).'), ('Q: Can I use Amazon Redshift in Amazon Virtual Private Cloud (Amazon VPC)?  Yes, you can use Amazon Redshift as part of your VPC configuration. With Amazon VPC, you can define a virtual network topology that closely resembles a traditional network that you might operate in your own datacenter. This gives you complete control over who can access your Amazon Redshift data warehouse cluster.', 'You can use Redshift Spectrum with an Amazon Redshift cluster that is part of your VPC. Note that Redshift Spectrum does not currently support Enhanced VPC Routing.'), ("Q: Can I access my Amazon Redshift compute nodes directly?  No. Your Amazon Redshift compute nodes are in a private network space and can only be accessed from your data warehouse cluster's leader node. This provides an additional layer of security for your data. ", 'Back to top » '), ('Q: What happens to my data warehouse cluster availability and data durability if a drive on one of my nodes fails?  Your Amazon Redshift data warehouse cluster will remain available in the event of a drive failure however you may see a slight decline in performance for certain queries. In the event of a drive failure, Amazon Redshift will transparently use a replica of the data on that drive which is stored on other drives within that node. In addition, Amazon Redshift will attempt to move your data to a healthy drive or will replace your node if it is unable to do so.\xa0Single node clusters do not support data replication. In the event of a drive failure you will need to restore the cluster from snapshot on S3. We recommend using at least two nodes for production.', 'Q: What happens to my data warehouse cluster availability and data durability in the event of individual node failure?  Amazon Redshift will automatically detect and replace a failed node in your data warehouse cluster. The data warehouse cluster will be unavailable for queries and updates until a replacement node is provisioned and added to the DB. Amazon Redshift makes your replacement node available immediately and loads your most frequently accessed data from S3 first to allow you to resume querying your data as quickly as possible.\xa0Single node clusters do not support data replication. In the event of a drive failure you will need to restore the cluster from snapshot on S3. We recommend using at least two nodes for production.'), ("Q: What happens to my data warehouse cluster availability and data durability in the event if my data warehouse cluster's Availability Zone (AZ) has an outage?  If your Amazon Redshift data warehouse cluster's Availability Zone becomes unavailable, you will not be able to use your cluster until power and network access to the AZ are restored. Your data warehouse cluster's data is preserved so you can start using your Amazon Redshift data warehouse as soon as the AZ becomes available again. In addition, you can also choose to restore any existing snapshots to a new AZ in the same Region. Amazon Redshift will restore your most frequently accessed data first so you can resume queries as quickly as possible.", "Q: Does Amazon Redshift support Multi-AZ Deployments?  Currently, Amazon Redshift only supports Single-AZ deployments. You can run data warehouse clusters in multiple AZ's by loading data into two Amazon Redshift data warehouse clusters in separate AZs from the same set of Amazon S3 input files. With Redshift Spectrum, you can spin up multiple clusters across AZs and access data in Amazon S3 without having to load it into your cluster. In addition, you can also restore a data warehouse cluster to a different AZ from your data warehouse cluster snapshots. "), ('Back to top » ', 'Q: How does Amazon Redshift back up my data?  Amazon Redshift replicates all your data within your data warehouse cluster when it is loaded and also continuously backs up your data to S3. Amazon Redshift always attempts to maintain at least three copies of your data (the original and replica on the compute nodes and a backup in Amazon S3). Redshift can also asynchronously replicate your snapshots to S3 in another region for disaster recovery.'), ('Q: How long does Amazon Redshift retain backups?\xa0Is it configurable?  By default, Amazon Redshift retains backups for 1 day. You can configure this to be as long as 35 days.', 'Q: How do I restore my Amazon Redshift data warehouse cluster from a backup?  You have access to all the automated backups within your backup retention window. Once you choose a backup from which to restore, we will provision a new data warehouse cluster and restore your data to it.'), ('Q: Do I need to enable backups for my data warehouse cluster or is it done automatically?  By default, Amazon Redshift enables automated backups of your data warehouse cluster with a 1-day retention period. Free backup storage is limited to the total size of storage on the nodes in the data warehouse cluster and only applies to active data warehouse clusters. For example, if you have total data warehouse storage of 8TB, we will provide at most 8TB of backup storage at no additional charge. If you would like to extend your backup retention period beyond one day, you can do so using the AWS Management Console or the Amazon Redshift APIS. For more information on automated snapshots, please refer to the Amazon Redshift Management Guide. Amazon Redshift only backs up data that has changed so most snapshots only use up a small amount of your free backup storage.', 'Q: How do I manage the retention of my automated backups and snapshots?  You can use the AWS Management Console or ModifyCluster API to manage the period of time your automated backups are retained by modifying the RetentionPeriod parameter. If you desire to turn off automated backups altogether, you can do so by setting the retention period to 0 (not recommended).'), ('Q: What happens to my backups if I delete my data warehouse cluster?  When you delete a data warehouse cluster, you have the ability to specify whether a final snapshot is created upon deletion, which enables a restore of the deleted data warehouse cluster at a later date. All previously created manual snapshots of your data warehouse cluster will be retained and billed at standard Amazon S3 rates, unless you choose to delete them. ', 'Back to top » '), ("Q: How do I scale the size and performance of my Amazon Redshift data warehouse cluster?  If you would like to increase query performance or respond to CPU, memory or I/O over-utilization, you can increase the number of nodes within your data warehouse cluster via the AWS Management Console or the ModifyCluster API. When you modify your data warehouse cluster, your requested changes will be applied immediately. Metrics for compute utilization, storage utilization, and read/write traffic to your Amazon Redshift data warehouse cluster are available free of charge via the AWS Management Console or Amazon CloudWatch APIs. You can also add additional, user-defined metrics via Amazon Cloudwatch's custom metric functionality.", 'With Redshift Spectrum, you can run multiple Amazon Redshift clusters accessing the same data in Amazon S3. You can use different clusters for different use cases. For example, you can use one cluster for standard reporting and another for data science queries. Your marketing team can use their own clusters different from your operations team. Depending on the type and number of nodes in your local cluster, and the number of files need to be processed for your query, Redshift Spectrum automatically distributes the execution of your query to several Redshift Spectrum workers out of a shared resource pool to read and process data from Amazon S3, and pulls results back into your Amazon Redshift cluster for any remaining processing.'), ('Q: Will my data warehouse cluster remain available during scaling?  The existing data warehouse cluster remains available for read operations while a new data warehouse cluster gets created during scaling operations. When the new data warehouse cluster is ready, your existing data warehouse cluster will be temporarily unavailable while the canonical name record of the existing data warehouse cluster is flipped to point to the new data warehouse cluster. This period of unavailability typically lasts only a few minutes, and will occur during the maintenance window for your data warehouse cluster, unless you specify that the modification should be applied immediately. Amazon Redshift moves data in parallel from the compute nodes in your existing data warehouse cluster to the compute nodes in your new cluster. This enables your operation to complete as quickly as possible. ', 'Back to top » '), ('Q: Is Amazon Redshift compatible with my preferred business intelligence software package and ETL tools?  Amazon Redshift uses industry-standard SQL and is accessed using standard JDBC and ODBC drivers. You can download Amazon Redshift custom JDBC and ODBC drivers from the Connect Client tab of our Console. We have validated integrations with popular BI and ETL vendors, a number of which are offering free trials to help you get started loading and analyzing your data. You can also go to the AWS Marketplace\xa0to deploy and\xa0configure solutions designed to work with Amazon Redshift in minutes.', 'Q: What kinds of queries does Redshift Spectrum support?'), ('You use exactly the same query syntax and have the same query capabilities to access tables in Redshift Spectrum as you have for tables in the local storage of your cluster. External tables are referenced using the schema name defined in the CREATE EXTERNAL SCHEMA command where they were registered.', 'Q: What happens if a table in my local storage has the same name as an external table?'), ('Just like with local tables, you can use the schema name to pick exactly which one you mean by using schema_name.table_name in your query.', 'Q: What BI tools and SQL Clients does Redshift Spectrum support?'), ('Redshift Spectrum supports all Amazon Redshift client tools. The client tools can continue to connect to the Amazon Redshift cluster endpoint using ODBC or JDBC connections. No changes are required.', 'Q: What data formats does Redshift Spectrum support?'), ('Redshift Spectrum currently supports numerous open source data formats, including Avro, CSV, Grok, ORC, Parquet, RCFile, RegexSerDe, SequenceFile, TextFile, and TSV.', 'Q: What compression formats does Redshift Spectrum support?'), ('Redshift Spectrum currently supports Gzip and Snappy compression.', 'Q: I use a Hive Metastore to store metadata about my S3 data lake. Can I use Redshift Spectrum?'), ('Yes. The CREATE EXTERNAL SCHEMA command supports Hive Metastores. We do not currently support DDL against the Hive Metastore.', 'Q: How do I get a list of all external database tables created in my cluster?'), ('You can query the system table SVV_EXTERNAL_TABLES to get that information. ', 'Q: How do I monitor the performance of my Amazon Redshift data warehouse cluster?'), ('Metrics for compute utilization, storage utilization, and read/write traffic to your Amazon Redshift data warehouse cluster are available free of charge via the AWS Management Console or Amazon CloudWatch APIs. You can also add additional, user-defined metrics via Amazon Cloudwatch’s custom metric functionality. In addition to CloudWatch metrics, Amazon Redshift also provides information on query and cluster performance via the AWS Management Console. This information enables you to see which users and queries are consuming the most system resources and diagnose performance issues. In addition, you can see the resource utilization on each of your compute nodes to ensure that you have data and queries that are well balanced across all nodes.', 'Q: I notice that some queries accessing data in my cluster are running slower than my Redshift Spectrum queries. Why is that?'), ('Amazon Redshift queries are run on your cluster resources against local disk. Redshift Spectrum queries run using per-query scale-out resources against data in S3. For most queries, local disk will be faster, but for queries that scan a lot of data and do minimal compute processing, we can apply a lot of Redshift Spectrum workers and complete them quickly. ', 'Q: What is a maintenance window? Will my data warehouse cluster be available during software maintenance?'), ('Amazon Redshift periodically performs maintenance to apply fixes, enhancements and new features to your cluster. You can change the scheduled maintenance windows by modifying the cluster, either programmatically or by using the Amazon Redshift Console. During these maintenance windows, your Amazon Redshift cluster is not available for normal operations. For more information about maintenance windows and schedules by region, see Maintenance Windows in the Amazon Redshift Management Guide.', 'Back to top »'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/dms/faqs/': [('Q: Will AWS Database Migration Service help me convert my Oracle PL/SQL and SQL Server T-SQL code to Amazon Aurora or MySQL and PostgreSQL stored procedures?', 'Yes, part of the AWS Database Migration Service is the free AWS Schema Conversion Tool (SCT) that automates the conversion of Oracle PL/SQL and SQL Server T-SQL code to equivalent code in the Amazon Aurora / MySQL dialect of SQL or the equivalent PL/pgSQL code in PostgreSQL. When a code fragment cannot be automatically converted to the target language, SCT will clearly document all locations that require manual input from the application developer.'), ('Q: How do I get started with AWS Database Migration Service?', 'Getting started with AWS Database Migration Service is quick and simple. Most data replication tasks can be set up in less than 10 minutes. Visit the AWS Database Migration Service section of the AWS Management Console and enter the Start Migration wizard. Specify your source and target endpoints, select an existing replication instance or create a new one, and accept the default schema mapping rules or define your own transformations. Data replication will start immediately after you complete the wizard.'), ('Q. In addition to one-time data migration, can I use AWS Database Migration Service for continuous data replication?', 'Yes, you can use AWS Database Migration Service for both one-time data migration into RDS and EC2-based databases as well as for continuous data replication. AWS Database Migration Service will capture changes on the source database and apply them in a transactionally-consistent way to the target. Continuous replication can be done from your data center to the databases in AWS or in the reverse, replicating to a database in your datacenter from a database in AWS. Ongoing continuous replication can also be done between homogenous or heterogeneous databases. For ongoing replication it would be preferable to use Multi-AZ for high-availability.'), ('Q. How are AWS Database Migration Service (DMS) and AWS Schema Conversion Tool (SCT) related?', 'DMS and SCT work in conjunction to both migrate databases and support ongoing replication for a variety of uses such as populating datamarts, synchronizing systems, etc. SCT can copy database schemas for homogeneous migrations and convert them for hetergeneous migrations. The schemas can be between databases e.g.) Oracle to PostgreSQL or between data warehouses e.g.) Netezza to Amazon Redshift.'), ('Once a schema has been created on an empty target, depending on the volume of data and/or supported engines, either DMS or SCT are then used to move the data. DMS traditionally moves smaller relational workloads (<10 TB) and MongoDB, whereas SCT is primarily used to migrate large data warehouse workloads. DMS supports ongoing replication to keep the target in sync with the source; SCT does not.', 'Q. What sources and targets does AWS Database Migration Service support?'), ('AWS Database Migration Service (DMS) supports a range of homogenous and heterogeneous data replications.', 'Either the source or the target database (or both) need to reside in RDS or on EC2. Replication between on-premises to on-premises databases is not supported.'), ('Q. What sources and targets does AWS Schema Conversion Tool support?', 'AWS Schema Converstion Tool (SCT) supports a range of database and data warehouse conversions which are listed here. Note that SCT can be used to:'), ('Q: Why should I use AWS Database Migration Service instead of my own self-managed replication solution?', 'AWS Database Migration Service is very easy to use. Replication tasks can be set up in minutes instead of hours or days, compared to the self-managed replication solutions that have to be installed and configured. AWS Database Migration Service monitors for replication tasks, network or host failures, and automatically provisions a host replacement in case of failures that can’t be repaired.Users of AWS Database Migration Service don’t have to overprovision capacity and invest in expensive hardware and replication software, as they typically have to do with self-managed solutions. With AWS Database Migration Service users can take advantage of on-demand pricing and scale their replication infrastructure up or down, depending on the load. AWS Database Migration Service data replication integrates tightly with the AWS Schema Conversion Tool, simplifying heterogeneous database migration projects. '), ('Q. Can you summarize the database migration steps using AWS Database Migration Service for me?', 'During a typical simple database migration you will create a target database, migrate the database schema, setup the data replication process, initiate the full load and a subsequent change data capture and apply, and conclude with a switchover of your production environment to the new database once the target database is caught up with the source database.'), ('Q. Are these steps different for continuous data replication?', 'The only difference is in the last step (the production environment switchover), which is absent for continuous data replication. Your data replication task will run until you change or terminate it.'), ('Q. Can I monitor the progress of a database migration task?', 'Yes. AWS Database Migration Service has a variety of metrics displayed in the AWS Management Console. It provides an end-to-end view of the data replication process, including diagnostic and performance data for each point in the replication pipeline. AWS Database Migration Service also integrates with other AWS services such as CloudTrail and CloudWatch Logs. Customers can also leverage the AWS Database Migration Service API and CLI to integrate with their existing tools or build custom monitoring tools to suit their specific needs.'), ('Q. How do I integrate AWS Database Migration Service with other applications?', 'AWS Database Migration Service provides a provisioning API that allows creating a replication task directly from your development environment, or scripting their creation at scheduled times during the day. The service API and CLI allows developers and database administrators to automate the creation, restart, management and termination of replication tasks.'), ('Q. Can I replicate data from encrypted data sources?', 'Yes, AWS Database Migration Service can read and write from and to encrypted databases. AWS Database Migration Service connects to your database endpoints on the SQL interface layer. If you use the Transparent Data Encryption features of Oracle or SQL Server, AWS Database Migration Service will be able to extract decrypted data from such sources and replicate it to the target. The same applies to storage-level encryption. As long as AWS Database Migration Service has the correct credentials to the database source, it will be able to connect to the source and propagate data (in decrypted form) to the target. We recommend using encryption-at-rest on the target to maintain the confidentiality of your information. If you use application-level encryption, the data will be transmitted through AWS Database Migration Service as is, in encrypted format, and then inserted into the target database.'), ('Q. Does AWS Database Migration Service migrate the database schema for me?', "To quickly migrate a database schema to your target instance you can rely on the Basic Schema Copy feature of AWS Database Migration Service. Basic Schema Copy will automatically create tables and primary keys in the target instance if the target does not already contain tables with the same names. Basic Schema Copy is great for doing a test migration, or when you are migrating databases heterogeneously e.g. Oracle to MySQL or SQL Server to Oracle. Basic Schema Copy will not migrate secondary indexes, foreign keys or stored procedures. When you need to use a more customizable schema migration process (e.g. when you are migrating your production database and need to move your stored procedures and secondary database objects), you can use the AWS Schema Conversion Tool for both homogeneou and heterogeneou migrations, or use the schema export tools native to the source engine, if you are doing homogenous migrations like (1) SQL Server Management Studio's Import and Export Wizard, (2) Oracle's SQL Developer Database Export tool or script the export using the dbms_metadata package, (3) MySQL's Workbench Migration Wizard."), ('Q. Can I use DMS to perform bi-directional replication? ', 'Bi-directional replication is not recommended with DMS. A typical replication scenario has a single source and a target. When the source and target endpoints are distinct, DMS guarantees transactional integrity. In bi-directional replication these source and targets can be reversed and lead to unintended consequences if the same row is updated by two different replication tasks. Two-way replication works best when the tables being updated from the source to the target are logically independent from the tables being updated from the target to the source.'), ('Q. How much does DMS cost?', 'You can find full pricing details on the DMS pricing page. Also check out Free DMS, in which you can use DMS free for 6 months when migrating databases to Aurora.'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/application-discovery/faqs/': [('General', 'Q: What is the AWS Application Discovery Service?'), ('AWS Application Discovery Service collects and presents data to enable enterprise customers to understand the configuration, usage, and behavior of servers in their IT environments. Server data is retained in the Application Discovery Service where it can be tagged and grouped into applications to help organize AWS migration planning. Collected data can be exported for analysis in Excel or other cloud migration analysis tools. ', 'Q: How does the AWS Application Discovery Service help enterprises migrate to AWS?'), ('AWS Application Discovery Service helps enterprises obtain a snapshot of the current state of their data center servers by collecting server specification information, hardware configuration, performance data, and details of running processes and network connections. Once the data is collected, you can use it to perform a Total Cost of Ownership (TCO) analysis and then create a cost optimized migration plan based on your unique business requirements.', 'Q: How does the AWS Application Discovery Service work?'), ('AWS Application Discovery Service supports agent-based and agentless modes of operation. With the agentless discovery, VMware customers collect VM configuration and performance profiles without deploying the AWS Application Discovery Agent on each host, which accelerates data collection. Customers in a non-VMware environment or that need additional information, like network dependencies and information about running processes, may install the Application Discovery Agent on servers and virtual machines (VMs) to collect data.', 'Q: How can I get started using the AWS Application Discovery Service?'), ('To get started with AWS Application Discovery Service, simply visit the AWS Migration Hub console.\xa0', 'Q: Where is AWS Application Discovery Service available?'), ('AWS Application Discovery Service is available worldwide. This means you can perform discovery on resources regardless of their location. The service is hosted in the US West (Oregon) region. ', 'Q: Should I use agentless or agent-based application discovery?'), ('Agentless Application Discovery is recommended for VMware customers because it does not require customers installing an agent on each host, and gathers server information regardless of the VM’s operating systems. It does not collect information on non-VMware environments.', 'If you run a non-VMware environment, or are looking for process and network connection details, use the AWS Application Discovery Agent. You can run agent-based and agentless Application Discovery simultaneously. '), ('Agent-based Discovery', 'Q: What data does the AWS Application Discovery Agent capture?'), ('The agent captures system configuration, system performance, running processes, and details of the network connections between systems.', 'Q: What operating systems does AWS Application Discovery Service provide agents for?'), ('AWS Application Discovery Service launched a new 2.0 version of the Discovery Agent that offers better operating system support. 2.0 version of the Discovery Agent supports Microsoft Windows Server 2003 R2 SP2, 2008 R1 SP2, 2008 R2 SP1, 2012 R1, 2012 R2,2016, Amazon Linux 2012.03, 2015.03, Ubuntu 12.04, 14.04, 16.04, Red Hat Enterprise Linux 5.11, 6.9, 7.3, CentOS 5.11, 6.9, 7.3 and SUSE 11 SP4, 12 SP2. ', 'Q: How is the data protected while in transit to AWS?'), ('The AWS Application Discovery Agent uses HTTPS/TLS to transmit data to the AWS Application Discovery Service. The AWS Application Discovery Agent can be operated in an offline test mode that writes data to a local file so customers can review collected data before enabling online mode. ', 'Q: How do I install the AWS Application Discovery Agent in my data center?'), ('Please refer to the documentation for details on how to install the AWS Application Discovery Agent.', 'Q: Will the AWS Application Discovery Service Agent grant AWS remote access to my data center server?'), ('No, the AWS Application Discovery Service Agent deployed on your data center server will not grant AWS remote access. However, the Agent does need to establish an outbound SSL connection to transfer the collected data to AWS. ', 'Q: Can I run agents in my EC2 instances? '), ('Yes. You can install the AWS Discovery Agents on your EC2 instances to perform discovery and report upon performance information, network connections, and running processes, just as for any other server. ', 'Agentless Discovery'), ('Q: What does ‘agentless’ Application Discovery mean?', '‘Agentless’ means no software needs to be installed on each host to use Application Discovery. Simply install the AWS Application Discovery Agentless Connector as an OVA on VMware vCenter. '), ('Q: What data does the AWS Application Discovery Agentless Connector capture?', 'The AWS Application Discovery Agentless Connector is delivered as an Open Virtual Appliance (OVA) package that can be deployed to a VMware host. Once configured with credentials to connect to vCenter, the Discovery Connector collects VM inventory, configuration, and performance history such as CPU, memory, and disk usage and uploads it to Application Discovery Service data store. '), ('Q: What operating systems does the agentless discovery support?', 'Agentless discovery is OS agnostic. It collects information about VMware virtual machines regardless of the VM operating system. '), ('Q: How is the data protected while in transit to AWS?', 'The AWS Application Discovery Agentless Connector uses HTTPS/TLS to transmit data to the AWS Application Discovery Service. The AWS Application Agentless Discovery Connector can be operated in an offline test mode that writes data to a local file so customers can review collected data before enabling online mode. '), ('Q: How do I install the Application Discovery Agentless Connector in my data center?', 'Please refer to the documentation for details on how to install the AWS Agentless Application Discovery Connector. '), ('Q: How can I start the data collection?', 'Data collection can be enabled or disabled from the AWS console or via the AWS Discovery SDK or AWS Command Line Interface (CLI). Newly installed Connectors have data collection initially disabled when installed. '), ('Q: Will the AWS Application Discovery Agentless Connector grant AWS remote access to my data center servers?', 'No, the AWS Agentless Connector deployed on your VMware environment will not grant AWS remote access to your data center servers. However, the Agentless Connector requires VMware credentials in order to collect data. These credentials reside locally and are never shared with AWS. The Agentless Connector establishes outbound SSL connection to transfer only the collected data. '), ('Q: Can I run agentless discovery in my EC2 instances?', 'No. The AWS Agentless Discovery Connector installs on VMware and collects information only from VMware vCenter. '), ('Discovered Data', 'Q: What kind of information is captured by AWS Application Discovery Service?'), ('AWS Application Discovery Service is designed to capture a variety of data including static configuration such as server hostnames, IP addresses, MAC addresses, CPU allocation, network throughput, memory allocation, disk resource allocations, DNS servers. It also captures resource utilization metrics such as CPU usage and memory usage. In addition, the AWS Application Discovery Agent can help determine server workloads and network relationships by identifying network connections between systems. ', 'Q: Does this service capture any storage metrics?'), ('Yes, disk metrics, such as read and write volume, throughout, allocated/provisioned and utilized capacity, are captured by this service. ', 'Q: How often is the information within AWS Application Discovery Service updated?'), ('Information is gathered only when the AWS Application Discovery Agent or the Agentless Discovery Connector is online. ', 'Using the AWS Application Discovery Service Data'), ('Q: Can I ingest data into the AWS Application Discovery Service from my existing configuration management database (CMDB)?', 'No, this capability is not supported.'), ('Q: How do I access the data from this service?', 'Summary data can be viewed in the AWS console. You can export detailed data collected by the AWS Application Discovery Service using the AWS Console or a public API. The service exports data in CSV format. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/server-migration-service/faqs/': [('Q. How do I get started with AWS Server Migration Service?  Use the wizard in the AWS Server Migration Service dashboard of the AWS Management Console. Visit the Getting Started Guide for more details, including how to replicate a server.', 'Q. What is the output of AWS Server Migration Service?  Each server volume replicated is saved as a new Amazon Machine Image (AMI), which can be launched as an EC2 instance (virtual machine) in the AWS cloud.'), ('Q. What kind of servers can be migrated to AWS using AWS Server Migration Service?  Currently, you can migrate VMware virtual machines to AWS using AWS Server Migration Service. Support for other hypervisors and physical servers is coming soon.', 'Q. In what Regions is AWS Server Migration Service available?  This service is currently available in\xa0US East (N. Virginia), Asia Pacific (Sydney), EU (Ireland), US West (Oregon), US East (Ohio), Canada (Central), Asia Pacific (Tokyo), Asia Pacific (Seoul), and Asia Pacific (Mumbai).'), ('Q. How do I track the status of the migration? Visit the AWS Server Migration Service dashboard in the AWS Management Console to see the status of the replication.', 'Q. What operating systems does AWS Server Migration Service support?  AWS Server Migration Service supports migrating Windows Server 2003, 2008, 2012, and 2016, and Windows 7, 8, and 10; Red Hat Enterprise Linux (RHEL), SUSE/SLES, CentOS, Ubuntu, Oracle Linux, Fedora, and Debian Linux operating systems. Learn more.'), ('Q. How long can I replicate my server volumes from on-premises to AWS? You can replicate your on-premises servers to AWS for up to 90 days (per server). Usage time is calculated from the time a server replication begins until you terminate the replication job. After 90 days, your replication job will be automatically terminated. If you want to increase this limit, please discuss your use case with the AWS Support team.', 'Q: What is the difference between EC2 VM Import and AWS Server Migration Service? AWS Server Migration Service is a significant enhancement of EC2 VM Import. The AWS Server Migration Service provides automated, live incremental server replication and AWS Console support. For customers using EC2 VM Import for migration, we recommend using AWS Server Migration Service. \xa0'), ('Q. What is the AWS Server Migration Service Connector? The connector appliance is a pre-configured FreeBSD virtual machine (in OVA format). To set up AWS Server Migration Service, you need to first deploy the AWS Server Migration Service Connector virtual appliance on your on-premises VMware vCenter environment.', 'Q. How many AWS Server Migration Service Connectors do I need to install?  You need to install one AWS Server Migration Service Connector for each VMware vCenter environment.'), ('Q. What permissions does the AWS Server Migration Service Connector require from VMware vCenter?  At minimum, the AWS Server Migration Service Connector requires the ability to create and delete snapshots on VMs that need to be migrated to AWS. Learn more.', 'Q. Can I use a proxy for communicating with the AWS Server Migration Service?  Yes. The AWS Server Migration Service Connector supports password-based proxy; it does not support NTLM-based proxy.'), ('Q. Are server volumes securely transferred from my data center to AWS?  Yes. Replicated server volumes are encrypted in transit by Transport Layer Security (TLS).', 'Q. What data does the AWS Server Migration Service Connector capture from VMware vCenter?  The AWS Server Migration Service Connector captures VM inventory information from VMware vCenter and replicates server volumes to AWS.'), ('Q. How do I update the AWS Server Migration Service Connector?  Updates are automatically downloaded and applied when you enable the auto-upgrade option; otherwise, they can be applied on-demand.', 'Q. Is it secure to deploy the AWS Server Migration Service Connector on my virtualization environment?  Yes, the AWS Server Migration Service Connector only captures basic VM inventory information and snapshots of server volumes from VMware vCenter and does not gather any sensitive information.'), ('Q. Where are my replicated server volumes stored?  Your replicated server volumes are converted to AMIs and stored in your AWS account. ', 'Q. Does AWS Premium Support cover AWS Server Migration Service?  Yes, AWS Premium Support covers issues related to your use of the AWS Server Migration Service. Learn more.'), ('Q. What other support options are available?  Visit the AWS Community discussion forum. ', 'What are the key benefits of using AWS Server Migration Service for migrating on premise Hyper-V VMs?'), ('By automating an incremental replication of live server volumes to the AWS cloud as AMIs, SMS allows customers to speed up migration process and reduce manual labor of migration significantly. SMS orchestrates server migrations by allowing customers to schedule replications and track the progress of a group of servers, alleviating the logistical burden of coordinating large-scale server migrations. With the support of incremental replication, customers are able to test server migrations easily. With the support of AWS console-based GUI, customers are able to start and manage migration and track progress easily.', 'Who can benefit from AWS Server Migration Service for Hyper-V?'), ('Any customer who is looking to migrate their Microsoft Hyper-V virtual machines managed by SCVMM or standalone Hyper-Vs to AWS will benefit from Hyper-V support in SMS. This may include enterprise customers, System integrators, and IT consulting firms who help enterprise customers migrate Hyper-V workloads to AWS.', 'What components does AWS Server Migration Service have for Hyper-V VM migration?'), ('SMS has an on-premises appliance, the SMS Connector, which talks to the service in AWS. The Connector incrementally transfers volumes of running Hyper-V VMs to the SMS service, and the service creates the AMI incrementally from the transferred volume.', 'Where can I download the SMS Connector for Hyper-V VM migration?'), ('You can go to the AWS Server Migration Service Console or the SMS public documentation.', 'What permissions are required in System Center to deploy SMS Connector and start migration?\xa0'), ('The SMS connector securely communicates with the SCVMM server using Windows remote management protocol (WinRM). Connector requires a non-admin AD user that is added to “Remote Management Users” group on the SCVMM host, has limited permissions on the CMIV2 and SCVMM WMI objects and is a part of the “Delegated administrator” group within SCVMM. A firewall port needs to be opened on the SCVMM server to allow for secure transfer of remote commands from Connector deployed on a private network within your datacenter. The AD user also needs read permissions on the VM data store on the Hyper-V machine. For additional security, customers may configure WinRM to allow only encrypted traffic over SSL using self-signed certificate and limit access to Connector IP/hostname alone.For more details, please refer to the SMS technical documentation.', 'How do I set up AWS Server Migration Service for Hyper-V?'), ('AWS console will walk you through a wizard that help you download and install the SMS Connector. You will need to work with your system administrators to create an active directory user for Hyper-V VM migration use. AWS SMS provides an interactive PowerShell script, to be executed with administrative privileges on your Hyper-V host, that automates the permissions setup/configuration. You will provide the AD user credentials and networking/proxy settings as necessary in the SMS Connector. For more details, please refer to the SMS technical documentation.', 'Do I need to have SCVMM for AWS SMS to work with my Hyper-V hosts?'), ('No. The SMS Connector can be configured to use SCVMM or standalone Hyper-V VMs.', 'I’m operating both VMware and Hyper-V environments. Can I migrate VMware VMs and Hyper-V VMs simultaneously?'), ('Yes, but you will need two separate SMS Connectors to simultaneously migrate VMs from both VMware and Hyper-V environments.', 'What versions of Hyper-V, a component of the Windows server, does SMS support?'), ('SMS Supports Hyper-V running on Windows Servers 2012 R2 and above.', 'What operating systems does AWS Server Migration Service support?'), ('AWS Server Migration Service supports migrating Windows Server 2003, 2008, 2012, and 2016, and Windows 7, 8, and 10; Red Hat Enterprise Linux (RHEL), SUSE/SLES, CentOS, Ubuntu, Oracle Linux, Fedora, and Debian Linux operating systems. Learn more.', 'How can I view my on-premises Hyper-V VM inventory in AWS console?'), ('After configuring the SMS Connector, customers can import their on-premises Hyper-V inventory by clicking on the "Import server catalog" button in "AWS Console --> Server Migration --> Servers" tab.', 'I’m going to migrate Hyper-V and VMware VMs simultaneously. Can I view the inventory of Hyper-V and VMware VMs together in a single pane of glass in AWS console?'), ('Yes. SMS enables you to view the VM inventory of both Microsoft’s Hyper-V and VMware environments in a single pane of glass. After you import your on-premises Hyper-V VM inventory by clicking on the "Import server catalog" button in AWS SMS console, SMS automatically collects the VM inventory from all the SMS Connectors, deployed across Hyper-V and VMware environments, as a default.', 'Can I see the VM inventory of Hyper-V and VMware environments separately?'), ('Yes, on the ‘servers’ page on the AWS SMS console, you can filter by VM manager in the search bar to show only the VMs imported from Hyper-V or VMware environments.', 'How can I distinguish Hyper-V VMs from VMware VMs during migration?'), ('Yes, on the ‘replication jobs’ page on the AWS SMS console, you can filter by VM manager in the search bar to show only the progress of SMS replication jobs for VMs from Hyper-V or VMware environments.', 'Can I track the progress of Hyper-V and VMware VMs migration simultaneously?'), ('Yes. Customers can track the progress of Hyper-V and VMware VM migration in a single pane of glass under the ‘Replication Jobs’ page on the AWS SMS console.', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/codecommit/faqs/': [('Q: What is AWS CodeCommit? AWS CodeCommit is a secure, highly scalable, managed source control service that hosts private Git repositories. AWS CodeCommit eliminates the need for you to operate your own source control system or worry about scaling its infrastructure. You can use AWS CodeCommit to store anything from code to binaries, and it works seamlessly with your existing Git tools. ', 'Q: What is Git? Git is an open-source distributed version control system. To work with AWS CodeCommit repositories, you use the Git command line interface (CLI) or any of the available Git clients. To learn more about Git, see the Git documentation. To learn more about using AWS CodeCommit with Git, see Getting Started with AWS CodeCommit. '), ('Q: Who should use AWS CodeCommit? AWS CodeCommit is designed for software developers who need a secure, reliable, and scalable source control system to store and version their code. In addition, AWS CodeCommit can be used by anyone looking for an easy to use, fully managed data store that is version controlled. For example, IT administrators can use AWS CodeCommit to store their scripts and configurations. Web designers can use AWS CodeCommit to store HTML pages and images. ', 'Q: How is AWS CodeCommit different from other Git-based source control systems? AWS CodeCommit offers a number of features not offered by other Git source control systems: '), ('Q: How does AWS CodeCommit compare to a versioned S3 bucket? AWS CodeCommit is designed for collaborative software development. It manages batches of changes across multiple files, offers parallel branching, and includes version differencing (“diffing”). In comparison, Amazon S3 versioning supports recovering past versions of individual files but doesn’t support tracking batched changes that span multiple files or other features needed for collaborative software development. ', ''), ('Q: How do I get started with AWS CodeCommit? You can sign in to the AWS Management Console, create a repository, and start working with the repository using Git. If you want an introduction to the service, see Getting Started, which includes a step-by-step tutorial. ', 'Q: How do I create a repository? You can create a repository from the AWS Management Console or by using the AWS Command Line Interface (AWS CLI), the AWS SDKs, or the AWS CodeCommit APIs. '), ('Q: How do I update files in my repository? You use Git to work with the repository. For example, you can use the git clone command to make a local copy of the AWS CodeCommit repository. Make changes to the local files and use the git commit command when you’re ready to save the changes. Finally, use the git push command to upload the changes to the AWS CodeCommit repository. For step-by-step instructions, see Getting Started with AWS CodeCommit. ', 'Q: How do I import my existing repository to AWS CodeCommit? You can use Git to import any existing Git repository to AWS CodeCommit. For other repositories, such as Subversion and Perforce, you can use a Git importer to first migrate it to a Git repository. For step by step instructions on importing Git repositories, see Migrate an Existing Repository to AWS CodeCommit. For instructions on migrating other repositories to Git, see the Git migration documentation. '), ('Q: What Git operations are currently supported by AWS CodeCommit? AWS CodeCommit currently supports clone, pull, push and fetch commands. ', 'Q: Does AWS CodeCommit support Git submodules? Yes. AWS CodeCommit can be used with Git repositories that include submodules. '), ('Q: What are the service limits when using AWS CodeCommit? For information on the service limits, see Limits. ', 'Q: What is the maximum size for a single file that I can store in CodeCommit? A single file in a repository cannot be more than 2 GB in size. '), ('Q: How do I backup my repository? If you have a local copy of the repository from doing a full git clone, you can use that to restore data. If you want additional backups, there are multiple ways to do so. One way is to install Git on your backup server and run a scheduled job that uses the git clone command to take regular snapshots of your repository. You can use git pull instead of git clone if you want to copy only the incremental changes. Note that these operations may incur an additional user and/or request charges based on how you setup the backup server and the polling frequency.', 'Q: How do I restore a deleted AWS CodeCommit repository? Deleting an AWS CodeCommit repository is a destructive one-way operation that cannot be undone. To restore a deleted repository, you will need to create the repository again and use either a backup or a local copy from a full clone to upload the data. We recommend using IAM policies along with MFA-protection to restrict users who can delete repositories. For more details, see the Can I use AWS Identity and Access Management (IAM) to manage access to AWS CodeCommit? question in the Security section of the FAQ. '), ('Q: How do I manage code reviews with AWS CodeCommit? For code reviews, you can use any Git-compatible code review system like\xa0Review Board. ', 'Q: How do I integrate my continuous integration system with AWS CodeCommit? Continuous Integration (CI) systems can be configured to use Git to pull code from AWS CodeCommit. For examples on using CI systems with AWS CodeCommit, see our blog post on integrating AWS CodeCommit with Jenkins.'), ('Q: How do I create webhooks using AWS CodeCommit? In the Amazon Simple Notification Service (SNS) console, you can create a SNS topic with an HTTP endpoint and the desired URL for the webhook. From the AWS CodeCommit console, you can then configure that SNS topic to a repository event using triggers.', 'Q: Can I get a history of AWS CodeCommit Git operations and API calls made in my account for security analysis and operational troubleshooting purposes?  Yes. To receive a history of CodeCommit Git operations and API calls made in your account, you simply turn on AWS CloudTrail in the AWS Management Console. The logging of individual commits within a Git push is not currently supported. Visit the CloudTrail user guide to learn more. '), ('Q: Can I use AWS Identity and Access Management (IAM) to manage access to AWS CodeCommit? Yes. AWS CodeCommit supports resource-level permissions. For each AWS CodeCommit repository, you can specify which users can perform which actions. You can also specify AWS multi-factor authentication (MFA) for a CodeCommit action. This allows you to add an extra level of protection for destructive actions such as deleting repositories. In addition to the AWS CodeCommit APIs, you can also specify git pull and git push as actions to control access from Git clients. For example, you can create a read-only user for a repository by allowing that user access to git pull but not git push on the repository. For more information on using IAM with AWS CodeCommit, see Access Permissions Reference.\xa0For more information on authenticating API access using MFA, see Configuring MFA-Protected API Access. ', ''), ('Q: What communication protocols are supported by AWS CodeCommit? You can use either the HTTPS or SSH protocols or both to communicate with AWS CodeCommit. To use HTTPS, first install the AWS CLI. The AWS CLI installs a Git credential helper that can be configured with AWS credentials. It automatically signs all HTTPS requests to AWS CodeCommit using the Signature Version 4 signing specification. To use SSH, users create their own public-private key pairs and add their public keys to their IAM users. The private key encrypts the communication with AWS CodeCommit. For step-by-step instructions on setting up HTTPS and SSH access, see the Setting up AWS CodeCommit page. ', 'Q: What ports should I open in my firewall for access to AWS CodeCommit? You will have to open outbound access to an AWS CodeCommit service endpoint on port 22 (SSH) or port 443 (HTTPS). '), ('Q: How do I encrypt my repository in AWS CodeCommit? Repositories are automatically encrypted at rest. No customer action is required. AWS CodeCommit uses AWS Key Management Service (KMS) to encrypt repositories. When you create your first repository, an AWS-managed CodeCommit key is created under your AWS account. For details, see Encryption for AWS CodeCommit Repositories. ', 'Q: Can I enable cross-account access to my repository? Yes. You can create an IAM role in your AWS account to delegate access to a repository to IAM users in other AWS accounts. The IAM users can then configure their AWS CLI to use AWS Security Token Service (STS) and assume the role when running commands. For details see Assuming a Role in the AWS CLI documentation. '), ('Q: Which regions does AWS CodeCommit support? Please refer to Regional Products and Services for details of CodeCommit availability by region. ', 'Q: How much does AWS CodeCommit cost? AWS CodeCommit costs $1 per active user per month. For every active user, your account receives an additional allowance of 10 GB-month of storage and 2,000 Git requests for that month. Unused allowance for storage and Git requests does not carry over to later months. If you need more storage or Git requests for your users, additional usage will be charged at $0.06 per GB-month and $0.001 per Git request. Users may store as many Git repositories as they would like. Your usage is calculated each month across all regions and automatically applied to your bill. Please see the pricing page for more details. '), ('Q: What is the definition of an active user in AWS CodeCommit? An active user is any unique AWS identity (IAM user/role, federated user, or root account) that accesses AWS CodeCommit repositories during the month, either through Git requests or by using the AWS Management Console. A server accessing CodeCommit using a unique AWS identity counts as an active user.  ', 'Q: Which Git requests are considered towards the monthly allowance? A Git request includes any push or pull that transmits repository objects. The request does not count towards your Git request allowance if there is no object transfer due to local and remote branches being up-to-date. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/codebuild/faqs/': [('Q: What is AWS CodeBuild?', 'AWS CodeBuild is a fully managed build service in the cloud. CodeBuild compiles source code, runs tests, and produces packages that are ready to deploy. CodeBuild eliminates the need to provision, manage, and scale your own build servers. CodeBuild scales continuously and processes multiple builds concurrently, so your builds don’t have to wait in a queue. You can get started quickly by using CodeBuild prepackaged build environments, or you can use custom build environments to use your own build tools. With CodeBuild, you only pay by the minute.'), ('Q: Why should I use CodeBuild?', 'Instead of having to set up, patch, and maintain the build server software yourself, you can use CodeBuild’s fully managed experience. You submit your build jobs to CodeBuild, and it runs them in temporary compute containers that are created fresh on every build and then discarded when finished. You don’t need to manage build server hardware or software. CodeBuild also automatically scales to meet your build volume. It immediately processes each build you submit and can run separate builds concurrently, meaning your builds are never left waiting in a queue.'), ('Q: What is the pricing for CodeBuild?', 'See the AWS CodeBuild pricing page for details.'), ('Q: Can I use CodeBuild to automate my release process?', 'Yes. CodeBuild is integrated with AWS CodePipeline. You can add a build action and set up a continuous integration and continuous delivery process that runs in the cloud. You can learn how to set up and monitor your builds from the CodePipeline console here.'), ('Q: What is a build project?', 'A build project is used to define how CodeBuild will run a build. It includes information such as where to get the source code, which build environment to use, the build commands to run, and where to store the build output. A build environment is the combination of operating system, programming language runtime, and tools used by CodeBuild to run a build.'), ('Q: How do I configure a build project?', 'A build project can be configured through the console or the AWS CLI. You specify the source repository location, the runtime environment, the build commands, the IAM role assumed by the container, and the compute class required to run the build. Optionally, you can specify build commands in a buildspec.yml file.'), ('Q: Which source repositories does CodeBuild support?', 'CodeBuild can connect to AWS CodeCommit, S3, GitHub, and GitHub Enterprise to pull source code for builds.'), ('Q: Which programming frameworks does CodeBuild support?', 'CodeBuild provides preconfigured environments for supported versions of Java, Ruby, Python, Go, Node.js, Android, and Docker. You can also customize your own environment by creating a Docker image and uploading it to the Amazon EC2 Container Registry or the Docker Hub registry. You can then reference this custom image in your build project.'), ('Q: What happens when a build is run?', 'CodeBuild will create a temporary compute container of the class defined in the build project, load it with the specified runtime environment, download the source code, execute the commands configured in the project, upload the generated artifact to an S3 bucket, and then destroy the compute container. During the build, CodeBuild will stream the build output to the service console and Amazon CloudWatch Logs.'), ('Q: How do I set up my first build?', 'Sign in to the AWS Management Console, create a build project, and then run a build. For an introduction to CodeBuild, see Getting Started, which includes a step-by-step tutorial.'), ('Q: Can I use CodeBuild with Jenkins?', 'Yes. The CodeBuild Plugin for Jenkins can be used to integrate CodeBuild into Jenkins jobs. The build jobs are sent to CodeBuild, eliminating the need for provisioning and managing the Jenkins worker nodes.'), ('Q: How can I view past build results?', 'You can access your past build results through the console or the API. The results include outcome (success or failure), build duration, output artifact location, and log location.'), ('Q: How can I debug a past build failure?', 'You can debug a build by inspecting the detailed logs generated during the build run. '), (' Q: Can I encrypt the build artifacts stored by CodeBuild? ', ' Yes. You can specify a key stored in the AWS Key Management Service (AWS KMS) to encrypt your artifacts.'), (' Q: How does CodeBuild isolate builds that belong to other customers?', 'CodeBuild runs your build in fresh environments isolated from other users and discards each build environment upon completion. CodeBuild provides security and separation at the infrastructure and execution levels.'), (' Q: Can I use AWS Identity and Access Management (IAM) to manage access to CodeBuild? ', 'Yes. You can control access to your build projects through resource-level permissions in IAM policies.'), (' Q: Which regions does CodeBuild support?', 'See Regional Products and Services for details.'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/codedeploy/faqs/': [('Q: What is AWS CodeDeploy? AWS CodeDeploy is a service that automates code deployments to any instance, including Amazon EC2 instances and instances running on-premises. AWS CodeDeploy makes it easier for you to rapidly release new features, helps you avoid downtime during deployment, and handles the complexity of updating your applications. You can use AWS CodeDeploy to automate deployments, eliminating the need for error-prone manual operations, and the service scales with your infrastructure so you can easily deploy to one instance or thousands. ', 'Q: Who should use AWS CodeDeploy? AWS CodeDeploy is designed for developers and administrators who need to deploy applications to any instance, including Amazon EC2 instances and instances running on-premises. It is flexible and can also be used by anyone wanting to update software or run scripts on their instances.'), ('Q: What types of applications can be deployed with AWS CodeDeploy? AWS CodeDeploy can be used for deploying any type of application. To use AWS CodeDeploy, you specify the files to copy and the scripts to run on each instance during the deployment. AWS CodeDeploy is programming language and architecture agnostic, so you can use scripts for any custom deployment logic.', 'Q: What operating systems does AWS CodeDeploy support? AWS CodeDeploy supports a wide variety of operating systems. AWS CodeDeploy provides agents that have been tested on Amazon Linux, Red Hat Enterprise Linux, Ubuntu Server, and Microsoft Windows Server. If you want to use other operating systems, the AWS CodeDeploy agent is available as open source software here. For more information on operating system support, see AWS CodeDeploy Documentation.'), ('Q:Will AWS CodeDeploy work with my existing tool chain? Yes. AWS CodeDeploy works with a variety of configuration management systems, continuous integration and deployment systems, and source control systems. For more information, see product integrations page.', 'Q: How is AWS CodeDeploy different from other AWS deployment and management services such as AWS Elastic Beanstalk and AWS OpsWorks? AWS CodeDeploy is a building block service focused on helping developers deploy and update software on any instance, including Amazon EC2 instances and instances running on-premises. AWS Elastic Beanstalk and AWS OpsWorks are end-to-end application management solutions. '), ('Q: Does AWS CodeDeploy support on-premises instances? Yes. AWS CodeDeploy supports any instance that can install the CodeDeploy agent and connect to AWS public endpoints.  ', '\xa0'), ('Q: What is an application? An application is a collection of software and configuration to be deployed to a group of instances. Typically, the instances in the group run the same software. For example, if you have a large distributed system, the web tier will likely constitute one application and the data tier another application.', 'Q: What is a revision? A revision is a specific version of deployable content, such as source code, post-build artifacts, web pages, executable files, and deployment scripts, along with an AppSpec file. The AWS CodeDeploy Agent can access a revision from GitHub or an Amazon S3 bucket.'), ('Q: What is a deployment group? A deployment group is a set of instances associated with an application that you target for a deployment. You can add instances to a deployment group by specifying a tag, an Auto Scaling group name, or both. You can define multiple deployment groups for an application such as staging and production. For information on tags, see Working with Amazon EC2 Tags in the Console. For more information on deploying to Auto Scaling groups, see Auto Scaling Integration.', 'Q: What is a deployment configuration? A deployment configuration is a constraint that determines how a deployment progresses through the instances in a deployment group. You can use a deployment configuration to perform zero-downtime deployments to multi-instance deployment groups. For example, if your application needs at least 50% of the instances in a deployment group to be up and serving traffic, you can specify that in your deployment configuration so that a deployment does not cause downtime. If no deployment configuration is associated with either the deployment or the deployment group, then by default AWS CodeDeploy will deploy to one instance at a time. For more information on deployment configuration, see Instance Health.'), ('Q: What are the parameters that I need to specify for a deployment? There are three parameters you specify for a deployment: ', ''), ('Q: What are deployment lifecycle events? A deployment goes through a set of predefined phases called deployment lifecycle events. A deployment lifecycle event gives you an opportunity to run code as part of the deployment. The following table lists the different deployment lifecycle events currently supported, in their order of execution, along with examples of when you may want to use them.', 'Q: How do I get started with AWS CodeDeploy? You can sign in to the AWS Management Console and start using AWS CodeDeploy. If you are looking for a quick overview of the service, see Getting Started, which includes a step-by-step tutorial. '), ('Q: Are there any prerequisites for using an existing Amazon EC2 instance with AWS CodeDeploy? The Amazon EC2 instance must be associated with an IAM instance profile and should be running a supported operating system. For more information, see Use an Existing Amazon EC2 Instance.', 'Q: What are the typical steps to go through for deploying an application using AWS CodeDeploy? The following diagram shows the typical steps during a deployment. Creating an application and deployment group (see the Concepts section for an explanation of these terms) are typically one-time setup tasks per application. The recurring actions are uploading a revision and deploying it. For a detailed explanation, including step-by-step instructions for each of these tasks, see Deployments.'), ('Q: How can I access AWS CodeDeploy? You can access AWS CodeDeploy using the AWS Management Console, the AWS Command Line Interface (AWS CLI), the AWS SDKs, and the AWS CodeDeploy APIs.', 'Q: What changes do I need to make to my code to deploy using AWS CodeDeploy? You don’t need to make any changes to your code. You simply add a configuration file (called an AppSpec file) in the root directory of your revision bundle that specifies the files to be copied and scripts to be executed.'), ('Q: How can I deploy an application from my source control system using AWS CodeDeploy? If you are using GitHub, you can deploy a revision in a .zip, .tar, or .tar.gz format from your repository directly to instances. For other source control systems, you can bundle and upload the revision to an Amazon S3 bucket in a .zip, .tar, or .tar.gz format and specify the Amazon S3 location when doing a deployment. If your application needs a build step, make sure that the GitHub repository or the Amazon S3 bucket contains the post-build artifacts. For more information on using GitHub with AWS CodeDeploy, see our product integrations page. For more information on using Amazon S3 for storing revisions, see Push a Revision.', 'Q: How will AWS CodeDeploy work with my configuration management tool? You can invoke your configuration management tool from any deployment lifecycle event hook in the AppSpec file. For example, if you have a Chef recipe that you want to run as part of a deployment, you can do so by specifying it in the appropriate deployment lifecycle event hook in the AppSpec file. In addition, you can leverage your configuration management system to install the AWS CodeDeploy agent on instances. For samples that illustrate using AWS CodeDeploy with configuration management systems such as Chef, Puppet, Ansible, and Saltstack, see our product integrations page.'), ('Q: Can I use AWS CodeDeploy with continuous integration and deployment systems? Yes. You can integrate AWS CodeDeploy with your continuous integration and deployment systems by calling the public APIs using the AWS CLI or AWS SDKs. You can find prebuilt integrations and samples on our product integrations page.', 'Q: How do I get my application on the instances that I just added to the deployment group? Deploy the latest revision to the deployment group for the newly added instances to get your application. Except for Amazon EC2 instances that are launched as part of an Auto Scaling group, AWS CodeDeploy doesn’t automatically deploy the latest revision to newly added instances.'), ('Q: How does AWS CodeDeploy work with Auto Scaling? You can associate an Auto Scaling group with a deployment group to make sure that newly launched instances always get the latest version of your application. Every time a new Amazon EC2 instance is launched for that Auto Scaling group, it will be first put in a Pending state and a deployment of the last successful revision for that deployment group triggered on that Amazon EC2 instance. If the deployment completes successfully, the state of the Amazon EC2 instance is changed to InService. If that deployment fails, the Amazon EC2 instance is terminated, a new Amazon EC2 instance is launched in Pending state, and a deployment triggered for the newly launched EC2 instance. For more information on Auto Scaling group instance lifecycle events, see Auto Scaling Group Lifecycle.', 'Q: How do I track the status of a deployment? You can track the status of a deployment using the AWS Management Console, the AWS Command Line Interface (AWS CLI), the AWS SDKs, and the AWS CodeDeploy APIs.You can see the overall status of a deployment and drill down further to see the status of each instance and the status of each deployment lifecycle event for the instance. You can also see the log entries corresponding to any failure, making it easy to debug deployment issues without having to log into the instance.'), ('Q: Can I stop an in-flight deployment? Yes. When you stop an in-flight deployment, the AWS CodeDeploy service will instruct the agent on each instance to stop executing additional scripts. To get your application back to a consistent state, you can either redeploy the revision, or deploy another revision.', 'Q: How do I roll back an application to the previous revision? To roll back an application to a previous revision, you just need to deploy that revision. AWS CodeDeploy keeps track of the files that were copied for the current revision and removes them before starting a new deployment, so there is no difference between redeploy and roll back. However, you need to make sure that the previous revisions are available for roll back.'), ('Q: Can I use a versioned Amazon S3 bucket to store revisions? Yes. You can use a versioned Amazon S3 bucket and specify the version ID to uniquely identify a revision. ', 'Q: What are the service limits when using AWS CodeDeploy? For information on the service limits, see Limits. To increase your service limits, submit a request through the AWS Support Center.'), ('Q: Can I get a history of AWS CodeDeploy API calls made on my account for security analysis and operational troubleshooting purposes? Yes. To receive a history of AWS CodeDeploy API calls made on your account, you simply turn on AWS CloudTrail in the AWS Management Console. ', 'Q: Can I use AWS CodeDeploy to deploy an application to Amazon EC2 instances running within an Amazon Virtual Private Cloud (VPC)? Yes, but the AWS CodeDeploy agent installed on the Amazon EC2 instances must be able to access the public AWS CodeDeploy and Amazon S3 service endpoints. For more information, see AWS CodeDeploy Endpoints and Amazon S3 Endpoints.'), ('Q: Can I use AWS Identity and Access Management (IAM) to manage access to AWS CodeDeploy? Yes. AWS CodeDeploy supports resource-level permissions. For each AWS CodeDeploy resource, you can specify which user has access and to which actions. For example, you can set an IAM policy to let a user deploy a particular application but only list revisions for other applications. You can therefore prevent users from inadvertently making changes to the wrong application. For more information on using IAM with AWS CodeDeploy, see Access Permissions Reference. ', 'Q: Which regions does AWS CodeDeploy support? Please refer to Regional Products and Services for details of CodeDeploy availability by region. '), ('Q: How do I deploy an AWS CodeDeploy application to multiple regions? AWS CodeDeploy performs deployments with AWS resources located in the same region. To deploy an application to multiple regions, define the application in your target regions, copy the application bundle to an Amazon S3 bucket in each region, and then start the deployments using either a serial or parallel rollout across the regions. ', 'Q: How much does AWS CodeDeploy cost? There is no additional charge for code deployments to Amazon EC2 instances through AWS CodeDeploy. You pay $0.02 per on-premises instance update using AWS CodeDeploy. Please see the Pricing page for more details.  '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/codepipeline/faqs/': [('Q: What is AWS CodePipeline? AWS CodePipeline is a continuous delivery service that enables you to model, visualize, and automate the steps required to release your software. With AWS CodePipeline, you model the full release process for building your code, deploying to pre-production environments, testing your application and releasing it to production. AWS CodePipeline then builds, tests, and deploys your application according to the defined workflow every time there is a code change. You can integrate partner tools and your own custom tools into any stage of the release process to form an end-to-end continuous delivery solution. ', 'Q: Why should I use AWS CodePipeline? By automating your build, test, and release processes, AWS CodePipeline enables you to increase the speed and quality of your software updates by running all new changes through a consistent set of quality checks.'), ('Q: What is continuous delivery? Continuous delivery is a software development practice where code changes are automatically built, tested, and prepared for a release to production. AWS CodePipeline is a service that helps you practice continuous delivery. Learn more about continuous delivery here. ', 'The diagram below represents the concepts discussed in this section.'), ('Q: What is a pipeline? A pipeline is a workflow construct that describes how software changes go through a release process. You define the workflow with a sequence of stages and actions. ', 'Q: What is a revision? A revision is a change made to the source location defined for your pipeline. It can include source code, build output, configuration, or data. A pipeline can have multiple revisions flowing through it at the same time.'), ('Q: What is a stage? A stage is a group of one or more actions. A pipeline can have two or more stages.', 'Q: What is an action? An action is a task performed on a revision. Pipeline actions occur in a specified order, in serial or in parallel, as determined in the configuration of the stage. For more information, see Edit a Pipeline and Action Structure Requirements in AWS CodePipeline.'), ('Q: What is an artifact? When an action runs, it acts upon a file or set of files. These files are called artifacts. These artifacts can be worked upon by later actions in the pipeline. For example, a source action will output the latest version of the code as a source artifact, which the build action will read in. Following the compilation, the build action will upload the build output as another artifact, which will be read by the later deployment actions.', 'Q: What is a transition? The stages in a pipeline are connected by transitions, and are represented by arrows in the AWS CodePipeline console. Revisions that successfully complete the actions in a stage will be automatically sent on to the next stage as indicated by the transition arrow. Transitions can be disabled or enabled between stages. '), ('\xa0', '\xa0'), ('Q: How do I get started with AWS CodePipeline? You can sign in to the AWS Management Console, create a pipeline, and start using the service. If you want an introduction to AWS CodePipeline, see Getting Started, which includes step-by-step tutorials. Or, see the Pipeline Starter Kit to quickly provision a preconfigured release pipeline with a Jenkins build server using an AWS CloudFormation template. ', 'Q: How do I start a pipeline? After you create a pipeline, it will automatically trigger a run to release the latest revision of your source code. From then on, every time you make a change to your source location, a new run is triggered. In addition, you can re-run the last revision through a pipeline using the Release Change button in the pipeline console.'), ('Q: How do I stop a pipeline? To stop a pipeline, you can disable a transition from one stage to another. Once disabled, your pipeline will continue to run revisions through the actions, but it will not promote revisions through the disabled transition to later stages. For more details, see Disable or Enable Transitions in AWS CodePipeline. ', 'Q: Can I edit an existing pipeline? Yes. You can use the AWS CodePipeline console or AWS CLI to add or remove stages in a pipeline as well as to add, edit, or remove actions in a stage. '), ('Q: Can I create a copy of an existing pipeline? Yes. You can use the get-pipeline AWS CLI command to get the JSON structure of your existing pipeline. You can then use that JSON and the create-pipeline AWS CLI command to create a new pipeline with the same structure as the existing one. ', 'Q: Can actions run in parallel? Yes. You can configure one or more actions to run in parallel for any given stage.'), ('Q: How can I practice continuous delivery for my serverless applications and AWS Lambda functions? You can release updates to your serverless application by including the AWS Serverless Application Model template and its corresponding files in your source code repository. You can use AWS CodeBuild in your pipeline to package your code for deployment. You can then use AWS CloudFormation actions to create a change set and deploy your serverless application. You have the option to extend your workflow with additional steps such as manual approvals or automated tests. Learn more here.', 'Q: How can I provision and manage my AWS resources through a release workflow process? Using AWS CodePipeline and AWS CloudFormation, you can use continuous delivery to automatically build and test changes to your AWS CloudFormation stacks before promoting them to production stacks. This release process lets you rapidly and reliably make changes to your AWS infrastructure. You can extend your workflow with additional actions such as manual approvals, test actions, or invoke AWS Lambda actions. For more details, see Continuous Delivery with AWS CloudFormation page. '), ('Q: What product integrations are available with AWS CodePipeline? AWS CodePipeline integrates with AWS services such as AWS CodeCommit, Amazon S3, AWS CodeBuild, AWS CodeDeploy, AWS Elastic Beanstalk, AWS CloudFormation, AWS OpsWorks, Amazon ECS, and AWS Lambda. In addition, AWS CodePipeline integrates with a number of partner tools. For details see the product integrations page. Finally, you can write your own custom actions and integrate any existing tool with CodePipeline. For more details on custom actions, see the Create and Add a Custom Action in AWS CodePipeline page.', 'Q: Can I get a history of AWS CodePipeline API calls? Yes. To receive a history of AWS CodePipeline API calls made on your account for security analysis and operational troubleshooting purposes, you simply turn on AWS CloudTrail in the AWS Management Console. For more information, see Logging AWS CodePipeline API calls by Using AWS CloudTrail. '), ('Q: What are the service limits when using AWS CodePipeline? For information on the service limits, see Limits. ', 'Q: What do I need to do to integrate with AWS CodePipeline? If you’re interested in becoming an AWS partner who integrates your developer service with AWS CodePipeline, please contact codepipeline-request@amazon.com.'), ('Q: Can I use AWS Identity and Access Management (IAM) to manage access to AWS CodePipeline? Yes. AWS CodePipeline supports resource-level permissions. You can specify which user can perform what action on a pipeline. For example, you can provide a user read-only access to a pipeline, if you want them to see the pipeline status but not modify the pipeline. You can also set permissions for any stage or action within a pipeline. For more information on using IAM with AWS CodePipeline, see Access Permissions Reference.', 'Q: Can I enable the pipeline in one AWS account to be accessed by an IAM user in another AWS account? Yes. You can create an IAM role in the AWS account that owns the pipeline to delegate access to the pipeline and any related resources to an IAM user in another account. For a walkthrough on enabling such a cross account access, see Walkthrough: Delegating Access Across AWS Accounts For Accounts You Own Using IAM Roles and Configure Cross-Account Access to a Pipeline. '), ('Q: Which regions does AWS CodePipeline support? Please refer to Regional Products and Services for details of CodePipeline availability by region. ', 'Q: How much does AWS CodePipeline cost? For details on AWS CodePipeline cost, see the pricing page. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/xray/faqs/': [('Q: What is AWS X-Ray?', 'AWS X-Ray helps developers analyze and debug production, distributed applications, such as those built using a microservices architecture. With X-Ray, you can understand how your application and its underlying services are performing to identify and troubleshoot the root cause of performance issues and errors. X-Ray provides an end-to-end view of requests as they travel through your application, and shows a map of your application’s underlying components. You can use X-Ray to analyze both applications in development and in production, from simple three-tier applications to complex microservices applications consisting of thousands of services.'), ('Q: Why should I use X-Ray?', 'Currently, if you build and run distributed applications, you have to rely on a per-service or per-resource process to track requests for your application as it travels across various components that make up your application. This problem is further complicated by the varying log formats and storage mediums across frameworks, services, and resources your application runs on or uses. This makes it difficult to correlate the various pieces of data and create an end-to-end picture of a request from the time it originates at the end-user or service to when a response is returned by your application. X-Ray provides a user-centric model, instead of service-centric or resource-centric model, for collecting data related to requests made to your application. This model enables you to create a user-centric picture of requests as they travel across services and resources. By correlating and aggregating data on your behalf, X-Ray enables you to focus on improving the experience for end-users of your application. '), ('Q: What can I do with X-Ray?', 'X-Ray makes it easy for you to:'), ('Q: What is a trace?', 'An X-Ray trace is a set of data points that share the same trace ID. For example, when a client makes a request to your application, it is assigned a unique trace ID. As the request makes its way through services in your application, the services relay information regarding the request back to X-Ray using this unique trace ID. The piece of information relayed by each service in your application to X-Ray is a segment, and a trace is a collection of segments.'), ('Q: What is a segment?', 'An X-Ray segment encapsulates all the data points for a single component (for example, authorization service) of the distributed application. Segments include system-defined and user-defined data in the form of annotations and are composed of one or more sub-segments that represent remote calls made from the service. For example, when your application makes a call to a database in response to a request, it creates a segment for that request with a sub-segment representing the database call and its result. The sub-segment can contain data such as the query, table used, timestamp, and error status.'), ('Q: What is an annotation?', 'An X-Ray annotation is system-defined or user-defined data associated with a segment. A segment can contain multiple annotations. System-defined annotations include data added to the segment by AWS services, whereas user-defined annotations are metadata added to a segment by a developer. For example, a segment created by your application can automatically be injected with region data for AWS service calls, whereas you might choose to add region data yourself for calls made to non-AWS services.'), ('Q: What are errors?', 'X-Ray errors are system annotations associated with a segment for a call that results in an error response. The error includes the error message, stack trace, and any additional information (for example, version or commit ID) to associate the error with a source file.'), ('Q: What is sampling?', 'To provide a performant and cost-effective experience, X-Ray does not collect data for every request that is sent to an application. Instead, it collects data for a statistically significant number of requests. X-Ray should not be used as an audit or compliance tool because it does not guarantee data completeness.'), ('Q: What is the X-Ray agent?', 'The X-Ray agent collects data from log files and sends them to the X-Ray service for aggregation, analysis, and storage. The agent makes it easier for you to send data to the X-Ray service, instead of using the APIs directly, and is available for Amazon Linux AMI, Red Hat Enterprise Linux (RHEL), and Windows Server 2012 R2 or later operating systems. '), ('Q: How do I get started with X-Ray?', 'You can get started with X-Ray by including the X-Ray language SDK in your application and installing the X-Ray agent. For more information see the X-Ray user guide.'), ('Q: What types of applications can I use with X-Ray?', 'X-Ray can be used with distributed applications of any size to trace and debug both synchronous requests and asynchronous events. For example, X-Ray can be used to trace web requests made to a web application or asynchronous events that utilize Amazon SQS queues.'), ('Q: Which AWS services can I use with X-Ray?', 'You can use X-Ray with applications running on EC2, ECS, Lambda, and Elastic Beanstalk. In addition, the X-Ray SDK automatically captures metadata for API calls made to AWS services using the AWS SDK. In addition, the X-Ray SDK provides add-ons for MySQL and PostgreSQL drivers.'), ('Q: What code changes do I need to make to my application to use X-Ray?', 'If you’re using Elastic Beanstalk, you will need to include the language-specific X-Ray libraries in your application code. For applications running on other AWS services, such as EC2 or ECS, you will need to install the X-Ray agent and instrument your application code.'), ('Q: Does X-Ray provide an API?', 'Yes, X-Ray provides a set of APIs for ingesting request data, querying traces, and configuring the service. You can use the X-Ray API to build analysis and visualization applications in addition to those provided by X-Ray. '), ('Q: In which regions is X-Ray available?', 'See Regional Products and Services for details. '), ('Q: Can I use X-Ray to track requests from applications or services spread across multiple regions?', 'Yes, you can use X-Ray to track requests flowing through applications or services across multiple regions. X-Ray data is stored locally to the processed region but with enough information to enable client applications to combine the data and provide a global view of traces. Region annotation for AWS services will be added automatically, however, customers will need to instrument custom services to add the regional annotation to make use of the cross-region support.'), ('Q: How long does it take for trace data to be available in X-Ray?', ' Trace data sent to X-Ray is generally available for retrieval and filtering within 30 seconds of it being received by the service.'), ('Q: How far back can I query the trace data? How long does X-Ray store trace data for?', 'X-Ray stores trace data for the last 30 days. This enables you to query trace data going back 30 days.'), ('Q: Why do I sometimes see partial traces?', 'X-Ray makes the best effort to present complete trace information. However, in some situations (connectivity issues, delay in receiving segments, and so on) it is possible that trace information provided by the X-Ray APIs will be partial. In those situations, X-Ray tags traces as incomplete or partial.'), ('Q: My application components run in their own AWS accounts. Can I use X-Ray to collect data across AWS accounts?', 'Yes, the X-Ray agent can assume a role to publish data into an account different from the one in which it is running. This enables you publish data from various components of your application into a central account. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/cloudwatch/faqs/': [('Q: \xa0What is Amazon CloudWatch?', 'Amazon CloudWatch is a monitoring service for AWS cloud resources and the applications you run on AWS. You can use Amazon CloudWatch to collect and track metrics, collect and monitor log files, and set alarms. Amazon CloudWatch can monitor AWS resources such as Amazon EC2 instances, Amazon DynamoDB tables, and Amazon RDS DB instances, as well as custom metrics generated by your applications and services, and any log files your applications generate. You can use Amazon CloudWatch to gain system-wide visibility into resource utilization, application performance, and operational health. You can use these insights to react and keep your application running smoothly.'), ('Q: What can I use to access CloudWatch?', 'Amazon CloudWatch can be accessed via API, command-line interface, AWS SDKs, and the AWS Management Console.'), ('Q: \xa0Which operating systems does Amazon CloudWatch support?', 'Amazon CloudWatch receives and provides metrics for all Amazon EC2 instances and should work with any operating system currently supported by the Amazon EC2 service.'), ('Q: What access management policies can I implement for CloudWatch?', 'Amazon CloudWatch integrates with AWS Identity and Access Management (IAM) so that you can specify which CloudWatch actions a user in your AWS Account can perform. For example, you could create an IAM policy that gives only certain users in your organization permission to use GetMetricStatistics. They could then use the action to retrieve data about your cloud resources.'), ("You can't use IAM to control access to CloudWatch data for specific resources. For example, you can't give a user access to CloudWatch data for only a specific set of instances or a specific LoadBalancer. Permissions granted using IAM cover all the cloud resources you use with CloudWatch. In addition, you can't use IAM roles with the Amazon CloudWatch command line tools.", 'Q: \xa0What is Amazon CloudWatch Logs?'), ('Amazon CloudWatch Logs lets you monitor and troubleshoot your systems and applications using your existing system, application and custom log files.', 'With CloudWatch Logs, you can monitor your logs, in near real time, for specific phrases, values or patterns. For example, you could set an alarm on the number of errors that occur in your system logs or view graphs of latency of web requests from your application logs. You can then view the original log data to see the source of the problem. Log data can be stored and accessed indefinitely in highly durable, low-cost storage so you don’t have to worry about filling up hard drives. '), ('Q: What kinds of things can I do with CloudWatch Logs?', 'CloudWatch Logs is capable of monitoring and storing your logs to help you better understand and operate your systems and applications. You can use CloudWatch Logs in a number of ways. '), ('Real time application and system monitoring: You can use CloudWatch Logs to monitor applications and systems using log data. For example, CloudWatch Logs can track the number of errors that occur in your application logs and send you a notification whenever the rate of errors exceeds a threshold you specify. CloudWatch Logs uses your log data for monitoring; so, no code changes are required.', 'Long term log retention: You can use CloudWatch Logs to store your log data indefinitely in highly durable and cost effective storage without worrying about hard drives running out of space. The CloudWatch Logs Agent makes it easy to quickly move both rotated and non rotated log files off of a host and into the log service. You can then access the raw log event data when you need it. '), ('Q: \xa0What platforms does the CloudWatch Logs Agent support?', 'The CloudWatch Logs Agent is supported on Amazon Linux, Ubuntu, CentOS, Red Hat Enterprise Linux, and Windows. This agent will support the ability to monitor individual log files on the host. '), ('Q: \xa0Does the CloudWatch Logs Agent support IAM roles?', 'Yes. The CloudWatch Logs Agent is integrated with Identity and Access Management (IAM) and includes support for both access keys and IAM roles.'), ('Q: How much does Amazon CloudWatch cost?', 'Please see our pricing page for the latest information.'), ('Q: Does the Amazon CloudWatch monitoring charge change depending on which type of Amazon EC2 instance I monitor?', 'No, the Amazon CloudWatch monitoring charge does not vary by Amazon EC2 instance type. '), ('Q: \xa0Do your prices include taxes?', 'Except as otherwise noted, our prices are exclusive of applicable taxes and duties, including VAT and applicable sales tax.\xa0Learn more.'), ('Q:\xa0 Why does my AWS monthly bill for CloudWatch appear different between July 2017 and previous months?', 'Prior to July 2017, charges for CloudWatch were split under two different sections in your AWS bill and Cost and Usage Reports. For historical reasons, charges for CloudWatch Alarms,\xa0CloudWatch Metrics, and CloudWatch API usage\xa0were reported under the “Elastic Compute Cloud”\xa0(EC2) detail section of your bill,\xa0while charges for CloudWatch Logs and CloudWatch Dashboards are reported under the “CloudWatch” detail section. To help consolidate and simplify your monthly AWS CloudWatch usage and billing, we moved the charges for your CloudWatch Metrics, Alarms, and API usage from the “EC2” section of your bill to the “CloudWatch” section, effectively bringing together all of your CloudWatch monitoring charges under the “CloudWatch” section. Note that this has no impact to your total AWS bill amount. Your bill and Cost and Usage Reports will now simply display charges for CloudWatch under a single section.'), ('Additionally, there is a Billing Metric in CloudWatch named “Estimated Charges” that can be viewed as Total Estimated Charge or broken down By Service. The “Total Estimated Charge” metric will not change. However, the “EstimatedCharges” metric broken down by Service will change for dimension ServiceName equal to “AmazonEC2” and dimension ServiceName equal to “AmazonCloudWatch”. Due to the billing consolidation, you may see that your AmazonEC2 billing metric decrease and AmazonCloudWatch billing metric increase as usage and billing charges get moved out of EC2 and into CloudWatch. \xa0', 'Q: What can I measure with Amazon CloudWatch Metrics?'), ('Amazon CloudWatch allows you to monitor AWS cloud resources and the applications you run on AWS. Metrics are provided automatically for a number of AWS products and services, including Amazon EC2 instances, EBS volumes, Elastic Load Balancers, Auto Scaling groups, EMR job flows, RDS DB instances, DynamoDB tables, ElastiCache clusters, RedShift clusters, OpsWorks stacks, Route 53 health checks, SNS topics, SQS queues, SWF workflows, and Storage Gateways. You can also monitor custom metrics generated by your own applications and services.', 'Q: What is the retention period of all metrics?'), (' CloudWatch launched High Resolution Custom Metrics on July 26, 2017. This enables you to publish and store custom metrics down to 1-second resolution. Extended retention of metrics was launched on November 1, 2016, and enabled storage of all metrics for customers from the previous 14 days to 15 months. CloudWatch retains metric data as follows:  ', 'Data points that are initially published with a shorter period are aggregated together for long-term storage. For example, if you collect data using a period of 1 minute, the data remains available for 15 days with 1-minute resolution. After 15 days this data is still available, but is aggregated and is retrievable only with a resolution of 5 minutes. After 63 days, the data is further aggregated and is available with a resolution of 1 hour. If you need availability of metrics longer than these periods, you can use the GetMetricStatistics API to retrieve the datapoints for offline or different storage.'), ('The feature is currently available in US East (N. Virginia), US West (Oregon), US West (N. California), EU (Ireland), EU (Frankfurt), S. America (São Paulo), Asia Pacific (Singapore), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Mumbai), Asia Pacific (Sydney), EU (London), Canada (Central), US East (Ohio), and China (Beijing).\xa0 \xa0', 'Q: What is the minimum resolution for the data that Amazon CloudWatch receives and aggregates?'), ('The minimum resolution supported by CloudWatch is 1-second data points, which is a high-resolution metric, or you can store metrics at 1-minute granularity. Sometimes metrics are received by Cloudwatch at varying intervals, such as 3-minute or 5-minute intervals. If you do not specify that a metric is high resolution, by setting the StorageResolution field in the PutMetricData API request, then by default CloudWatch will aggregate and store the metrics at 1-minute resolution.', 'Depending on the age of data requested, metrics will be available at the resolutions defined in the retention schedules above. For example, if you request for 1-minute data for a day from 10 days ago, you will receive the 1440 data points. However, if you request for 1-minute data from 5 months back, the UI will automatically change the granularity to 1-hour and the GetMetricStatistics API will not return any output.'), ('Q: Can I delete any metrics?', 'CloudWatch does not support metric deletion. Metrics expire based on the retention schedules described above.'), ('Q: Will I lose the metrics data if I disable monitoring for an Amazon EC2 instance?', 'No. You can always retrieve metrics data for any Amazon EC2 instance based on the retention schedules described above. However, the CloudWatch console limits the search of metrics to 2 weeks after a metric is last ingested to ensure that the most up to date instances are shown in your namespace.'), ('Q: Can I access the metrics data for a terminated Amazon EC2 instance or a deleted Elastic Load Balancer? Yes. Amazon CloudWatch stores metrics for terminated Amazon EC2 instances or deleted Elastic Load Balancers for 15 months.', 'Q: Why does the graphing of the same time window look different when I view the metrics in 5 minute and 1 minute periods?'), ('If you view the same time window in a 5 minute period versus a 1 minute period, you may see that data points are displayed in different places on the graph. For the period you specify in your graph, Amazon CloudWatch will find all the available data points and calculates a single, aggregate point to represent the entire period. In the case of a 5 minute period, the single data point is placed at the beginning of the 5 minute time window. In the case of a 1 minute period, the single data point is placed at the 1 minute mark. We recommend using a 1 minute period for troubleshooting and other activities that require the most precise graphing of time periods.', 'Q: What is a Custom Metric?'), ('You can use Amazon CloudWatch to monitor data produced by your own applications, scripts, and services. A custom metric is any metric you provide to Amazon CloudWatch. For example, you can use custom metrics as a way to monitor the time to load a web page, request error rates, number of processes or threads on your instance, or amount of work performed by your application. You can get started with custom metrics by using the PutMetricData API, our sample monitoring scripts for Windows and Linux, CloudWatch collectd plugin, as well as a number of applications and tools offered by AWS partners.', 'Q: What resolution can I get from a Custom Metric?'), ('A custom metric can be one of the following:', 'By default, metrics are stored at 1-minute resolution in CloudWatch. You can define a metric as high-resolution by setting the StorageResolution parameter to 1 in the PutMetricData API request. If you do not set the optional StorageResolution parameter, then CloudWatch will default to storing the metrics at 1-minute resolution.'), ('When you publish a high-resolution metric, CloudWatch stores it with a resolution of 1 second, and you can read and retrieve it with a period of 1 second, 5 seconds, 10 seconds, 30 seconds, or any multiple of 60 seconds.', 'Custom metrics follow the same retention schedule listed above.\xa0 '), ('Q: What metrics are available at high resolution?', 'Currently, only custom metrics that you publish to CloudWatch are available at high resolution.\xa0 High-resolution custom metrics are stored in CloudWatch at 1-second resolution.\xa0 High resolution is defined by the StorageResolution parameter in the PutMetricData API request, with a value of 1, and is not a required field.\xa0 If you do not specify a value for the optional StorageResolution field, then CloudWatch will store the custom\xa0 metric at 1-minute resolution by default.\xa0 '), ('Q: Are high-resolution custom metrics priced differently than regular custom metrics?', 'No, high-resolution custom metrics are priced in the same manner as standard 1-minute custom metrics.\xa0  '), ('Q: When would I use a Custom Metric over having my program emit a log to CloudWatch Logs?', 'You can monitor your own data using custom metrics, CloudWatch Logs, or both. You may want to use custom metrics if your data is not already produced in log format, for example operating system processes or performance measurements. Or, you may want to write your own application or script, or one provided by an AWS partner. If you want to store and save individual measurements along with additional detail, you may want to use CloudWatch Logs.'), ('Q: What statistics can I view and graph in CloudWatch?', 'You can retrieve, graph, and set alarms on the following statistical values for Amazon CloudWatch metrics: Average, Sum, Minimum, Maximum, and Sample Count. Statistics can be computed for any time periods between 60-seconds and 1-day. For high-resolution custom metrics, statistics can be computed for time periods between 1-second and 3-hours.\xa0 '), ('Q: What log monitoring does Amazon CloudWatch provide? ', 'CloudWatch Logs lets you monitor and troubleshoot your systems and applications using your existing system, application and custom log files. '), ('With CloudWatch Logs, you can monitor your logs, in near real time, for specific phrases, values or patterns. For example, you could set an alarm on the number of errors that occur in your system logs or view graphs of latency of web requests from your application logs. You can then view the original log data to see the source of the problem. Log data can be stored and accessed for up to as long as you need in highly durable, low-cost storage so you don’t have to worry about filling up hard drives.', 'Q. What are Amazon CloudWatch Vended Logs?'), ('Amazon CloudWatch Vended logs are logs that are natively published by AWS services on behalf of the customer. VPC Flow logs is the first Vended log type that will benefit from this tiered model. However, more AWS Service log types will be added to Vended Log type in the future. ', 'Q: Is CloudWatch Logs available in all regions? '), ('Please refer to Regional Products and Services for details of CloudWatch Logs service availability by region. ', 'Q: How much does CloudWatch Logs cost? '), ('Please see our pricing page for the latest information. ', 'Q: What kinds of things can I do with my logs and Amazon CloudWatch? '), ('CloudWatch Logs is capable of monitoring and storing your logs to help you better understand and operate your systems and applications. When you use CloudWatch Logs with your logs, your existing log data is used for monitoring, so no code change are required. Here are a two examples of what you can do with Amazon CloudWatch and your logs: ', "Real time Application and System Monitoring: You can use CloudWatch Logs to monitor applications and systems using log data in near real time. For example, CloudWatch Logs can track the number of errors that occur in your application logs and send you a notification whenever the rate of errors exceeds a threshold you specify. Amazon CloudWatch uses your log data for monitoring and consequently it doesn't involve any code changes from you. "), ('Long Term Log Retention: You can use CloudWatch Logs to store your log data for as long as you need in highly durable and cost effective storage without worrying about hard drives running out of space. The CloudWatch Logs Agent makes it easy to quickly move both rotated and non rotated log files off of a host and into the log service. You can then access the raw log event data when you need it. ', 'Q: What types of data can I send to Amazon CloudWatch Logs from my EC2 instances running Microsoft SQL Server and Microsoft Windows Server?'), ('You can configure the EC2Config service to send a variety of data and log files to CloudWatch including: custom text logs, Event (Application, Custom, Security, System) logs, Event Tracing (ETW) logs, and Performance Counter (PCW) data. Learn more about the EC2Config service here. ', 'Q: How frequently does the CloudWatch Logs Agent send data? '), ('The CloudWatch Logs Agent will send log data every five seconds by default and is configurable by the user. ', 'Q: What log formats does CloudWatch Logs support? '), ('CloudWatch Logs can ingest, aggregate and monitor any text based common log data or JSON-formatted logs. ', 'Q: What if I configure the CloudWatch Logs Agent to send non-text log data? '), ('The CloudWatch Logs Agent will record an error in the event it has been configured to report non text log data. This error is recorded in the /var/logs/awslogs.log. ', 'Q: How do I start monitoring my logs with CloudWatch Logs? '), ('You can monitor log events as they are sent to CloudWatch Logs by creating Metric Filters. Metric Filters turn log data into Amazon CloudWatch Metrics for graphing or alarming. Metric Filters can be created in the Console or the CLI. Metric Filters search for and match terms, phrases or values in your log events. When a Metric Filter finds one of the terms, phrases or values in your log events, it counts it in an Amazon CloudWatch Metric that you choose. For example, you can create a Metric Filter to search for and count the occurrence of the word “Error” in your log events. Metric Filters can also extract values from space delimited log events, such as the latency of web requests. You can also use conditional operators and wildcards to create exact matches. The Amazon CloudWatch Console can help you test your patterns before creating Metric Filters. ', 'Q: What is the syntax of Metric Filter patterns? '), ('A Metric Filter pattern can contain search terms or a specification of your common log or JSON event format. ', 'For example, if you want to search for the term Error, the pattern for the metric filter would just be the term Error. Multiple search terms can be included to search for multiple terms. For example, if you wanted to count events which contained the terms Error and Exception you would use the pattern Error Exception. If you wanted to match the term Error Exception exactly, you would put double quotes around the search term, "Error Exception". You can specify as many search terms as you like. '), ('CloudWatch Logs can also be used to extract values from a log event in common log or JSON format. For example, you could track the bytes transferred from your Apache access logs. You can also use conditional operators and wildcards to match and extract the data you are interested in. To use the extraction feature of Metric Filters, log events must be space delimited and use a starting and ending double quote """, or, a starting square brace "[" and a closing square brace "]"square, to enclose fields. Alternatively, they can be JSON-formatted log events. For the full details of the syntax and examples, please see the Developer Guide for Metric Filters. ', 'Q: How do I know that a Metric Filter pattern I specified will match my log events? '), ('CloudWatch Logs lets you test the Metric Filter patterns you want before you create a Metric Filter. You can test your patterns against your own log data that is already in CloudWatch Logs or you can supply your own log events to test. Testing your pattern will show you which log events matched the Metric Filter pattern and, if extracting values, what the extracted value is in the test data. Metric Filter testing is available for use in the console and the CLI. ', 'Q: Can I use regular expressions with my log data? '), ('Amazon CloudWatch Metric Filters does not support regular expressions. To process your log data with regular expressions, consider using Amazon Kinesis and connect the stream with a regular expression processing engine. ', 'Q: How do I retrieve my log data?'), ('You can retrieve any of your log data using the CloudWatch Logs console or through the CloudWatch Logs CLI. Log events are retrieved based on the Log Group, Log Stream and time with which they are associated. The CloudWatch Logs API for retrieving log events is GetLogEvents.', 'Q: How do I search my logs?'), ('You can use the CLI to retrieve your log events and search through them using command line grep or similar search functions.', 'Q: How long does CloudWatch Logs store my log data?'), ('You can store your log data in CloudWatch Logs for as long as you want. By default, CloudWatch Logs will store your log data indefinitely. You can change the retention for each Log Group at any time. ', 'Q: What types of CloudWatch Alarms can be created?'), ('You can create an alarm to monitor any Amazon CloudWatch metric in your account. For example, you can create alarms on an Amazon EC2 instance CPU utilization, Amazon ELB request latency, Amazon DynamoDB table throughput, Amazon SQS queue length, or even the charges on your AWS bill.', 'You can also create an alarm on custom metrics that are specific to your custom applications or infrastructure. If the custom metric is a high-resolution metric, you have the option of creating high-resolution alarms that alert as soon as 10-second or 30-second periods.'), ('Please reference the CloudWatch pricing page to learn more. \xa0', 'Q: What actions can I take from a CloudWatch Alarm?'), ('When you create an alarm, you can configure it to perform one or more automated actions when the metric you chose to monitor exceeds a threshold you define. For example, you can set an alarm that sends you an email, publishes to an SQS queue, stops or terminates an Amazon EC2 instance, or executes an Auto Scaling policy. Since Amazon CloudWatch alarms are integrated with Amazon Simple Notification Service, you can also use any notification type supported by SNS.', 'Q: What thresholds can I set to trigger a CloudWatch Alarm?'), ('When you create an alarm, you first choose the Amazon CloudWatch metric you want it to monitor. Next, you choose the evaluation period (e.g., five minutes or one hour) and a statistical value to measure (e.g., Average or Maximum). To set a threshold, set a target value and choose whether the alarm will trigger when the value is greater than (>), greater than or equal to (>=), less than (<), or less than or equal to (<=) that value. ', 'Q: My CloudWatch Alarm is constantly in the Alarm state, what did I do wrong?'), ('Alarms continue to evaluate metrics against your chosen threshold, even after they have already triggered. This allows you to view its current up-to-date state at any time. You may notice that one of your alarms stays in the ALARM state for a long time. If your metric value is still in breach of your threshold, the alarm will remain in the ALARM state until it no longer breaches the threshold. This is normal behavior. If you want your alarm to treat this new level as OK, you can adjust the alarm threshold accordingly.', 'Q: How long can I view my Alarm history?'), ('Alarm history is available for 14 days. To view your alarm history, log in to CloudWatch in the AWS Management Console, choose Alarms from the menu at left, select your alarm, and click the History tab in the lower panel. There you will find a history of any state changes to the alarm as well as any modifications to the alarm configuration. ', 'Q: What is CloudWatch Dashboards?'), ('Amazon CloudWatch Dashboards allow you to create, customize, interact with, and save graphs of AWS resources and custom metrics. ', 'Q: What can I do with CloudWatch dashboards?'), ('You can use CloudWatch Dashboards to monitor your applications and resources to quickly identify issues that might be impacting the health of your applications. You can save and revisit dashboards, add multiple graphs, or add text widgets into a dashboard to embed links and comments. For example, you can include graphs of your resource and application metrics to see when resource health problems might be impacting your applications. You can also view metrics from multiple regions on the same page.', 'Q: How do I get started with CloudWatch Dashboards?'), ('To get started, visit the Amazon CloudWatch Console and select “Dashboards”. Click the “Create Dashboard” button.', 'Q: Do the dashboards support auto refresh?'), ('Yes. Dashboards will auto refresh while you have them open.', 'Q: Can I share my dashboard?'), ('Yes, a dashboard is available to anyone with the correct permissions for the account with the dashboard. ', 'Q: What is CloudWatch Events?'), ('Amazon CloudWatch Events (CWE) is a stream of system events describing changes in your AWS resources. The events stream augments the existing CloudWatch Metrics and Logs streams to provide a more complete picture of the health and state of your applications. You write declarative rules to associate events of interest with automated actions to be taken. ', 'Q: What services emit CloudWatch Events?'), ('Currently, Amazon EC2, Auto Scaling, and AWS CloudTrail are supported. Via AWS CloudTrail, mutating API calls (i.e., all calls except Describe*, List*, and Get*) across all services are visible in CloudWatch Events. ', 'Q: What can I do once an event is received?'), ("When an event matches a rule you've created in the system, you can automatically invoke an AWS Lambda function, relay the event to an Amazon Kinesis stream, notify an Amazon SNS topic, or invoke a built-in workflow. ", 'Q: Can I generate my own events?'), ('Yes. Your applications can emit custom events by using the PutEvents API, with a payload uniquely suited to your needs.', 'Q: Can I do things on a fixed schedule?'), ('CloudWatch Events is able to generate events on a schedule you set by using the popular Unix cron syntax. By monitoring for these events, you can implement a scheduled application. ', 'Q: What is the difference between CloudWatch Events and AWS CloudTrail? '), ('CloudWatch Events is a near real time stream of system events that describe changes to your AWS resources. With CloudWatch Events, you can define rules to monitor for specific events and perform actions in an automated manner. AWS CloudTrail is a service that records API calls for your AWS account and delivers log files containing API calls to your Amazon S3 bucket or a CloudWatch Logs log group. With AWS CloudTrail, you can look up API activity history related to creation, deletion and modification of AWS resources and troubleshoot operational or security issues. ', 'Q: What is the difference between CloudWatch Events and AWS Config? '), ('AWS Config is a fully managed service that provides you with an AWS resource inventory, configuration history, and configuration change notifications to enable security and governance. Config rules help you determine whether configuration changes are compliant. CloudWatch Events is for reacting in near real time to resource state changes. It doesn’t render a verdict on whether the changes comply with policy or give detailed history like Config/Config Rules do. It is a general purpose event stream. ', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/ec2/systems-manager/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/cloudtrail/faqs/': [('Q: What is AWS CloudTrail? AWS CloudTrail is a web service that records activity made on your account and delivers log files to your Amazon S3 bucket.', 'Q: What are the benefits of CloudTrail?  CloudTrail provides visibility into user activity by recording actions taken on your account. CloudTrail records important information about each action, including who made the request, the services used, the actions performed, parameters for the actions, and the response elements returned by the AWS service. This information helps you to track changes made to your AWS resources and to troubleshoot operational issues. CloudTrail makes it easier to ensure compliance with internal policies and regulatory standards. For more details, refer to the AWS compliance white paper “Security at scale: Logging in AWS”.'), ('Q: Who should use CloudTrail? Customers who need to track changes to resources, answer simple questions about user activity, demonstrate compliance, troubleshoot, or perform security analysis should use CloudTrail.', 'Q: If I am a new AWS customer or existing AWS customer and don’t have CloudTrail setup, do I need to enable or setup anything to view my account activity? No, nothing is required to begin viewing your account activity. You can visit the AWS CloudTrail console or AWS CLI and begin viewing up to the past 90 days of account activity.'), ('Q: Does the CloudTrail Event History show all account activity within my account? AWS CloudTrail will only show the results of the CloudTrail Event History for the current region you are viewing for the last 90 days and support the AWS services found here. These events are limited to management events with create, modify, and delete API calls and account activity. For a complete record of account activity, including all management events, data events, and read-only activity, you’ll need to configure a CloudTrail trail.', 'Q: What search filters can I use to view my account activity? You can specify Time range and one of the following attributes: Event name, User name, Resource name, Event source, Event ID, and Resource type.'), ('Q: Can I use the lookup-events CLI command even if I don’t have a trail configured? Yes, you can visit the CloudTrail console or use the CloudTrail API/CLI and begin viewing the past 90 days of account activity.', 'Q: What additional CloudTrail features are available by setting up CloudTrail and creating a trail?  By setting up a CloudTrail trail you can deliver your CloudTrail events to Amazon S3, Amazon CloudWatch Logs, and Amazon CloudWatch Events. This enables you to leverage features to help you archive, analyze, and respond to changes in your AWS resources.'), ('Q: Can I restrict access for users in my account from seeing the CloudTrail Event History? Yes, CloudTrail integrates with AWS Identity and Access Management (IAM), which allows you to control access to CloudTrail and to other AWS resources that CloudTrail requires, including the ability to restrict permissions to view and search account activity. This is accomplished by removing the "cloudtrail:LookupEvents" from the Users IAM policy which will then prevent that IAM user from viewing account activity.', 'Q: Is there any cost associated with CloudTrail Event History being enabled on my account upon creation?  There is no cost for viewing or searching account activity with CloudTrail Event History.'), ('Q: Can I turn CloudTrail Event History off for my account? For any CloudTrail trails that you have created, you can stop logging or delete the trails which will also stop the delivery of account activity to the S3 bucket you had designated as part of your trail configuration as well as delivery to CloudWatch Logs if configured. Account activity for the past 90 days will still be collected and visible within the CloudTrail console and through the AWS CLI. \xa0', 'Q: What services are supported by CloudTrail? AWS CloudTrail records account activity and service events from most AWS services. For the list of supported services, see CloudTrail Supported Services in the CloudTrail User Guide.'), ('Q: Are API calls made from the AWS Management Console recorded?  Yes. CloudTrail records API calls made from any client. The AWS Management Console, AWS SDKs, command line tools, and higher level AWS services call AWS APIs, so these calls are recorded.', ' Q: Where are my log files stored and processed before they are delivered to my Amazon S3 bucket? Activity information for services with regional end points (EC2, RDS etc.) is captured and processed in the same region as to which the action is made and delivered to the region associated with your Amazon S3 bucket. Action information for services with single end points (IAM, STS, etc.) is captured in the region where the end point is located, processed in the region where the CloudTrail trail is configured and delivered to the region associated with your Amazon S3 bucket. '), ('Q: What is applying a trail to all regions? Applying a trail to all regions refers to creating a trail that will record AWS account activity in all regions. This setting also applies to any new regions that are added. For more details on regions and partitions, refer to the Amazon Resource Names and AWS Service Namespaces page.', 'Q: What are the benefits of applying a trail to all regions? You can create and manage a trail across all regions in the partition in one API call or few clicks. You will receive a record of account activity made in your AWS account across all regions to one S3 bucket or CloudWatch logs log group. When AWS launches a new region, you will receive the log files containing event history for the new region without taking any action.'), ('Q: How do I apply a trail to all regions?  In the CloudTrail console, you select yes to apply to all regions in the trail configuration page. If you are using the SDKs or AWS CLI, You set the IsMultiRegionTrail to true.', 'Q: What happens when I apply a trail to all regions?  Once you apply a trail in all regions, CloudTrail will create a new trail in all regions by replicating the trail configuration. CloudTrail will record and process the log files in each region and will deliver log files containing account activity across all AWS regions to a single S3 bucket and a single CloudWatch Logs log group. If you specified an optional SNS topic, CloudTrail will deliver SNS notifications for all log files delivered to a single SNS topic.'), ('Q: Can I apply an existing trail to all regions? Yes. You can apply an existing trail to all regions. When you apply an existing trail to all regions, CloudTrail will create a new trail for you in all regions. If you previously created trails in other regions, you can view, edit and delete those trails from the CloudTrail console.', 'Q: How long will it take for CloudTrail to replicate the trail configuration to all regions? Typically, it will take less than 30 seconds to replicate the trail configuration to all regions.'), ('Q: How many trails can I create in an AWS region?  You can create up to five trails in an AWS region. A trail that applies to all regions exists in each region and is counted as one trail in each region.', 'Q: What is the benefit of creating multiple trails in an AWS region?  With multiple trails, different stakeholders such as security administrators, software developers and IT auditors can create and manage their own trails. For example, a security administrator can create a trail that applies to all regions and configure encryption using one KMS key. A developer can create a trail that applies to one region for troubleshooting operational issues.'), ('Q: Does CloudTrail support resource level permissions? Yes. Using resource level permissions, you can write granular access control policies to allow or deny access to specific users for a particular trail. For more details, go to CloudTrail documentation.', 'Q: How can I secure my CloudTrail log files? By default, CloudTrail log files are encrypted using S3 Server Side Encryption (SSE) and placed into your S3 bucket. You can control access to log files by applying IAM or S3 bucket policies. You can add an additional layer of security by enabling S3 Multi Factor Authentication (MFA) Delete on your S3 bucket. For more details on creating and updating a trail, see the CloudTrail documentation.'), ('Q: Where can I download a sample S3 bucket policy and an SNS topic policy?  You can download a sample S3 bucket policy and an SNS topic policy from CloudTrail S3 bucket. You need to update the sample policies with your information before you apply them to your S3 bucket or SNS topic.', 'Q: How long can I store my activity log files?  You control the retention policies for your CloudTrail log files. By default, log files are stored indefinitely. You can use Amazon S3 object lifecycle management rules to define your own retention policy. For example, you may want to delete old log files or archive them to Amazon Glacier.'), ('Q: What information is available in an event?  An event contains information about the associated activity: who made the request, the services used, the actions performed, and parameters for the action, and the response elements returned by the AWS service. For more details, see the CloudTrail Event Reference section of the user guide. ', 'Q: How long does it take CloudTrail to deliver an event for an API call?  Typically, CloudTrail delivers an event within 15 minutes of the API call.'), ('Q: How often will CloudTrail deliver log files to my Amazon S3 bucket?  CloudTrail delivers log files to your S3 bucket approximately every 5 minutes. CloudTrail does not deliver log files if no API calls are made on your account.', 'Q: Can I be notified when new log files are delivered to my Amazon S3 bucket?  Yes. You can turn on Amazon SNS notifications so that you can take immediate action on delivery of new log files.'), ('Q: What happens if CloudTrail is turned on for my account but my Amazon S3 bucket is not configured with the correct policy?  CloudTrail log files are delivered in accordance with the S3 bucket policies that you have in place. If the bucket policies are misconfigured, CloudTrail will not be able to deliver log files.', 'Q: What are Data events?  Data events provide insights into the resource (“data plane”) operations performed on or within the resource itself. Data events are often high volume activities and include operations such as Amazon S3 object level APIs and Lambda function invoke API. Data events are disabled by default when you configure a trail. To record CloudTrail data events, you must explicitly add the supported resources or resource types you want to collect activity on. Unlike management events, data events incur additional costs. For more information, see CloudTrail pricing. '), ('Q: How can I consume Data events? Data events that are recorded by AWS CloudTrail are delivered to S3, similar to management events. Once enabled, these events are also available in Amazon CloudWatch Events. ', 'Q: What are Amazon S3 Data events? How do I record them? Amazon S3 data events represent API activity on Amazon S3 Objects. To get CloudTrail to record these actions, you specify a S3 bucket in the data events section when creating a new trail or modifying an existing one. Any API actions on the objects within the specified S3 bucket are recorded by CloudTrail. '), ('Q: What are AWS Lambda Data Events? How do I record them? AWS Lambda data events record execution activity of your Lambda functions. With Lambda data events, you can get details on Lambda function executions, such as the IAM user or service that made the Invoke API call, when the call was made, and which function was executed. All Lambda data events are delivered to an Amazon S3 bucket and Amazon CloudWatch Events. You can turn on logging for AWS Lambda data events using the AWS CLI or AWS CloudTrail console and select which Lambda functions get logged by creating a new trail or editing an existing trail.', 'Q: I have multiple AWS accounts. I would like log files for all the accounts to be delivered to a single S3 bucket. Can I do that?  Yes. You can configure one S3 bucket as the destination for multiple accounts. For detailed instructions, refer to aggregating log files to a single Amazon S3 bucket section of the AWS CloudTrail User Guide.'), ('Q: What is CloudTrail integration with CloudWatch Logs? CloudTrail integration with CloudWatch Logs delivers management and data events captured by CloudTrail to a CloudWatch Logs log stream in the CloudWatch Logs log group you specify.', 'Q: What are the benefits of CloudTrail integration with CloudWatch Logs? This integration enables you to receive SNS notifications of account activity captured by CloudTrail. For example, you can create CloudWatch alarms to monitor API calls that create, modify and delete Security Groups and Network ACL’s.'), ('Q: How do I turn on CloudTrail integration with CloudWatch Logs? You can turn on CloudTrail integration with CloudWatch Logs from the CloudTrail console by specifying a CloudWatch Logs log group and an IAM role. You can also use the AWS SDKs or the AWS CLI to turn on this integration.', 'Q: What happens when I turn on CloudTrail integration with CloudWatch Logs? After you turn on the integration, CloudTrail continuously delivers account activity to a CloudWatch Logs log stream in the CloudWatch Logs log group you specified. CloudTrail also continues to deliver logs to your Amazon S3 bucket as before.'), ('Q: In which AWS regions is CloudTrail integration with CloudWatch Logs supported? This integration is supported in the regions where CloudWatch Logs is supported. For more information, see Regions and Endpoints in the Amazon Web Services General Reference.', 'Q: How does CloudTrail deliver events containing account activity to my CloudWatch Logs? CloudTrail assumes the IAM role you specify to deliver account activity to CloudWatch Logs. You limit the IAM role to only the permissions it requires to deliver events to your CloudWatch Logs log stream. To review IAM role policy, go to the user guide of the CloudTrail documentation.'), ('Q: What charges do I incur once I turn on CloudTrail integration with CloudWatch Logs? After you turn on CloudTrail integration with CloudWatch Logs, you incur standard CloudWatch Logs and CloudWatch charges. For details, go to CloudWatch pricing page.', 'Q: What is the benefit of CloudTrail log file encryption using Server-side Encryption with KMS?  CloudTrail log file encryption using SSE-KMS allows you to add an additional layer of security to CloudTrail log files delivered to an Amazon S3 bucket by encrypting the log files with a KMS key. By default, CloudTrail will encrypt log files delivered to your Amazon S3 bucket using Amazon S3 server-side encryption.'), ('Q: I have an application that ingests and processes CloudTrail log files. Do I need to make any changes to my application?  With SSE-KMS, Amazon S3 will automatically decrypt the log files so that you do not need to make any changes your application. As always, you need to make sure that your application has appropriate permissions, i.e. Amazon S3 GetObject and KMS Decrypt permissions.', 'Q: How do I configure CloudTrail log file encryption? You can use the AWS Management Console, or AWS CLI or the AWS SDKs to configure log file encryption. For detailed instructions, refer to the documentation.'), ('Q: What charges do I incur once I configure encryption using SSE-KMS? Once you configure encryption using SSE-KMS, you will incur standard AWS KMS charges. For details,go to AWS KMS pricing page.', 'Q: What is CloudTrail log file integrity validation? CloudTrail log file integrity validation feature allows you to determine whether a CloudTrail log file was unchanged, deleted, or modified since CloudTrail delivered it to the specified Amazon S3 bucket.'), ('Q: What is the benefit of CloudTrail log file integrity validation?  You can use the log file integrity validation as an aid in your IT security and auditing processes.', 'Q: How do I enable CloudTrail log file integrity validation?  You can enable the CloudTrail log file integrity validation feature from the AWS Management Console, AWS CLI or AWS SDKs.'), ('Q: What happens once I turn on the log file integrity validation feature? Once you turn on the log file integrity validation feature, CloudTrail will deliver digest files on an hourly basis. The digest files contain information about the log files that were delivered to your Amazon S3 bucket, hash values for those log files, digital signatures for the previous digest file, and the digital signature for the current digest file in the Amazon S3 metadata section. For more information about digest files, digital signatures and hash values, go to CloudTrail documentation.', 'Q: Where are the digest files delivered to?  The digest files are delivered to the same Amazon S3 bucket where your log files are delivered to. However, they are delivered to a different folder so that you can enforce granular access control policies. For details, refer to the digest file structure section of the CloudTrail documentation.'), ('Q: How can I validate the integrity of a log file or digest file delivered by CloudTrail? You can use the AWS CLI to validate that the integrity of log file or digest file. You can also build your own tools to do the validation. For more details on using the AWS CLI for validating the integrity of a log file, refer to the CloudTrail documentation.', 'Q: I aggregate all my log files across all regions and multiple accounts into one single Amazon S3 bucket. Will the digest files be delivered to the same Amazon S3 bucket?  Yes. CloudTrail will deliver the digest files across all regions and multiple accounts into the same Amazon S3 bucket. '), ('Q: What is AWS CloudTrail Processing Library? AWS CloudTrail Processing Library is a Java library that makes it easy to build an application that reads and processes CloudTrail log files. You can download CloudTrail Processing Library from GitHub.', 'Q: What functionality does CloudTrail Processing Library provide? CloudTrail Processing Library provides functionality to handle tasks such as continuously polling a SQS queue, reading and parsing SQS messages, downloading log files stored in S3, parsing and serializing events in the log file in a fault tolerant manner. For more information, go to the user guide section of the CloudTrail documentation.'), ('Q: What software do I need to start using the CloudTrail Processing Library? You need aws-java-sdk version 1.9.3 and Java 1.7 or higher. ', 'Q: How do I get charged for AWS CloudTrail? AWS CloudTrail allows you to view and download the last 90 days of your account activity for create, modify, and delete operations of supported services free of charge.'), ('There is no charge from AWS CloudTrail for creating a CloudTrail trail and the first copy of management events within each region is delivered to the S3 bucket specified in your trail free of charge. Once a CloudTrail trail is setup, Amazon S3 charges apply based on your usage. You will be charged for any data events or additional copies of management events recorded in that region, per the published\xa0pricing plan. For example, if you create a multi-region trail and a single-region trail within the same region, you will be charged for a copy of management events recorded in that region. \xa0', 'Q: If I have only one trail with management Events, and apply it to all regions, will I incur charges? No. The first copy of management events is delivered free of charge in each region.'), ('Q: If I enable data events on an existing trail with free management events, will I get charged? Yes. You will only be charged for the data events. The first copy of management events is delivered free of charge.', 'Q: How do the AWS partner solutions help me analyze the events recorded by CloudTrail? Multiple partners offer integrated solutions to analyze CloudTrail log files. These solutions include features like change tracking, troubleshooting, and security analysis. For more information, see the CloudTrail partners section.'), (' Q: Will turning on CloudTrail impact the performance of my AWS resources, or increase API call latency? No. Turning on CloudTrail has no impact on performance of your AWS resources or API call latency.', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/config/faq/': [('What is AWS Config?', 'AWS Config is a fully managed service that provides you with an AWS resource inventory, configuration history, and configuration change notifications to enable security and governance. With AWS Config you can discover existing AWS resources, export a complete inventory of your AWS resources with all configuration details, and determine how a resource was configured at any point in time. These capabilities enable compliance auditing, security analysis, resource change tracking, and troubleshooting.'), ('What is a Config Rule?', 'A Config Rule represents desired configurations for a resource and is evaluated against configuration changes on the relevant resources, as recorded by AWS Config. The results of evaluating a rule against the configuration of a resource are available on a dashboard. Using Config Rules, you can assess your overall compliance and risk status from a configuration perspective, view compliance trends over time and pinpoint which configuration change caused a resource to drift out of compliance with a rule. '), ('What are the benefits of AWS Config?', 'AWS Config makes it easy to track your resource’s configuration without the need for up-front investments and avoiding the complexity of installing and updating agents for data collection or maintaining large databases. Once you enable AWS Config, you can view continuously updated details of all configuration attributes associated with AWS resources. You are notified via Amazon Simple Notification Service (SNS) of every configuration change.'), ('\xa0', 'How can AWS Config help with audits?'), ('AWS Config gives you access to resource configuration history. You can relate configuration changes with AWS CloudTrail events that possibly contributed to the change in configuration. This information provides you full visibility, right from details, such as “Who made the change?”, “From what IP address?” to the effect of this change on AWS resources and related resources. You can use this information to generate reports to aid auditing and assessing compliance over a period of time.', 'Who should use AWS Config and Config Rules?'), ('Any AWS customer looking to improve their security and governance posture on AWS by continuously evaluating the configuration of their resources would benefit from this capability. Administrators within larger organizations who recommend best practices for configuring resources can codify these rules as Config Rules, and enable self-governance among users. Information Security experts who monitor usage activity and configurations to detect vulnerabilities can benefit from Config Rules. Customers with workloads that need to comply with specific standards (e.g. PCI-DSS or HIPAA) can use this capability to assess compliance of their AWS infrastructure configurations, and generate reports for their auditors. Operators who manage large AWS infrastructure or components that change frequently can also benefit from Config Rules for troubleshooting.Customers who want to track changes to resources configuration, answer questions about resource configurations, demonstrate compliance, troubleshoot or perform security analysis should turn on AWS Config.', 'Does the service guarantee that my configurations are never out of compliance? '), ('Config Rules provides information about whether your resources are compliant with configuration rules you specify. It will evaluate rules as soon as updated Configuration Items (CIs) for the resource are available within AWS Config. It does not guarantee that resources will be compliant or prevent users from taking non-compliant actions. Further, Config Rules does not automatically snap non-compliant resources back into compliance.', 'Does the service prevent users from taking non-compliant actions? '), ('Config Rules does not directly affect how end-users consume AWS. It evaluates resource configurations only after a configuration change has been completed and recorded by AWS Config. Config Rules does not prevent the user from making changes that could be non-compliant. To control what a user can provision on AWS and configuration parameters allowed during provisioning, please use AWS Identity and Access Management (IAM) Policies and AWS Service Catalog respectively.', 'Can rules be evaluated prior to provisioning a resource?'), ('Config Rules evaluates rules after the Configuration Item (CI) for the resource is captured by AWS Config. It does not evaluate rules prior to provisioning a resource or prior to making configuration changes on the resource.', 'How does AWS Config work with AWS CloudTrail?'), ('AWS CloudTrail records user API activity on your account and allows you to access information about this activity. You get full details about API actions, such as identity of the caller, the time of the API call, the request parameters, and the response elements returned by the AWS service. AWS Config records point-in-time configuration details for your AWS resources as Configuration Items (CIs). You can use a CI to answer “What did my AWS resource look like?” at a point in time. You can use AWS CloudTrail to answer “Who made an API call to modify this resource?” For example, you can use the AWS Management Console for AWS Config to detect security group “Production-DB” was incorrectly configured in the past. Using the integrated AWS CloudTrail information, you can pinpoint which user misconfigured “Production-DB” security group.', '\xa0'), ('How do I get started with this service?', 'The quickest way to get started with AWS Config is to use the AWS Management Console. You can turn on AWS Config in a few clicks. For additional details, see the Getting Started documentation.'), ('How do I access my resources’ configuration?', 'You can lookup current and historical resource configuration using the AWS Management Console, AWS Command Line Interface or SDKs.'), ('For additional details, please refer to AWS Config documentation.', 'Do I turn on AWS Config regionally or globally?'), ('You turn on AWS Config on a per-region basis for your account.', 'Can AWS Config aggregate data across different AWS accounts?'), ('Yes, you can set up AWS Config to deliver configuration updates from different accounts to one S3 bucket, once the appropriate IAM policies are applied to the S3 bucket. You can also publish notifications to the one SNS Topic, within the same region, once appropriate IAM policies are applied to the SNS Topic.', 'Is API activity on AWS Config itself logged by AWS CloudTrail?'), ('Yes. All AWS Config API activity, including use of AWS Config APIs to read configuration data, is logged by AWS CloudTrail.', 'What time and timezones are displayed in the timeline view of a resource? What about daylight savings? '), ('AWS Config displays the time at which Configuration Items (CIs) were recorded for a resource on a timeline. All times are captured in Coordinated Universal Time (UTC). When the timeline is visualized on the management console, the services uses the current time zone (adjusted for daylight savings, if relevant) to display all times in the timeline view.', 'What is a resource’s configuration?'), ('Configuration of a resource is defined by the data included in the Configuration Item (CI) of AWS Config. The initial release of Config Rules makes the CI for a resource available to relevant rules. Config Rules can use this information along with any other relevant information such as other attached resource, business hours, etc. to evaluate compliance of a resource’s configuration.', 'What is a rule?'), ('A rule represents desired Configuration Item (CI) attribute values for resources and are evaluated by comparing those attribute values with CIs recorded by AWS Config. There are two types of rules:', 'AWS managed rules: AWS managed rules are pre-built and managed by AWS. You simply choose the rule you want to enable, then supply a few configuration parameters to get started. Learn more »'), ('Customer managed rules: Customer managed rules are custom rules, defined and built by you. You can create a function in AWS Lambda that can be invoked as part of a custom rule and these functions execute in your account. Learn more »', 'The quickest way to get started with AWS Config is to use the AWS Management Console. You can turn on AWS Config in a few clicks. For additional details, see the Getting Started documentation.'), ('How are rules created?', 'Rules are typically set up by the AWS account administrator. They can be created by leveraging AWS managed rules – a predefined set of rules provided by AWS or through customer managed rules. With AWS managed rules updates to the rule are automatically applied to any account using that rule. In the customer-managed model, the customer has a full copy of the rule, and executes the rule within his/her own account. These rules are maintained by the customer.'), ('How many rules can I create?', 'You can create up to 50 rules in your AWS account by default. Additionally, you can request an increase for the limit on the number of rules in your account by visiting the AWS Service Limits page.'), ('How are rules evaluated? ', 'Any rule can be setup as a change-triggered rule or as a periodic rule. A change-triggered rule is executed when AWS Config records a configuration change for any of the resources specified. Additionally, one of the following must be specified:'), ('Tag Key:(optional Value): A tag key:value implies any configuration changes recorded for resources with the specified tag key:value will trigger an evaluation of the rule.', 'Resource type(s): Any configuration changes recorded for any resource within the specified resource type(s) will trigger an evaluation the rule.'), ('Resource ID: Any changes recorded to the resource specified by the resource type and resource ID will trigger an evaluation of the rule.', 'A periodic rule is triggered at a specified frequency. Available frequencies are 1hr, 3hr, 6hr, 12hr or 24hrs. A periodic rule has a full snapshot of current Configuration Items (CIs) for all resources available to the rule. '), ('What is an evaluation? ', 'Evaluation of a rule determines whether a rule is compliant with a resource at a particular point in time. It is the result of evaluating a rule against the configuration of a resource. Config Rules will capture and store the result of each evaluation. This result will include the resource, rule, time of evaluation and a link to Configuration Item (CI) that caused non-compliance. '), ('What does compliance mean? ', 'A resource is compliant if complies with all rules that apply to it. Otherwise it is noncompliant. Similarly, a rule is compliant if all resources evaluated by the rule comply with the rule. Otherwise it is noncompliant. In some cases, such as when inadequate permissions are available to the rule, an evaluation may not exist for the resource, leading to a state of insufficient data. This state is excluded from determining the compliance status of a resource or rule. '), ('What information does the Config Rules dashboard provide?', 'The Config Rules dashboard gives you an overview of resources tracked by AWS Config, and a summary of current compliance by resource and by rule. When you view compliance by resource, you can determine if any rule that applies to the resource is currently not compliant. You can view compliance by rule, which tells you if any resource under the purview of the rule is currently non-compliant. Using these summary views, you can dive deeper into the Config timeline view of resources, to determine which configuration parameters changed. Using this dashboard, you can start with an overview and drill into fine-grained views that give you full information about changes in compliance status, and which changes caused non-compliance. '), ('What AWS resources types are covered by AWS Config?', ''), ('Review our documentation for a complete list of supported resource types. ', 'What regions is AWS Config available in?'), ('For details on the regions where AWS Config is available, please visit this page:', 'http://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/ '), ('\xa0', 'What is a configuration item?'), ('A Configuration Item (CI) is the configuration of a resource at a given point-in-time. A CI consists of 5 sections:', 'Learn more about configuration items'), ('What are AWS Config relationships and how are they used?', 'AWS Config takes the relationships among resources into account when recording changes. For example, if a new Amazon EC2 Security Group is associated with an Amazon EC2 Instance, AWS Config records the updated configurations of both the primary resource, the Amazon EC2 Security Group, and related resources, such as the Amazon EC2 Instance, if these resources actually changed. '), ('Does AWS Config record every state a resource has been in?', "AWS Config detects change to resource's configuration and records the configuration state that resulted from that change. In cases where several configuration changes are made to a resource in quick succession (e.g. within a span of few minutes), Config will only record the latest configuration of that resource that represents cumulative impact of the set of changes. In these situations, Config will only list the latest change in the relatedEvents field of the Configuration Item.This allows users and programs to continue to change infrastructure configurations without having to wait for Config to record intermediate transient states."), ('Does AWS Config record configuration changes that did not result from API activity on that resource?', "Yes, AWS Config will regularly scan configuration of resources for changes that haven't yet been recorded and record these changes. CIs recorded from these scans will not have a relatedEvent field in the payload, and only the latest state that is different from state already recorded is picked up."), ('Does AWS Config record configuration changes to software within EC2 instances?  Yes. AWS Config enables you to record configuration changes to software within EC2 instances in your AWS account and also virtual machines (VMs), or servers in your on-premises environment. The configuration information recorded by AWS Config includes Operating System updates, network configuration, installed applications, etc. You can evaluate whether your instances, VMs, and servers are in compliance with your guidelines using AWS Config Rules. The deep visibility and continuous monitoring capabilities provided by AWS Config allow you to assess compliance and troubleshoot operational issues.', 'Does AWS Config continue to send notifications if a resource that was previously non-compliant is still non-compliant after a periodic rule evaluation? AWS Config sends notifications only when the compliance status changes. If a resource was previously non-compliant and is still non-compliant, Config will not send a new notification. If the compliance status changes to “compliant”, you will receive a notification for the change in status.'), ('Can I flag or exempt resources from being evaluated by Config rules? When you configure Config rules, you can specify whether your rule runs evaluations against specified resource types or resources with a specific tag.', 'How will I be charged for this service?'), ('With AWS Config, you are charged based on the number Configuration Items (CIs) recorded for supported resources in your AWS account. You are charged only once for recording the CI. There no additional fee for retaining the CI or any up-front commitment. You can stop recording CIs at any time and continue to access the CIs previously recorded. Charges per CI are rolled up into your monthly bill. See pricing details. ', 'If you are using AWS Config Rules, you will be charged based on active Config Rules in that month. When a rule is compared with an AWS resource, the result is recorded as an evaluation. An rule is active if it has one or more evaluations in a month.'), ('Configuration snapshots and configuration history files are delivered to you in the Amazon S3 bucket that you choose, and configuration change notifications are delivered via Amazon Simple Notification Service (SNS). Standard rates for Amazon S3 and Amazon SNS apply. Customer managed rules are authored using AWS Lambda. Standard rates for AWS Lambda apply. ', 'Does the pricing for Config Rules include the costs for AWS Lambda functions?'), ('You can choose from a set of managed rules provided by AWS or you can author your own rules, written as AWS Lambda functions. Managed rules are fully managed and maintained by AWS and you do not pay any additional AWS Lambda charges to run them. Simply enable managed rules, provide any required parameters, and pay a single rate for each AWS Config rule. On the other hand, customer managed rules give you full control by executing these rules as AWS Lambda functions in your account. In addition to monthly charges for an active rule, standard AWS Lambda free tier and function execution rates apply to customer managed rules.', 'What does shared quota for Config Rules mean?  '), ('You receive a quota 20,000 evaluations per active rule per month. For example, if you have 3 Config Rules, you get a quota of 60,000 evaluations for the account. You can choose spread this allowance across the rules in any way. ', 'Do unused evaluations carry over to the next month?'), ('Unused evaluations expire and are reset every billing cycle. ', 'Can you provide breakdown of charges using an example?'), ('Pricing example 1: AWS Config records each AWS resource and configuration change as a Configuration Item (CI). Assume you record 7,000 CIs/month and have created 5 active rules (2 periodic and 3 change triggered), reporting a combined total of 150 evaluations per day.', 'AWS Config costs: 7,000 * $0.003 = $21.00 Cost for 5 active rules = 5 * $2.00 = $10.00'), ('Quota for evaluation results = 5 * 20,000 = 100,000 Number of evaluation results used = 150 evaluations * 30 days = 4,500 evaluations/month Additional charges from evaluation results = $0.0', 'Total AWS Config monthly charges = $31.00'), ('The service charges you incur depend on the number of CIs recoded by your resources. This depends on the number of resources in your account, and the configuration changes you make to these resources. For an account with several hundred resources, and standard configuration change activity, AWS Config would capture fewer than 3,000 CIs per month, or less than $9 per month.', ' Pricing Example 2:  Assume you record 50,000 CIs/month and have created 2 active rules, and each of these is evaluated on every CI and report a result results each time.'), ('AWS Config costs: 50,000 * $0.003 = $150.00 Cost for 2 active rules = 2 * $2.00 = $4.00', 'Quota for evaluation results = 2 * 20,000 = 40,000 Number of evaluation results used = 2 * 50,000 = 100,000 Additional charges from evaluation results = (100,000 – 40,000) = 60,000 * 0.0001 = $6.00'), ('Total AWS Config monthly charges = $150.00 + $4.00+ $6.00 = $160.00', 'What AWS partner solutions are available for AWS Config?'), ('Ecosystem partners such as Splunk, ServiceNow, Evident.IO, CloudCheckr, Redseal Networks and RedHat CloudForms provide offerings that are fully integrated with data from AWS Config. Managed Service Providers, such as 2nd Watch and CloudNexa have also announced integrations with AWS Config. Additionally, with Config Rules, partners such as CloudHealth Technologies, AlertLogic and TrendMicro are providing integrated offerings that can be used by customers. These solutions include capabilities such as change management and security analysis and allow you to visualize, monitor and manage AWS resource configurations.', 'For more information, see AWS Config partner solutions.'), ('\xa0', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/managed-services/faqs/': [(' Why did we build AWS Managed Services? How can I start using the service? How can AWS Managed Services help Enterprises accelerate cloud adoption? Is AWS Managed Services just for Enterprises? Does AWS Managed Services manage applications? What is the difference between AWS Managed Services and the AWS Managed Service Provider (MSP) Program? What opportunities do APN Partners have with AWS Managed Services? How do APN Partners and AWS Managed Services work together? How can APN Partners offer AWS Managed Services to AWS customers? How does AWS Managed Services leverage automation? Will AWS Managed Services work with existing ITSMs? For which ITSM tools does AWS Managed Services provide standard integrations? What industry standards does AWS Managed Services comply with? What operating systems does AWS Managed Services support? Does AWS Managed Services manage all AWS services? Can AWS Managed Services support traditional workloads? How do I deploy applications on AWS Managed Services? Does AWS Managed Services manage on-premises resources or other public clouds? Will I still have access to my resources? Can I access my managed environments from my corporate network? In which AWS regions is AWS Managed Services available? What languages are supported by AWS Managed Services? Does AWS Managed Services use sub-contractors for operations? How much does AWS Managed Services cost?', '\xa0'), ('\xa0', ' Why did we build AWS Managed Services?'), ('It all comes down to customer choice. When our customers ask us for a capability, we listen. AWS Managed Services was built for Fortune 100 companies who asked us to develop the single-vendor capabilities required for them to move thousands of workloads to AWS, and receive comparable SLAs and capabilities of their existing on-premises solutions and outsource providers. AWS Managed Services was our response to this very specific ask, and we are building the prescriptive standards and tools needed to unlock very significant enterprise workloads at scale. We believe that there is a huge opportunity for multiple companies to be successful serving these needs, especially those that are using the cloud to reinvent the managed services industry.', '\xa0'), ('How can I start using the service?', 'Onboarding for AWS Managed Services is initiated through an AWS Managed Services Jumpstart. Each Jumpstart follows a standard process, and consists of three distinct phases: IT transformation design and strategy, initial selection of applications for migration, and the onboarding to the AWS Managed Services platform. For more information on onboarding to AWS Managed Services, please contact your AWS sales representative.'), ('\xa0', 'How can AWS Managed Services help Enterprises accelerate cloud adoption?'), ('AWS Managed Services helps accelerate cloud adoption by defining a standardized operating environment and common application stack templates for use by both cloud-native and traditional workloads. AWS Managed Services can fast-track cloud adoption by providing a turnkey service that augments or replaces your infrastructure management capability, and maintains your existing operational processes.', '\xa0'), ('Is AWS Managed Services just for Enterprises?', 'We designed AWS Managed Services to meet the needs of Enterprises that require stringent SLAs, adherence to corporate compliance, and integration with their systems and ITIL®-based processes. While there is nothing to prevent smaller businesses from gaining value from AWS Managed Services, this level of infrastructure management is intended for the Enterprises.'), ('\xa0', 'Does AWS Managed Services manage applications?'), ('No. AWS Managed Services manages endpoint security, directory services, and critical network appliances, but does not manage the installation, configuration, or monitoring of applications. We have a community of APN Partners who provide application management as part of their portfolio of services.', '\xa0'), ('What is the difference between AWS Managed Services and the AWS Managed Service Provider (MSP) Program?', 'AWS Managed Services is not to be confused with the AWS Managed Services Program, which thoroughly vets an APN Partner’s own managed services offerings and next-generation cloud managed services capabilities. AWS Managed Services is a new AWS offering that AWS Managed Services Partners may add to complement their overall managed services portfolio. These Partners undergo AWS Managed Services-specific training, which includes simulated customer onboarding and operational experience with the AWS MS API/CLI.'), ('AWS MSP Partners undergo a rigorous validation audit of over 80 checks that includes capabilities around application migration, DevOps, CI/CD, security, as well as cloud and application management. They also have many years of experience in providing full lifecycle migration, integration, cloud management, application management and application development.', '\xa0'), ('What opportunities do APN Partners have with AWS Managed Services?', 'AWS MSP Partners maintain a significant opportunity to differentiate themselves with AWS Managed Services. The traditional role of an MSP has been focused on running and operating environments, which is what AWS Managed Services is also focused on; however, next-generation AWS MSPs provide services well beyond this scope to help customers take greater advantage of cloud-native functionality to drive agility and innovation across their businesses. AWS MSPs can plan & design, build & migrate, run & operate, and optimize on an iterative basis from infrastructure through applications. AWS Managed Services is able to fulfill the run & operate portion of this lifecycle for infrastructure for a specific set of customers and workload types, but many customers require MSP services above and beyond that scope.'), ('Key to the integration and deployment of AWS Managed Services, AWS Consulting Partners enable Enterprises to migrate their existing applications to AWS, and integrate their on-premises management tools with their cloud deployments. AWS Consulting Partners will also be instrumental in building and managing cloud-based applications for customers running on the infrastructure stacks managed by AWS Managed Services. Onboarding to AWS Managed Services typically requires 8-10 weeks of design/strategy, system/process integration, and initial application migration, all of which can be performed by qualified AWS Consulting Partners.', '\xa0'), ('How do APN Partners and AWS Managed Services work together?', 'AWS Managed Services is focused on managing AWS infrastructure, and customers will continue to rely on APN Partners for many of the services they do today, such as hybrid, multi-cloud, application management, application development, and application migration. Customers can benefit from our APN Consulting Partners’ deep industry-specific expertise. For customers who want a single vendor to manage both applications and AWS infrastructure, validated AWS Managed Service Providers deliver full-lifecycle support for applications, while AWS Managed Services manages ongoing infrastructure operations.'), ('\xa0', 'How can APN Partners offer AWS Managed Services to AWS customers?'), ('In early 2017, we plan to launch an AWS Managed Services partner program that will allow AWS MSP, as well as AWS Migration and DevOps Competency partners to add AWS Managed Services to their service portfolio. This will include a new AWS Managed Services designation as part of the AWS Service Delivery Program for APN Partners. In order to qualify to participate and become a designated AWS Managed Services Service Delivery Partner, APN Partners will need to complete either the AWS Managed Service Provider Program validation process, and/or earn the Migration or DevOps Competency, as well as complete the specialized AWS Managed Services Partner training. Please bookmark the APN Blog for up-to-date announcements pertaining to this launch.', '\xa0'), ('How does AWS Managed Services leverage automation?', 'Automation is pervasive throughout AWS Managed Services, but it is most prevalent via our change management system. A “change type” within AWS Managed Services can be fully automated, manual, or a mix of both. AWS Managed Services will automate repetitive requests as encountered, and fully automated change types, such as provisioning new resources, are self-service, meaning you do not have to wait for an engineer to execute the change via a manual queue. Automated changes also have the advantage of having known risk profiles, pre-defined rollbacks, and support concurrent execution.'), ('\xa0', 'Will AWS Managed Services work with existing ITSMs?'), ('We designed AWS Managed Services to operate via APIs, making it possible to integrate the service into a wide range of existing ITSM systems and development platforms. An AWS Console presence is also available to fast track proofs of concept, and for interim operation before a full ITSM integration by AWS Professional Services or an AWS Managed Services Partner.', '\xa0'), ('For which ITSM tools does AWS Managed Services provide standard integrations?', "We provide standard integrations with ServiceNow's Helsinki, and Istanbul release."), ('\xa0', 'What industry standards does AWS Managed Services comply with?'), ('AWS Managed Services follows ITIL, a popular IT service management framework used by many Enterprises. Many of the underlying AWS services managed by AWS Managed Services are certified (PCI, ISO, SOX, HIPAA), and AWS Managed Services is in the process of obtaining its own certifications.', '\xa0'), ('What operating systems does AWS Managed Services support?', 'AWS Managed Services currently supports Microsoft Windows Server, Red Hat Enterprise, and Amazon Linux.'), ('\xa0', 'Does AWS Managed Services manage all AWS services?'), ('AWS Managed Services currently supports the 20+ services most critical for Enterprises, and will continue to expand our list of integrated AWS services.', '\xa0'), ('Can AWS Managed Services support traditional workloads?', 'Yes. With the AWS services currently supported, AWS Managed Services can support the majority of workloads that can run on AWS.'), ('\xa0', 'How do I deploy applications on AWS Managed Services?'), ('AWS Managed Services supports three methods of application deployment:', '\xa0 - Immutable – Applications are installed and burnt into an AMI, which is used to deploy new infrastructure for each release.'), ('\xa0 - Deployment Automation (e.g. CodeDeploy, Chef, Puppet) – automatically install and configure your application on existing or newly created infrastructure using scripting and recipes.', '\xa0- Manual – deploy your infrastructure and submit a follow-up change request for administrative access to install an application during a change window.'), ('Operational processes and logging remain the same regardless of the method of application deployment, leaving the choice up to you and your application developers.', '\xa0'), ('Does AWS Managed Services manage on-premises resources or other public clouds?', 'No, AWS Managed Services focuses on managing operations for AWS.'), ('\xa0', 'Will I still have access to my resources?'), ('As part of onboarding, AWS Managed Services will assume control of your account, but you can still receive full administrative access to your OS by filing change requests which kick off network access (via bastion), activation of your corporate AD credentials on the stack, and logging within a change window. AWS Managed Services engineers follow the same process as you do to gain access to managed resources. All access requests flow through change management, and neither party has persistent access to managed resources.', '\xa0'), ('Can I access my managed environments from my corporate network?', 'Yes. All resources are part of your private address space and domain. Managed workloads can access on-premises applications, middleware, and data via AWS Direct Connect or VPN.'), ('\xa0', 'In which AWS regions is AWS Managed Services available?'), ('AWS Managed Services is currently available in US East/West, EU (Ireland), and Asia Pacific (Sydney).', '\xa0'), ('What languages are supported by AWS Managed Services?', 'Currently AWS Managed Services provides support in English.'), ('\xa0', 'Does AWS Managed Services use sub-contractors for operations?'), ('No. Sub-contractors are not used for AWS Managed Services operations.', '\xa0'), ('How much does AWS Managed Services cost?', 'The price of AWS Managed Services is calculated as a percentage of AWS usage within the accounts that we manage. For more information on pricing and SLAs, please contact your AWS sales representative.'), (' ITIL® is a (registered) Trade Mark of AXELOS Limited. All rights reserved.', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/servicecatalog/faqs/': [('Q: What is AWS Service Catalog?', 'AWS Service Catalog allows IT administrators to create, manage, and distribute catalogs of approved products to end users, who can then access the products they need in a personalized portal. Administrators can control which users have access to each product to enforce compliance with organizational business policies. Administrators can also setup adopted roles so that End users only require IAM access to AWS Service Catalog in order to deploy approved resources. AWS Service Catalog allows your organization to benefit from increased agility and reduced costs because end users can find and launch only the products they need from a catalog that you control. '), ('\xa0', 'Q: Who should use AWS Service Catalog?'), ('AWS Service Catalog was developed for organizations, IT teams, and managed service providers (MSPs) that need to centralize policies. It allows IT administrators to vend and manage AWS resource and services. For large organizations, it provides a standard method of provisioning cloud resources for thousands of users. It is also suitable for small teams, where front-line development managers can provide and maintain a standard dev/test environment.', 'Q: How do I get started with AWS Service Catalog?'), ('In the AWS Management Console, choose AWS Service Catalog in Management Tools. In the AWS Service Catalog console, administrators can create portfolios, add products, and grant users permissions to use them with just a few clicks. End users logged into the AWS Service Catalog console can see and launch the products that administers have created for them.', 'Q: What can end users to do with AWS Service Catalog that they could not do before?'), ('End users have a simple portal in which to discover and launch products that comply with organizational policies and budget constraints.', 'Q: What is a portfolio?'), ('A portfolio is a collection of products, with configuration information that determines who can use those products and how they can use them. Administrators can create a customized portfolio for each type of user in an organization and selectively grant access to the appropriate portfolio. When an administrator adds a new version of a product to a portfolio, that version is automatically available to all current portfolio users. The same product can be included in multiple portfolios. Administrators also can share portfolios with other AWS accounts and allow the administrators of those accounts to extend the portfolios by applying additional constraints. By using portfolios, permissions, sharing, and constraints, administrators can ensure that users are launching products that are configured properly for the organization’s needs.', 'Q: What is a product?'), ('A product is a service or application for end users. A catalog is a collection of products that the administrator creates, adds to portfolios, and provides updates for using AWS Service Catalog. A product can comprise one or more AWS resources, such as Amazon Elastic Compute Cloud (Amazon EC2) instances, storage volumes, databases, monitoring configurations, and networking components. It can be a single compute instance running AWS Linux, a fully configured multitier web application running in its own environment, or anything in between.', 'Administrators distribute products to end users in portfolios. Administrators create catalogs of products by importing AWS CloudFormation templates. These templates define the AWS resources that the product needs to work, the relationships between components, and the parameters that the end user chooses when launching the product to configure security groups, create key pairs, and perform other customizations.'), ('An end user with access to a portfolio can use the AWS Management Console to find a standard dev/test environment product, for example, in the form of an AWS CloudFormation template, then manage the resulting resources using the AWS CloudFormation console. For information about creating a product, see “How do I create a product?” in the Administrator FAQ.', 'Q: Is AWS Service Catalog a regionalized service?'), ('Yes. AWS Service Catalog is fully regionalized, so you can control the regions in which data is stored. Portfolios and products are a regional construct which will need to be created per region and are only visible/usable on the regions in which they were created.', 'Q: In which Regions is AWS Service Catalog available?'), ('For a full list of supported AWS Regions, see the AWS Region Table.', 'Q: Are APIs available? Can I use the CLI to access AWS Service Catalog?'), ('Yes, APIs are available and enabled through the CLI. Actions from the management of Service Catalog artifacts through to provisioning and terminating are available. You can find more information in the AWS Service Catalog documentation or download the latest AWS SDK or CLI.', 'Q: Can I privately access AWS Service Catalog APIs from my Amazon Virtual Private Cloud (VPC) without using public IPs?'), ('Yes, you can privately access AWS Service Catalog APIs from your Amazon Virtual Private Cloud (VPC) by creating VPC Endpoints. With VPC Endpoints, the routing between the VPC and AWS Service Catalog is handled by the AWS network without the need for an Internet gateway, NAT gateway, or VPN connection. The latest generation of VPC Endpoints used by AWS Service Catalog are powered by AWS PrivateLink, an AWS technology enabling the private connectivity between AWS services using Elastic Network Interfaces (ENI) with private IPs in your VPCs. To learn more about AWS PrivateLink, visit the AWS PrivateLink documentation. ', 'Q: How do I create a portfolio?'), ('You create portfolios in the AWS Service Catalog console. For each portfolio, you specify the name, a description, and owner. ', 'Q: How do I create a product?'), ('To create a product, you first create an AWS CloudFormation template by using an existing AWS CloudFormation template or creating a custom template. Next, you use the AWS Service Catalog console to upload the template and create the product. When creating products, you can provide additional information for the product listing, including a detailed product description, version information, support information, and tags.', 'Q: Why would I use tags with a portfolio?'), ('Tags are useful for identifying and categorizing AWS resources that are provisioned by end users. You can also use tags in AWS Identity and Access Management (IAM) policies to allow or deny access to IAM users, groups, and roles or to restrict operations that can be performed by IAM users, groups, and roles. When you add tags to your portfolio, the tags are applied to all instances of resources provisioned from products in the portfolio.', 'Q: How do I make a portfolio available to my users?'), ('You publish portfolios that you’ve created or that have been shared with you to make them available to IAM users in the AWS account. To publish a portfolio, you add IAM users, groups, or roles to the portfolio from the AWS Service Catalog console by navigating to the portfolio details page. When you add users to a portfolio, they can browse and launch any of the products in the portfolio. Typically, you create multiple portfolios with different products and access permissions customized for specific types of end users. For example, a portfolio for a development team will likely contain different products from a portfolio targeted at the sales and marketing team. A single product can be published to multiple portfolios with different access permissions and provisioning policies.', 'Q: Can I share my portfolio with other AWS accounts?'), ('Yes. You can share your portfolios with users in one or more other AWS accounts. When you share your portfolio with other AWS accounts, you retain ownership and control of the portfolio. Only you can make changes, such as adding new products or updating products. You, and only you, can also “unshare” your portfolio at any time. Any products, or stacks, currently in use will continue to run until the stack owner decides to terminate them.', 'To share your portfolio, you specify the account ID you want to share with, and then send the Amazon Resource Number (ARN) of the portfolio to that account. The owner of that account can create a link to this shared portfolio, and then assign IAM users from that account to the portfolio. To help end users with discovery, you can curate a directory of portfolios.'), ('Q: Can I customize the experience for end users when they use a product?', 'Yes. You can tailor a product’s user experience for specific end users. The AWS CloudFormation template contains input parameters that drive the user experience. You can define business-level input parameters (such as “How many users do you need to support?” or “Are you going to store PII data?”) or infrastructure-level input parameters (such as “Which Amazon EC2 instance type?”) depending on the user. When the AWS CloudFormation template is deployed, the user is asked these questions and can select from a constrained list of answers for each question. Depending on the answers, the template may be deployed using different Amazon Elastic Compute Cloud (EC2) instances and different AWS resources.'), ('Q: Can I create a product from an existing Amazon EC2 AMI?', 'Yes. You can use an existing Amazon EC2 AMI to create a product by wrapping it in an AWS CloudFormation template.'), ('Q: Can I use products from the AWS Marketplace?', 'Yes. You can subscribe to a product in the AWS Marketplace and use the copy to Service Catalog action to copy your Marketplace product directly to Service Catalog.\xa0 Also you can use the Amazon EC2 AMI for the product to create an AWS Service Catalog product. To do that, you wrap the subscribed product in an AWS CloudFormation template. For more details on how to copy or package your AWS Marketplace products, please click here.'), ('Q: How do I control access to portfolios and products?', 'To control access to portfolios and products, you assign IAM users, groups, or roles on the Portfolio details page. Providing access allows users to see the products that are available to them in the AWS Service Catalog console.'), ('Q: Can I provide a new version of a product?', 'Yes. You can create new product versions in the same way you create new products. When a new version of a product is published to a portfolio, end users can choose to launch the new version. They can also choose to update their running stacks to this new version. AWS Service Catalog does not automatically update products that are in use when an update becomes available.'), ('Q: Can I provide a product and retain full control over the associated AWS resources?', 'Yes. You have full control over the AWS accounts and roles used to provision products. To provision AWS resources, you can use either the user’s IAM access permissions or your pre-defined IAM role. To retain full control over the AWS resources, you specify a specific IAM role at the product level. AWS Service Catalog uses the role to provision the resources in the stack.'), ('Q: Can I restrict the AWS resources that users can provision?', 'Yes. You can define rules that limit the parameter values that a user enters when launching a product. These rules are called template constraints because they constrain how the AWS CloudFormation template for the product is deployed. You use a simple editor to create template constraints, and you apply them to individual products.'), ('AWS Service Catalog applies constraints when provisioning a new product or updating a product that is already in use. It always applies the most restrictive constraint among all constraints applied to the portfolio and the product. For example, consider a scenario where the product allows all EC2 instances to be launched and the portfolio has two constraints: one that allows all non-GPU type EC2 instances to be launched and one that allows only t1.micro and m1.small EC2 instances to be launched. For this example, AWS Service Catalog applies the second, more restrictive constraint (t1.micro and m1.small).', 'Q: Can I use a YAML language CloudFormation template in Service Catalog?'), ('Yes, we currently support both JSON and YAML language templates. \xa0', ' Q: How do I find out which products are available?'), (' You can see which products are available by logging in to the AWS Service Catalog console and searching the portal for products that meet your needs, or you can navigate to the full product list page. You can sort to find the product that you want.', ' For each product, you can view a Product details page that displays information about the product, including the version, whether a newer version of the product is available, a description, support information, and tags associated with the product. The Product details page might also indicate whether the product will be provisioned using your access permissions (Self) or an administrator-specified role (role-arn). &nbsp;'), (' Q: How do I deploy a product?', ' When you find a product that meets your requirements in the portal, choose Launch. You will be guided through a series of questions about how you plan to use the product. The questions might be about your business needs or your infrastructure requirements (such as “Which EC2 instance type?”). When you have provided the required information, you’ll see the product in the AWS Service Catalog console. While the product is being provisioned, you will see that it is “in progress.” After provisioning is complete, you will see “complete” and information, such as endpoints or Amazon Resource Names (ARNs), that you can use to access the product.'), (' Q: Can I see which products I am using?', ' Yes. You can see which products you are using in the AWS Service Catalog console. You can see all of the stacks that are in use, along with the version of the product used to create them.'), (' How do I update my products when a new version becomes available?', ' When a new version of a product is published, you can use the Update Stack command to use that version. If you are currently using a product for which there is an update, it continues to run until you close it, at which point you can choose to use the new version.'), (' Q: How do I monitor the health of my products?', ' You can see the products that you are using and their health state in the AWS Service Catalog console. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/premiumsupport/ta-faqs/': [('Service Limit Check Questions', 'EC2 On-Demand Limit Check Notes'), ('Reserved Instance Optimization Check Questions ', 'For more information about Trusted Advisor, see the Trusted Advisor section of the AWS Support FAQs. '), ('Q. What service limits do you check?', 'The following table shows the limits that Trusted Advisor checks. For information about limits, see AWS Service Limits. '), ('Note: The Active Load Balancers limit check is currently inaccurate. Although the limit applies to the total number of load balancers, the check counts only Classic Load Balancers and does not count Application Load Balancers.', 'Note: Data for EC2 On-Demand instance limits is available only for these AWS Regions: Asia Pacific (Tokyo) [ap-northeast-1] Asia Pacific (Singapore) [ap-southeast-1] Asia Pacific (Sydney) [ap-southeast-2] EU (Ireland) [eu-west-1] South America (São Paulo) [sa-east-1] US East (N. Virginia) [us-east-1] US West (N. California) [us-west-1] US West (Oregon) [us-west-2]'), ('Note: Trusted Advisor does not currently track regional limits for EC2 On-Demand instances. By default, this limit is 20 on-demand instances per account, per region.', 'In cases where you have reached this regional limit, you might be unable to launch new on-demand instances even though Trusted Advisor will indicate that you have not reached any of your per-instance type limits within that region. For more detail on EC2 On-Demand limits, please refer to How many instances can I run in Amazon EC2.'), ('We are constantly working on including more services in the Service Limits check. Your feedback is really helpful to us.', 'Q. What are the default service limits?  '), ('For a list of the default service limits and instructions for requesting increases, see AWS Service Limits. ', 'Q. How can I get the Service Limit data with command-line tools?'), ('You can retrieve Service Limit data using the AWS CLI. This AWS Command Line Interface command displays the regions Trusted Advisor has flagged as approaching or reaching the limit for Amazon EC2 on-demand instance utilization, sorted by region name.', 'You can check any of the limits covered by Trusted Advisor using this method. For more details, see Check Categories, IDs, and Report Columns.'), ('Q. What data set are you using to make a Reserved Instance recommendation?', 'We calculate the recommendation based on the usage in the last completed calendar month. For example, if it is the 25th of April, the recommendation is based on data from March 1 to March 31. '), ('Q. Does the recommendation consider volume discounts?', 'No, the recommendation uses standard pricing. Actual results may vary on discounted pricing tiers. We recommend contacting your sales representative by completing the AWS Sales & Business Development form to review a more detailed optimization plan if you are receiving volume discounts. '), ('Q. I just purchased a new Reserved Instance. Why isn’t it showing up in the recommendation?', 'New Reserved Instance purchases are updated on a daily basis. Refresh the check 24 hours after you make your purchase to see the new recommendation. Also note that the check does not include third-party Reserved Instances purchased from the Reserved Instance Marketplace. '), ('Q. How do you calculate the optimized number of Reserved Instances?', 'Our system analyzes the hourly usage history during the previous calendar month across all consolidated accounts. The system calculates the number of running instances in each Availability Zone and for each type of instance. An hourly cost is determined by aggregating the cost of all instances that ran the previous month, whether they ran as On-Demand or as a Reserved Instance. In addition to the hourly usage charges, the system calculates a fixed charge by amortizing the one-time upfront fees for each Reserved Instance already purchased.'), ('By adding the aggregated hourly charges and the amortized upfront fees, the system is able to determine your baseline cost for the month. The system then incorporates the hourly and amortized upfront costs for additional Partial Upfront Reserved Instances, and the amortized upfront costs of any existing Reserved Instances into the calculation. Given the baseline cost based on the previous usage, and the costs for adding additional Partial Upfront Reserved Instances, the system uses a simple gradient descent algorithm to determine the number of Partial Upfront Reserved Instances that would result in the lowest overall cost. ', 'Q. How do you amortize the cost of existing Reserved Instances?  '), ('The upfront fee for each Reserved Instance is amortized over the period of the Reserved Instance. In simple terms, if the upfront fee was $1200, and the term length was one year, the system will divide $1200 by 12 months, resulting in a cost of $100 per month. ', 'Q. I have many accounts, and the Availability Zones are different for each one. How do you account for that?'), ('We normalize all Availability Zones across all Consolidated Billing accounts and reflect the values using the primary payer account mapping. ', 'Q. Do you include other Reserved Instance types in the recommendation?'), ('Only Partial Upfront Reserved Instances are recommended by this check. However, hourly usage charges and amortized upfront fees for other Reserved Instance types are included in the calculation. ', 'Q. Why are there separate sections for 1\xa0year and 3 year Reserved Instances?'), ('Customers have a choice between buying 1 year and 3 year term Reserved Instances from AWS. This check assumes you will purchase Reserved Instances for either 1 year or 3 year terms, not both. As a result, recommendations for purchasing additional 1 year or 3 year term Reserved Instances are not additive across both term lengths, so recommendations are called out separately.', 'To illustrate: In a recommendation for three additional 1 year Reserved Instances or four additional 3 year Reserved Instances, we are recommending the purchase of three or four Reserved Instances respectively, not a total of seven additional Reserved Instances.'), ('Q. Are all instance types included in the recommendation?', 'Recommendations are available for Amazon Linux/UNIX and Windows Reserved Instances. The calculation excludes usage and recommendations for Red Hat Enterprise Linux, SUSE Linux Enterprise, Amazon RDS, Amazon ElastiCache, and others. '), ('Q. I use Spot instances. Do you include Spot rates in the calculation?', 'Due to the variability of the Spot instance market, the system uses on-demand rates when calculating the optimized number of Reserved Instances. '), ('Q. I have third-party Reserved Instances from the Reserved Instance Marketplace. Do you include those in the results?', 'No; only Reserved Instances offered directly by AWS are included. If you have Reserved Instances from third-party sellers, those Reserved Instances are not accounted for by this check. '), ('Q. Does the recommendation include any money I make if I sell my existing Reserved Instances to purchase the recommended Partial Upfront Reserved Instances?', 'The system does not include any money that could result from the sale of existing Reserved Instances when calculating the optimal number of Partial Upfront Reserved Instances.  '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/console/faqs/': [('Q: What is the AWS Management Console?', 'The AWS Management Console provides a simple web interface for Amazon Web Services. You can log in using your AWS account name and password. If you’ve enabled AWS Multi-Factor Authentication, you will be prompted for your device’s authentication code. '), ('Q: How do I sign into the Management Console?', 'You can sign into the management console using your AWS or IAM account credentials at https://console.aws.amazon.com/console/home. For the AWS GovCloud (US) region, you can sign into the management console using your IAM account credentials at https://console.amazonaws-us-gov.com. '), ('Q: How can I find a service in the AWS Management Console? ', 'There are several ways for you to locate and navigate to the services you need. On Console Home, you can utilize the search functionality, select services from the Recently visited services section, or expand the All services\xa0 section to browse through the list of all the services offered by AWS.'), ('At any time, you can also select the Services menu in the top level navigation bar, which also includes the search functionality and the list of all services, either grouped, or arranged alphabetically. ', 'Q: Can I create shortcuts for the services I use?'), ('Yes. You can add service shortcuts to the top level toolbar in the Console. Select the pin icon beside the Resource Groups menu and drag and drop the service links you want to save as shortcuts. You have the option to display the service icon alone, the service name alone, or both together. ', 'Q: What can I expect to find under "Build a solution"? '), ('The Build a Solution section, on the AWS Console Home page, features various simplified and automated workflows and wizards that utilize and introduce you to different AWS services in order to create the resources required to build your intended solution. ', 'Q: What can I expect to find under "Learn to Build"?'), ('The Learn to Build section, on the AWS Console Home page, presents training and learning resources for various solutions and use cases that might interest you. Selecting one of the categories presented in this section, you can expect to find materials such as introduction videos, webinar recordings, simple tutorials, project guides, self-paced labs, documentation, and other resources. ', 'Q: Can I provide feedback?'), ('Yes! Click the Feedback button at the bottom of the console. We’re eager to hear about your experience with the new console. ', 'Q: When does my session expire?'), ('For security purpose, a login session will expire in 12 hours when you sign into the AWS Management Console with your AWS or IAM account credentials. To resume your work after the session expires, we ask you to click the "Click login to continue" button and login again. The duration of federated sessions varies depending on the federation API (GetFederationToken or AssumeRole) and the administrator’s preference. Please go to our Security Blog to learn more about building a secure delegation solution to grant temporary access to your AWS account. ', 'Q: What browsers does the Management Console support?'), ('Important: As of May 1, 2016, the AWS Management Console no longer supports versions of Internet Explorer older than version 11. We recommend migrating to a more recent browser version to ensure the best possible experience and security.', 'Please contact us if you have any questions. '), ('Q: What is a Resource Group?', ''), ('A resource group is a collection of resources that share common tags. With the Resource Groups tool, you can create a custom console that organizes and consolidates the information you need based on your project and the resources you use. If you manage resources in multiple regions, you can create a resource group to view resources from different regions on the same screen. ', 'Q: How can I use Resource Groups?'), ('', 'Resource Groups are a simple way to organize and find the resources that you use every day. You can create a resource group for each project, application, or environment that you manage in your AWS account. Since a resource group is simply a collection of resources that share common tags that you have applied to those resources, you can create a resource group for collections of resources that complement the way you use the AWS Management Console. Create resource groups that help you work faster and make you more productive.'), ('To read more about how to use Resource Groups features, click here.', 'Q: How much does Resource Groups cost?'), ('Resource Groups is free to use. You will not incur any additional charges for creating or using them.', 'Q: Who can see my resource groups?'), ('Your resource groups are unique to your identity. Each IAM user identity has its own Resource Groups storage, so other identities in your account will not see the resource groups that you create. However, tags on an account’s resources are visible to all identities that have permission to view tags in that account.', 'Q: What permissions do I need to use Resource Groups?'), ('Click here to view the specific permissions required to use Resource Groups. ', 'Q: How can I create a resource group using a tag substring or wildcards in my tag search? '), ('Resource Groups lets you include resources in your resource group by identifying a tag substring. This is similar to appending a wildcard to the beginning and end of a string in the tag value field. To use this feature, begin typing a string in the tag value field of the Resource Group create or edit forms and select the Contains: option to find values that contain the characters that you typed. For example, a search using Contains: Prod value for the "Name" tag key would return a resource tagged with "FooApp-DB-Prod" as the value in the "Name" tag key. Remember, tag search is case-sensitive. ', 'Q: How many resource groups can I create?'), ('You can create up to 20 resource goups, unless you reach the storage limit. Since Resource Groups can be configured to search for resources based on a number of different parameters (tag key, tag value, resource type, and region), and because each parameter can be of varying lengths, each saved resource group may be a different size. If your groups are simple, you will be able to store up to 20. If your groups are complex, you may receive an error message notifying you that you have reached the storage limit. To create more resource groups, simplify your group configurations to use fewer and smaller parameters.  ', 'Q: What resource types are supported in Resource Groups?'), ('Click here to view a list of resource types supported in Resource Groups.', 'Q: Why can’t I view a list of existing tag keys or values when searching for resources, or why doesn’t tag autocomplete work?'), ('You may have limited permissions to access tag data. Click here to view the specific permissions required to use Resource Groups.  ', 'Q: Why can’t I find resources using a resource group?'), ("You may have limited permissions to access tag data. Click here to view the specific permissions required to use Resource Groups. If you have all required permissions to use Resource Groups, check your resource group's configuration and ensure that the resources you are searching for have the correct tags. ", "Q: The system recognizes me as a federated user. Why are my resource groups shared, or why can't I find my resource groups after I sign out? "), ("For federated users using SAML, resource groups are stored using the value provided for RoleSessionName. This value is configured by your organization's identity provider. More info about SAML federation setup can be found here. This value should be unique to each user authenticating with each role. If RoleSessionName is different for each session, saved resource groups will not be accessible after the session is terminated. If RoleSessionName is the same for each user, saved resource groups will be shared across all identities, and they will not function correctly. ", 'Q: Can I provide feedback?'), ('Yes! Click the Feedback button at the bottom of the console. We’re eager to hear about your experience with Resource Groups. ', 'Q: What is Tag Editor?'), ('Tag Editor is a tool to view and manage tags on your AWS resources, regardless of service or region. Use the tag editor to search for resources by resource type, region, or tag, and then manage the tags applied to those resources. ', 'Q: How can I use Tag Editor?'), ('Click here to read documentation on the Tag Editor’s features and how to use them.', 'Q: What permissions do I need to use Tag Editor? '), ('Click here to view the specific permissions required to use Tag Editor. ', 'Q: How do tags work?'), ('Tags are words or phrases that act as metadata for organizing your AWS resources. A tag is a key-value pair. In Tag Editor, tag keys are represented as columns, and tag values are strings in the cells of a tag key’s column. Click here to read more about how tags work.', 'Q: How can I bulk edit tags for multiple resources?'), ('You can use Tag Editor to edit tags for multiple resources in multiple regions at once. In Tag Editor, select the checkboxes for each of the resources you want to edit, and then click Edit tags for selected. Follow the on-screen prompts to manage tags on these resources. ', 'Q: How can I search for resources by tag substring or use wildcards in my tag search? '), ('Tag Editor lets you search for resources by tag substring. This is similar to appending a wildcard to the beginning and end of a string. To use this feature, begin typing a string in the tag value field of the Tag Editor search form and select the Contains: option to find values that contain the characters that you typed. For example, a search using Contains: Prod value for the "Name" tag key would return a resource tagged with "FooApp-DB-Prod" as the value in the "Name" tag key. Remember, tag search is case-sensitive. ', 'Q: How can I use the Tag Editor to search for resources that do not have a particular tag key applied or that have an empty value? '), ('Tag Editor lets you search for resources that do not have a particular tag key applied. You can also search for resources that have a tag key applied with an empty (blank) tag value. To search for untagged resources, select the appropriate tag key, and then select "Not tagged" or "Empty value" in the tag value search field. ', 'Q: What resource types can be tagged using the Tag Editor?'), ('Tag Editor supports all resource types that support tags. You can view all of the services that support tags here. ', 'Q: Why can’t I search for resources by tag?'), ('You may have limited permissions to access tag data. Click here to view the specific permissions required to use Tag Editor.', 'Q: Why can’t I add, remove, or modify a tag key or value?'), ('You may have limited permissions to access tag data. Click here to view the specific permissions required to use Tag Editor.', 'Q: Can I provide feedback?'), ('Yes! Click the Feedback button at the bottom of the console. We’re eager to hear about your experience with the Tag Editor. ', 'Q: How do I sign in?'), ('The app supports several authentication methods, including owner/root credentials, IAM user credentials, and AWS access keys. An owner account is the AWS login that created the account. An IAM user is an identity that has been created by an administrator through the IAM service. Note that IAM users need to also provide their account alias, which can be found at the top of the web console sign-in screen. AWS access keys are used to sign programmatic requests that the app makes to AWS.', "For security reasons, we recommend that you secure your device with a passcode and that you follow an AWS best practice by creating and using an IAM user's credentials to log in to the app. If you lose your device, an IAM user can be deactivated to prevent unauthorized access. Root accounts cannot be deactivated."), ('Click here to learn more about the different types of AWS security credentials. ', 'Q: Where can I download the app?'), ('Download the app from Amazon Appstore, Google Play, or iTunes. ', 'Q: What services are supported?'), ('The app supports Elastic Compute Cloud (EC2), Amazon S3, Elastic Load Balancing (ELB), Amazon Route 53, Amazon Relational Database Service (RDS), Auto Scaling, AWS Elastic Beanstalk, Amazon DynamoDB, AWS CloudFormation, AWS OpsWorks, and CloudWatch. The mobile app does not support the AWS GovCloud (US) region. For a full description, see the AWS Console Mobile App page. We plan to add new features to the mobile app. Tell us what you need using the feedback link in the app. ', 'Q: Is MFA supported?'), ('Yes. We recommend using either a hardware MFA device or a virtual MFA on a separate mobile device for the greatest level of account protection. ', 'Q: Can I create resources?'), ("You cannot create resources in the current version. However, we’re considering this for future releases. Please use the feedback link in the app's menu to tell us what you need. ", 'Q: Can I download S3 objects? '), ('You can use the app to generate a pre-signed URL for an S3 object. A pre-signed URL grants time-limited permission to download the object. Read more about pre-signed URLs here. ', 'In order to open a pre-signed URL for an S3 object in your device\'s browser, use the app to navigate to the S3 object\'s detail page and tap "View in browser". Your device configuration will determine what actions are possible with the object.'), ('', 'Q: Can I view my current AWS usage charges?'), ('Yes, you can view your current usage charges in the app. Simply visit your Billing Preferences page and select the checkbox to Receive Billing Alerts. In order to view usage charges, your identity must have permission to view CloudWatch. ', 'Q: What time period and services does the Service Health section cover?'), ('The Service Health section covers all AWS services in all regions for the previous 36 hours. ', 'Q: What versions of Android are supported?'), ('iOS 5.0+ and Android 2.3+ are supported. ', 'Q: Does the app support tablets?'), ('The app is currently optimized for iOS and Android phones, but it works on iPad and Android tablet devices. ', 'Q: What Android app permissions are required?'), ('Q: My app is having trouble. What should I do?', "From your phone's home screen press the menu and select settings. From the settings options, go to Apps, select AWS Console, and press the clear data button. The next time you start the app, the app will be reset. "), ('Q: I lost my phone. What should I do?', "We strongly recommend that in addition to signing out of the app when you have completed your tasks and using a password lock on your phone, you use an IAM user to manage AWS on your phone. If you lose your phone, you can remove the IAM user's access. "), ('Q: Can I provide feedback?', "Yes! Click the Feedback button in the app's menu. We’re eager to hear about your experience with the app. "), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/lex/faqs/': [('Q: What is Amazon Lex?', 'Amazon Lex is a service for building conversational interfaces using voice and text. Powered by the same conversational engine as Alexa, Amazon Lex provides high quality speech recognition and language understanding capabilities, enabling addition of sophisticated, natural language ‘chatbots’ to new and existing applications. Amazon Lex reduces multi-platform development effort, allowing you to easily publish your speech or text chatbots to mobile devices and multiple chat services, like Facebook Messenger, Slack, Kik, or Twilio SMS. Native interoperability with AWS Lambda, AWS MobileHub and Amazon CloudWatch and easy integration with many other services on the AWS platform including Amazon Cognito, and Amazon DynamoDB makes bot development effortless.  Q. How can I get started with Amazon Lex?'), ('To start using Amazon Lex, simply sign into the AWS Management Console and navigate to “Lex” under the “Artificial Intelligence” category. You must have an Amazon Web Services account to start using Amazon Lex. If you do not already have one, you will be prompted to create one during the sign-up process. Please refer to the Amazon Lex Getting Started Guide for more information.\xa0', 'Q. What are the most common use cases for Amazon Lex?'), ('The most common use-cases include: • Informational bot – build an automated customer support agent or bot that answers questions • Application/Transactional bot – build a stand-alone pizza ordering agent or a travel bot • Enterprise Productivity bot – build custom bots to connect to enterprise data resources • Device Control bot– use Amazon Lex to issue control commands to connected devices  ', 'Q. How does Amazon Lex work with other AWS services?'), ('Amazon Lex leverages AWS Lambda for Intent fulfillment, Amazon Cognito for user authentication, and Amazon Polly for text to speech. \xa0In addition, AWS Mobile Hub can be used to automatically provision bots from a template.', 'Q. Do I have to be a machine learning expert to use Amazon Lex?'), ('No machine learning expertise is necessary to use Amazon Lex. Developers can declaratively specify the conversation flow and Amazon Lex will take care of the speech recognition and natural language understanding functionality. Developers provide some sample utterances in plain English and the different parameters (slots) that they would like to collect from their user with the corresponding prompts. The language model gets built automatically.', 'Q. In which AWS regions is Amazon Lex available?'), ('For a list of the supported Amazon Lex AWS regions, please visit the AWS Region Table for all AWS global infrastructure.\xa0 Also for more information, see Regions and Endpoints in the AWS General Reference.  Q. What is the maximum bandwidth supported on Amazon Lex?', 'Amazon Lex scales to your needs and does not impose bandwidth constraints.'), ('Q: Is Amazon Lex a managed service?', 'Amazon Lex is a completely managed service so you don’t have to manage scaling of resources or maintenance of code. Your interaction schema and language models are automatically backed up. We also provide comprehensive versioning capability for easy rollback. Amazon Lex architecture does not require storage or backups of end user data. '), ('Q. When do I use Amazon Polly vs. Amazon Lex?', 'Amazon Polly converts text inputs to speech. Amazon Lex is a service for building conversational interfaces using voice and text.'), ('Q. Does Amazon Lex get more intelligent over time?', 'Yes. Amazon Lex uses deep learning to improve over time. \xa0'), ('Q: I was in the Amazon Lex preview program. \xa0Now that Amazon Lex is GA, what happens to my account?', 'On April 19, 2017, Amazon Web Services announced that Amazon Lex exited Preview and entered General Availability. As such, we will be terminating the Amazon Lex Preview Program on May 1, 2017. Usage will be charged as per the pricing plan starting May 1st. Your first 12 months for the free tier will start on May 1st. Please note that Amazon Lex is now supported under Developer Support, Business Support and Enterprise Support plans. You can also post your queries on the public Amazon Lex forums.\xa0'), ('Q: How do I create a bot in Amazon Lex?  To create a bot, you will first define the actions performed by the bot. These actions are the intents that need to be fulfilled by the bot. For each intent, you will add sample utterances and slots. Utterances are phrases that invoke the intent. Slots are input data required to fulfill the intent. Lastly, you will provide the business logic necessary to execute the action. An Amazon Lex bot can be created both via Console and REST APIs.', 'Q. Can I implement business logic on the client?  Yes. Amazon Lex provides the option of returning parsed intent and slots back to the client for business logic implementation.'), ('Q. How can I validate user input?   Amazon Lex provides deep integration with AWS Lambda and you can validate user input using the initialization and validation codeHook. This code gets executed at every turn of the conversation. The codehook can be used to set up session parameters, validate user input and customize responses.', 'Q. What is an Intent?   To build an Amazon Lex bot, you will need to identify a set of actions - known as \xa0‘intents’ -- that you want your bot to fulfill. A bot can have multiple intents. For example, a ‘BookTickets’ bot can have intents to make reservations, cancel reservations and review reservations.  Q. What is an utterance?   An ‘utterance’ is the spoken or typed phrase to invoke an intent. For example, to invoke the intent to make reservations, you would provide a sample utterance such as, “Can I make a reservation?”'), ("Q. What are slots?   To fulfill an intent, the Amazon Lex bot needs information from the user. This information is captured in ‘slots’. For example, you would define show name and time as slots for intent to make reservations.  Q. What are prompts?   Amazon Lex elicits the defined ‘slots’ by using the ‘prompts’ provided. For example, to elicit value for the slot ‘time’ you will define a prompt such as “What show time would you like to reserve?”. Amazon Lex is capable of eliciting multiple slot values via a multi-turn conversation.  Q. How is an action fulfilled?   Amazon Lex integrates with AWS Lambda for ‘fulfillment’ of the action or business logic. Alternately, you can configure Amazon Lex to return parsed intent and slot values to the client for action fulfillment.  Q. How do I monitor and track my bot?   You can track metrics for your bot on the ‘Monitoring’ dashboard in the Amazon Lex Console. Currently, you can track the number of missed utterances, request latency and traffic by channel for your bot.\xa0You can view list of utterances that were not recognized by your bot, aka 'missed utterances'. With these monitoring capabilities, you view how your users are interacting with the bot and make improvements over time. ", 'Q: What happens when I ‘build’ a bot?  Building a bot triggers machine learning and creates the models for your bot. A new version of your intents and slot types is created. Once created a version is immutable.'), ('Q. How can I test an Amazon Lex bot?  You can test your Amazon Lex bot via the test window on the console. \xa0Any business logic implemented in AWS Lambda can be tested via this console as well. \xa0All supported browsers allow for testing text with your Amazon Lex bot; voice can be tested from a Chrome browser. \xa0', 'Q: Can I use the same bot for voice and text inputs?  Yes. Once you have built a bot it can be used for voice as well as text inputs.'), ('Q. How can I create Amazon Lex bots for mobile?  Amazon Lex provides SDKs for iOS and Android. You can develop bots for your mobile use cases with these SDKs. User authentication can be enabled via Amazon Cognito. You can use AWS Mobile Hub to build, test and monitor bots for your mobile platforms. AWS Mobile Hub can be used to automatically provision Amazon Lex bots from a template.', 'Q. How can I make Amazon Lex bots available on messaging services?  Amazon Lex bots can be published to messaging platforms like Facebook Messenger, Slack, Kik, and Twilio SMS. To publish the bot you can provide the tokens for authentication in the console, and we will store it securely and provide a callback URL that you can provide to the chat service.'), ('Q. Do I have to submit my bot for certification prior to deployment?  You don’t need to certify your bot with Amazon prior to deployment.', 'Q. Can I have an Amazon Lex bot version deployed for use by end users while I continue to develop on a different version?  Yes. You can build and deploy a version of your bot into production while you continue to develop on a different version. Every version of an Amazon Lex bot will have an ARN. Each version can be associated with a different alias. You can use these tools to set up dev, stage and prod environments.'), ('Q. Can I choose different versions while deploying to different messaging services?  Yes. You can deploy a specific version to each messaging service. Every version of Amazon Lex will have an ARN. Each version can be associated with an alias. You can use different aliases for deployment to different messaging service. Also, you can have multiple bots deployed to the same messaging service.', 'Q. What is the maximum duration of speech input?  Amazon Lex supports up to 15 seconds of speech input.'), ('Q. Can I configure for speech input and text output?  Yes, you can just choose the PostContent API to provide voice input and choose text output.', 'Q. How many languages are supported on Amazon Lex?  Currently, Amazon Lex supports US English.'), ('Q. What audio formats does Amazon Lex support?  Amazon Lex supports the following formats for input audio: LPCM and Opus; Supported output audio formats: MPEG, OGG, PCM.', 'Q. Can I use Amazon Lex in VPC?  Amazon Lex can be accessed from VPC via public endpoints for building and running a bot. Currently, Amazon Lex does not provide a VPC endpoint.'), ('Q. Can I access Amazon Lex bots locally i.e. without an Internet connection?  No. End users will need to access the Amazon Lex runtime endpoint over the Internet. ', 'Q. How is this different from Alexa Skills Kit?'), ('Alexa Skills Kit (ASK) is used to build skills for use in the Alexa ecosystem and devices and lets developers take advantage of all Alexa capabilities such as the Smart Home and Flash Briefing API, streaming audio and rich GUI experiences. Amazon Lex bots support both voice and text and can be deployed across mobile and messaging platforms.', 'Q. Do I need a wake word to invoke an Amazon Lex intent?'), ('Amazon Lex does not support wake word functionality. The app that integrates with Amazon Lex will be responsible for triggering the microphone, i.e. push to talk.', 'Q. Can an Amazon Lex bot respond using Alexa’s voice?'), ('Currently we do not support the Alexa voice for Amazon Lex responses. However, there are 7 other voices from which to choose.', 'Q. Can I create an Alexa Skill from an Amazon Lex bot ?'), ('Amazon Lex provides the ability for you to export your Amazon Lex bot schema into a JSON file that is compatible with Amazon Alexa. Once downloaded as JSON, you need to log in to the Alexa developer portal, navigate to the ‘Interaction Model’ tab, launch the Alexa Skill Builder, and paste the bot schema into the Code Editor of your Alexa Skill.\xa0 More details and steps can be found in the Amazon Lex documentation.', 'Q: When exporting my Amazon Lex bot schema to use in an Alexa skill, are my AWS Lambda functions exported and included in the bot schema?'), ('No. Only the bot definition will be downloaded.', 'Q: I have created an Alexa Skill from an Amazon Lex bot using the schema export feature. Which Alexa platforms support the Amazon Lex bot schema? '), ('All Alexa platforms that support Alexa skills can be used: The Amazon Echo, Amazon Dot, Amazon Look, Amazon Tap, Amazon Echo Show and any third-party Alexa-enabled devices.', 'Q. Are voice and text inputs processed by Amazon Lex stored, and how are they used by AWS?'), ('Amazon Lex may store and use voice and text inputs processed by the service solely to provide and maintain the service and to improve and develop the quality of Amazon Lex and other Amazon machine-learning/artificial-intelligence technologies. Use of your content is necessary for continuous improvement of your Amazon Lex customer experience, including the development and training of related technologies. We do not use any personally identifiable information that may be contained in your content to target products, services or marketing to you or your end users. Your trust, privacy, and the security of your content are our highest priority and we implement appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that our use complies with our commitments to you. Please see https://aws.amazon.com/compliance/data-privacy-faq/ for more information.', 'Q. Can I delete voice and text inputs stored by Amazon Lex?'), ('Yes. You can request deletion of voice and text inputs associated with your account by contacting AWS Support. Deleting voice and text inputs may degrade your Amazon Lex experience.', 'Q: Who has access to my content that is processed and stored by Amazon Lex?'), ('Only authorized employees will have access to your content that is processed by Amazon Lex. Your trust, privacy, and the security of your content are our highest priority and we implement appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that our use complies with our commitments to you. Please see https://aws.amazon.com/compliance/data-privacy-faq/ for more information.', 'Q: Do I still own my content that is processed and stored by Amazon Lex?'), ('You always retain ownership of your content and we will only use your content with your consent.', 'Q: Is the content processed by Amazon Lex moved outside the AWS region where I am using Amazon Lex?'), ('Any content processed by Amazon Lex is encrypted and stored at rest in the AWS region where you are using Amazon Lex. Some portion of content processed by Amazon Lex may be stored in another AWS region solely in connection with the continuous improvement and development of your Amazon Lex customer experience and other Amazon machine-learning/artificial-intelligence technologies. You can request deletion of voice and text inputs associated with your account by contacting AWS Support. Your trust, privacy, and the security of your content are our highest priority and we implement appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that our use complies with our commitments to you. Please see https://aws.amazon.com/compliance/data-privacy-faq/ for more information.', 'Q: Can I use Amazon Lex in connection with websites, programs or other applications that are directed or targeted to children under age 13 and subject to the Children’s Online Privacy Protection Act (COPPA)?'), ('Yes, subject to your compliance with the Amazon Lex Service Terms, including your obligation to provide any required notices and obtain any required verifiable parental consent under COPPA, you may use Amazon Lex in connection with websites, programs, or other applications that are directed or targeted, in whole or in part, to children under age 13. Amazon Lex does not store or retain voice or text utterance information from websites, programs, or applications that are identified by customers in accordance with the Amazon Lex Service Terms as being directed or targeted, in whole or in part, to children under age 13 and subject to COPPA.', 'Q: How do I determine whether my website, program, or application is subject to COPPA?'), ('For information about the requirements of COPPA and guidance for determining whether your website, program, or other application is subject to COPPA, please refer directly to the resources provided and maintained by the United States Federal Trade Commission. This site also contains information regarding how to determine whether a service is directed or targeted, in whole or in part, to children under age 13. ', 'Q. What SDKs are supported for Amazon Lex? Amazon Lex currently supports SDKs for runtime services. IoS and Android SDKs, as well as Java, JS, Python, CLI, .Net, Ruby, PHP, Go, and CPP support both text and speech input. '), ('Q. Can I use SDKs to build bots?', 'You can build bots using SDKs: Java, JavaScript, Python, CLI, .NET, Ruby on Rails, PHP, Go, and CPP. '), ('Q. Which enterprise connectors are supported on Amazon Lex?  Amazon Lex integrates with enterprise connectors via AWS Lambda. The following enterprise connectors can be provisioned via AWS Mobile Hub: Salesforce, Microsoft Dynamics, Marketo, Zendesk, Quickbooks, and HubSpot. ', 'Q. What support is provided for Amazon Lex?  Depending on your AWS support contract, Amazon Lex is supported under Developer Support, Business Support and Enterprise Support plans. \xa0You can also post your queries on the Amazon Lex forums.'), ('Q. How does Amazon Lex count the number of requests?', 'Every input to an Amazon Lex bot is counted as a request. For example, if an end user provides 5 inputs to the bot as part of conversation, these are billed as 5 requests. Usage is metered and billed per request.'), ('Q. How much does Amazon Lex cost?  It is free to get started. Please see Amazon Lex Pricing Page for current pricing information.', 'Q. Does Amazon Lex participate in the AWS Free Tier?  Yes. \xa0You can try Amazon Lex for free. From the date you get started with Amazon Lex, you can process up to 10,000 text requests and 5,000 speech requests per month for free during the first year.'), ('Q: I was in the Amazon Lex preview program. Now that Amazon Lex is GA, what happens to my account?', 'On April 19, 2017, Amazon Web Services announced that Amazon Lex exited Preview and entered General Availability. As such, we will be terminating the Amazon Lex Preview Program on May 1, 2017. Usage will be charged as per the pricing plan starting May 1st. Your first 12 months for the free tier will start on May 1st. Please note that Amazon Lex is now supported under Developer Support, Business Support and Enterprise Support plans. You can also post your queries on the public Amazon Lex forums. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/polly/faqs/': [('Q. What is Amazon Polly?  Amazon Polly is a service that turns text into lifelike speech. Amazon Polly enables existing applications to speak as a first class feature and creates the opportunity for entirely new categories of speech-enabled products, from mobile apps and cars, to devices and appliances. Amazon Polly includes dozens of lifelike voices and support for multiple languages, so you can select the ideal voice and distribute your speech-enabled applications in many geographies. Amazon Polly is easy to use – you just send the text you want converted into speech to the Amazon Polly API, and Amazon Polly immediately returns the audio stream to your application so you can play it directly or store it in a standard audio file format, such as MP3. Amazon Polly supports Speech Synthesis Markup Language (SSML) tags like prosody so you can adjust the speech rate, pitch, or volume. Amazon Polly is a secure service that delivers all of these benefits at high scale and at low latency. You can cache and replay Amazon Polly’s generated speech at no additional cost. Amazon Polly lets you convert 5M characters per month for free during the first year, upon sign-up. Amazon Polly’s pay-as-you-go pricing, low cost per request, and lack of restrictions on storage and reuse of voice output make it a cost-effective way to enable speech synthesis everywhere.', 'Q. Why should I use Amazon Polly?  You can use Amazon Polly to power your application with high-quality spoken output. This cost-effective service has very low response times, and is available for virtually any use case, with no restrictions on storing and reusing generated speech.'), ('Q. What features are available?  You can control various aspects of speech such as pronunciation, volume, pitch, speech rate, etc. using standardized Speech Synthesis Markup Language (SSML). You can detect when specific words or sentences in the text are being spoken to the user based on the metadata included in the audio stream. This allows the developer to synchronize graphical highlighting and animations, such as the lip movements of an avatar, with the synthesized speech. You can modify the pronunciation of particular words, such as company names, acronyms, foreign words and neologisms, e.g. “P!nk”, “ROTFL”, “C’est la vie” (when spoken in a non-French voice) using custom lexicons.', 'Q: What are Speech Marks?'), ('Speech Marks are designed to complement the synthesized speech that is generated from the input text. Using this metadata alongside the synthesized speech audio stream, customers can provide their application with an enhanced visual experience such as speech-synchronized animation or karaoke-style highlighting.', 'Amazon Polly generates Speech Marks using the following four elements:'), ('1) Sentence, which indicates a sentence element in the input text to be spoken;', '2) Word, which Indicates a word element in the text;'), ('3) Viseme, which describes the shape of the lips that corresponds to the sound that is spoken;', '4) SSML, which describes an SSML element used in the text.'), ('Speech Marks are delivered in form of a JSON stream -- specifically, a set of standalone JSON objects delimited with new lines -- containing anywhere from one to all four of these elements, when using the synthesize-speech method with the speech-mark-types parameter. You can find more information in the Amazon Polly Developer Guide. ', 'Q. What are the most common use cases for this service?  With Amazon Polly, you can bring your applications to life, by adding life-like speech capabilities. For example, in E-learning and education, you can build applications leveraging Amazon Polly’s Text-to-Speech (TTS) capability to help people with reading disabilities. Amazon Polly can be used to help the blind and visually impaired consume digital content (eBooks, news etc). Amazon Polly can be used in announcement systems in public transportation and industrial control systems for notifications and emergency announcements. There are a wide range of devices such as set-top boxes, smart watches, tablets, smartphones and IoT devices, which can leverage Amazon Polly for providing audio output. Amazon Polly can be used in telephony solutions to voice Interactive Voice Response systems. Applications such as quiz games, animations, avatars or narration generation are common use-cases for cloud-based TTS solution like Amazon Polly.'), ('Q. How does this product work with other AWS products?  When combined with Amazon Lex, developers can create full-blown Voice User Interfaces for their applications. Within Amazon Connect, Amazon Polly speech is used to create self-service , cloud-based contact center services. On top of that, developers of mobile applications and Internet-of-Things (IoT) solutions can leverage Amazon Polly to add spoken output to their own systems.', 'Q. What are the advantages of a cloud-based Text-to-Speech solution over an on-device one?  On-device text-to-speech solutions require significant computing resources, notably CPU power, RAM, and disk space to be available on the device. This can result in higher development cost and higher power consumption on devices such as tablets, smartphones, etc. In contrast, text-to-speech conversion done in the cloud dramatically reduces local resource requirements. This makes it possible to support all of the available languages and voices at the highest possible quality. Moreover, speech corrections and enhancements are instantly available to all end-users and do not require additional updates for all devices. Cloud-based text-to-speech (TTS) is platform independent, so it minimizes development time and effort.'), ('Q. How do I get started with Amazon Polly?  Simply login to your AWS account and navigate to the Amazon Polly console (which is a part of the AWS Console). You can then use the console to type in any text and listen to generated speech or save it as an audio file.', 'Q. In which regions is the service available?  Amazon Polly is accessible worldwide from the following 14 AWS regions:\xa0Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), EU (Frankfurt), EU (Ireland), EU (London), South America (São Paulo), US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon).'), ('Q. Which programming languages are supported?  Amazon Polly supports all the programming languages included in the AWS SDK (Java, Node.js, .NET, PHP, Python, Ruby, Go, and C++) and AWS Mobile SDK (iOS/Android). Amazon Polly also supports an HTTP API so you can implement your own access layer.', 'Q. Which audio formats are supported?  With Amazon Polly, you can stream audio to your users in near real time. You can also choose from various sampling rates to optimize bandwidth and audio quality for your application. Amazon Polly supports MP3, Vorbis, and raw PCM audio stream formats.'), ('Q. Which languages are supported? ', 'Q: Does Amazon Polly have AWS service limits?'), ('To help guarantee the availability of AWS resources and to minimize billing risk for new customers, AWS maintains service limits for each account. When using Amazon Polly to power your application with high-quality spoken output, there are default service limits including limitations on throttling, operations, and Speech Synthesis Markup Language (SSML) use. For details, see Limits in Amazon Polly in the Amazon Polly Developer Guide. Combining Amazon Polly with other AWS services, such as AWS Batch for efficient batch processing, can help you make the most of Amazon Polly within those service limits.', 'Q. How much does Amazon Polly cost?'), ('Please see the Amazon Polly Pricing Page for current pricing information.', 'Q. Can I use the service for generating static voice prompts that will be replayed multiple times?'), ('Yes, you can. The service does not restrict this and there are no additional costs for doing so.', 'Q. Can I use the service to generate content that will be used in mass notification systems (for example on train station)?'), ('Yes, you can. The service does not restrict this and there are no additional costs for doing so.', 'Q. If I request 1,000 characters to be synthesized and request Speech Marks with the same 1,000 characters, will I be charged for 2,000 characters?'), ('Yes. You will be charged for every request for speech or Speech Marks based on the number of characters you send to the service.', 'Q. Does Amazon Polly participate in the AWS Free Tier?'), ('Yes, as part of the AWS Free Usage Tier, you can get started with Amazon Polly for free. Upon sign-up, new Amazon Polly customers can synthesize up to 5M characters for free each month for the first 12 months.', 'Q. Do your prices include taxes?'), ('For details on taxes, please see Amazon Web Services Tax Help. ', 'Q. Will Amazon Polly use my Content to improve its service? What is your privacy policy for Amazon Polly?'), ('Amazon Polly may use Your Content to improve the quality of our Service Offerings and other machine learning related products and services offered by AWS and its affiliates. Some use of Your Content is crucial for further development of the underlying technology and improvement of the Amazon Polly customer experience. Your trust, privacy and the security of Your Content are our highest priority and we implement responsible and sophisticated technical and physical controls designed to prevent unauthorized access to or disclosure of Your Content and ensure that our use complies with our commitments to you. Please see AWS Data Privacy FAQ for more information. \xa0', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/rekognition/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/amazon-ai1/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/athena/faqs/': [('Q: What is Amazon Athena?', 'Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL. Athena is serverless, so there is no infrastructure to setup or manage, and you can start analyzing data immediately. You don’t even need to load your data into Athena, it works directly with data stored in S3. To get started, just log into the Athena Management Console, define your schema, and start querying. Amazon Athena uses Presto with full standard SQL support and works with a variety of standard data formats, including CSV, JSON, ORC, Apache Parquet and Avro. While Amazon Athena is ideal for quick, ad-hoc querying and integrates with Amazon QuickSight for easy visualization, it can also handle complex analysis, including large joins, window functions, and arrays.'), ('Q: What can I do with Amazon Athena?', 'Amazon Athena helps you analyze data stored in Amazon S3. You can use Athena to run ad-hoc queries using ANSI SQL, without the need to aggregate or load the data into Athena. Amazon Athena can process unstructured, semi-structured, and structured data sets. Examples include CSV, JSON, Avro or columnar data formats such as Apache Parquet and Apache ORC. Amazon Athena integrates with Amazon QuickSight for easy visualization. You can also use Amazon Athena to generate reports or to explore data with business intelligence tools or SQL clients, connected via a JDBC driver. '), ('Q: How do I get started with Amazon Athena?', 'To get started with Amazon Athena, simply log into the AWS Management Console for Athena and create your schema by writing DDL statements on the console or by using a create table wizard. You can then start querying data using a built-in query editor. Athena queries data directly from Amazon S3 so there’s no loading required. \xa0'), ('Q: How do you access Amazon Athena?', 'Amazon Athena can be accessed via the AWS Management Console, an API, or a JDBC driver. You can programmatically run queries, add tables or partitions using the JDBC driver. \xa0'), ('Q: What are the service limits associated with Amazon Athena?', 'Please click here to learn more about service limits'), ('Q: What is the underlying technology behind Amazon Athena?', 'Amazon Athena uses Presto with full standard SQL support and works with a variety of standard data formats, including CSV, JSON, ORC, Avro, and Parquet. Athena can handle complex analysis, including large joins, window functions, and arrays. Because Amazon Athena uses Amazon S3 as the underlying data store, it is highly available and durable with data redundantly stored across multiple facilities and multiple devices in each facility. '), ('Q: How does Amazon Athena store table definitions and schema?', 'Amazon Athena uses a managed Data Catalog to store information and schemas about the databases and tables that you create for your data stored in Amazon S3. In regions where AWS Glue is available, you can upgrade to using the AWS Glue Data Catalog with Amazon Athena. In regions where AWS Glue is not available, Athena uses an internal Catalog.'), ('You can modify the catalog using DDL statements or via the AWS Management Console. Any schemas you define are automatically saved unless you explicitly delete them. Athena uses schema-on-read technology, which means that your table definitions applied to your data in S3 when queries are being executed. There’s no data loading or transformation required. You can delete table definitions and schema without impacting the underlying data stored on Amazon S3.', 'Q: Why should I upgrade to AWS Glue Data Catalog?'), ('AWS Glue is a fully managed ETL service. Glue has three main components: 1) a crawler that automatically scans your data sources, identifies data formats and infers schemas, 2) a fully managed ETL service that allows you to transform and move data to various destinations, and 3) a Data Catalog that stores metadata information about databases & tables either stored in S3 or a JDBC-compliant data store. To use the benefits of Glue, you must upgrade from using Athena’s internal Data Catalog to the Glue Data Catalog.', 'The benefits of upgrading to the Glue Data Catalog are:'), ('Click here to learn more about the Glue Data Catalog.', 'Q. Is there a step-by-step to upgrade to the AWS Data Catalog?'), ('Yes. Step-by-Step guide can be found here.', 'Q: What regions is Amazon Athena available in?'), ('Please refer to Regional Products and Services for details of Amazon Athena service availability by region. ', ' Q: What is the difference between Amazon Athena, Amazon EMR, and Amazon Redshift?'), ('Query services like Amazon Athena, data warehouses like Amazon Redshift, and sophisticated data processing frameworks like Amazon EMR, all address different needs and use cases. You just need to choose the right tool for the job. Amazon Redshift provides the fastest query performance for enterprise reporting and business intelligence workloads, particularly those involving extremely complex SQL with multiple joins and sub-queries. Amazon EMR makes it simple and cost effective to run highly distributed processing frameworks such as Hadoop, Spark, and Presto when compared to on-premises deployments. Amazon EMR is flexible - you can run custom applications and code, and define specific compute, memory, storage, and application parameters to optimize your analytic requirements. Amazon Athena provides the easiest way to run ad-hoc queries for data in S3 without the need to setup or manage any servers.', 'Q: When should you use a full featured enterprise data warehouse, like Amazon Redshift vs. a query service like Amazon Athena?'), ('A data warehouse like Amazon Redshift is your best choice when you need to pull together data from many different sources – like inventory systems, financial systems, and retail sales systems – into a common format, and store it for long periods of time, to build sophisticated business reports from historical data; then a data warehouse like Amazon Redshift is the best choice.', 'Data warehouses collect data from across the company and act as the “single source of truth” for report generation and analysis. Data warehouses pull data from many sources, format and organize it, store it, and support complex, high speed queries that produce business reports. The query engine in Amazon Redshift has been optimized to perform especially well on this use case - where you need to run complex queries that join large numbers of very large database tables. TPC-DS is a standard benchmark designed to replicate this use case, and Redshift runs these queries up to 20x faster than query services that are optimized for unstructured data. When you need to run queries against highly structured data with lots of joins across lots of very large tables, you should choose Amazon Redshift.'), ('By comparison, query services like Amazon Athena make it easy to run interactive queries against data directly in Amazon S3 without worrying about formatting data or managing infrastructure. For example, Athena is great if you just need to run a quick query on some web logs to troubleshoot a performance issue on your site. With query services, you can get started fast. You just define a table for your data and start querying using standard SQL.', 'You can also use both services together. If you stage your data on Amazon S3 before loading it into Amazon Redshift, that data can also be registered with and queried by Amazon Athena.'), ('Q: When should I use Amazon EMR vs. Amazon Athena?', 'Amazon EMR goes far beyond just running SQL queries. With EMR you can run a wide variety of scale-out data processing tasks for applications such as machine learning, graph analytics, data transformation, streaming data, and virtually anything you can code. You should use Amazon EMR if you use custom code to process and analyze extremely large datasets with the latest big data processing frameworks such as Spark, Hadoop, Presto, or Hbase. Amazon EMR gives you full control over the configuration of your clusters and the software installed on them. '), ('You should use Amazon Athena if you want to run interactive ad hoc SQL queries against data on Amazon S3, without having to manage any infrastructure or clusters.', 'Q: Can I use Amazon Athena to query data that I process using Amazon EMR?'), ("Yes, Amazon Athena supports many of the same data formats as Amazon EMR. Athena’s data catalog is Hive metastore compatible. If you're using EMR and already have a Hive metastore, you simply execute your DDL statements on Amazon Athena, and then you can start querying your data right away without impacting your Amazon EMR jobs. ", 'Q: How do I create tables and schemas for my data on Amazon S3?'), (' Amazon Athena uses Apache Hive DDL to define tables. You can run DDL statements using the Athena console, via a JDBC driver, via the API, or using the Athena create table wizard. If you use the AWS Glue Data Catalog with Athena, you can also use Glue crawlers to automatically infer schemas and partitions. An AWS Glue crawler connects to a data store, progresses through a prioritized list of classifiers to extract the schema of your data and other statistics, and then populates the Glue Data Catalog with this metadata. Crawlers can run periodically to detect the availability of new data as well as changes to existing data, including table definition changes. Crawlers automatically add new tables, new partitions to existing table, and new versions of table definitions. You can customize Glue crawlers to classify your own file types.', 'When you create a new table schema in Amazon Athena the schema is stored in the Data Catalog and used when executing queries, but it does not modify your data in S3. Athena uses an approach known as schema-on-read, which allows you to project your\xa0schema onto your data at the time you execute a query. This eliminates the need for any data loading or transformation. Learn more about creating tables.'), ('Q: What data formats does Amazon Athena support?', 'Amazon Athena supports a wide variety of data formats like CSV, TSV, JSON, or Textfiles and also supports open source columnar formats such as Apache ORC and Apache Parquet. Athena also supports compressed data in Snappy, Zlib, LZO, and GZIP formats. By compressing, partitioning, and using columnar formats you can improve performance and reduce your costs. '), ('Q: What kind of data types does Amazon Athena support?', 'Amazon Athena supports both simple data types such as INTEGER, DOUBLE, VARCHAR and complex data types such as MAPS, ARRAY and STRUCT. \xa0'), ('Q: Can I run any Hive Query on Athena?', 'Amazon Athena uses Hive only for DDL (Data Definition Language) and for creation/modification and deletion of tables and/or partitions. Please click here for a complete list of statements supported. Athena uses Presto when you run SQL queries on Amazon S3. You can run ANSI-Compliant SQL SELECT statements to query your data in Amazon S3.'), ('Q: What is a SerDe?', 'SerDe stands for Serializer/Deserializer, which are libraries that tell Hive how to interpret data formats. Hive DLL statements require you to specify a SerDe, so that the system knows how to interpret the data that you’re pointing to. Amazon Athena uses SerDes to interpret the data read from Amazon S3. The concept of SerDes in Athena is the same as the concept used in Hive. Amazon Athena supports the following SerDes:'), ('Q: Can I add my own SerDe (Serializer/Deserializer) to Amazon Athena?', 'Currently, you cannot add your own SerDe to Amazon Athena. We appreciate your feedback, so if there are any SerDes you would like to see added, please contact the Athena team at Athena-feedback@amazon.com'), ('Q: I created Parquet/ORC files using Spark/Hive. Will I be able to query them via Athena?', 'Yes, Parquet and ORC files created via Spark can be read in Athena.'), ('Q: I have data coming from Kinesis Firehose. How can I query it using Athena?', 'If your Kinesis Firehose data is stored in Amazon S3, you can query it using Amazon Athena. Simply create a schema for your data in Athena and start querying. We recommend that you organize the data into partitions to optimize performance. You can add partitions created by Kinesis Firehose using ALTER TABLE DDL statements. Learn more about partitions.'), ('Q: Does Amazon Athena support data partitioning?', 'Yes. Amazon Athena allows you to partition your data on any column. Partitions allow you to limit the amount of data each query scans, leading to cost savings and faster performance. You can specify your partitioning scheme using the PARTITIONED BY clause in the CREATE TABLE statement. Learn more about partitioning data.'), ('Q: How do I add new data to an existing table in Amazon Athena?', 'If your data is partitioned, you will need to run a metadata query (ALTER TABLE ADD PARTITION) to add the partition to Athena once new data becomes available on Amazon S3. If your data is not partitioned, just adding the new data (or files) to the existing prefix automatically adds the data to Athena. Learn more about partitioning data.'), ('Q: I already have large quantities of log data in Amazon S3. Can I use Amazon Athena to query it?', 'Yes, Amazon Athena makes it easy to run standard SQL queries on your existing log data. Athena queries data directly from Amazon S3 so there’s no data movement or loading required. Simply define your schema using DDL statements and start querying your data right away. '), (' Q: What kinds of queries does Amazon Athena support?', 'Amazon Athena supports ANSI SQL queries. Amazon Athena uses Presto, an open source, in-memory, distributed SQL engine, and can handle complex analysis, including large joins, window functions, and arrays. '), ('Q: Can I use Amazon QuickSight with Amazon Athena?', 'Yes. Amazon Athena integrates with Amazon QuickSight, allowing you to easily visualize your data stored in Amazon S3. '), ('Q: Does Athena support other BI Tools and SQL Clients?', 'Yes. Amazon Athena comes with a JDBC driver you can use with other business intelligence tools and SQL clients. Learn more about using a JDBC driver with Athena. '), ('Q: Does Athena support User Defined Functions (UDFs)?', 'Currently, Athena does not support custom UDFs. If you need custom UDF support, please email us at athena-feedback@amazon.com so we can learn more about your requirements. '), ('Q: How do I access the functions supported by Amazon Athena?', 'Click here to learn more about functions supported by Amazon Athena. '), ('Q: How do I improve the performance of my query?', 'You can improve the performance of your query by compressing, partitioning, or converting your data into columnar formats. Amazon Athena supports open source columnar data formats such as Apache Parquet and Apache ORC. Converting your data into a compressed, columnar format lowers your cost and improves query performance by enabling Athena to scan less data from S3 when executing your query. '), ('Q: How do I control access to my data?', 'Amazon Athena allows you to control access to your data by using AWS Identity and Access Management (IAM) policies, Access Control Lists (ACLs), and Amazon S3 bucket policies. With IAM policies, you can grant IAM users fine-grained control to your S3 buckets. By controlling access to data in S3, you can restrict users from querying it using Athena.'), ('Can Athena query encrypted data in Amazon S3?', 'Yes, you can query data that’s encrypted using Server-Side Encryption with Amazon S3-Managed Encryption Keys, Server-Side Encryption with AWS Key Management Service (KMS) – Managed Keys, and Client-Side Encryption with keys managed by KMS. Amazon Athena also integrates with KMS and provides you an option to encrypt your result sets.'), ('Q: Is Athena highly available?', 'Yes. Amazon Athena is highly available and executes queries using compute resources across multiple facilities, automatically routing queries appropriately if a particular facility is unreachable. Athena uses Amazon S3 as its underlying data store, making your data highly available and durable. Amazon S3 provides durable infrastructure to store important data and is designed for durability of 99.999999999% of objects. Your data is redundantly stored across multiple facilities and multiple devices in each facility. '), ('Q: Can I provide cross-account access to someone else’s S3 bucket?', 'Yes, you can provide cross-account access to Amazon S3. '), (' Q: How is Amazon Athena priced?', 'Amazon Athena is priced per query and charges based on the amount of data scanned by the query. You can store data in a variety of formats on Amazon S3. If you compress your data, partition, or convert it to columnar storage formats, you pay less because you scan less data. Converting data to the columnar format allows Athena to read only the columns it needs to process the query. Please see the Athena pricing page for more details'), ('Q: Why do I get charged less when I use a columnar format?', 'Amazon Athena charges you for the amount of data scanned per query. Compressing your data allows Amazon Athena to scan less data. Converting your data to columnar formats allows Athena to selectively read only required columns to process the data. Partitioning your data also allows Athena to restrict the amount of data scanned. This leads to cost savings and improved performance. See pricing example for details.'), ('Q: How do I lower my costs?', 'You can save 30%-90% on your query costs and get better performance by compressing, partitioning, and converting your data into columnar formats. Each of these operations reduces the amount of data Amazon Athena needs to scan to execute a query. Amazon Athena supports Apache Parquet and ORC, two of the most popular open-source columnar formats. You can see the amount of data scanned per query, on the Athena console. \xa0'), ('Q: Does Amazon Athena charge me for failed queries?', 'No, you are not charged for failed queries.'), ('Q: Does Amazon Athena charge me for cancelled queries?', 'Yes, if you cancel a query manually, you are charged for the amount of data scanned up to the point at which you cancelled the query.'), ('Q: Are there any additional charges associated with Amazon Athena?', 'Amazon Athena queries data directly from Amazon S3, so your source data is billed at S3 rates. When Amazon Athena runs a query, it stores the results in an S3 bucket of your choice and you are billed at standard S3 rates for these result sets. We recommend you monitor these buckets and use lifecycle policies to control how much data gets retained.'), ('Q. Will I be charged for using AWS Glue Data Catalog?', 'Yes, you are charged separately for using the AWS Glue Data Catalog. Click here to learn more about Glue Data Catalog pricing.'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/elasticsearch-service/faqs/': [('Q: What is Amazon Elasticsearch Service? ', 'Amazon Elasticsearch Service is a managed service that makes it easy to deploy, operate, and scale Elasticsearch clusters in the AWS Cloud.'), ('Q: Which Elasticsearch version does Amazon Elasticsearch Service support? ', 'Amazon Elasticsearch Service currently supports Elasticsearch versions 6.0, 5.5, 5.3, 5.1, 2.3, and 1.5. '), ('Q: What is an Amazon Elasticsearch domain? ', 'Amazon Elasticsearch domains are Elasticsearch clusters created using the Amazon Elasticsearch Service console, CLI, or API. Each domain is an Elasticsearch cluster in the cloud with the compute and storage resources you specify. You can create and delete domains, define infrastructure attributes, and control access and security. You can run one or more Amazon Elasticsearch domains.'), ('Q: What does Amazon Elasticsearch Service manage on my behalf? ', 'Amazon Elasticsearch Service manages the work involved in setting up a domain, from provisioning infrastructure capacity in the network environment you request to installing the Elasticsearch software. Once your domain is running, Amazon Elasticsearch Service automates common administrative tasks, such as performing backups, monitoring instances and patching software. Amazon Elasticsearch Service integrates with Amazon CloudWatch to produce metrics that provide information about the state of the domains. Amazon Elasticsearch Service also offers options to modify your domain instance and storage settings to simplify the task of tailoring your domain based to your application needs.'), ('Q: Does Amazon Elasticsearch Service support the open source Elasticsearch APIs?', "Amazon Elasticsearch Service supports most of the commonly used Elasticsearch APIs, so the code, applications, and popular tools that you're already using with your current Elasticsearch environments work seamlessly. For a full list of supported Elasticsearch operations, see our documentation. "), ('Return to Top >>', 'Q: Can I create and modify my Amazon Elasticsearch domain through the Amazon Elasticsearch Service console? '), ('Yes. You can create a new Amazon Elasticsearch domain with the Domain Creation Wizard in the console with just a few clicks. While creating a new domain you can specify the number of instances, instance types, and EBS volumes you want allocated to your domain. You can also modify or delete existing Amazon Elasticsearch domains using the console.', 'Q: Does Amazon Elasticsearch Service support Amazon VPC?'), ('Yes, Amazon Elasticsearch Service is integrated with Amazon VPC. When choosing VPC access, IP addresses from your VPC are attached to your Amazon Elasticsearch Service domain and all network traffic stays within the AWS network and is not accessible to the Internet. Moreover, you can use security groups and IAM policies to restrict access to your Amazon Elasticsearch Service domains.', 'Q: Can I use CloudFormation Templates to provision Amazon ES domains?'), ('Yes. AWS CloudFormation supports Amazon ES. For more information, see the CloudFormation Template Reference documentation.', 'Q: Does Amazon Elasticsearch Service support configuring dedicated master nodes? '), ('Yes. You can configure dedicated master nodes for your domains. When choosing a dedicated master configuration, you can specify the instance type and instance count.', 'Q: Can I create multiple Elasticsearch indices within a single Amazon Elasticsearch domain? '), ('Yes. You can create multiple Elasticsearch indices within the same Amazon Elasticsearch domain. Elasticsearch\xa0automatically distributes the indices and any associated replicas between the instances allocated to the domain.', 'Q: How do I ingest data into my Amazon Elasticsearch Service domain? '), ('Amazon Elasticsearch Service supports three options for data ingestion:', 'Q: Does Amazon Elasticsearch Service support integration with Logstash?'), ('Yes. Amazon Elasticsearch Service supports integration with Logstash. You can set up your Amazon Elasticsearch domain as the backend store for all logs coming through your Logstash implementation. You can set up access control on your Amazon Elasticsearch domain to either use request signing to authenticate calls from your Logstash implementation, or use resource based IAM policies to include IP addresses of instances running your Logstash implementation.', 'Q: Does Amazon Elasticsearch Service support integration with Kibana? '), ('Yes. Amazon Elasticsearch Service includes a built-in Kibana install that is deployed with your Amazon Elasticsearch Service domain. ', 'Q: Can I create custom reports with the Kibana installation included with Amazon Elasticsearch Service? '), ('Yes. Kibana supports creating and saving custom reports through the user interface. For more information on using Kibana, refer to Kibana documentation.', 'Q: What storage options are available with Amazon Elasticsearch Service? '), ('You can choose between local on-instance storage or EBS volumes. During domain creation, if you select EBS storage, you can increase and decrease the size of the storage volume as necessary. ', 'Q: What types of EBS volumes does Amazon Elasticsearch Service support? '), ('You can choose between Magnetic, General Purpose, and Provisioned IOPS EBS volumes.', 'Q:\xa0Is there a limit on the amount of EBS storage that can be allocated to an Amazon Elasticsearch domain? '), ('Yes. Amazon Elasticsearch Service supports one EBS volume (max size of 1.5 TB) per instance associated with a domain. With the default maximum of 20 data nodes allowed per Amazon Elasticsearch Service domain, you can allocate about 30 TB of EBS storage to a single domain. You can request a service limit increase up to 100 instances per domain by creating a case with the AWS Support Center. With 100 instances, you can allocate about 150 TB of EBS storage to a single domain.', 'Return to Top >>'), ('Q: Can programs running on servers in my own data center access my Amazon Elasticsearch domains?', 'Yes. The programs with public Internet access can access Amazon Elasticsearch Service domains through a public endpoint. If your data center is already connected to Amazon VPC through Direct Connect or SSH tunneling, you can also use VPC access. In both cases, you can configure IAM policies and security groups to allow programs running on servers outside of AWS to access your Amazon Elasticsearch domains. Click here for more information about signed requests.'), ('Q: How can I migrate data from my existing Elasticsearch cluster to a new Amazon Elasticsearch domain? ', 'To migrate data from an existing Elasticsearch cluster you should create a snapshot of an existing Elasticsearch cluster, and store the snapshot in your Amazon S3 bucket. Then you can create a new Amazon Elasticsearch domain and load data from the snapshot into the newly created Amazon Elasticsearch domain using the Elasticsearch restore API.'), ('Q: How can I scale an Amazon Elasticsearch domain? ', 'Amazon Elasticsearch Service allows you to control the scaling of your Amazon Elasticsearch domains using the console, API, and CLI. You can scale your Amazon Elasticsearch domain by adding, removing, or modifying instances or storage volumes depending on your application needs. Amazon Elasticsearch Service is integrated with Amazon CloudWatch to provide metrics about the state of your Amazon Elasticsearch domains to enable you to make appropriate scaling decisions for your domains.'), ('Q: Does scaling my Amazon Elasticsearch domain require downtime? ', 'No. Scaling your Amazon Elasticsearch domain by adding or modifying instances, and storage volumes is an online operation that does not require any downtime.'), ('Q: What options does Amazon Elasticsearch Service provide for node failures? ', 'Amazon Elasticsearch Service automatically detects node failures and replaces the node. The service will acquire new instances, and will then redirect Elasticsearch requests and document updates to the new instances. In the event that the node cannot be replaced, customers will be able to use any snapshots they have of their cluster to restart the domain with preloaded data.'), ('Q: Does Amazon Elasticsearch Service support cross-zone replication? ', 'Yes. Customers can enable Zone Awareness for their Amazon Elasticsearch domains either at domain creation time or by modifying a live domain. When Zone Awareness is enabled, Amazon Elasticsearch Service will distribute the instances supporting the domain across two different Availability Zones. Then, if replication is enabled in the Elasticsearch engine, Elasticsearch will allocate replicas of the domain across these different instances enabling cross-zone replication.'), ('Q: Does Amazon Elasticsearch Service expose any performance metrics through Amazon CloudWatch? ', 'Yes. Amazon Elasticsearch Service exposes several performance metrics through Amazon CloudWatch including number of nodes, cluster health, searchable documents, EBS metrics (if applicable), CPU, memory and disk utilization for data and master nodes. Please refer to the service documentation for a full listing of available CloudWatch metrics.'), ('Q: I wish to perform security analysis or operational troubleshooting of my Amazon Elasticsearch Service deployment. Can I get a history of all the Amazon Elasticsearch Service API calls made on my account? ', "Yes. AWS CloudTrail is a web service that records AWS API calls for your account and delivers log files to you. The AWS API call history produced by AWS CloudTrail enables security analysis, resource change tracking, and compliance auditing. Learn more about AWS CloudTrail at the AWS CloudTrail detail page, and turn it on via CloudTrail's AWS Management Console home page."), ('Q: What is a snapshot? ', 'A snapshot is a copy of your Amazon Elasticsearch domain at a moment in time.'), ('Q: Why would I need snapshots? ', 'Creating snapshots can be useful in case of data loss caused by node failure, as well as the unlikely event of a hardware failure. You can use snapshots to recover your Amazon Elasticsearch domain with preloaded data or to create a new Amazon Elasticsearch domain with preloaded data. Another common reason to use backups is for archiving purposes. Snapshots are stored in Amazon S3.'), ('Q: Does Amazon Elasticsearch Service provide automated snapshots? ', 'Yes. By default, Amazon Elasticsearch Service will automatically create daily snapshots of each Amazon Elasticsearch domain. The daily snapshots are setup to occur between midnight and 1AM UTC. Customers will also be able to modify the timing of the automated snapshot to better suit their needs.'), ('Q: Can I change the default settings for the automated daily snapshot provided by Amazon Elasticsearch Service? ', 'Yes. You will be able to change the timing of the automated daily snapshot to suit your application schedule.'), ('Q: How long are the automated daily snapshots stored by Amazon Elasticsearch Service? ', 'Amazon Elasticsearch Service will retain the last 14 days worth of automated daily snapshots.'), ('Q: Is there a charge for the automated daily snapshots? ', 'There is no additional charge for the automated daily snapshots. The snapshots are stored for free in an Amazon Elasticsearch Service S3 bucket and will be made available for node recovery purposes.'), ('Q: Can I create additional snapshots of my Amazon Elasticsearch domains as needed? ', 'Yes. You can use the Elasticsearch snapshot API to create additional manual snapshots in addition to the daily-automated snapshots created by Amazon Elasticsearch Service. The manual snapshots are stored in your S3 bucket and will incur relevant Amazon S3 usage charges.'), ('Q: Can snapshots created by the manual snapshot process be used to recover a domain in the event of a failure? ', 'Yes. Customers can create a new Amazon Elasticsearch domain and load data from the snapshot into the newly created Amazon Elasticsearch domain using the Elasticsearch restore API.'), ('Q: What happens to my snapshots when I delete my Amazon Elasticsearch domain? ', 'The daily snapshots retained by Amazon Elasticsearch Service will be deleted as part of domain deletion. Before deleting a domain, you should consider creating a snapshot of the domain in your own S3 buckets using the manual snapshot process. The snapshots stored in your S3 bucket will not be affected if you delete your Amazon Elasticsearch domain.'), ('Q: What are slow logs?', 'Slow logs are log files that help track the performance of various stages in an operation. Elasticsearch exposes two kinds of slow logs:'), ('For complete details on Elasticsearch slow logs, please refer to Elasticsearch documentation.', 'Q: How can I enable slow logs on Amazon ES?'), ('Slows logs can be enabled via the click of a button from the Console or via our CLI and APIs. For more details please refer to our documentation.', 'Q: Can I only enable slow logs for specific indices?'), ('Yes. You can update the settings for a specific index to enable or disable slow logs for it. For more details refer to our documentation.', 'Q: Does turning on slow logs in Amazon ES automatically enable logging for all indexes?'), ('No. Turning on slow logs in Amazon ES enables the option to publish the generated logs to Amazon CloudWatch Logs for indices in the given domain. However, in order to generate the logs you have to update the settings for one or more indices to start the logging process. For more details on setting the index configuration for enabling slow logs, please refer to our documentation.', 'Q: If I turn off the Slow Logs in Amazon ES, does it mean that log files are no longer being generated?'), ('No. The generation of log files are dependent on the index settings. To turn off generation of the log files you have to update the index configuration. For more details on setting the index configuration for enabling slow logs, see our documentation.', 'Q: Can I adjust the granularity of logging?'), ('Yes. Elasticsearch exposes multiple levels of logging. You need to set the appropriate level in the configuration for your index. For more details on setting the index configuration for enabling slow logs, see our documentation.', 'Q: Does enabling Slow Logs cost me anything?'), ('When Slow Logs are enabled, Amazon ES starts publishing the generated logs to Amazon CloudWatch Logs. Amazon ES does not charge for enabling slow logs. However, standard CloudWatch charges apply.', 'Q: Is there any limit on the size of each log entry?'), ('Yes. Each log entry made into CloudWatch will be limited to 255,000 characters. If your log entry is bigger than that, it will be truncated to 255,000 characters.', 'Q: What is the recommended best practice for using slow logs?'), ('Slow logs are only needed when you want to troubleshoot your indexes or fine-tune performance. The recommended approach is to only enable logging for those indexes for which you need additional performance insights. Also, once the investigation is done, you should turn off logging so that you don’t incur any additional costs on account of it. For more details, see our documentation.', 'Q: How can I consume logs from CloudWatch Logs? CloudWatch offers multiple ways to consume logs. You can view log data, export it to S3,\xa0or process it in real time. To learn more, see the CloudWatch Logs developer guide.'), ('Q: Are slow logs available for all versions of Elasticsearch supported by Amazon ES?', 'Yes. slow logs can be enabled for all versions of Elasticsearch supported by Amazon ES. However, there are slight differences in the way log settings can be specified for each version of Elasticsearch. Please refer to our documentation for more details.'), ('Q: Will the cluster have any down time when logging is turned on or off?', 'No. There will not be any down-time. Every time the log status is updated, we will deploy a new cluster in the background and replace the existing cluster with the new one. This process will not cause any down time. However, since a new cluster is deployed the update to the log status will not be instantaneous. \xa0'), ('Return to Top >>', 'Q: How can I secure my Amazon Elasticsearch Service domain?'), ('If you use VPC to secure your applications, data, and network traffic, you can set up VPC access for Amazon Elasticsearch Service, which allows you to control network access using your VPC security groups. You can also use IAM-based policies to provide fine-grained access control to which IAM roles can perform administrative tasks, use the Elasticsearch APIS and have access to the resources in the domain down to the index-level.', 'If you want to make your Amazon Elasticsearch Service domain accessible from the Internet, you can specify public access. With public access, you can control access to the endpoint by IP address and require authentication using IAM roles. IAM policies can control access to Amazon Elasticsearch domains and sub resources like indices within the domains.'), ('IAM policies can also be set up to control access to the management API for operations such as creating and scaling clusters and Elasticsearch API for operations like uploading documents and executing Elasticsearch requests.', 'Q: Can I encrypt my data at rest while using Amazon Elasticsearch Service?'), ('Amazon Elasticsearch Service provides an option that allows you to encrypt your data using keys you manage through AWS Key Management Service (KMS). If enabled, all of your data stored at rest in the underlying storage systems are encrypted, including primary and replica indices, log files, memory swap files, and automated S3 snapshots. Amazon Elasticsearch Service handles encryption and decryption seamlessly, so you don’t have to modify your application to access your data. You can choose to enable encryption when you create new domains via the AWS Management Console or API. Amazon Elasticsearch Service can create a KMS master key for you, or you can choose one of your own. Encryption at rest supports both Amazon Elastic Block Store (EBS) and instance storage.', 'For more information about the use of AWS KMS with Amazon Elasticsearch Service, see the Amazon Elasticsearch Service Developer Guide. To learn more about AWS KMS, visit the web page.'), ('Q: How can I set up the VPC access for Amazon Elasticsearch Service?', 'You configure VPC access when creating an Amazon Elasticsearch Service domain. The VPC access can be set up via a few clicks in the console or via our CLI and APIs. For more details, see the Amazon Elasticsearch Service developer guide.'), ('Q: If I set up VPC access for my Amazon Elasticsearch Service domain, how can I access Kibana?', 'When VPC access is enabled, the endpoint for Amazon Elasticsearch Service is only accessible within the customer VPC. To use your laptop to access Kibana from outside the VPC, you need to connect the laptop to the VPC using VPN or VPC Direct Connect. '), ('Return to Top >>', 'Q: How will I be charged and billed for my use of Amazon Elasticsearch Service? '), ('You pay only for what you use, and there are no minimum or setup fees. You are billed based on:', 'Please refer to the Amazon Elasticsearch Service pricing page for detailed pricing information. '), (' Q: When does billing of my Amazon Elasticsearch domain begin and end? ', 'Billing commences for an Amazon Elasticsearch instance as soon as the instance is available. Billing continues until the Amazon Elasticsearch instance terminates, which would occur upon deletion or in the event of instance failure.'), ('Q: What defines billable instance hours for Amazon Elasticsearch Service? ', 'Amazon Elasticsearch instance hours are billed for each hour your instance is running in an available state. If you no longer wish to be charged for your Amazon Elasticsearch instance, you must delete the domain to avoid being billed for additional instance hours. Partial Amazon Elasticsearch instance hours consumed are billed as full hours.'), ('Return to Top >>', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/kinesis/streams/faqs/': [('\xa0', 'Q: What is Amazon Kinesis Data Streams?'), ('Amazon Kinesis Data Streams enables you to build custom applications that process or analyze streaming data for specialized needs. You can continuously add various types of data such as clickstreams, application logs, and social media to an Amazon Kinesis data stream from hundreds of thousands of sources. Within seconds, the data will be available for your Amazon Kinesis Applications to read and process from the stream.', 'Q: What does Amazon Kinesis Data Streams manage on my behalf?'), ('Amazon Kinesis Data Streams manages the infrastructure, storage, networking, and configuration needed to stream your data at the level of your data throughput. You do not have to worry about provisioning, deployment, ongoing-maintenance of hardware, software, or other services for your data streams. In addition, Amazon Kinesis Data Streams synchronously replicates data across three availability zones, providing high availability and data durability.', 'Q: What can I do with Amazon Kinesis Data Streams?'), ('Amazon Kinesis Data Streams is useful for rapidly moving data off data producers and then continuously processing the data, be it to transform the data before emitting to a data store, run real-time metrics and analytics, or derive more complex data streams for further processing. The following are typical scenarios for using Amazon Kinesis Data Streams:', 'Q: How do I use Amazon Kinesis Data Streams?'), ('After you sign up for Amazon Web Services, you can start using Amazon Kinesis Data Streams by:', 'Q: What are the limits of Amazon Kinesis Data Streams?'), ('The throughput of an Amazon Kinesis data stream is designed to scale without limits via increasing the number of shards within a data stream. However, there are certain limits you should keep in mind while using Amazon Kinesis Data Streams:', 'For more information about other API level limits, see Amazon Kinesis Data Streams Limits.'), ('Q: How does Amazon Kinesis Data Streams differ from Amazon SQS?', 'Amazon Kinesis Data Streams enables real-time processing of streaming big data. It provides ordering of records, as well as the ability to read and/or replay records in the same order to multiple Amazon Kinesis Applications. The Amazon Kinesis Client Library (KCL)\xa0delivers all records for a given\xa0partition key to the same record processor, making it easier to build multiple applications reading from the same Amazon Kinesis data stream (for example, to perform counting, aggregation, and filtering).'), ('Amazon Simple Queue Service (Amazon SQS) offers a reliable, highly scalable hosted queue for storing messages as they travel between computers. Amazon SQS lets you easily move data between distributed application components and helps you build applications in which messages are processed independently (with message-level ack/fail semantics), such as automated workflows.', 'Q: When should I use Amazon Kinesis Data Streams, and when should I use Amazon SQS?'), ('We recommend Amazon Kinesis Data Streams for use cases with requirements that are similar to the following:', 'We recommend Amazon SQS for use cases with requirements that are similar to the following:'), ('Q: What is a shard?', 'Shard is the base throughput unit of an Amazon Kinesis data stream. One shard provides a capacity of 1MB/sec data input and 2MB/sec data output. One shard can support up to 1000 PUT records per second. You will specify the number of shards needed when you create a data stream. For example, you can create a\xa0data stream with two shards. This\xa0data stream has a throughput of 2MB/sec data input and 4MB/sec data output, and allows up to 2000 PUT records per second.\xa0You can monitor shard-level metrics in Amazon\xa0Kinesis Data Streams and add or remove shards from your\xa0data stream dynamically as your data throughput changes by\xa0resharding\xa0the data stream.'), ('Q: What is a record?', 'A record is the unit of data stored in an Amazon Kinesis data stream. A record is composed of a sequence number, partition key, and data blob. Data blob is the data of interest your data producer adds to a data stream. The maximum size of a data blob (the data payload before Base64-encoding) is 1 megabyte (MB).'), ('Q: What is a partition key?', 'Partition key is used to segregate and route records to different shards of a data stream. A partition key is specified by your data producer while adding data to an Amazon Kinesis data stream. For example, assuming you have a\xa0data stream with two shards (shard 1 and shard 2). You can configure your data producer to use two partition keys (key A and key B) so that all records with key A are added to shard 1 and all records with key B are added to shard 2.\xa0'), ('Q: What is a sequence number?', 'A sequence number is a unique identifier for each record. Sequence number is assigned by Amazon Kinesis when a data producer calls PutRecord or PutRecords operation to add data to an Amazon Kinesis data stream. Sequence numbers for the same partition key generally increase over time; the longer the time period between PutRecord\xa0or PutRecords requests, the larger the sequence numbers become. '), ('Q: How do I create an Amazon Kinesis data stream?', 'After you sign up for Amazon Web Services, you can create an Amazon Kinesis\xa0data stream through either Amazon Kinesis Management Console or\xa0CreateStream\xa0operation.'), ('Q: How do I decide the throughput of my Amazon Kinesis data stream?', 'The throughput of an Amazon Kinesis\xa0data stream is determined by the number of\xa0shards within the data stream. Follow the steps below to estimate the initial number of shards your\xa0data stream needs. Note that you can dynamically adjust the number of shards within your\xa0data stream via resharding.'), ('You can then calculate the initial number of shards (number_of_shards) your\xa0data stream needs using the following formula:', 'number_of_shards = max (incoming_write_bandwidth_in_KB/1000, outgoing_read_bandwidth_in_KB/2000)'), ('Q: What is the minimum throughput I can request for my Amazon Kinesis data stream?', 'The throughput of an Amazon Kinesis\xa0data stream scales by unit of shard. One single shard is the smallest throughput of a data stream, which provides 1MB/sec data input and 2MB/sec data output.'), ('Q: What is the maximum throughput I can request for my Amazon Kinesis data stream?', 'The throughput of an Amazon Kinesis\xa0data stream is designed to scale without limits. By default, each account can provision 10 shards per region. You can use the Amazon\xa0Kinesis Data Streams Limits form to request more than 10 shards within a single region.'), ('Q: How can record size affect the throughput of my Amazon Kinesis data stream?', 'A shard provides 1MB/sec data input rate and supports up to 1000 PUT records per sec. Therefore, if the record size is less than 1KB, the actual data input rate of a shard will be less than 1MB/sec, limited by the maximum number of PUT records per second.'), ('Q: How do I add data to my Amazon Kinesis data stream?', 'You can add data to an Amazon Kinesis\xa0data stream via PutRecord and PutRecords\xa0operations, Amazon Kinesis Producer Library (KPL), or Amazon Kinesis Agent.'), ('Q: What is the difference between PutRecord and PutRecords?', 'PutRecord operation allows a single data record within an API call and PutRecords operation allows multiple data records within an API call. For more information about PutRecord and PutRecords operations, see PutRecord\xa0and PutRecords.'), ('Q: What is Amazon Kinesis Producer Library (KPL)?', 'Amazon Kinesis Producer Library (KPL) is an easy to use and highly configurable library that helps you put data into an Amazon Kinesis data stream. KPL presents a simple, asynchronous, and reliable interface that enables you to quickly achieve high producer throughput with minimal client resources.'), ('Q: What programming languages or platforms can I use to access Amazon Kinesis API?', 'Amazon Kinesis API is available in Amazon Web Services SDKs. For a list of programming languages or platforms for Amazon Web Services SDKs, see Tools for Amazon Web Services.'), ('Q: What programming language is Amazon Kinesis Producer Library (KPL) available in?', "Amazon Kinesis Producer Library (KPL)'s core is built with C++ module and can be compiled to work on any platform with a recent C++ compiler. The library is currently available in a Java interface.\xa0We are looking to add support for other programming languages."), ('Q: What is Amazon Kinesis Agent?', 'Amazon Kinesis Agent is a pre-built Java application that offers an easy way to collect and send data to your Amazon Kinesis data stream. You can install the agent on Linux-based server environments such as web servers, log servers, and database servers. The agent monitors certain files and continuously sends data to your data stream. For more information, see Writing with Agents.'), ('Q: What platforms do Amazon Kinesis Agent support?', 'Amazon Kinesis Agent currently supports Amazon Linux or Red Hat Enterprise Linux.'), ('Q: Where do I get Amazon Kinesis Agent?', 'You can download and install Amazon Kinesis Agent using the following command and link:'), ('On Amazon Linux: sudo yum install –y aws-kinesis-agent', 'On Red Hat Enterprise Linux: sudo yum install –y https://s3.amazonaws.com/streaming-data-agent/aws-kinesis-agent-latest.amzn1.noarch.rpm'), ('From GitHub: awlabs/amazon-kinesis-agent ', 'Q: How do I use Amazon Kinesis Agent?'), ('After installing Amazon Kinesis Agent on your servers, you configure it to monitor certain files on the disk and then continuously send new data to your Amazon Kinesis data stream. For more information, see Writing with Agents.', 'Q: What happens if the capacity limits of an Amazon Kinesis\xa0data stream are exceeded while the data producer adds data to the data stream?'), ('The capacity limits of an Amazon Kinesis\xa0data stream are defined by the number of\xa0shards within the data stream. The limits can be exceeded by either data throughput or the number of PUT records. While the capacity limits are exceeded, the put data call will be rejected with a ProvisionedThroughputExceeded exception. If this is due to a temporary rise of the data stream’s input data rate, retry by the data producer will eventually lead to completion of the requests. If this is due to a sustained rise of the data stream’s input data rate, you should increase the number of shards within your\xa0data stream to provide enough capacity for the put data calls to consistently succeed. In both cases, Amazon CloudWatch metrics allow you to learn about the change of the data stream’s input data rate and the occurrence of ProvisionedThroughputExceeded exceptions.', 'Q: What data is counted against the data throughput of an Amazon Kinesis\xa0data stream during a PutRecord\xa0or PutRecords call?'), ('Your data blob, partition key, and\xa0data stream name are required parameters of a PutRecord\xa0or PutRecords call. The size of your data blob (before Base64 encoding) and partition key will be counted against the data throughput of your Amazon Kinesis data stream, which is determined by the number of shards within the data stream. ', 'Q: What is an Amazon Kinesis Application?'), ('An Amazon Kinesis Application is a data consumer that reads and processes data from an Amazon Kinesis data stream. You can build your applications using either Amazon Kinesis API or Amazon Kinesis Client Library (KCL).', 'Q: What is Amazon Kinesis Client Library (KCL)?'), ('Amazon Kinesis Client Library (KCL) for Java\xa0|\xa0Python\xa0|\xa0Ruby\xa0|\xa0Node.js\xa0| .NET is a pre-built library that helps you easily build Amazon Kinesis Applications for reading and processing data from an Amazon Kinesis data stream. KCL handles complex issues such as adapting to changes in\xa0data stream volume, load-balancing streaming data, coordinating distributed services, and processing data with fault-tolerance. KCL enables you to focus on business logic while building applications.', 'Q: What is Amazon Kinesis Connector Library?'), ('Amazon Kinesis Connector Library is a pre-built library that helps you easily integrate Amazon\xa0Kinesis Data Streams with other AWS services and third-party tools. Amazon Kinesis Client Library (KCL) for Java\xa0|\xa0Python\xa0|\xa0Ruby\xa0|\xa0Node.js\xa0| .NET is required for using Amazon Kinesis Connector Library. The current version of this library provides connectors to Amazon DynamoDB, Amazon Redshift, Amazon S3, and Elasticsearch. The library also includes sample connectors of each type, plus Apache Ant build files for running the samples.', 'Q: What is Amazon Kinesis Storm Spout?'), ('Amazon Kinesis Storm Spout is a pre-built library that helps you easily integrate Amazon\xa0Kinesis Data Streams with Apache Storm. The current version of Amazon Kinesis Storm Spout fetches data from Amazon Kinesis\xa0data stream and emits it as tuples. You will add the spout to your Storm topology to leverage Amazon\xa0Kinesis Data Streams as a reliable, scalable, stream capture, storage, and replay service.', 'Q: What programming language are Amazon Kinesis Client Library (KCL), Amazon Kinesis Connector Library, and Amazon Kinesis Storm Spout available in?'), ('Amazon Kinesis Client Library (KCL) is currently available in Java,\xa0Python,\xa0Ruby, Node.js, and .NET.\xa0Amazon Kinesis Connector Library\xa0and Amazon Kinesis Storm Spout are currently available in Java. We are looking to add support for other programming languages.', 'Q: Do I have to use Amazon Kinesis Client Library (KCL) for my Amazon Kinesis Application?'), ('No, you can also use Amazon Kinesis API to build your Amazon Kinesis Application. However, we recommend using Amazon Kinesis Client Library (KCL) for Java\xa0|\xa0Python\xa0|\xa0Ruby\xa0|\xa0Node.js\xa0| .NET if applicable because it performs heavy-lifting tasks associated with distributed stream processing, making it more productive to develop applications.', 'Q: How does Amazon Kinesis Client Library (KCL) interact with an Amazon Kinesis Application?'), ('Amazon Kinesis Client Library (KCL) for Java\xa0|\xa0Python\xa0|\xa0Ruby\xa0|\xa0Node.js\xa0| .NET\xa0acts as an intermediary between Amazon\xa0Kinesis Data Streams and your Amazon Kinesis Application. KCL uses the IRecordProcessor interface to communicate with your application. Your application implements this interface, and KCL calls into your application code using the methods in this interface.', 'For more information about building application with KCL, see Developing Consumer Applications for Amazon Kinesis Using the Amazon Kinesis Client Library.'), ('Q: What is a worker and a record processor generated by Amazon Kinesis Client Library (KCL)?', 'An Amazon Kinesis Application can have multiple application instances and a worker is the processing unit that maps to each application instance. A record processor is the processing unit that processes data from a shard of an Amazon Kinesis data stream. One worker maps to one or more record processors. One record processor maps to one shard and processes records from that shard.'), ('At startup, an application calls into Amazon Kinesis Client Library (KCL) for Java\xa0|\xa0Python\xa0|\xa0Ruby\xa0|\xa0Node.js\xa0| .NET to instantiate a worker. This call provides KCL with configuration information for the application, such as the\xa0data stream name and AWS credentials. This call also passes a reference to an IRecordProcessorFactory implementation. KCL uses this factory to create new record processors as needed to process data from the data stream. KCL communicates with these record processors using the IRecordProcessor interface.', 'Q: How does Amazon Kinesis Client Library (KCL) keep tracking data records being processed by an Amazon Kinesis Application?'), ('Amazon Kinesis Client Library (KCL) for Java\xa0|\xa0Python\xa0|\xa0Ruby\xa0|\xa0Node.js\xa0| .NET\xa0automatically creates an Amazon DynamoDB table for each Amazon Kinesis Application to track and maintain state information such as resharding events and sequence number checkpoints. The DynamoDB table shares the same name with the application so that you need to make sure your application name doesn’t conflict with any existing DynamoDB tables under the same account within the same region.', 'All workers associated with the same application name are assumed to be working together on the same Amazon Kinesis data stream. If you run an additional instance of the same application code, but with a different application name, KCL treats the second instance as an entirely separate application also operating on the same data stream.'), ('Please note that your account will be charged for the costs associated with the Amazon DynamoDB table in addition to the costs associated with Amazon Kinesis Data Streams.', 'For more information about how KCL tracks application state, see Tracking Amazon Kinesis Application state.'), ('Q: How can I automatically scale up the processing capacity of my Amazon Kinesis Application using Amazon Kinesis Client Library (KCL)?', 'You can create multiple instances of your Amazon Kinesis Application and have these application instances run across a set of Amazon EC2 instances that are part of an Auto Scaling group. While the processing demand increases, an Amazon EC2 instance running your application instance will be automatically instantiated. Amazon Kinesis Client Library (KCL) for Java\xa0|\xa0Python\xa0|\xa0Ruby\xa0|\xa0Node.js\xa0| .NET will generate a worker for this new instance and automatically move record processors from overloaded existing instances to this new instance.'), ('Q: Why does GetRecords\xa0call return empty result while there is data within my Amazon Kinesis data stream?', 'One possible reason is that there is no record at the position specified by the current shard iterator. This could happen even if you are using TRIM_HORIZON as shard iterator type. An Amazon Kinesis\xa0data stream represents a continuous stream of data. You should call GetRecords\xa0operation in a loop and the record will be returned when the shard iterator advances to the position where the record is stored.'), ('Q: What is\xa0ApproximateArrivalTimestamp returned in GetRecords operation?', 'Each record includes a value called ApproximateArrivalTimestamp.\xa0It is set when the record is successfully received and stored by Amazon Kinesis. This timestamp has millisecond precision and there are no guarantees about the timestamp accuracy. For example, records in a shard or across a\xa0data stream might have timestamps that are out of order.'), ('Q: What happens if the capacity limits of an Amazon Kinesis\xa0data stream are exceeded while Amazon Kinesis Application reads data from the data stream?', 'The capacity limits of an Amazon Kinesis\xa0data stream are defined by the number of\xa0shards within the data stream. The limits can be exceeded by either data throughput or the number of read data calls. While the capacity limits are exceeded, the read data call will be rejected with a ProvisionedThroughputExceeded exception. If this is due to a temporary rise of the data stream’s output data rate, retry by the Amazon Kinesis Application will eventually lead to completions of the requests. If this is due to a sustained rise of the data stream’s output data rate, you should increase the number of shards within your\xa0data stream to provide enough capacity for the read data calls to consistently succeed. In both cases, Amazon CloudWatch metrics allow you to learn about the change of the data stream’s output data rate and the occurrence of ProvisionedThroughputExceeded exceptions. '), ('Q: How do I change the throughput of my Amazon Kinesis data stream?', 'There are two ways to change the throughput of your data stream. You can use the UpdateShardCount API or the AWS Management Console to scale the number of shards in a data stream, or you can change the throughput of an Amazon Kinesis\xa0data stream by adjusting the number of shards within the\xa0data stream (resharding). \xa0'), ('Q: How long does it take to change the throughput of my Amazon Kinesis\xa0data stream using UpdateShardCount or the AWS Management Console?', 'Typical scaling requests should take a few minutes to complete. Larger scaling requests will take longer than smaller ones.'), ('Q: What are the limitations of UpdateShardCount?', 'For information about limitations of UpdateShardCount, see the Amazon Kinesis Data Streams Service API Reference.'), ('Q: Does Amazon Kinesis Data Streams remain available when I change the throughput of my Amazon Kinesis\xa0data stream using UpdateShardCount or via resharding?', 'Yes. You can continue adding data to and reading data from your Amazon Kinesis\xa0data stream while you use UpdateShardCount or reshard to change the throughput of the data stream.'), ('Q: What is resharding?', 'Resharding is the process used to scale your\xa0data stream using a series of shard splits or merges. In a shard split, a single shard is divided into two shards, which increases the throughput of the data stream. In a shard merge, two shards are merged into a single shard, which decreases the throughput of the data stream. For more information, see Resharding a Data Stream\xa0in the Amazon Kinesis Data Streams developer guide.'), ('Q: How often can I and how long does it take to change the throughput of my Amazon Kinesis\xa0data stream by resharding it?', 'A resharding operation such as shard split or shard merge takes a few seconds. You can only perform one resharding operation at a time. Therefore, for an Amazon Kinesis\xa0data stream with only one shard, it takes a few seconds to double the throughput by splitting one shard. For a\xa0data stream with 1000 shards, it takes 30K seconds (8.3 hours) to double the throughput by splitting 1000 shards. We recommend increasing the throughput of your\xa0data stream ahead of the time when extra throughput is needed.'), ('Q: How do I change the data retention period of my Amazon Kinesis data stream?', 'Amazon Kinesis stores your data for up to 24 hours by default. You can raise data retention period to up to 7 days by enabling extended data retention.'), ('For more information about changing data retention period, see Changing Data Retention Period.', 'Q: How do I monitor the operations and performance of my Amazon Kinesis data stream?'), ('Amazon Kinesis Data Streams Management Console displays key operational and performance metrics such as throughput of data input and output of your Amazon Kinesis data streams. Amazon Kinesis Data Streams also integrates with Amazon CloudWatch so that you can collect, view, and analyze CloudWatch metrics for your data streams and shards within those data streams. For more information about Amazon Kinesis Data Streams metrics, see Monitoring Amazon Kinesis Data Streams with Amazon CloudWatch.', 'Please note that all stream-level metrics are free of charge. All enabled shard-level metrics are charged at Amazon CloudWatch Pricing. \xa0'), ('Q: How do I manage and control access to my Amazon Kinesis data stream?', 'Amazon Kinesis Data Streams integrates with AWS Identity and Access Management (IAM), a service that enables you to securely control access to your AWS services and resources for your users. For example, you can create a policy that only allows a specific user or group to add data to your Amazon Kinesis data stream. For more information about access management and control of your data stream, see Controlling Access to Amazon Kinesis Data Streams Resources using IAM.'), ('Q: How do I log API calls made to my Amazon Kinesis\xa0data stream for security analysis and operational troubleshooting?', 'Amazon Kinesis integrates with Amazon CloudTrail, a service that records AWS API calls for your account and delivers log files to you. For more information about API call logging and a list of supported Amazon Kinesis API operations, see Logging Amazon Kinesis API calls Using Amazon CloudTrail.'), ('Q: How do I effectively manage my Amazon Kinesis data streams and the costs associated with these data streams?', 'Amazon Kinesis Data Streams allows you to tag your Amazon Kinesis data streams for easier resource and cost management. A tag is a user-defined label expressed as a key-value pair that helps organize AWS resources. For example, you can tag your data streams by cost centers so that you can categorize and track your Amazon Kinesis Data Streams costs based on cost centers. For more information about Amazon Kinesis Data Streams tagging, see Tagging Your Amazon Kinesis Data Streams.'), ('Q: How can I describe how I’m utilizing my shard limit?', 'You can understand how you’re utilizing your shard limit for an account using the DescribeLimits API. The DescribeLimits API will return the shard limit and the number of open shards in your account. If you need to raise your shard limit, please request a limit increase. '), ('Q:\xa0When I use Kinesis Data Streams, how secure is my data?', 'Kinesis is secure by default. Only the account and\xa0data stream owners have access to the Kinesis resources they create. Kinesis supports user authentication to control access to data. You can use AWS IAM policies to selectively grant permissions to users and groups of users. You can securely put and get your data from Kinesis through SSL endpoints using the HTTPS protocol. If you need extra security you can use server-side encryption with AWS KMS master keys to encrypt data stored in your data stream. AWS KMS allows you to use AWS generated KMS master keys for encryption, or if you prefer you can bring your own master key into AWS KMS. Lastly, you can use your own encryption libraries to encrypt data on the client-side before putting the data into Kinesis.'), ('Q: Can I privately access Kinesis Data Streams APIs from my Amazon Virtual Private Cloud (VPC) without using public IPs?', 'Yes, you can privately access Kinesis Data Streams APIs from your Amazon Virtual Private Cloud (VPC) by creating VPC Endpoints. With VPC Endpoints, the routing between the VPC and Kinesis Data Streams is handled by the AWS network without the need for an Internet gateway, NAT gateway, or VPN connection. The latest generation of VPC Endpoints used by Kinesis Data Streams are powered by AWS PrivateLink, a technology that enables private connectivity between AWS services using Elastic Network Interfaces (ENI) with private IPs in your VPCs. To learn more about PrivateLink, visit the PrivateLink documentation.\xa0'), ('Q:\xa0Can I encrypt the data I put into a Kinesis data stream?', 'Yes, and there are two options for encrypting the data you put into a Kinesis data stream. You can use server-side encryption , which is a fully managed feature that automatically encrypts and decrypts data as you put and get it from a data stream. Or you can write encrypted data to a\xa0data stream by encrypting and decrypting on the client side.'), ('Q: Why should I use server-side encryption instead of client-side encryption?', 'Customers often choose server-side encryption over client-side encryption for one of the following reasons:'), ('Q: What is server-side encryption?', 'Server-side encryption for Kinesis Data Streams automatically encrypts data using a user specified AWS KMS master key (CMK) before it is written to the\xa0data stream storage layer, and decrypts the data after it is retrieved from storage. Encryption makes writes impossible and the payload and the partition key unreadable unless the user writing or reading from the\xa0data stream has the permission to use the key selected for encryption on the data stream. As a result, server-side encryption can make it easier to meet internal security and compliance requirements governing your data.'), ('With server-side encryption your client-side applications (producers and consumers) do not need to be aware of encryption, they do not need to manage CMKs or cryptographic operations, and your data is encrypted when it is at rest and in motion within the Kinesis Data Streams service. All CMKs used by the server-side encryption feature are provided by the AWS KMS. AWS KMS makes it easy to use an AWS-managed CMK for Kinesis(a “one-click” encryption method), your own AWS KMS generated CMK, or a CMK that you imported for encryption.', 'Q: Is there a server-side encryption getting started guide?'), ('Yes, there is a getting started guide in the user documentation.', 'Q: Does server-side encryption interfere with how my applications interact with Kinesis Data Streams?'), ('Possibly. This depends on the key you use for encryption and the permissions governing access to the key.', 'Q: Is there an additional cost associated with the use of server-side encryption?'), ('Yes, however if you are using the AWS-managed CMK for Kinesis and are not exceeding the free tier KMS API usage costs, then your use of server-side encryption is free. The following describes the costs by resource:', 'Keys:'), ('KMS API Usage:', 'Q: Which AWS regions offer server-side encryption for Kinesis Data Streams?'), ('Kinesis Data Streams server-side encryption is available in the AWS GovCloud region and all public regions except the China (Beijing) region.', 'Q: How do I start, update, or remove server-side encryption from a data stream?'), ('All of these operations can be completed using the AWS management console or using the AWS SDK. To learn more, see the Kinesis Data Streams server-side encryption getting started guide.', 'Q: What encryption algorithms is used for server-side encryption?'), ('Kinesis Data Streams uses an AES-GCM 256 algorithm for encryption.', 'Q: If I encrypt a\xa0data stream that already has data written to it, either in plain text or ciphertext, will all of the data in the\xa0data stream be encrypted or decrypted if I update encryption?'), ('No, only new data written into the\xa0data stream will be encrypted (or left decrypted) by the new application of encryption.', 'Q: What does server-side encryption for Kinesis Data Streams encrypt?'), ('Server-side encryption encrypts the payload of the message along with the partition key, which is specified by the\xa0data stream producer applications.', 'Q: Is server-Side encryption a shard specific feature or a stream specific feature?'), ('Server-side encryption is a stream specific feature.', 'Q: Can I change the CMK that is used to encrypt a specific data stream?'), ('Yes, using the AWS management console or the AWS SDK you can choose a new master key to apply to a specific data stream.', 'Q: Can you walk me through the encryption lifecycle of my data from the point in time when I send it to a Kinesis\xa0data stream with server-side encryption enabled, and when I retrieve it?'), ('The following walks you through how Kinesis Data Streams uses AWS KMS CMKs to encrypt a message before it is stored in the PUT path, and to decrypt it after it is retrieved in the GET path. Kinesis and AWS KMS perform the following actions (including decryption) when you call putRecord(s) or getRecords on a\xa0data stream with server-side encryption enabled.', 'Kinesis and AWS KMS perform the following actions (including decryption) when you call getRecords.'), ('\xa0', 'Q: Is Amazon Kinesis Data Streams available in AWS Free Tier?'), ('No. Amazon Kinesis Data Streams is not currently available in AWS Free Tier. AWS Free Tier is a program that offers free trial for a group of AWS services. For more details about AWS Free Tier, see AWS Free Tier.', 'Q: How much does Amazon Kinesis Data Streams cost?'), ('Amazon Kinesis Data Streams uses simple pay as you go pricing. There is neither upfront cost nor minimum fees and you only pay for the resources you use. The costs of Amazon Kinesis\xa0Data Streams has two core dimensions and one optional dimension:', 'For more information about Amazon Kinesis\xa0Data Streams costs, see Amazon Kinesis Data Streams Pricing.'), ('Q: Does my PUT Payload Unit cost change by using PutRecords operation instead of PutRecord operation?', 'PUT Payload Unit charge is calculated based on the number of 25KB payload units added to your Amazon Kinesis data stream. PUT Payload Unit cost is consistent when using PutRecords operation or PutRecord operation.'), ('Q: Am I charged for shards in "CLOSED" state?', 'A shard could be in "CLOSED" state after resharding. You will not be charged for shards in "CLOSED" state.'), ('Q: Other than Amazon Kinesis\xa0Data Streams costs, are there any other costs that might incur to my Amazon Kinesis\xa0Data Streams usage?', 'If you use Amazon EC2 for running your Amazon Kinesis Applications, you will be charged for Amazon EC2 resources in addition to Amazon Kinesis\xa0Data Streams costs.'), ('Amazon Kinesis Client Library (KCL) uses Amazon DynamoDB table to track state information of record processing. If you use KCL for you Amazon Kinesis Applications, you will be charged for Amazon DynamoDB resources in addition to Amazon Kinesis Data Streams costs.', 'If you enable Enhanced Shard-Level Metrics, you will be charged for Amazon\xa0CloudWatch\xa0cost associated with enabled shard-level metrics in addition to Amazon Kinesis Data Streams costs.'), ('Please note that the above are three common but not exhaustive cases. ', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/cloud-directory/faqs/': [(' What is Amazon Cloud Directory?', ' Amazon Cloud Directory is a cloud-native, highly scalable, high-performance, multi-tenant directory service that provides web-based directories to make it easy for you to organize and manage all your application resources such as users, groups, locations, devices, and policies, and the rich relationships between them. Cloud Directory is a foundational building block for developers to create directory-based solutions easily and without having to worry about deployment, global scale, availability, and performance.'), (' Unlike existing traditional directory systems, Cloud Directory does not limit organizing directory objects in a single fixed hierarchy. In Cloud Directory, you can organize directory objects into multiple hierarchies to support multiple organizational pivots and relationships across directory information. For example, a directory of users may provide a hierarchical view based on reporting structure, location, and project affiliation. Similarly, a directory of devices may have multiple hierarchical views based on its manufacturer, current owner, and physical location.', ' Cloud Directory provides virtually unlimited directories. It scales each directory to hundreds of millions of nodes automatically while offering consistent performance. Cloud Directory is optimized for a high rate of low-latency, eventually consistent reads. Developers model directory objects using extensible schemas to enforce data correctness constraints automatically and to make it easier to program against. Cloud Directory offers rich information lookup based on customer-defined indexed attributes, thus enabling fast tree traversals and searches within the directory trees. Cloud Directory data is encrypted at rest and in transit.'), ('What are the important characteristics of Amazon Cloud Directory?', 'Important characteristics include:'), ('What are core use cases for Cloud Directory?', ' Customers can use Cloud Directory to build applications such as IoT device registries, social networks, network configurations, and user directories. Each of these use cases typically needs to organize data hierarchically, perform high-volume and low-latency lookups, and scale to hundreds of millions of objects with global availability.'), (' What kind of customers can use Cloud Directory?', ' Customers of all sizes can use Amazon Cloud Directory to build directory-based applications easily.'), (' How is Cloud Directory different than traditional directories?', ' Amazon Cloud Directory is a foundational service for developers to build cloud-native directories for hundreds of millions of objects and relationships. It provides the necessary APIs for you to create a directory with a schema, add objects and relationships, and attach policies to those objects and relationships.'), (' Traditional LDAP-based directories are designed as IT tools for organizations to manage users and devices. They provide authentication and policy frameworks, but lack the scalability to manage hundreds of millions of objects and relationships. Traditional directories are optimized for IT use cases, not for developers building cloud, mobile, and IoT applications.', ' When should I use Cloud Directory versus AWS Directory Service for Microsoft Active Directory (Enterprise Edition) or Amazon Cognito User Pools?'), (' AWS Directory Service for Microsoft Active Directory (Enterprise Edition), or AWS Microsoft AD, is designed to support Windows-based workloads that require Microsoft Active Directory. AWS Microsoft AD is intended for enterprise IT use cases and applications that depend on Microsoft Active Directory.', ' Amazon Cognito User Pools is an identity solution for developers that need authentication, federation, and credentials management for users.'), (' Amazon Cloud Directory is designed for developers who need to manage large volumes of hierarchical data, and need a flexible directory solution that supports multiple sets of relationships and built-in data validation.', 'What are the key terms and concepts that I need to be aware of to use Amazon Cloud Directory?'), (' To use Amazon Cloud Directory, you need to know the following key terms: ', 'What is a directory?'), (' A directory defines the scope for the data store (like a table in Amazon DynamoDB), completely isolating it from all other directories in the service. It also defines the transaction scope, query scope, and the like. A directory also represents the root object for a customer’s tree and can have multiple directory objects as its children. Customers must apply schemas at the directory level. ', 'What is a schema?'), (' A schema defines facets, attributes, and constraints allowed within a directory. This includes defining: ', 'What is a facet?'), (' A facet is a collection of attributes and constraints. A single or multiple facets when combined help define the objects in a directory. For example, Person and Device can be facets that define corporate employees with the associations of multiple devices. ', 'What is an object?'), (' An object represents a structured data entity in a directory. An object in a directory is intended to capture metadata about a physical or logical entity, usually for the purpose of information discovery and enforcing policies. For example, users, devices, and applications are all types of objects. An object’s structure and type information are expressed using a collection of facets. ', 'What is an attribute?'), (' An attribute is a user-defined unit of metadata associated with an object. For example, the user object can have an attribute called email-address. Attributes are always associated with an object. ', 'What is a hierarchy?'), (' A hierarchy is a view in which groups and objects are organized in parent-child relationships similar to a file system in which folders have files and subfolders beneath them. Amazon Cloud Directory supports organizing objects into multiple hierarchies. ', 'What is a policy?'), (' A policy is a specialized object type with attributes that define the type of policy and policy document. A policy can be attached to objects or the root of a hierarchy. By default, objects inherit policies from their parents. Amazon Cloud Directory does not interpret policies. \xa0', 'How do I provision a new directory in Amazon Cloud Directory?'), ('You can provision a new directory in Amazon Cloud Directory with the following steps: ', 'You can also use the AWS Command Line Interface (CLI) to perform the same steps to create a new Amazon Cloud Directory container. Amazon Cloud Directory provides an SDK to create, read, delete, and update directories programmatically. '), ('How do I create and manage schemas?', ' Amazon Cloud Directory provides an SDK and CLI to create, read, and update schemas. Cloud Directory also supports uploading a compliant JSON file to create a schema. You can also create and manage schemas using the Cloud Directory console. '), ('Does Amazon Cloud Directory provide any sample schemas?', ' Yes, currently Amazon Cloud Directory provides the following sample schemas: '), (' What are eventually consistent and strongly consistent read operations in Cloud Directory?', 'Amazon Cloud Directory is a distributed directory store. This means that data is distributed to multiple servers in different Availability Zones.'), ('When reading data from Cloud Directory, you must specify either an eventually consistent or strongly consistent read type operation. The read type is based on consistency level. The two consistency levels are EVENTUAL for eventually consistent reads and SERIALIZABLE for strongly consistent reads. For more information, see Consistency Levels.', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/inspector/faqs/': [('Q: What is Amazon Inspector? Amazon Inspector is an automated security assessment service that helps you test the security state of your applications running on Amazon EC2.', 'Q: What can I do with Amazon Inspector? Amazon Inspector allows you to automate security vulnerability assessments throughout your development and deployment pipeline or against static production systems. This allows you to make security testing a more regular occurrence as part of development and IT operations. Amazon Inspector is agent-based, API-driven, and delivered as a service to make it easy to deploy, manage, and automate.'), ('Q: What makes up the Amazon Inspector service? Amazon Inspector consists of an Amazon-developed agent that is installed in the operating system of your Amazon EC2 instances and a security assessment service that uses telemetry from the agent and AWS configuration to assess instances for security exposures and vulnerabilities.', 'Q: What is an assessment template? An assessment template is a configuration that you create in Amazon Inspector to define your assessment run. This assessment template includes a rules package against which you want Amazon Inspector to evaluate your assessment target, the duration of the assessment run, Amazon Simple Notification Service (SNS) topics to which you want Amazon Inspector to send notifications about assessment run states and findings, and Amazon Inspector-specific attributes (key/value pairs) that you can assign to findings generated by the assessment run.'), ("Q: What is an assessment run? An assessment run is the process of discovering potential security issues through the analysis of your assessment target's configuration and behavior against specified rule packages. During an assessment run, the agent monitors, collects, and analyzes behavioral data (telemetry) within the specified target, such as the use of secure channels, network traffic among running processes, and details of communication with AWS services. Next, the agent analyzes the data and compares it against a set of security rule packages specified in the assessment template used during the assessment run. A completed assessment run produces a list of findings - potential security issues of various severity.", 'Q: Is there any performance impact during an Amazon Inspector assessment run? Amazon Inspector and the Amazon Inspector Agent have been designed for minimal performance impact during the assessment run process.'), ('Q: What is an assessment target? An assessment target represents a collection of AWS resources that work together as a unit to help you accomplish your business goal(s). Amazon Inspector evaluates the security state of the resources that constitute the assessment target. You create an assessment target by using Amazon EC2 tags, and you can then define these tagged resources as an assessment target for an assessment run defined by the assessment template.', 'Q: What is a finding? A finding is a potential security issue discovered during the Amazon Inspector assessment run of the specified target. Findings are displayed in the Amazon Inspector console or retrieved through the API, and contain both a detailed description of the security issue and a recommendation on how to fix it.'), ('Q: What is a rules package? A rules package is a collection of security tests that can be configured as part of an assessment template and assessment run. Amazon Inspector has many rules packages including common vulnerabilities and exposures (CVE), Center for Internet Security (CIS) Operating System configuration benchmarks, and security best practices. See the Amazon Inspector documentation for a full list of rules packages available.', 'Q: Can I define my own rules for assessment templates? No. Only the pre-defined rules will initially be allowed for assessment runs. However, over time we are exploring the inclusion of both premium rules sets from vendors in the AWS Marketplace and self-developed custom rules.'), ('Q: Which applications can Inspector analyze for vulnerabilities? Amazon Inspector finds applications by querying the package manager or software installation system on the operating system where the agent is installed. This means that software that was installed through the package manager is assessed for vulnerabilities. The version and patch level of software that is not installed through these methods is not recognized by Inspector. For example, software installed via apt, yum, or Microsoft Installer will be assessed by Inspector. Software installed through make config / make install, or binary files copied directly to the system using automation software such as Puppet or Ansible will not be assessed by Inspector.', 'Q: What is an assessment report, and what does it include? An Amazon Inspector assessment report can be generated for an assessment run once it has been successfully completed. An assessment report is a document that details what is tested in the assessment run, and the results of the assessment. The results of your assessment are formatted into a standard report, which can be generated to share results within your team for remediation actions, to enrich compliance audit data, or to store for future reference.'), ('You can select from two types of report for your assessment, a findings report or a full report. The findings report contains an executive summary of the assessment, the instances targeted, the rules packages tested, the rules that generated findings, and detailed information about each of these rules along with the list of instances that failed the check. The full report contains all the information in the findings report, and additionally provides the list of rules that were checked and passed on all instances in the assessment target.', 'Q: What happens if some of my targets are unavailable when I run an assessment? Amazon Inspector will gather vulnerability data for all available targets configured for the assessment template and return any appropriate security findings for the available targets. If there are no available targets for the assessment template when the run is started, the system will report that the assessment could not be run and will return the following notification: “The assessment run could not executed at this time as there are no targeted instances available for the selected assessment template.”'), ('Q: How do Targets become unavailable? Targets in an assessment could be unavailable for a number of reasons, such as: the EC2 instance is down or unresponsive; the Tagged (targeted) instance does not have the Amazon Inspector Agent installed; the installed Amazon Inspector Agent is unavailable or cannot return vulnerability data.', 'Q: What is the pricing for Amazon Inspector? Inspector pricing is based on the number of assessment runs and the number of agents or systems that were assessed during those runs. We call this “agent-assessments.” An on-demand billing period is one calendar month like all AWS services. For example:'), ('\xa0\xa0\xa0\xa0 1 assessment run against 1 agent = 1 agent-assessment \xa0\xa0\xa0\xa0 1 assessment run against 10 agents = 10 agents-assessments \xa0\xa0\xa0\xa0 10 assessment runs against 2 agents each = 20 agent-assessments \xa0\xa0\xa0\xa0 30 assessment runs against 10 agents each = 300 agent-assessments', 'If the above represented the Amazon Inspector assessment runs activity in your account for a given billing period, you would be charged for 331 total agent-assessments.'), ('The price of each individual agent-assessment is based on a tiered pricing model. As you move up the volume of agent-assessments in a given billing period, you pay a lower price per agent-assessment. For example, the first two tiers of agent-assessment pricing are:', '\xa0\xa0\xa0\xa0 First 250 agent-assessments = $0.30 per agent-assessment \xa0\xa0\xa0\xa0 Next 750 agent-assessments = $0.25 per agent-assessment'), ('So for our example above of 331 total agent-assessments in a given billing period, you would be charged $0.30 for the first 250 and $0.25 for the next 81, or $95.25 total for the billing period. See the Amazon Inspector pricing page for the full pricing table.', 'Q: Is there a free trial for Amazon Inspector? Yes. Amazon Inspector offers the first 250 agent-assessments at no cost for the first 90 days of using the service. All AWS accounts new to the Amazon Inspector service are eligible.'), ('Q: What Operating Systems does Amazon Inspector support? Please see the Amazon Inspector documentation for a current list of supported operating systems. ', 'Q: In what regions is Amazon Inspector available? Please see the Amazon Inspector documentation for a current list of supported regions. '), ('Q: Which Linux kernel versions are supported for Amazon Inspector assessments? You can run successful assessments for an EC2 instance with a Linux-based OS using the Common Vulnerabilities and Exposures (CVE), Center for Internet Security (CIS) Benchmarks, or Security Best Practices rules packages regardless of the kernel version. However, to run an assessment using the Runtime Behavior Analysis rules package, your Linux instance must have a kernel version that is supported for Amazon Inspector. An up-to-date list of Linux kernel versions that are supported for Amazon Inspector assessments is available here.', 'Q: Amazon Inspector sounds great, how do I get started? Simply sign up for Amazon Inspector from the AWS Management Console. Once signed up, you install the appropriate Amazon Inspector Agent on your Amazon EC2 instances, create a new assessment template, select the rules packages you want to use, and schedule an assessment run. Once it completes, the system will generate a findings report on any issues it identified for your environment.'), ("Q: Does the Amazon Inspector Agent have to be installed on all of the EC2 instances I wish to assess? Yes. During an assessment run, the Amazon Inspector Agent monitors the behavior of the operating system and applications of the EC2 instance it's installed on, collects configuration and behavioral data, and passes the data to the Amazon Inspector service.", 'Q: How can I install the Amazon Inspector Agent? There are several ways to install the agent. For simple installations, you can install it manually on each instance or do a one-time load using the AWS Systems Manager Run Command document (AmazonInspector-ManageAWSAgent). For larger deployments, you can automate agent installations using the EC2 User Data Function when configuring your instances or you can create automated installs of the agent using AWS Lambda. You can also launch an EC2 instance using the Amazon Linux AMI with the pre-installed Amazon Inspector Agent from the EC2 Console or the AWS Marketplace.'), ('Q: How do I check whether the Amazon Inspector Agent is installed and healthy on my EC2 instances? You can view the status of the Amazon Inspector Agent for all the EC2 instances in your assessment target by using the ‘Preview Targets’ functionality available in the Inspector console and through the PreviewAgents API query. Agent status includes whether the agent is installed on the EC2 instance and the health of the agent. Along with the Inspector Agent status on the targeted EC2 instance, the instance ID, public hostname, and public IP address (if defined) are also displayed, along with links into the EC2 console for each instance.', 'Q: Can Amazon Inspector run without tagging the resources? No. Amazon Inspector requires you to use Amazon EC2 instance tags in order to run an assessment.'), ('Q: Does Amazon Inspector access other AWS services in my account? Amazon Inspector needs to enumerate your EC2 instances and tags to identify the instances specified in the assessment target. Amazon Inspector gets access to these through a service-linked role that is created on your behalf when you get started with Inspector as a new customer or in a new region. The Inspector service-linked role is managed by Amazon Inspector, so you don’t have to worry about inadvertently revoking permissions required by Amazon Inspector. For some existing customers, an IAM role that was registered while getting started with Inspector might be used for accessing other AWS services until the Inspector service-linked role is created. You can create the Inspector service-linked role through the Inspector console’s dashboard page. ', 'Q: I use a Network Address Translation (NAT) for my instances. Will Amazon Inspector work with these instances? Yes. Instances that use a NAT are supported by Amazon Inspector with no action required from you.'), ('Q: I use a Proxy for my instances. Will Amazon Inspector work with these instances? Yes. The Amazon Inspector Agent supports proxy environments. For Linux instances, we support HTTPS Proxy, and for Windows instances, we support WinHTTP proxy. See the Amazon Inspector User Guide for instructions to configure Proxy support for the Amazon Inspector Agent.', 'Q: I would like to automate the assessment of my infrastructure on a regular basis. Do you provide an automated way to submit assessments? Yes. Amazon Inspector provides a full API allowing automatic creation of application environments, creation of assessments, evaluation of policies, creation of policy exceptions, and filters as well as retrieval of the results.'), ('Q: Can I schedule security assessments to run at certain dates and times? Yes. Amazon Inspector assessments can be triggered by any Amazon CloudWatch Event. You can set up a recurring Schedule event with either a simple fixed recurring rate or a more detailed Cron expression. ', 'Q: Can I trigger security assessments to run based on an event? Yes. You can use Amazon CloudWatch Events to create event patterns which monitor other AWS services for actions to trigger an assessment. For example, you can create an event which monitors AWS Auto Scaling for new Amazon EC2 Instances being launched, or monitors AWS CodeDeploy notifications for when a code deployment has been successfully completed. Once CloudWatch Events have been configured against Amazon Inspector templates, these assessment events will be displayed in the Inspector console as part of your assessment templates so you can see all of the automated triggers for that assessment.'), ('Q: Can I set up Amazon Inspector assessments through AWS CloudFormation? Yes, you can create Amazon Inspector resource groups, assessment targets, and assessment templates using AWS CloudFormation templates. This allows you to automatically set up security assessments for your EC2 instances as they are deployed. In your CloudFormation template, you can also bootstrap installation of the Inspector Agent on EC2 instances by using agent installation commands in either AWS::CloudFormation::Init or EC2 user data. Alternatively, you can create EC2 instances in your CloudFormation template using an AMI with the Inspector Agent pre-installed.', 'Q: Where can I find metrics information on my Amazon Inspector assessments? Amazon Inspector automatically publishes metrics data on your assessments to Amazon CloudWatch. If you are a CloudWatch user, your Inspector assessment statistics will automatically be populated to CloudWatch. The Inspector metrics that are currently available are: number of assessment runs, agents targeted, and findings generated. For more details, see the Amazon Inspector documentation for details on the assessment metrics published to CloudWatch.'), ('Q: Can Amazon Inspector be integrated with other AWS services for logging and notifications? Amazon Inspector integrates with Amazon SNS to provide notification for various events such as monitoring milestones, failures, or expiration of exceptions and integrates with AWS CloudTrail for logging of calls to Amazon Inspector.', 'Q: What is the “CIS Operating System Security Configuration Benchmarks” rules package? CIS Security Benchmarks are provided by the Center for Internet Security and are the only consensus-based, best-practice security configuration guides both developed and accepted by government, business, industry, and academia. Amazon Web Services is a CIS Security Benchmarks Member company and the list of Amazon Inspector certifications can be viewed here. CIS benchmark rules are designed to be pass/fail security checks. For every CIS check that fails, Inspector generates a finding with High severity. Additionally, an Informational finding is generated for each instance that lists all the CIS rules that are checked, and the pass/fail result for each rule. '), ("Q: What is the “Common Vulnerabilities and Exposures” rules package? The Common Vulnerabilities and Exposures or CVE rules check for exposure to publicly known information security vulnerabilities and exposures. CVE rule details are available publicly at the National Vulnerability Database (NVD). We use the NVD's Common Vulnerability Scoring System (CVSS) as the primary source of severity information. In case a CVE is not scored by NVD but is present in Amazon Linux AMI Security Advisory (ALAS), we use the severity from Amazon Linux advisory. In case neither of these scores is available for a CVE, we do not report that CVE as a finding. We check daily for latest information from NVD and ALAS and update our rules packages accordingly.", 'Q: What is the severity of a finding? Each Amazon Inspector rule has an assigned severity level, which Amazon has classified as High, Medium, Low, or Informational. Severity is intended to help you prioritize your responses to findings. '), ('Q: How is the severity determined? Severity of a rule is based on potential impact of the security issue found. Although some rules packages have Severity levels provided as part of the rules they provide, these can often differ by rules set. Amazon Inspector has normalized the severity for findings across all available rules packages by mapping the individual severities to common High, Medium, Low, and Informational classifications. For “High”, “Medium”, and “Low” severity findings, the higher the severity of the finding, the more security impact the underlying issue has. Findings that are classified as “Informational” are provided to advise you of security issues which might not have an immediate security impact. ', 'Q: When I describe findings via the API (DescribeFindings), each finding has a “numericSeverity” attribute. What does this attribute signify? The “numericSeverity” attribute is the numeric representation of the severity of a finding. The numeric severity values map to Severity as follows: \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 Informational = 0.0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 Low = 3.0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 Medium = 6.0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 High = 9.0'), ('Q: Does Amazon Inspector work with AWS partner solutions? Yes, Amazon Inspector has public facing APIs that are available for customers and AWS partners to utilize. Several partners have integrated with Amazon Inspector incorporating findings into email, ticketing systems, pager platforms, or broader security dashboards. For detail on supporting partners, please visit the Amazon Inspector Partners page.', 'Q: Is Amazon Inspector a HIPAA eligible service? Yes, Amazon Inspector is a HIPAA eligible service and has been added to the AWS Business Associate Addendum (BAA). If you have an executed BAA with AWS, you can run Inspector on your EC2 instances that contain protected health information (PHI).'), ('Q: What compliance and assurance programs does Amazon Inspector support? Inspector supports SOC 1, SOC 2, SOC 3, ISO 9001, ISO 27001, ISO 27017, ISO 27018, and HIPAA. Inspector meets the controls for FedRAMP and we’re waiting for the completion of the audit report. If you want to learn more about the AWS services in scope by compliance program, please visit the AWS Services in Scope Page.', '\xa0'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/certificate-manager/faqs/': [('Q: What is AWS Certificate Manager (ACM)?', 'AWS Certificate Manager (ACM) is a service that lets you easily provision, manage, and deploy Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates for use with AWS services. SSL/TLS certificates are used to secure network communications and establish the identity of websites over the Internet. ACM removes the time-consuming manual process of purchasing, uploading, and renewing SSL/TLS certificates. With ACM, you can request a certificate, deploy it on AWS resources such as Elastic Load Balancers, Amazon CloudFront distributions, or APIs on Amazon API Gateway, and let AWS Certificate Manager handle certificate renewals. You can also import third-party certificates into ACM and associate them with supported AWS Services. SSL/TLS certificates provisioned through ACM are free. You pay only for the AWS resources you create to run your application. '), ('Q: What is an SSL/TLS certificate?', 'SSL/TLS certificates allow web browsers to identify and establish encrypted network connections to web sites using the Secure Sockets Layer/Transport Layer Security (SSL/TLS) protocol. Certificates are used within a cryptographic system known as a public key infrastructure (PKI). PKI provides a way for one party to establish the identity of another party using certificates if they both trust a third party- known as a certificate authority. The Concepts topic in the ACM User Guide provides additional background information and definitions.'), ('Q: What can I do with AWS Certificate Manager?', 'You can request and provision SSL/TLS certificates and use services integrated with ACM – such as Elastic Load Balancing, Amazon CloudFront, or Amazon API Gateway – to deploy certificates to your website or application. Once you validate ownership of the requested domain and the certificate is issued, you can select the SSL/TLS certificate from a drop-down list in the AWS Management Console to deploy it. Alternatively, you can deploy certificates provided by ACM to AWS resources using AWS Command Line Interface (CLI) commands or API calls. ACM manages certificate renewals and certificate deployment for you. '), ('Q: What are the benefits of using AWS Certificate Manager?', 'ACM makes it easier to enable SSL/TLS for a website or application on the AWS platform. ACM eliminates many of the manual processes previously associated with using and managing SSL/TLS certificates. ACM can also help you avoid downtime due to misconfigured, revoked, or expired certificates by managing renewals. You get SSL/TLS protection and easy certificate management. Enabling SSL/TLS can help improve the search rankings for your site and help you meet regulatory compliance requirements for encrypting data in transit.'), ('To validate that you own or control the domain name in your certificate, ACM uses either DNS validation or email validation based on your selection when you request a certificate. With DNS validation, you simply write a CNAME record to your DNS configuration to establish control of your domain name. To further simplify the DNS validation process, the ACM management console can configure DNS records for you if you manage your DNS records with Amazon Route 53. This makes it easy to establish control of your domain name with a few mouse clicks. Once the CNAME record is configured, ACM can automatically renew DNS-validated certificates before they expire, as long as the DNS record remains in place and the certificates are in use. Renewals are fully automatic and touchless. ACM also supports email validation for customers who don’t have the ability to update the DNS configuration for their domain.', 'When you use ACM, certificate private keys are securely protected and stored using strong encryption and key management best practices. ACM lets you use the AWS Management Console, AWS CLI, or AWS Certificate Manager APIs to centrally manage all of the SSL/TLS certificates provided by ACM in an AWS Region. ACM is integrated with other AWS services, so you can request an SSL/TLS certificate and provision it with your Elastic Load Balancing load balancer or Amazon CloudFront distribution from the AWS Management Console, through AWS CLI commands, or with API calls.'), ('Q: How can I get started with ACM?', 'To get started with AWS Certificate Manager, navigate to Certificate Manager in the AWS Management Console, and use the wizard to request an SSL/TLS certificate by entering the name of your site. You can also request a certificate using the AWS CLI or API. After ACM receives approval from the domain owner and the SSL/TLS certificate is issued, you can use it with other AWS services that are integrated with ACM. For each integrated service, you simply select the SSL/TLS certificate you want from a drop-down list in the AWS Management Console. Alternatively, you can execute an AWS CLI command or call an AWS API to associate the certificate with your resource. The integrated service then deploys the certificate to the resource you selected. For more information about requesting and using certificates provided by AWS Certificate Manager, visit Getting Started in the AWS Certificate Manager User Guide.'), ('Q: Why does ACM validate domain ownership?', 'Certificates are used to establish the identity of your site and secure connections between browsers and applications and your site. To issue a publicly trusted certificate, Amazon must validate that the certificate requestor has control over the domain name in the certificate request.'), ('Q: How does ACM validate domain ownership before issuing a certificate for a domain?', 'Prior to issuing a certificate, ACM validates that you own or control the domain names in your certificate request. You can choose DNS validation or email validation when requesting a certificate. With DNS validation, you can validate domain ownership by adding a CNAME record to your DNS configuration. Refer to DNS validation for further details. If you do not have the ability to write records to the public DNS configuration for your domain, you can use email validation instead of DNS validation. With email validation, ACM sends emails to the registered domain owner, and the owner or an authorized representative can approve issuance for each domain name in the certificate request. Refer to Email validation for further details.'), ('Q. Which validation method should I use: DNS or email?', 'We recommend that you use DNS validation if you have the ability to change the DNS configuration for your domain. Customers who are unable to receive validation emails from ACM and those using a domain registrar that does not publish domain owner email contact information in WHOIS should use DNS validation. If you cannot modify your DNS configuration, you should use email validation.'), ('Q. Can I convert an existing certificate from email validation to DNS validation?', 'No, but you can request a new, free certificate from ACM and choose DNS validation for the new one.'), ('Q: What type of certificates does ACM provide?', 'ACM provides Domain Validated (DV) certificates for use with websites and applications that terminate SSL/TLS. For more details about certificates provided by ACM, see Certificate Characteristics.'), ('Q: With which AWS services can I use certificates provided by ACM?', 'You can use ACM with the following AWS services: • Elastic Load Balancing – Refer to the Elastic Load Balancing documentation • Amazon CloudFront – Refer to the CloudFront documentation • Amazon API Gateway – Refer to the API Gateway documentation • AWS Elastic Beanstalk – Refer to the AWS Elastic Beanstalk documentation • AWS CloudFormation – Refer to the AWS CloudFormation documentation'), ('Q: In what Regions is ACM available?', 'Please visit the AWS Global Infrastructure pages to see the current Region availability for AWS services. To use an ACM certificate with Amazon CloudFront, you must request or import the certificate in the US East (N. Virginia) region. ACM certificates in this region that are associated with a CloudFront distribution are distributed to all the geographic locations configured for that distribution. '), ('Q: Can I use the same certificate in more than one AWS Region?', 'It depends on whether you’re using Elastic Load Balancing or Amazon CloudFront. To use a certificate with Elastic Load Balancing for the same site (the same fully qualified domain name, or FQDN, or set of FQDNs) in a different Region, you must request a new certificate for each Region in which you plan to use it. To use an ACM certificate with Amazon CloudFront, you must request the certificate in the US East (N. Virginia) region. ACM certificates in this region that are associated with a CloudFront distribution are distributed to all the geographic locations configured for that distribution. '), ('Q: Can I copy a certificate between Regions?', 'Not at this time.'), ('Q: Can I provision a certificate with ACM if I already have a certificate from another provider for the same domain name?', 'Yes. '), ('Q: Can I use certificates on Amazon EC2 instances or on my own servers?', 'No. At this time, certificates provided by ACM can only be used with specific AWS services. See With which AWS services can I use certificates provided by ACM?.'), ('Q: Is there a limit to the number of certificates I can provision with ACM?', 'You can provision up to 100 certificates per account in each Region by default. Each certificate provisioned with ACM can have up to ten fully qualified domain names. You may request a limit increase by visiting the AWS Support Center. Refer to the AWS Documentation for further details. '), ('Back to Top ', 'Q: How can I provision a certificate from ACM?'), ('You can use the AWS Management Console, AWS CLI, or ACM APIs/SDKs. To use the AWS Management Console, navigate to the Certificate Manager, choose Request a certificate, enter the domain name for your site, and follow the instructions on the screen to complete your request. You can add additional domain names to your request if users can reach your site by other names. Before ACM can issue a certificate, it validates that you own or control the domain names in your certificate request. You can choose DNS validation or email validation when requesting a certificate. With DNS validation, you write a record to the public DNS configuration for your domain to establish that you own or control the domain. After you use DNS validation once to establish control of your domain, you can obtain additional certificates and have ACM renew existing certificates for the domain as long as the record remains in place and the certificate remains in use. You do not have to validate control of the domain again. If you choose email validation instead of DNS validation, emails are sent to the domain owner requesting approval to issue the certificate. After validating that you own or control each domain name in your request, the certificate is issued and ready to be provisioned with other AWS services, such as Elastic Load Balancing or Amazon CloudFront. Refer to the ACM Documentation for details. ', 'Q: How long does it take for a certificate to be issued?'), (' The time to issue a certificate after all of the domain names in a certificate request have been validated may be several hours or longer.', 'Q: What happens when I request a certificate?'), ('ACM attempts to validate ownership or control of each domain name in your certificate request, according to the validation method you chose, DNS or email, when making the request. The status of the certificate request is Pending validation while ACM attempts to validate that you own or control the domain. Refer to the DNS validation and Email validation sections below for more information about the validation process. After all of the domain names in the certificate request are validated, the time to issue certificates may be several hours or longer. When the certificate is issued, the status of the certificate request changes to Issued and you can start using it with other AWS services that are integrated with ACM.', 'Q: Why is the status of my certificate request “Pending validation”?'), ('Certificates that have been requested but not yet validated have status Pending validation. The domain in the certificate request must be validated before the certificate can be issued. To determine why your request may be in this state, please visit the ACM Troubleshooting Guide.', 'Q: Why does the status of my certificate request appear as Failed?'), ('The process for validating control of the domain can fail for several reasons. Reasons include, but are not limited to, the domain being included on a list of URLs for web resources that are believed to contain malware or phishing content. To determine why your request failed, please visit the ACM Troubleshooting Guide.', 'Q: Why does the status of my certificate request appear as Validation timed out?'), ('Requests for ACM certificates time out if they are not validated within 72 hours. Refer to the ACM User Guide for troubleshooting suggestions.', 'Q: Does ACM support checking of DNS Certificate Authority Authorization (CAA) records?'), ('Yes. DNS Certificate Authority Authorization (CAA) records allow domain owners to specify which certificate authorities are authorized to issue certificates for their domain. When you request an ACM Certificate, AWS Certificate Manager looks for a CAA record in the DNS zone configuration for your domain. If a CAA record is not present, then Amazon can issue a certificate for your domain. Most customers fall into this category.', 'If your DNS configuration contains a CAA record, that record must specify one of the following CAs before Amazon can issue a certificate for your domain: amazon.com, amazontrust.com, awstrust.com, or amazonaws.com. Refer to Configure a CAA Record or Troubleshooting CAA Problems in the AWS Certificate Manager User Guide for more information.'), ('Q: Does ACM support any other methods for validating a domain?', 'Not at this time.'), ('\xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0\xa0 \xa0\xa0\xa0 \xa0\xa0\xa0 Back To Top >> ', ' Q. What is DNS validation?'), ('With DNS validation, you can validate your ownership of a domain by adding a CNAME record to your DNS configuration. DNS Validation makes it easy for you to establish that you own a domain when requesting SSL/TLS certificates from ACM.', 'Q. What are the benefits of DNS validation?'), ('DNS validation makes it easy to validate that you own or control a domain so that you can obtain an SSL/TLS certificate. With DNS validation, you simply write a CNAME record to your DNS configuration to establish control of your domain name. To simplify the DNS validation process, the ACM management console can configure DNS records for you if you manage your DNS records with Amazon Route 53. This makes it easy to establish control of your domain name with a few mouse clicks. Once the CNAME record is configured, ACM automatically renews certificates that are in use (associated with other AWS resources) as long as the DNS validation record remains in place. Renewals are fully automatic and touchless.', 'Q. Who should use DNS validation?'), ('Anyone who requests a certificate through ACM and has the ability to change the DNS configuration for the domain they are requesting should consider using DNS validation.', 'Q. Does ACM still support email validation?'), ('Yes. ACM continues to support email validation for customers who can’t change their DNS configuration.', 'Q. What records do I need to add to my DNS configuration to validate a domain?'), ('You must add a CNAME record for the domain you want to validate. For example, to validate the name www.example.com, you add a CNAME record to the zone for example.com. The record you add contains a random token that ACM generates specifically for your domain and your AWS account. You can obtain the two parts of the CNAME record (name and label) from ACM. For further instructions, refer to the ACM User Guide.', 'Q. How can I add or modify DNS records for my domain?'), ('For more information about how to add or modify DNS records, check with your DNS provider. The Amazon Route 53 DNS documentation provides further information for customers who use Amazon Route 53 DNS.', 'Q. Can ACM simplify DNS validation for Amazon Route 53 DNS customers?'), ('Yes. For customers who are using Amazon Route 53 DNS to manage DNS records, the ACM console can add records to your DNS configuration for you when you request a certificate. Your Route 53 DNS hosted zone for your domain must be configured in the same AWS account as the one you are making the request from, and you must have sufficient permissions to make a change to your Amazon Route 53 configuration. For further instructions, refer to the ACM User Guide.', 'Q. Does DNS Validation require me to use a specific DNS provider?'), ('No. You can use DNS validation with any DNS provider as long as the provider allows you to add a CNAME record to your DNS configuration.', 'Q. How many DNS records do I need if I want more than one certificate for the same domain?'), ('One. You can obtain multiple certificates for the same domain name in the same AWS account using one CNAME record. For example, if you make 2 certificate requests from the same AWS account for the same domain name, you need only 1 DNS CNAME record.', 'Q. Can I validate multiple domain names with the same CNAME record?'), ('No. Each domain name must have a unique CNAME record.', 'Q. Can I validate a wildcard domain name using DNS validation?'), ('Yes.', 'Q. How does ACM construct CNAME records?'), ('DNS CNAME records have two components: a name and a label. The name component of an ACM-generated CNAME is constructed from an underscore character (_) followed by a token, which is a unique string that is tied to your AWS account and your domain name. ACM prepends the underscore and token to your domain name to construct the name component. ACM constructs the label from an underscore character prepended to a different token which is also tied to your AWS account and your domain name. ACM prepends the underscore and token to a DNS domain name used by AWS for validations: acm-validations.aws. The following examples show the formatting of CNAMEs for www.example.com, subdomain.example.com, and *.example.com.', '_TOKEN1.www.example.com\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 CNAME\xa0\xa0\xa0\xa0 _TOKEN2.acm-validations.aws _TOKEN3.subdomain.example.com\xa0 CNAME\xa0 \xa0\xa0 _TOKEN4.acm-validations.aws _TOKEN5.example.com\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 CNAME\xa0\xa0\xa0\xa0 _TOKEN6.acm-validations.aws'), ('Notice that ACM removes the wildcard label (*) when generating CNAME records for wildcard names. As a result, the CNAME record generated by ACM for a wildcard name (such as *.example.com) is the same record returned for the domain name without the wildcard label (example.com).', 'Q. Can I validate all subdomains of a domain using one CNAME record?'), ('No. Each domain name, including host names and subdomain names, must be validated separately, each with a unique CNAME record.', 'Q. Why does ACM use CNAME records for DNS validation instead of TXT records?'), ('Using a CNAME record allows ACM to renew certificates for as long as the CNAME record exists. The CNAME record directs to a TXT record in an AWS domain (acm-validations.aws) that ACM can update as needed to validate or re-validate a domain name, without any action from you.', 'Q. Does DNS validation work across AWS Regions?'), ('Yes. You can create one DNS CNAME record and use it to obtain certificates in the same AWS account in any AWS Region where ACM is offered. Configure the CNAME record once and you can get certificates issued and renewed from ACM for that name without creating another record.', 'Q. Can I choose different validation methods in the same certificate?'), ('No. Each certificate can have only one validation method.', 'Q. How do I renew a certificate validated with DNS validation?'), ('ACM automatically renews certificates that are in use (associated with other AWS resources) as long as the DNS validation record remains in place.', 'Q. Can I revoke permission to issue certificates for my domain?'), ('Yes. Simply remove the CNAME record. ACM does not issue or renew certificates for your domain using DNS validation after you remove the CNAME record and the change is distributed through DNS. The propagation time to remove the record depends on your DNS provider.', 'Q. What happens if I remove the CNAME record?'), ('ACM cannot issue or renew certificates for your domain using DNS validation if you remove the CNAME record.', '\u2003Back to Top >> '), (' Q: What is email validation?', ' With email validation, an approval request email is sent to the registered domain owner for each domain name in the certificate request. The domain owner or an authorized representative (approver) can approve the certificate request by following the instructions in the email. The instructions direct the approver to navigate to the approval website and click the link in the email or paste the link from the email into a browser to navigate to the approval web site. The approver confirms the information associated with the certificate request, such as the domain name, certificate ID (ARN), and the AWS account ID initiating the request, and approves the request if the information is accurate.'), (' Q: When I request a certificate and choose email validation, to which email addresses is the certificate approval request sent?', ' When you request a certificate using email validation, a WHOIS lookup for each domain name in the certificate request is used to retrieve contact information for the domain. Email is sent to the domain registrant, administrative contact, and technical contact listed for the domain. Email is also sent to five special email addresses, which are formed by prepending admin@, administrator@, hostmaster@, webmaster@ and postmaster@ to the domain name you’re requesting. For example, if you request a certificate for server.example.com, email is sent to the domain registrant, technical contact, and administrative contact using contact information returned by a WHOIS query for the example.com domain, plus admin@server.example.com, administrator@server.example.com, hostmaster@server.example.com, postmaster@server.example.com, and webmaster@server.example.com.  The five special email addresses are constructed differently for domain names that begin with "www" or wildcard names beginning with an asterisk (*). ACM removes the leading "www" or asterisk and email is sent to the administrative addresses formed by pre-pending admin@, administrator@, hostmaster@, postmaster@, and webmaster@ to the remaining portion of the domain name. For example, if you request a certificate for www.example.com, email is sent to the WHOIS contacts, as described previously, plus admin@example.com rather than admin@www.example.com. The remaining four special email addresses are similarly formed.'), (' After you request a certificate, you can display the list of email addresses to which the email was sent for each domain using the ACM console, AWS CLI, or APIs.', ' Q: Can I configure the email addresses to which the certificate approval request is sent?'), (' No, but you can configure the base domain name to which you want the validation email to be sent. The base domain name must be a superdomain of the domain name in the certificate request. For example, if you want to request a certificate for server.domain.example.com but want to direct the approval email to admin@domain.example.com, you can do so using the AWS CLI or API. See ACM CLI Reference and ACM API Reference for further details.', ' Q: Can I use domains that have proxy contact information (such as Privacy Guard or WhoisGuard)?'), (' Yes; however, email delivery may be delayed as a result of the proxy. Email sent through a proxy may end up in your spam folder. Refer to the ACM User Guide for troubleshooting suggestions.', ' Q: Can ACM validate my identity using the technical contact for my AWS account?'), (' No. Procedures and policies for validating the domain owner’s identity are very strict, and determined by the CA/Browser Forum which sets policy standards for publicly trusted certificate authorities. To learn more, please refer to the latest Amazon Trust Services Certification Practices Statement in the Amazon Trust Services Repository.', ' Q: What should I do if I did not receive the approval email?'), (' Refer to the ACM User Guide for troubleshooting suggestions. ', '\u2003Back to Top >> '), ('Q: Are certificates provided by ACM trusted by browsers, operating systems, and mobile devices?', 'Certificates provided by ACM are trusted by most modern browsers, operating systems, and mobile devices. ACM-provided certificates have 99% browser and operating system ubiquity, including Windows XP SP3 and Java 6 and later.'), ('Q: How can I confirm that my browser trusts certificates provided by ACM?', 'Browsers that trust certificates provided by ACM display a lock icon and do not issue certificate warnings when connected to sites that use certificates provided by ACM over SSL/TLS, for example using HTTPS.'), ('Certificates provided by ACM are verified by Amazon’s certificate authority (CA). Any browser, application, or OS that includes the Amazon Root CA 1, Starfield Services Root Certificate Authority - G2, or Starfield Class 2 Certification Authority trusts certificates provided by ACM.', 'Q: Can ACM provide certificates with multiple domain names?'), ('Yes. Each certificate must include at least one domain name, and you can add additional names to the certificate if you want to. For example, you can add the name “www.example.net” to a certificate for “www.example.com” if users can reach your site by either name. You must own or control all of the names included in your certificate request.', 'Q: What is a wildcard domain name?'), ('A wildcard domain name matches any first level subdomain or hostname in a domain. A first-level subdomain is a single domain name label that does not contain a period (dot). For example you can use the name *.example.com to protect www.example.com, images.example.com, and any other host name or first-level subdomain that ends with .example.com. Refer to the ACM User Guide for more details.', 'Q: Can ACM provide certificates with wildcard domain names?'), ('Yes.', 'Q: Does ACM provide Organizational Validation (OV) or Extended Validation (EV) certificates?'), ('Not at this time.', 'Q: Does ACM provide certificates for anything other than SSL/TLS for websites?'), ('Not at this time.', 'Q: Can I use certificates provided by ACM for code signing or email encryption?'), ('No.', 'Q: Does ACM provide certificates used to sign and encrypt email (S/MIME certificates)?'), ('Not at this time.', 'Q: What algorithms do certificates provided by ACM use?'), ('ACM certificates use RSA keys with a 2048-bit modulus and SHA-256.', 'Q: Does ACM support elliptic curve (ECDSA) certificates?'), ('Not at this time. ', 'Q: Where does Amazon describe its policies and practices for issuing certificates?'), ('They are described in the Amazon Trust Services Certificate Policies and Amazon Trust Services Certification Practices Statement documents. Refer to the Amazon Trust Services repository for the latest versions.', 'Q: How do I revoke a certificate?'), ('You can request ACM to revoke a certificate by visiting the AWS Support Center and creating a case.\u2003', 'Q: How can I notify AWS if the information in the certificate changes?'), ('You notify AWS by sending email to validation-questions[at]amazon.com.', '\u2003Back to Top >> '), ('Q: How are the private keys of ACM-provided certificates managed?', 'A key pair is created for each certificate provided by ACM. AWS Certificate Manager is designed to protect and manage the private keys used with SSL/TLS certificates. Strong encryption and key management best practices are used when protecting and storing private keys.'), ('Q: Does ACM copy certificates across AWS Regions?', ' No. The private key of each ACM certificate is stored in the Region in which you request the certificate. For example, when you obtain a new certificate in the US East (N. Virginia) Region, ACM stores the private key in the N. Virginia Region. ACM certificates are only copied across Regions if the certificate is associated with a CloudFront distribution. In that case, CloudFront distributes the ACM certificate to the geographic locations configured for your distribution.'), ('Q: Can I audit the use of certificate private keys?', 'Yes. Using AWS CloudTrail you can review logs that tell you when the private key for the certificate was used. '), ('Back To Top >> ', 'Q: How will I be charged and billed for my use of ACM certificates?'), ('SSL/TLS certificates provisioned, managed, and deployed through AWS Certificate Manager are free. You pay only for the AWS resources you create to run your application, such as Elastic Load Balancing load balancers or Amazon CloudFront distributions.', 'Back to Top >> '), ('Q: Can I use the same certificate with multiple Elastic Load Balancing load balancers and multiple CloudFront distributions?', 'Yes.'), ('Q: Can I use certificates for internal Elastic Load Balancing load balancers with no public Internet access?', 'Yes. See Managed Renewal and Deployment for details about how ACM handles renewals for certificates that are not reachable from the public Internet.'), ('Q: Will a certificate for www.example.com also work for example.com?', 'No. If you want your site to be referenced by both domain names (www.example.com and example.com), you must request a certificate that includes both names.'), ('Q: Can I import a third party certificate and use it with AWS services?', 'Yes. If you want to use a third-party certificate with Amazon CloudFront, Elastic Load Balancing, or Amazon API Gateway, you may import it into ACM using the AWS Management Console, AWS CLI, or ACM APIs. ACM does not manage the renewal process for imported certificates. You can use the AWS Management Console to monitor the expiration dates of an imported certificates and import a new third-party certificate to replace an expiring one.'), ('Q: What is the validity period for certificates provided by ACM?', 'Certificates provided by ACM are currently valid for 13 months.'), ('Q: How can ACM help my organization meet my compliance requirements?', 'Using ACM helps you comply with regulatory requirements by making it easy to facilitate secure connections, a common requirement across many compliance programs such as PCI, FedRAMP, and HIPAA. For specific information about compliance, please refer to http://aws.amazon.com/compliance.'), ('Q: Does ACM have a service level agreement (SLA)?', 'Not at this time.'), ('Q: Does ACM allow local language characters in domain names, otherwise known as Internationalized Domain Names (IDNs)?', 'ACM does not allow Unicode encoded local language characters; however, ACM allows ASCII-encoded local language characters for domain names.'), ('Q: Which domain name label formats does ACM allow?', 'ACM allows only UTF-8 encoded ASCII, including labels containing “xn—”, commonly known as Punycode for domain names. ACM does not accept Unicode input (u-labels) for domain names.'), ('Q: Does ACM provide a secure site seal or trust logo that I can display on my web site?', 'No. If you would like to use a site seal, you can obtain one from a third-party vendor. We recommend choosing a vendor that evaluates and asserts the security of your site, or your business practices, or both.'), ('Q: Does Amazon allow its trademarks or logo to be used as a certificate badge, site seal, or trust logo?', 'No. Seals and badges of this type can be copied to sites that do not use the ACM service, and used inappropriately to establish trust under false pretenses. To protect our customers and the reputation of Amazon, we do not allow our logo to be used in this manner.'), ('Back to Top >> ', ' Q: What logging information is available from AWS CloudTrail?'), (' You can identify which users and accounts called AWS APIs for services that support AWS CloudTrail, the source IP address the calls were made from, and when the calls occurred. For example, you can identify which user made an API call to associate a certificate provided by ACM with an Elastic Load Balancer and when the Elastic Load Balancing service decrypted the key with a KMS API call.', 'Back to Top >>'), ('Q: What is ACM managed renewal and deployment?', 'ACM managed renewal and deployment manages the process of renewing SSL/TLS certificates provided by ACM and deploying certificates after they are renewed.'), ('Q: What are the benefits of using ACM managed renewal and deployment?', 'ACM manages renewal and deployment of SSL/TLS certificates for you. ACM makes configuring and maintaining SSL/TLS for a secure web service or application more operationally sound than potentially error-prone manual processes. Managed renewal and deployment can help you avoid downtime due to expired certificates. ACM managed renewal and deployment doesn’t require you to install or maintain a software client or agent on your site. Instead, ACM operates as a service that is integrated with other AWS services. This means you can centrally manage and deploy certificates on the AWS platform by using the AWS management console, AWS CLI, or APIs.'), ('Q: Which certificates can be renewed and deployed automatically?', 'ACM can renew and deploy certificates provided by ACM without any additional validation from the domain owner. If a certificate cannot be renewed without additional validation, ACM manages the renewal process by validating domain ownership or control for each domain name in the certificate. After each domain name in the certificate has been validated, ACM renews the certificate and automatically deploys it with your AWS resources. If ACM cannot validate domain ownership, we will let you (the AWS account owner) know.'), ('If you chose DNS validation in your certificate request, ACM can renew your certificate indefinitely without any further action from you, as long as the certificate is in use (associated with other AWS resources) and your CNAME record remains in place. If you selected email validation when requesting a certificate, you can improve ACM’s ability to automatically renew and deploy certificates provided by ACM, by ensuring that the certificate is in use, that all domain names included in the certificate can be resolved to your site, and that all domain names are reachable from the internet. ', 'Q: When does ACM renew certificates?'), ('ACM begins the renewal process up to 60 days prior to the certificate’s expiration date. The validity period for certificates provided by ACM is currently 13 months. Refer to the ACM User Guide for more information about managed renewal.', 'Q: Will I be notified before my certificate is renewed and the new certificate is deployed?'), ('No. ACM may renew or rekey the certificate and replace the old one without prior notice.', 'Q: Can ACM renew certificates containing bare domains, such as “example.com” (also known as zone apex or naked domains)?'), ('If you chose DNS validation in your certificate request, then ACM can renew your certificate without any further action from you, as long as the certificate is in use (associated with other AWS resources) and your CNAME record remains in place.', 'If you selected email validation when requesting a certificate with a bare domain, ensure that a DNS lookup of the bare domain resolves to the AWS resource that is associated with the certificate. Resolving the bare domain to an AWS resource may be challenging unless you use Route 53 or another DNS provider that supports alias resource records (or their equivalent) for mapping bare domains to AWS resources. For more information, refer to the Route 53 Developer Guide.'), ('Q: Does my site drop existing connections when ACM deploys the renewed certificate?', 'No, connections established after the new certificate is deployed use the new certificate, and existing connections are not affected. '), ('Back to Top >> ', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/directoryservice/faqs/': [('Q: What is AWS Directory Service?', 'AWS Directory Service is a managed service offering, providing directories that contain information about your organization, including users, groups, computers, and other resources. As a managed offering, AWS Directory Service is designed to reduce management tasks, thereby allowing you to focus more of your time and resources on your business. There is no need to build out your own complex, highly-available directory topology because each directory is deployed across multiple Availability Zones, and monitoring automatically detects and replaces domain controllers that fail. In addition, data replication and automated daily snapshots are configured for you. There is no software to install and AWS handles all of the patching and software updates.'), ('Q: What can I do with AWS Directory Service?', 'AWS Directory Service makes it easy for you to setup and run directories in the AWS cloud, or connect your AWS resources with an existing on-premises Microsoft Active Directory. Once your directory is created, you can use it to manage users and groups, provide single sign-on to applications and services, create and apply group policy, join Amazon EC2 instances to a domain, as well as simplify the deployment and management of cloud-based Linux and Microsoft Windows workloads. AWS Directory Service enables your end users to use their existing corporate credentials when accessing AWS applications, such as Amazon WorkSpaces, Amazon WorkDocs and Amazon WorkMail, as well as directory-aware Microsoft workloads, including custom .NET and SQL Server-based applications. Finally, you can use your existing corporate credentials to administer AWS resources via AWS Identity and Access Management (IAM) role-based access to the AWS Management Console, so you do not need to build out more identity federation infrastructure.'), ('Q: How do I create a directory?', 'You can use the AWS Management Console or the API to create a directory. All you need to provide is some basic information such as a fully qualified domain name (FQDN) for your directory, Administrator account name and password, and the VPC you want the directory to be attached to.'), ('Q: Can I join an existing Amazon EC2 instance to an AWS Directory Service directory?', 'Yes, you can use the AWS Management Console or the API to add existing EC2 instances running Linux or Windows to a AWS Microsoft AD.'), ('Q: Are APIs supported for AWS Directory Service?', 'Public APIs are supported for creating and managing directories. You can now programmatically manage directories using public APIs. The APIs are available via the AWS CLI and SDK. Learn more about the APIs in the AWS Directory Service documentation.'), ('Q: Does AWS Directory Service support CloudTrail logging?', 'Yes. Actions performed via the AWS Directory Service APIs or management console will be included in your CloudTrail audit logs.'), ('Q: Can I receive notifications when the status of my directory changes?', 'Yes. You can configure Amazon Simple Notification Service (SNS) to receive email and text messages when the status of your AWS Directory Service changes. Amazon SNS uses topics to collect and distribute messages to subscribers. When AWS Directory Service detects a change in your directory’s status, it will publish a message to the associated topic, which is then sent to topic subscribers. Visit the documentation to learn more.'), ('Q: How much does AWS Directory Service cost?', 'See the pricing page for more information.'), ('Q. Can I tag my directory?', 'Yes. AWS Directory Service supports cost allocation tagging. Tags make it easier for you to allocate costs and optimize spending by categorizing and grouping AWS resources. For example, you can use tags to group resources by administrator, application name, cost center, or a specific project.'), ('Q. In which AWS regions is AWS Directory Service available?', 'Refer to Regional Products and Services for details of AWS Directory Service availability by region'), ('Q: How do I create a AWS Microsoft AD directory?', 'You can launch the AWS Directory Service console from the AWS Management Console to create a AWS Microsoft AD directory. Alternatively, you can use the AWS SDK or AWS CLI.'), ('Q: How are AWS Microsoft AD directories deployed?', 'AWS Microsoft AD directories are deployed across two Availability Zones in a region by default and connected to your Amazon Virtual Private Cloud (VPC). Backups are automatically taken once per day, and the Amazon Elastic Block Store (EBS) volumes are encrypted to ensure that data is secured at rest. Domain controllers that fail are automatically replaced in the same Availability Zone using the same IP address, and a full disaster recovery can be performed using the latest backup.'), ('Q: Can I configure the storage, CPU, or memory parameters of my AWS Microsoft AD directory?', 'No. This functionality is not supported at this time.'), ('Q: How do I manage users and groups for AWS Microsoft AD?', 'You can use your existing Active Directory tools—running on Windows computers that are joined to the AWS Microsoft AD domain—to manage users and groups in AWS Microsoft AD directories. No special tools, policies, or behavior changes are required.'), ('Q. How are my administrative permissions different between AWS Microsoft AD and running Active Directory in my own Amazon EC2 Windows instances?', 'In order to deliver a managed-service experience, AWS Microsoft AD must disallow operations by customers that would interfere with managing the service. Therefore, AWS does not provide Windows PowerShell access to directory instances, and it restricts access to directory objects, roles, and groups that require elevated privileges. AWS Microsoft AD does not allow direct host access to domain controllers via Telnet, Secure Shell (SSH), or Windows Remote Desktop Connection. When you create an AWS Microsoft AD directory, you are assigned an organizational unit (OU) and an administrative account with delegated administrative rights for the OU. You can create user accounts, groups, and policies within the OU by using standard Remote Server Administration Tools such as Active Directory Users and Groups.'), ('Q: Can I use Microsoft Network Policy Server (NPS) with AWS Microsoft AD?', 'Yes. The administrative account created for you when AWS Microsoft AD is set up has delegated management rights over the Remote Access Service (RAS) and Internet Authentication Service (IAS) security group. This enables you to register NPS with AWS Microsoft AD and manage network access policies for accounts in your domain.'), ('Q: Does AWS Microsoft AD support schema extensions?', 'Yes. AWS Microsoft AD supports schema extensions that you submit to the service in the form of a LDAP Data Interchange Format (LDIF) file. You may extend but not modify the core Active Directory schema.'), ('Q: Which applications are compatible with AWS Microsoft AD?', 'The following applications are compatible with AWS Microsoft AD:'), ('Note that not all configurations of these applications may be supported.', 'Q: Can I migrate my existing, on-premises Microsoft Active Directory to AWS Microsoft AD?'), ('AWS does not provide any migration tools to migrate a self-managed Active Directory to AWS Microsoft AD. You must establish a strategy for performing migration including password resets, and implement the plans using Remote Server Administration Tools.', 'Q: Can I configure conditional forwarders and trusts in the Directory Service console?'), ('Yes. You can configure conditional forwarders and trusts for AWS Microsoft AD using the Directory Service console as well as the API.', 'Q: Can I add additional domain controllers manually to my AWS Microsoft AD?'), ('Yes. You can add additional domain controllers to your managed domain using the AWS Directory Service console or API. Note that promoting Amazon EC2 instances to domain controllers manually is not supported.', 'Q: Can I use Microsoft Office 365 with user accounts managed in AWS Microsoft AD?'), ('Yes. You can synchronize identities from AWS Microsoft AD to Azure AD using Azure AD Connect and use Microsoft Active Directory Federation Services (AD FS) for Windows 2016 with AWS Microsoft AD to authenticate Office 365 users. For step-by-step instructions, see How to Enable Your Users to Access Office 365 with AWS Microsoft Active Directory Credentials. \xa0', 'Q: Can I use Security Assertion Markup Language (SAML) 2.0–based authentication with cloud applications using AWS Microsoft AD?'), ('Yes. You can use Microsoft Active Directory Federation Services (AD FS) for Windows 2016 with your AWS Microsoft AD managed domain to authenticate users to cloud applications that support SAML.', 'Q: Can I encrypt communication between my applications and AWS Microsoft AD using LDAPS?'), ('Yes. AWS Microsoft AD supports Lightweight Directory Access Protocol (LDAP) over Secure Socket Layer (SSL) on port 636, and LDAP over Transport Layer Security (TLS) on port 389, also known as LDAPS. You enable both types of LDAPS communication by installing a certificate on your AWS Microsoft AD domain controllers from a Microsoft Certificate Authority (CA). To learn more, see How to Enable LDAPS for Your AWS Microsoft AD Directory.', 'Q: How many users, groups, computers, and total objects does AWS Microsoft AD support?'), ('AWS Microsoft AD (Standard Edition) includes 1 GB of directory object storage. This capacity can support up to 5,000 users or 30,000 directory objects, including users, groups, and computers. AWS Microsoft AD (Enterprise Edition) includes 17 GB of directory object storage, which can support up to 100,000 users or 500,000 objects.', 'Q: Can I use AWS Microsoft AD as a primary directory?'), ('Yes. You can use it as a primary directory to manage users, groups, computers, and Group Policy objects (GPOs) in the cloud. You can manage access and provide single sign-on (SSO) to AWS applications and services, and to third-party directory-aware applications running on Amazon EC2 instances in the AWS Cloud. In addition, you can use Azure AD Connect and AD FS to support SSO to cloud applications, including Office 365.', 'Q: Can I use AWS Microsoft AD as a resource forest?'), ('Yes. You can use AWS Microsoft AD as a resource forest that contains primarily computers and groups with trust relationships to your on-premises directory. This enables your users to access AWS applications and resources with their on-premises AD credentials.', 'Q: What is seamless domain join?'), ('Seamless domain join is a feature that allows you to join your Amazon EC2 for Windows Server instances seamlessly to a domain, at the time of launch and from the AWS Management Console. You can join instances to AWS Microsoft AD that you launch in the AWS Cloud.', 'Q: How do I join an instance seamlessly to a domain?'), ('When you create and launch an EC2 for Windows instance from the AWS Management Console, you have the option to select which domain your instance will join. To learn more, see the documentation.', 'Q: Can I join existing EC2 for Windows Server instances seamlessly to a domain?'), ('You cannot use the seamless domain join feature from the AWS Management Console for existing EC2 for Windows Server instances, but you can join existing instances to a domain using the EC2 API or by using PowerShell on the instance. To learn more, see the documentation.', 'Q: How does AWS Directory Service enable single sign-on (SSO) to the AWS Management Console?'), ('AWS Directory Service allows you to assign IAM roles to AWS Microsoft AD or Simple AD users and groups in the AWS cloud, as well as an existing, on-premises Microsoft Active Directory users and groups using AD Connector. These roles will control users’ access to AWS services based on IAM policies assigned to the roles. AWS Directory Service will provide a customer-specific URL for the AWS Management Console which users can use to sign in with their existing corporate credentials. See our documentation for more information on this feature.', 'Q: Can I use AWS Microsoft AD for AWS Cloud workloads that are subject to compliance standards?'), ('Yes. AWS Microsoft AD has implemented the controls necessary to enable you to meet the U.S. Health Insurance Portability and Accountability Act (HIPAA) requirements and is included as an in-scope service in the Payment Card Industry Data Security Standard (PCI\xa0DSS) Attestation of Compliance and Responsibility Summary. \xa0', 'Q: How can I access compliance and security reports?'), ('To access a comprehensive list of documents relevant to compliance and security in the AWS Cloud, see\xa0AWS Artifact.\xa0', 'Q: What is the AWS Shared Responsibility Model?'), ('Security, including HIPAA and PCI DSS compliance, is a\xa0shared responsibility\xa0between AWS and you. For example, it is your responsibility to configure your AWS Microsoft AD password policies to meet PCI DSS requirements when using AWS Microsoft AD. To learn more about the actions you may need to take to meet HIPAA and PCI DSS compliance requirements, see the\xa0compliance documentation for AWS Microsoft AD, read the\xa0Architecting for HIPPA Security and Compliance on Amazon Web Services\xa0whitepaper, and see the\xa0AWS Cloud Compliance,\xa0HIPAA Compliance, and\xa0PCI DSS Compliance. ', 'For questions about AD Connector or Simple AD, please see AWS Directory Service, Other Directory Options. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/iam/faqs/': [('Q: What is AWS Identity and Access Management (IAM)? You can use AWS IAM to securely control individual and group access to your AWS resources. You can create and manage user identities ("IAM users") and grant permissions for those IAM users to access your resources. You can also grant permissions for users outside of AWS (federated users). ', 'Q: How do I get started with IAM? To start using IAM, you must subscribe to at least one of the AWS services that is integrated with IAM. You then can create and manage users, groups, and permissions via IAM APIs, the AWS CLI, or the IAM console, which gives you a point-and-click, web-based interface. You can also use the visual editor to create policies. '), ('Q: What problems does IAM solve?  IAM makes it easy to provide multiple users secure access to your AWS resources. IAM enables you to:', 'Q: Who can use IAM? Any AWS customer can use IAM. The service is offered at no additional charge. You will be charged only for the use of other AWS services by your users.'), ('Q: What is a user? A user is a unique identity recognized by AWS services and applications. Similar to a login user in an operating system like Windows or UNIX, a user has a unique name and can identify itself using familiar security credentials such as a password or access key. A user can be an individual, system, or application requiring access to AWS services. IAM supports users (referred to as "IAM users") managed in AWS\'s identity management system, and it also enables you to grant access to AWS resources for users managed outside of AWS in your corporate directory (referred to as "federated users").', "Q: What can a user do? A user can place requests to web services such as Amazon S3 and Amazon EC2. A user's ability to access web service APIs is under the control and responsibility of the AWS account under which it is defined. You can permit a user to access any or all of the AWS services that have been integrated with IAM and to which the AWS account has subscribed. If permitted, a user has access to all of the resources under the AWS account. In addition, if the AWS account has access to resources from a different AWS account, its users may be able to access data under those AWS accounts. Any AWS resources created by a user are under control of and paid for by its AWS account. A user cannot independently subscribe to AWS services or control resources."), ("Q: How do users call AWS services? Users can make requests to AWS services using security credentials. Explicit permissions govern a user's ability to call AWS services. By default, users have no ability to call service APIs on behalf of the account.", 'Q: How do I get started with IAM? To start using IAM, you must subscribe to at least one of the AWS services that is integrated with IAM. You then can create and manage users, groups, and permissions via IAM APIs, the AWS CLI, or the IAM console, which gives you a point-and-click, web-based interface. You can also use the AWS Policy Generator to create policies. '), ('Q: How are IAM users managed? IAM supports multiple methods to:', 'You can create and manage users, groups, and policies by using IAM APIs, the\xa0AWS CLI, or the IAM console. You also can use the visual editor and the\xa0IAM policy simulator to create and test policies.'), ('Q: What is a group? A group is a collection of IAM users. Manage group membership as a simple list:', 'Q: What kinds of security credentials can IAM users have? IAM users can have any combination of credentials that AWS supports, such as an AWS access key, X.509 certificate, SSH key, password for web app logins, or an MFA device. This allows users to interact with AWS in any manner that makes sense for them. An employee might have both an AWS access key and a password; a software system might have only an AWS access key to make programmatic calls; IAM users might have a private SSH key to access AWS CodeCommit repositories; and an outside contractor might have only an X.509 certificate to use the EC2 command-line interface. For details, see Temporary Security Credentials in the IAM documentation. '), ('Q: Which AWS services support IAM users? You can find the complete list of AWS services that support IAM users in the AWS Services That Work with IAM section of the IAM documentation. AWS plans to add support for other services over time.', "Q: Can I enable and disable user access? Yes. You can enable and disable an IAM user's access keys via the IAM APIs, AWS CLI, or IAM console. If you disable the access keys, the user cannot programmatically access AWS services."), ('Q: Who is able to manage users for an AWS account? The AWS account holder can manage users, groups, security credentials, and permissions. In addition, you may grant permissions to individual users to place calls to IAM APIs in order to manage other users. For example, an administrator user may be created to manage users for a corporation—a recommended practice. When you grant a user permission to manage other users, they can do this via the IAM APIs, AWS CLI, or IAM console.', 'Q: Can I structure a collection of users in a hierarchical way, such as in LDAP? Yes. You can organize users and groups under paths, similar to object paths in Amazon S3—for example /mycompany/division/project/joe.'), ('Q: Can I define users regionally? Not initially. Users are global entities, like an AWS account is today. No region is required to be specified when you define user permissions. Users can use AWS services in any geographic region.', 'Q: How are MFA devices configured for IAM users? You (the AWS account holder) can order multiple MFA devices. You can then assign these devices to individual IAM users via the IAM APIs, AWS CLI, or IAM console.'), ("Q: What kind of key rotation is supported for IAM users? User access keys and X.509 certificates can be rotated just as they are for an AWS account's root access identifiers. You can manage and rotate programmatically a user's access keys and X.509 certificates via the IAM APIs, AWS CLI, or IAM console.", 'Q: Can IAM users have individual EC2 SSH keys? Not in the initial release. IAM does not affect EC2 SSH keys or Windows RDP certificates. This means that although each user has separate credentials for accessing web service APIs, they must share SSH keys that are common across the AWS account under which users have been defined.'), ('Q: Where can I use my SSH keys?', 'Currently, IAM users can use their SSH keys only with AWS CodeCommit to access their repositories.'), ('Q: Do IAM user names have to be email addresses? No, but they can be. User names are just ASCII strings that are unique within a given AWS account. You can assign names using any naming convention you choose, including email addresses.', 'Q: Which character sets can I use for IAM user names? You can only use ASCII characters for IAM entities. '), ('Q: Are user attributes other than user name supported? Not at this time.', 'Q: How are user passwords set? You can set an initial password for an IAM user via the IAM console, AWS CLI, or IAM APIs. User passwords never appear in clear text after the initial provisioning, and are never displayed or returned via an API call. IAM users can manage their passwords via the My Password page in the IAM console. Users access this page by selecting the Security Credentials option from the drop-down list in the upper right corner of the AWS Management Console.'), ('Q: Can I define a password policy for my user’s passwords? Yes, you can enforce strong passwords by requiring minimum length or at least one number. You can also enforce automatic password expiration, prevent re-use of old passwords, and require a password reset upon the next AWS sign-in. For details, see Setting an Account Policy Password for IAM Users.', 'Q: Can I set usage quotas on IAM users? No. All limits are on the AWS account as a whole. For example, if your AWS account has a limit of 20 Amazon EC2 instances, IAM users with EC2 permissions can start instances up to the limit. You cannot limit what an individual user can do.'), ('Q: What is an IAM role? An IAM role is an IAM entity that defines a set of permissions for making AWS service requests. IAM roles are not associated with a specific user or group. Instead, trusted entities assume roles, such as IAM users, applications, or AWS services such as EC2.', 'Q: What problems do IAM roles solve? IAM roles allow you to delegate access with defined permissions to trusted entities without having to share long-term access keys. You can use IAM roles to delegate access to IAM users managed within your account, to IAM users under a different AWS account, or to an AWS service such as EC2.'), ('Q: How do I get started with IAM roles? You create a role in a way similar to how you create a user—name the role and attach a policy to it. For details, see Creating IAM Roles.', 'Q: How do I assume an IAM role? You assume an IAM role by calling the AWS Security Token Service (STS) AssumeRole APIs (in other words, AssumeRole, AssumeRoleWithWebIdentity, and AssumeRoleWithSAML). These APIs return a set of temporary security credentials that applications can then use to sign requests to AWS service APIs.'), ('Q: How many IAM roles can I assume? There is no limit to the number of IAM roles you can assume, but you can only act as one IAM role when making requests to AWS services. ', 'Q: Who can use IAM roles? Any AWS customer can use IAM roles.'), ('Q: How much do IAM roles cost? IAM roles are free of charge. You will continue to pay for any resources a role in your AWS account consumes.', 'Q: How are IAM roles managed? You can create and manage IAM roles via the IAM APIs, AWS CLI, or IAM console, which gives you a point-and-click, web-based interface.'), ('Q: What is the difference between an IAM role and an IAM user? An IAM user has permanent long-term credentials and is used to directly interact with AWS services. An IAM role does not have any credentials and cannot make direct requests to AWS services. IAM roles are meant to be assumed by authorized entities, such as IAM users, applications, or an AWS service such as EC2.', 'Q: When should I use an IAM user, IAM group, or IAM role?'), ('An IAM user has permanent long-term credentials and is used to directly interact with AWS services. An IAM group is primarily a management convenience to manage the same set of permissions for a set of IAM users. An IAM role is an AWS Identity and Access Management (IAM) entity with permissions to make AWS service requests. IAM roles cannot make direct requests to AWS services; they are meant to be assumed by authorized entities, such as IAM users, applications, or AWS services such as EC2. Use IAM roles to delegate access within or between AWS accounts.', 'Q: Can I add an IAM role to an IAM group? Not at this time.'), ('Q: How many policies can I attach to an IAM role?', 'For inline policies: You can add as many inline policies as you want to a user, role, or group, but the total aggregate policy size (the sum size of all inline policies) per entity cannot exceed the following limits:'), ('For managed policies: You can add up to 10 managed policies to a user, role, or group. The size of each managed policy cannot exceed 6,144 characters. ', 'Q: How many IAM roles can I create? You are limited to 1,000 IAM roles under your AWS account. If you need more roles, submit the IAM limit increase request form with your use case, and we will consider your request.'), ('Q: To which services can my application make requests? Your application can make requests to all AWS services that support role sessions. ', 'Q: What is IAM roles for EC2 instances? IAM roles for EC2 instances enables your applications running on EC2 to make requests to AWS services such as Amazon S3, Amazon SQS, and Amazon SNS without you having to copy AWS access keys to every instance. For details, see IAM Roles for Amazon EC2. '), ('Q: What are the features of IAM roles for EC2 instances? ', 'IAM roles for EC2 instances provides the following features:'), ('Q: What problem does IAM roles for EC2 instances solve? IAM roles for EC2 instances simplifies management and deployment of AWS access keys to EC2 instances. Using this feature, you associate an IAM role with an instance. Then your EC2 instance provides the temporary security credentials to applications running on the instance, and the applications can use these credentials to make requests securely to the AWS service resources defined in the role.', 'Q: How do I get started with IAM roles for EC2 instances? To understand how roles work with EC2 instances, you need to use the IAM console to create a role, launch an EC2 instance that uses that role, and then examine the running instance. You can examine the instance metadata to see how the role credentials are made available to an instance. You can also see how an application that runs on an instance can use the role. For more details, see How Do I Get Started? '), ('Q: Can I use the same IAM role on multiple EC2 instances? Yes.', 'Q: Can I change the IAM role on a running EC2 instance? Yes. Although a role is usually assigned to an EC2 instance when you launch it, a role can also be assigned to an EC2 instance that is already running. To learn how to assign a role to a running instance, see IAM Roles for Amazon EC2. You can also change the permissions on the IAM role associated with a running instance, and the updated permissions take effect almost immediately.\xa0'), ('Q: Can I associate an IAM role with an already running EC2 instance? Yes. You can assign a role to an EC2 instance that is already running. To learn how to assign a role to an already running instance, see IAM Roles for Amazon EC2.', 'Q: Can I associate an IAM role with an Auto Scaling group?'), ('Yes. You can add an IAM role as an additional parameter in an Auto Scaling launch configuration and create an Auto Scaling group with that launch configuration. All EC2 instances launched in an Auto Scaling group that is associated with an IAM role are launched with the role as an input parameter. For more details, see What Is Auto Scaling? in the Auto Scaling Developer Guide. ', 'Q: Can I associate more than one IAM role with an EC2 instance? No. You can only associate one IAM role with an EC2 instance at this time.\xa0This limit of one role per instance cannot be increased.'), ('Q: What happens if I delete an IAM role that is associated with a running EC2 instance? Any application running on the instance that is using the role will be denied access immediately. ', 'Q: Can I control which IAM roles an IAM user can associate with an EC2 instance? Yes. For details, see Permissions Required for Using Roles with Amazon EC2. '), ('Q: Which permissions are required to launch EC2 instances with an IAM role? You must grant an IAM user two distinct permissions to successfully launch EC2 instances with roles:', 'For details, see Permissions Required for Using Roles with Amazon EC2. '), ('Q: Who can access the access keys on an EC2 instance? Any local user on the instance can access the access keys associated with the IAM role.', 'Q: How do I use the IAM role with my application on the EC2 instance? If you develop your application with the AWS SDK, the AWS SDK automatically uses the AWS access keys that have been made available on the EC2 instance. If you are not using the AWS SDK, you can retrieve the access keys from the EC2 instance metadata service. For details, see Using an IAM Role to Grant Permissions to Applications Running on Amazon EC2 Instances. '), ('Q: How do I rotate the temporary security credentials on the EC2 instance? The AWS temporary security credentials associated with an IAM role are automatically rotated multiple times a day. New temporary security credentials are made available no later than five minutes before the existing temporary security credentials expire.', 'Q: Can I use IAM roles for EC2 instances with any instance type or Amazon Machine Image? Yes. IAM roles for EC2 instances also work in Amazon Virtual Private Cloud (VPC), with spot and reserved instances.'), ('Q: What is a service-linked role? A service-linked role is a type of role that links to an AWS service (also known as a linked service) such that only the linked service can assume the role. Using these roles, you can delegate permissions to AWS services to create and manage AWS resources on your behalf.', 'Q: Can I assume a service-linked role? No. A service-linked role can be assumed only by the linked service. This is the reason why the trust policy of a service-linked role cannot be modified.'), ('Q: Can I delete a service-linked role? Yes. If you no longer want an AWS service to perform actions on your behalf, you can delete its service-linked role. Before you delete the role, you must delete all AWS resources that depend on the role. This step ensures that you do not inadvertently delete a role required for your AWS resources to function properly.', 'Q: How do I delete a service-linked role? You can delete a service-linked role from the IAM console. Choose Roles in the navigation pane, choose the service-linked role that you want to delete, and choose Delete role.\xa0(Note: For Amazon Lex, you must use the Amazon Lex console to delete the service-linked role.)'), ('Q: How do permissions work?', 'Access control policies are attached to users, groups, and roles to assign permissions to AWS resources. By default, IAM users, groups, and roles have no permissions; users with sufficient permissions must use a policy to grant the desired permissions. '), ('Q: How do I assign permissions using a policy?', 'To set permissions, you can create and attach policies using the AWS Management Console, the IAM API, or the AWS CLI. Users who have been granted the necessary permissions can create policies and assign them to IAM users, groups, and roles. '), ('Q: What are managed policies?', 'Managed policies are IAM resources that express permissions using the IAM policy language. You can create, edit, and manage separately from the IAM users, groups, and roles to which they are attached. After you attach a managed policy to multiple IAM users, groups, or roles, you can update that policy in one place and the permissions automatically extend to all attached entities. Managed policies are managed either by you (these are called customer managed policies) or by AWS (these are called AWS managed policies). For more information about managed policies, see Managed Policies and Inline Policies.'), ('Q: How do I create a customer managed policy?', 'You can use the visual editor or the JSON editor in the IAM console. The\xa0 visual editor is a point-and-click editor that guides you through the process of granting permissions in a policy without requiring you to write the policy in JSON. You can create policies in JSON by using the CLI and SDK.'), ('Q: How do I assign commonly used permissions?', 'AWS provides a set of commonly used permissions that you can attach to IAM users, groups, and roles in your account. These are called AWS managed policies. One example is read-only access for Amazon S3. When AWS updates these policies, the permissions are applied automatically to the users, groups, and roles to which the policy is attached. AWS managed policies automatically appear in the Policies section of the IAM console. When you assign permissions, you can use an AWS managed policy or you can create your own customer managed policy. Create a new policy based on an existing AWS managed policy, or define your own.'), ('Q: How do group-based permissions work?', 'Use IAM groups to assign the same set of permissions to multiple IAM users. A user can also have individual permissions assigned to them. The two ways to attach permissions to users work together to set overall permissions. '), ('Q: What is the difference between assigning permissions using IAM groups and assigning permissions using managed policies?', 'Use IAM groups to collect IAM users and define common permissions for those users. Use managed policies to share permissions across IAM users, groups, and roles. For example, if you want a group of users to be able to launch an Amazon EC2 instance, and you also want the role on that instance to have the same permissions as the users in the group, you can create a managed policy and assign it to the group of users and the role on the Amazon EC2 instance. '), ('Q: How are IAM policies evaluated in conjunction with Amazon S3, Amazon SQS, Amazon SNS, and AWS KMS resource-based policies?', 'IAM policies are evaluated together with the service’s resource-based policies. When a policy of any type grants access (without explicitly denying it), the action is allowed. For more information about the policy evaluation logic, see IAM Policy Evaluation Logic.\xa0'), ('Q: Can I use a managed policy as a resource-based policy?', 'Managed policies can only be attached to IAM users, groups, or roles. You cannot use them as resource-based policies. '), ('Q: How do I set granular permissions using policies?', 'Using policies, you can specify several layers of permission granularity. First, you can define specific AWS service actions you wish to allow or explicitly deny access to. Second, depending on the action, you can define specific AWS resources the actions can be performed on. Third, you can define conditions to specify when the policy is in effect (for example, if MFA is enabled or not).'), ('Q: How can I easily remove unnecessary permissions?', 'To help you determine which permissions are needed, the IAM console now displays service last accessed data that shows the hour when an IAM entity (a user, group, or role) last accessed an AWS service. Knowing if and when an IAM entity last exercised a permission can help you remove unnecessary permissions and tighten your IAM policies with less effort.'), ('Q: Can I grant permissions to access or change account-level information (for example, payment instrument, contact email address, and billing history)? ', 'Yes, you can delegate the ability for an IAM user or a federated user to view AWS billing data and modify AWS account information. For more information about controlling access to your billing information, see Controlling Access. '), ('Q: Who can create and manage access keys in an AWS account?', 'Only the AWS account owner can manage the access keys for the root account. The account owner and IAM users or roles that have been granted the necessary permissions can manage access keys for IAM users. '), ('Q: Can I grant permissions to access AWS resources owned by another AWS account? Yes. Using IAM roles, IAM users and federated users can access resources in another AWS account via the AWS Management Console, the AWS CLI, or the APIs. See Manage IAM Roles for more information.', 'Q: What does a policy look like?'), ('The following policy grants access to add, update, and delete objects from a specific folder, example_folder, in a specific bucket, example_bucket.', '{ \xa0 \xa0"Version":"2012-10-17", \xa0 \xa0"Statement":[ \xa0 \xa0 \xa0 { \xa0 \xa0 \xa0 \xa0 \xa0"Effect":"Allow", \xa0 \xa0 \xa0 \xa0 \xa0"Action":[ \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 "s3:PutObject", \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 "s3:GetObject", \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 "s3:GetObjectVersion", \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 "s3:DeleteObject", \xa0 \xa0 \xa0 \xa0 \xa0 \xa0 "s3:DeleteObjectVersion" \xa0 \xa0 \xa0 \xa0 \xa0], \xa0 \xa0 \xa0 \xa0 \xa0"Resource":"arn:aws:s3:::example_bucket/example_folder/*" \xa0 \xa0 \xa0 } \xa0 \xa0] }'), ('Q: What is a policy summary?', 'If you are using the IAM console and choose a policy, you will see a policy summary. A policy summary lists the access level, resources, and conditions for each service defined in a policy (see the following screenshot for an example). The access level (View, Read, Write, or Permissions management) is defined by actions granted for each service in the policy. You can view the policy in JSON by choosing the JSON button.'), ('Q: What is the IAM policy simulator?  The IAM policy simulator is a tool to help you understand, test, and validate the effects of your access control policies. ', 'Q: What can the policy simulator be used for? \xa0 You can use the policy simulator in several ways. You can test policy changes to ensure they have the desired effect before committing them to production. You can validate existing policies attached to users, groups, and roles to verify and troubleshoot permissions. You can also use the policy simulator to understand how IAM policies and resource-based policies work together to grant or deny access to AWS resources. '), ('Q: Who can use the policy simulator?  The policy simulator is available to all AWS customers.', 'Q: How much does the policy simulator cost?  The policy simulator is available at no extra cost.'), ('Q: How do I get started?  Go to https://policysim.aws.amazon.com, or click the link on the IAM console under “Additional Information.” Specify a new policy or choose an existing set of policies from a user, group, or role that you’d like to evaluate. Then select a set of actions from the list of AWS services, provide any required information to simulate the access request, and run the simulation to determine whether the policy allows or denies permissions to the selected actions and resources. To learn more about the IAM policy simulator, watch our Getting Started video or see the documentation. ', 'Q: What kinds of policies does the IAM policy simulator support? The policy simulator supports testing of newly entered policies and existing policies attached to users, groups, or roles. In addition, you can simulate whether resource-level policies grant access to a particular resource for Amazon S3 buckets, Amazon Glacier vaults, Amazon SNS topics, and Amazon SQS queues. These are included in the simulation when an Amazon Resource Name (ARN) is specified in the Resource field in Simulation Settings for a service that supports resource policies. '), ('Q: If I change a policy in the policy simulator, do those changes persist in production? No. To apply changes to production, copy the policy that you’ve modified in the policy simulator and attach it to the desired IAM user, group, or role. ', 'Q: Can I use the policy simulator programmatically? Yes. You can use the policy simulator using the AWS SDKs or AWS CLI in addition to the policy simulator console. Use the\xa0iam:SimulatePrincipalPolicy API to programmatically test your existing IAM policies. To test the effects of new or updated policies that are not yet attached to a user, group, or role, call the iam:SimulateCustomPolicy API. \xa0'), ('Q: How does an IAM user sign in?', 'To sign in to the AWS Management Console as an IAM user, you must provide your account ID or account alias in addition to your user name and password. When your administrator created your IAM user in the console, they should have provided you with your user name and the URL to your account sign-in page. That URL includes your account ID or account alias.'), ('https://My_AWS_Account_ID.signin.aws.amazon.com/console/', 'You can also sign in at the following general sign-in endpoint and type your account ID or account alias manually:'), ('https://console.aws.amazon.com/', 'For convenience, the AWS sign-in page uses a browser cookie to remember the IAM user name and account information. The next time the user goes to any page in the AWS Management Console, the console uses the cookie to redirect the user to the account sign-in page.'), ('Note: IAM users can still use the URL link provided to them by their administrator to sign in to the AWS Management Console. ', 'Q: What is an AWS account alias?'), ('The account alias is a name you define to make it more convenient to identify your account. You can create an alias using the IAM APIs, AWS Command Line Tools, or the IAM console. You can have one alias per AWS account. ', 'Q: Which AWS sites can IAM users access?'), ('IAM users can sign in to the following AWS sites:', 'Q: Can IAM users sign in to other Amazon.com properties with their credentials? No. Users created with IAM are recognized only by AWS services and applications. '), ('Q: Is there an authentication API to verify IAM user sign-ins? No. There is no programmatic way to verify user sign-ins. ', 'Q: Can users SSH to EC2 instances using their AWS user name and password? No. User security credentials created with IAM are not supported for direct authentication to customer EC2 instances. Managing EC2 SSH credentials is the customer’s responsibility within the EC2 console. '), ('Q: What are temporary security credentials? Temporary security credentials consist of the AWS access key ID, secret access key, and security token. Temporary security credentials are valid for a specified duration and for a specific set of permissions. Temporary security credentials are sometimes simply referred to as tokens. Tokens can be requested for IAM users or for federated users you manage in your own corporate directory. For more information, see Common Scenarios for Temporary Credentials. ', 'Q: What are the benefits of temporary security credentials? Temporary security credentials allow you to:'), ('Q: How can I request temporary security credentials for federated users? You can call the GetFederationToken, AssumeRole, AssumeRoleWithSAML, or AssumeRoleWithWebIdentity STS APIs. ', 'Q: How can IAM users request temporary security credentials for their own use? IAM users can request temporary security credentials for their own use by calling the AWS STS GetSessionToken API. The default expiration for these temporary credentials is 12 hours; the minimum is 15 minutes, and the maximum is 36 hours.'), ('You can also use temporary credentials with Multi-Factor Authentication (MFA)-Protected API Access. ', "Q: How can I use temporary security credentials to call AWS service APIs? If you're making direct HTTPS API requests to AWS, you can sign those requests with the temporary security credentials that you get from AWS Security Token Service (AWS STS). To do this, do the following:"), ('Q: Which AWS services accept temporary security credentials? For a list of supported services, see AWS Services That Work with IAM. ', 'Q: What is the maximum size of the access policy that I can specify when requesting temporary security credentials (either GetFederationToken or AssumeRole)? The policy plaintext must be 2048 bytes or shorter. However, an internal conversion compresses it into a packed binary format with a separate limit. '), ('Q: Can a temporary security credential be revoked prior to its expiration? No. When requesting temporary credentials, we recommend the following:', 'Q: Can I reactivate or extend the expiration of temporary security credentials? No. It is a good practice to actively check the expiration and request a new temporary security credential before the old one expires. This rotation process is automatically managed for you when temporary security credentials are used in roles for EC2 instances.'), ('Q: Are temporary security credentials supported in all regions? Customers can request tokens from AWS STS endpoints in all regions, including AWS GovCloud (US) and China (Beijing) regions. Temporary credentials from AWS GovCloud (US) and China (Beijing) can be used only in the region from which they originated. Temporary credentials requested from any other region such as US East (N. Virginia) or EU (Ireland) can be used in all regions except AWS GovCloud (US) and China (Beijing). ', 'Q: Can I restrict the use of temporary security credentials to a region or a subset of regions?'), ('No. You cannot restrict the temporary security credentials to a particular region or subset of regions, except the temporary security credentials from AWS GovCloud (US) and China (Beijing), which can be used only in the respective regions from which they originated.', 'Q: What do I need to do before I can start using an AWS STS endpoint?'), ('AWS STS endpoints are active by default in all regions and you can start using them without any further actions. ', 'Q: What happens if I try to use a regional AWS STS endpoint that has \xa0been deactivated for my AWS account?'), ('If you attempt to use a regional AWS STS endpoint that has been deactivated for your AWS account, you will see an AccessDenied exception from AWS STS with the following message: “AWS STS is not activated in this region for account: AccountID. Your account administrator can activate AWS STS in this region using the IAM console.”', 'Q: What permissions are required to activate or deactivate AWS STS regions from the Account Settings page?'), ('Only users with at least iam:* permissions can activate or deactivate AWS STS regions from the Account Settings page in the IAM console. Note that the AWS STS endpoints in US East (N. Virginia), AWS GovCloud (US), and China (Beijing) regions are always active and cannot be deactivated.', 'Q: Can I use the API or CLI to activate or deactivate AWS STS regions?'), ('No. There is no API or CLI support at this time to activate or deactivate AWS STS regions. We plan to provide API and CLI support in a future release. ', 'Q: What is identity federation? AWS Identity and Access Management (IAM) supports identity federation for delegated access to the AWS Management Console or AWS APIs. With identity federation, external identities are granted secure access to resources in your AWS account without having to create IAM users. These external identities can come from your corporate identity provider (such as Microsoft Active Directory or from the AWS Directory Service) or from a web identity provider (such as Amazon Cognito, Login with Amazon, Facebook, Google, or any OpenID Connect-compatible provider).'), ('Q: What are federated users? Federated users (external identities) are users you manage outside of AWS in your corporate directory, but to whom you grant access to your AWS account using temporary security credentials. They differ from IAM users, which are created and maintained in your AWS account.', 'Q: Do you support SAML? Yes, AWS supports the Security Assertion Markup Language (SAML) 2.0.'), ('Q: What SAML profiles does AWS support? The AWS single sign-on (SSO) endpoint supports the IdP-initiated HTTP-POST binding WebSSO SAML Profile. This enables a federated user to sign in to the AWS Management Console using a SAML assertion. A SAML assertion can also be used to request temporary security credentials using the AssumeRoleWithSAML API. For more information, see About SAML 2.0-Based Federation.', 'Q: Can federated users access AWS APIs? Yes. You can programmatically request temporary security credentials for your federated users to provide them secure and direct access to AWS APIs. We have provided a sample application that demonstrates how you can enable identity federation, providing users maintained by Microsoft Active Directory access to AWS service APIs. For more information, see Using Temporary Security Credentials to Request Access to AWS Resources.'), ('Q: Can federated users access the AWS Management Console? Yes. There are a couple ways to achieve this. One way is by programmatically requesting temporary security credentials (such as GetFederationToken or AssumeRole) for your federated users and including those credentials as part of the sign-in request to the AWS Management Console. After you have authenticated a user and granted them temporary security credentials, you generate a sign-in token that is used by the AWS single sign-on (SSO) endpoint. The user’s actions in the console are limited to the access control policy associated with the temporary security credentials.\xa0For more details, see Creating a URL that Enables Federated Users to Access the AWS Management Console (Custom Federation Broker).', 'Alternatively, you can post a SAML assertion directly to AWS sign-in (https://signin.aws.amazon.com/saml). The user’s actions in the console are limited to the access control policy associated with the IAM role that is assumed using the SAML assertion. For more details, see Enabling SAML 2.0 Federated Users to Access the AWS Management Console.'), ('Using either approach allows a federated user to access the console without having to sign in with a user name and password. We have provided a sample application that demonstrates how you can enable identity federation, providing users maintained by Microsoft Active Directory access to the AWS Management Console.\xa0', 'Q: How do I control what a federated user is allowed to do when signed in to the console? When you request temporary security credentials for your federated user using an AssumeRole API, you can optionally include an access policy with the request. The federated user’s privileges are the intersection of permissions granted by the access policy passed with the request and the access policy attached to the IAM role that was assumed. The access policy passed with the request cannot elevate the privileges associated with the IAM role being assumed. When you request temporary security credentials for your federated user using the GetFederationToken API, you must provide an access control policy with the request. The federated user’s privileges are the intersection of the permissions granted by the access policy passed with the request and the access policy attached to the IAM user that was used to make the request. The access policy passed with the request cannot elevate the privileges associated with the IAM user used to make the request. These federated user permissions apply to both API access and actions taken within the AWS Management Console.'), ('Q: What permissions does a federated user need to use the console? A user requires permissions to the AWS service APIs called by the AWS Management Console. Common permissions required to access AWS services are documented in Using Temporary Security Credentials to Request Access to AWS Resources.', 'Q:\xa0How do I control how long a federated user has access to the AWS Management Console? Depending on the API used to create the temporary security credentials, you can specify a session limit between 15 minutes and 36 hours (for GetFederationToken and GetSessionToken) and between 15 minutes and 12 hours (for AssumeRole* APIs), during which time the federated user can access the console. When the session expires, the federated user must request a new session by returning to your identity provider, where you can grant them access again. Learn more about setting session duration.\xa0 '), ('Q: What happens when the identity federation console session times out? The user is presented with a message stating that the console session has timed out and that they need to request a new session. You can specify a URL to direct users to your local intranet web page where they can request a new session. You add this URL when you specify an Issuer parameter as part of your sign-in request. For more information, see Enabling SAML 2.0 Federated Users to Access the AWS Management Console.', 'Q: How many federated users can I give access to the AWS Management Console? There is no limit to the number of federated users who can be given access to the console.'), ('Q:\xa0What is web identity federation?', 'Web identity federation allows you to create AWS-powered mobile apps that use public identity providers (such as Amazon Cognito, Login with Amazon, Facebook, Google, or any OpenID Connect-compatible provider) for authentication. With web identity federation, you have an easy way to integrate sign-in from public identity providers (IdPs) into your apps without having to write any server-side code and without distributing long-term AWS security credentials with the app.'), ('For more information about web identity federation and to get started, see About Web Identity Federation. ', '\xa0'), ('Q: How do I enable web identity federation with accounts from public IdPs?', 'For best results, use Amazon Cognito as your identity broker for almost all web identity federation scenarios. Amazon Cognito is easy to use and provides additional capabilities such as anonymous (unauthenticated) access, and synchronizing user data across devices and providers. However, if you have already created an app that uses web identity federation by manually calling the AssumeRoleWithWebIdentity API, you can continue to use it and your apps will still work.'), ('Here are the basic steps to enable identify federation using one of the supported web IdPs:', 'For more detailed steps, see Using Web Identity Federation\xa0APIs for Mobile Apps.'), ('Q: How does identity federation using AWS Directory Service differ from using a third-party identity management solution?', 'If you want your federated users to be able to access only the AWS Management Console, using AWS Directory Service provides similar capabilities compared to using a third-party identity management solution. End users are able to sign in using their existing corporate credentials and access the AWS Management Console. Because AWS Directory Service is a managed service, customers do not need to set up or manage federation infrastructure, but rather need to create an AD Connector directory to integrate with their on-premises directory. If you are interested in providing your federated users access to AWS APIs, use a third-party offering, or deploy your own proxy server.'), ('Q: Does AWS Billing provide aggregated usage and cost breakdowns by user? No, this is not currently supported. ', 'Q: Does the IAM service cost anything? No, this is a feature of your AWS account provided at no additional charge.'), ('Q: Who pays for usage incurred by users under an AWS Account? The AWS account owner controls and is responsible for all usage, data, and resources under the account. ', 'Q: Is billable user activity logged in AWS usage data? Not currently. This is planned for a future release.'), ('Q: How does IAM compare with Consolidated Billing? IAM and Consolidated Billing are complementary features. Consolidated Billing enables you to consolidate payment for multiple AWS accounts within your company by designating a single paying account. The scope of IAM is not related to Consolidated Billing. A user exists within the confines of an AWS account and does not have permissions across linked accounts. For more details, see Paying Bills for Multiple Accounts Using Consolidated Billing.', 'Q: Can a user access the AWS accounts billing information? Yes, but only if you let them. In order for IAM users to access billing information, you must first grant access to the Account Activity or Usage Reports. See Controlling Access. '), ('Q: What happens if a user tries to access a service that has not yet been integrated with IAM? The service returns an “Access denied” error.', 'Q: Are IAM actions logged for auditing purposes? Yes. You can log IAM actions, STS actions, and AWS Management Console sign-ins by activating AWS CloudTrail. To learn more about AWS logging, see\xa0AWS CloudTrail. '), ('Q: Is there any distinction between people and software agents as AWS entities? No, both of these entities are treated like users with security credentials and permissions. However, people are the only ones to use a password in the AWS Management Console.', 'Q: Do users work with AWS Support Center and Trusted Advisor? Yes, IAM users have the ability to create and modify support cases as well as use Trusted Advisor.'), ('Q: Are there any default quota limits associated with IAM? Yes, by default your AWS account has initial quotas set for all IAM-related entities. For details see Limitations on IAM Entities and Objects.', 'These quotas are subject to change. If you require an increase, you can access the Service Limit Increase form\xa0via the Contact Us page, and choose IAM Groups and Users from the Limit Type\xa0drop-down list.'), ('Q. What is AWS MFA? AWS multi-factor authentication (AWS MFA) provides an extra level of security that you can apply to your AWS environment. You can enable AWS MFA for your AWS account and for individual AWS Identity and Access Management (IAM) users you create under your account.', 'Q. How does AWS MFA work? AWS MFA uses an authentication device that continually generates random, six-digit, single-use authentication codes. There are two primary ways to authenticate using an AWS MFA device:'), ('Q. How do I help protect my AWS resources with MFA? Follow two easy steps:', '1. Get an authentication device. You have two options:'), ('Visit the AWS MFA page for details about how to acquire a hardware or virtual MFA device.', '2. After you have an authentication device, you must activate it in the IAM console. You can also use the IAM CLI to activate the device for an IAM user.'), ('Q. Is there a fee associated with using AWS MFA? AWS does not charge any additional fees for using AWS MFA with your AWS account. However, if you want to use a physical authentication device then you will need to purchase an authentication device that is compatible with AWS MFA from Gemalto, a third party provider. For more details, please visit Gemalto’s website. ', 'Q. Can I have multiple authentication devices active for my AWS account? Yes. Each IAM user can have its own authentication device. However, each identity (IAM user or root account) can be associated with only one authentication device. '), ('Q. Can I use my authentication device with multiple AWS accounts? No. The authentication device or mobile phone number is bound to an individual AWS identity (IAM user or root account). If you have a TOTP-compatible application installed on your smartphone, you can create multiple virtual MFA devices on the same smartphone. Each one of the virtual MFA devices is bound to a single identity, just like a hardware device. If you dissociate (deactivate) the authentication device, you can then reuse it with a different AWS identity. The authentication device cannot be used by more than one identity simultaneously. ', 'Q. I already have a hardware authentication device from my place of work or from another service I use, can I re-use this device with AWS MFA? No. AWS MFA relies on knowing a unique secret associated with your authentication device in order to support its use. Because of security constraints that mandate such secrets never be shared between multiple parties, AWS MFA cannot support the use of your existing hardware authentication device. Only a compatible hardware authentication device purchased from Gemalto can be used with AWS MFA. '), ('Q. I’m having a problem with an order for an authentication device using the third-party provider Gemalto’s website. Where can I get help? Gemalto’s customer service can assist you. ', 'Q. I received a defective or damaged authentication device from the third party provider Gemalto. Where can I get help? Gemalto’s customer service can assist you.'), ('Q. I just received an authentication device from the third party provider Gemalto. What should I do? You simply need to activate the authentication device to enable AWS MFA for your AWS account.\xa0See the IAM console to perform this task. ', 'Q. What is a virtual MFA device? A virtual MFA device is an entry created in a TOTP compatible software application that can generate six-digit authentication codes. The software application can run on any compatible computing device, such as a smartphone. '), ('Q. What are the differences between a virtual MFA device and physical MFA devices? Virtual MFA devices use the same protocols as the physical MFA devices. Virtual MFA devices are software based and can run on your existing devices such as smartphones. Most virtual MFA applications also allow you to enable more than one virtual MFA device, which makes them more convenient than physical MFA devices.', "Q. Which virtual MFA applications can I use with AWS MFA? You can use applications that generate TOTP-compliant authentication codes, such as the Google Authenticator application, with AWS MFA. You can provision virtual MFA devices either automatically by scanning a QR code with the device's camera or by manual seed entry in the virtual MFA application. "), ('Visit the MFA page for a list of supported virtual MFA applications.', 'Q. What is a QR code? A QR code is a two-dimensional barcode that is readable by dedicated QR barcode readers and most smartphones. The code consists of black squares arranged in larger square patterns on a white background. The QR code contains the required security configuration information to provision a virtual MFA device in your virtual MFA application.'), ('Q. How do I provision a new virtual MFA device? You can configure a new virtual MFA device in the IAM console for your IAM users as well as for your AWS root account. You can also use the aws iam create-virtual-mfa-device command in the AWS CLI or the CreateVirtualMFADevice API to provision new virtual MFA devices under your account. The aws iam create-virtual-mfa-device and the CreateVirtualMFADevice API return the required configuration information, called a seed, to configure the virtual MFA device in your AWS MFA compatible application. You can either grant your IAM users the permissions to call this API directly or perform the initial provisioning for them. ', '\xa0'), ('Q. How should I handle and distribute the seed material for virtual MFA devices? You should treat seed material like any other secret (for example the AWS secret keys and passwords).', 'Q. How can I enable an IAM user to manage virtual MFA devices under my account? Grant the IAM user the permission to call the CreateVirtualMFADevice API. You can use this API to provision new virtual MFA devices. '), ('Q. Can I still request preview access to the SMS MFA?', 'We are no longer accepting new participants for the SMS MFA preview. We encourage you to use MFA on your AWS account by using either a hardware or virtual MFA device.'), ('Q. How can I begin using the SMS option during the preview?', 'For existing SMS MFA participants, you can navigate to the IAM console and enable SMS MFA for IAM users. The process involves entering a phone number for each IAM user. Then, when the IAM user signs in to the AWS Management Console, the user receives a six-digit security code via a standard SMS text message and must enter it when signing in. '), ('Q. Where do I enable AWS MFA? You can enable AWS MFA for an AWS account and your IAM users in the IAM console, the AWS CLI, or by calling the AWS API. ', 'Q. What information do I need to activate a hardware or virtual authentication device? If you are activating the MFA device with the IAM console then you only need the device. If you are using the AWS CLI or the IAM API then you need the following:'), ('1. The serial number of the authentication device. The format of the serial number depends on whether you are using a hardware device or a virtual device:', '- Hardware MFA device: The serial number is on the bar-coded label on the back of the device. - Virtual MFA device: The serial number is the Amazon Resource Name (ARN) value returned when you run the iam-virtualmfadevicecreate command in the AWS CLI or call the CreateVirtualMFADevice API. '), ('2. Two consecutive authentication codes displayed by the authentication device.', 'Q. My authentication device seems to be working normally, but I am not able to activate it. What should I do? Please contact us for help. '), ('Q. If I enable AWS MFA for my AWS root account or my IAM users, do they always have to use an authentication code to sign in to the AWS Management Console? Yes. The AWS root credential user and IAM users must have their MFA device with them any time they need to sign in to any AWS website.', "If your MFA device is lost, damaged, stolen, or not working, you can sign in using alternative factors of authentication, deactivate the MFA device, and activate a new device. As a security best practice, we recommend that you change your root account's password."), ('With virtual and hardware MFA, if your IAM users lose or damage their authentication device, or if it is stolen or stops working, you can disable AWS MFA yourself by using the IAM console or the AWS CLI.', 'Q. If I enable AWS MFA for my AWS root account or IAM users, do they always need to enter an MFA code to directly call AWS APIs? No, it’s optional. However, you must enter an MFA code if you plan to call APIs that are secured by MFA-protected API access.'), ('If you are calling AWS APIs using access keys for your AWS root account or IAM user, you do not need to enter an MFA code. For security reasons, we recommend that you remove all access keys from your AWS root account and instead call AWS APIs with the access keys for an IAM user that has the required permissions.', 'Q. How do I sign in to the AWS Portal and AWS Management Console using my authentication device? Follow these two steps:'), ('If you are signing in as an AWS root account, sign in as usual with your \n                \n                  user name \n                 and password when prompted. To sign in as an IAM user, use the account-specific URL and provide your \n                \n                  user name \n                 and password when prompted.', 'On the next page, enter the six-digit authentication code that appears on your authentication device.'), ('Q. Does AWS MFA affect how I access AWS Service APIs? AWS MFA changes the way IAM users access AWS Service APIs only if the account administrator(s) choose to enable MFA-protected API access. Administrators may enable this feature to add an extra layer of security over access to sensitive APIs by requiring that callers authenticate with an AWS MFA device. For more information, see the MFA-protected API access documentation in more detail. ', 'Other exceptions include S3 PUT bucket versioning, GET bucket versioning, and DELETE object APIs, which allow you to require MFA authentication to delete or change the versioning state of your bucket. For more information see the S3 documentation discussing Configuring a Bucket with MFA Delete in more detail. '), ('For all other cases, AWS MFA does not currently change the way you access AWS service APIs.', 'Q. Can I use a given authentication code more than once? No. For security reasons, you can use each authentication code only once.'), ('Q. I was recently asked to resync my authentication device because my authentication codes were being rejected. Should I be concerned? No, this can happen occasionally. AWS MFA relies on the clock in your authentication device being in sync with the clock on our servers. Sometimes, these clocks can drift apart. If this happens, when you use the authentication device to sign in to access secure pages on the AWS website or the AWS Management Console, AWS automatically attempts to resync the authentication device by requesting that you provide two consecutive authentication codes (just as you did during activation).', "Q. My authentication device seems to be working normally, but I am not able to use it to sign in to the AWS Management Console. What should I do? We suggest you resynchronize MFA devices\xa0for your IAM user's credentials.\xa0If you already tried to resync and are still having trouble signing in, you can sign in using alternate factors of authentication\xa0and reset your MFA device. If you are still encountering issues, contact us for help. "), ('Q. My authentication device is lost, damaged, stolen, or not working, and now I can’t sign in to the AWS Management Console. What should I do? If your authentication device is associated with an AWS root account:', 'Q. How do I disable AWS MFA?'), ('To disable AWS MFA for your AWS account, you can deactivate your authentication device using the Security Credentials page. To disable AWS MFA for your IAM users, you need to use the IAM console or the AWS CLI. ', 'Q. Can I use AWS MFA in GovCloud? Yes, you can use AWS virtual MFA and hardware MFA devices in GovCloud. '), ('Q. What is MFA-protected API access? MFA-protected API access is optional functionality that lets account administrators enforce additional authentication for customer-specified APIs by requiring that users provide a second authentication factor in addition to a password. Specifically, it enables administrators to include conditions in their IAM policies that check for and require MFA authentication for access to selected APIs. Users making calls to those APIs must first get temporary credentials that indicate the user entered a valid MFA code.', 'Q. What problem does MFA-protected API access solve? Previously, customers could require MFA for access to the AWS Management Console, but could not enforce MFA requirements on developers and applications interacting directly with AWS service APIs. MFA-protected API access ensures that IAM policies are universally enforced regardless of \n                \n                  access \n                 path. As a result, you can now develop your own application that uses AWS and prompts the user for MFA authentication before calling powerful APIs or accessing sensitive resources.'), ('Q. How do I get started with MFA-protected API access? You can get started in two simple steps:', 'Q. How do developers and users access APIs and resources secured with MFA-protected API access? Developers and users interact with MFA-protected API access both in the AWS Management Console and at the APIs.'), ('In the AWS Management Console, any MFA-enabled IAM user must authenticate with their device to sign in. Users that do not have MFA do not receive access to MFA-protected APIs and resources.', 'At the API level, developers can integrate AWS MFA into their applications to prompt users to authenticate using their assigned MFA devices before calling powerful APIs or accessing sensitive resources. Developers enable this functionality by adding optional MFA parameters (serial number and MFA code) to requests to obtain temporary security credentials (such requests are also referred to as “session requests”). If the parameters are valid, temporary security credentials that indicate MFA status are returned. See the temporary security credentials documentation for more information. '), ('Q. Who can use MFA-protected API access? MFA-protected API access is available for free to all AWS customers.', 'Q. Which services does MFA-protected API access work with? MFA-protected API access is supported by all AWS services that support temporary security credentials. For a list of supported services, see AWS Services that Work with IAM and review the column labeled Supports temporary security credentials. '), ('Q. What happens if a user provides incorrect MFA device information when requesting temporary security credentials? The request to issue temporary security credentials fails. Temporary security credential requests that specify MFA parameters must provide the correct serial number of the device linked to the IAM user as well as a valid MFA code.', 'Q. Does MFA-protected API access control API access for AWS root accounts? No, MFA-protected API access only controls access for IAM users. Root accounts are not bound by IAM policies, which is why we recommend that you create IAM users to interact with AWS service APIs rather than use AWS root account credentials.'), ('Q. Do users have to have an MFA device assigned to them in order to use MFA-protected API access? Yes, a user must first be assigned a unique hardware or virtual MFA device.', 'Q. Is MFA-protected API access compatible with S3 objects, SQS queues, and SNS topics? Yes.'), ('Q. How does MFA-protected API access interact with existing MFA use cases such as S3 MFA Delete? MFA-protected API access and S3 MFA Delete do not interact with each other. S3 MFA Delete currently does not support temporary security credentials. Instead, calls to the S3 MFA Delete API must be made using long-term access keys.', 'Q. Does MFA-protected API access work in the GovCloud (US) region? Yes.'), ('Q. Does MFA-protected API access work for federated users? Customers cannot use MFA-protected API access to control access for federated users. The GetFederatedSession API does not accept MFA parameters. Since federated users can’t authenticate with AWS MFA devices, they are unable to access resources designated using MFA-protected API access.', 'Q. What will I be charged for using AWS IAM?'), ('IAM is a feature of your AWS account offered at no additional charge. You will be charged only for the use of other AWS services by your users.', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/kms/faqs/': [('', ''), ('', ''), ('AWS KMS is a managed encryption service that enables you to easily encrypt your data. AWS KMS provides a highly available key storage, management, and auditing solution for you to encrypt your data across AWS services and within your own applications. ', 'If you are a developer who needs to encrypt data in your applications, you should use the AWS SDKs with AWS KMS support to easily use and protect encryption keys. If you’re an IT administrator looking for a scalable key management infrastructure to support your developers and their growing number of applications, you should use AWS KMS to reduce your licensing costs and operational burden. If you’re responsible for proving data security for regulatory or compliance purposes, you should use AWS KMS to verify that data is encrypted consistently across the applications where it is used and stored. '), ('The easiest way is to get started using AWS KMS is to check the box to encrypt your data within supported AWS services and use the default keys that are created in your account for each service. If you want further controls over the management of these keys, you can create keys in AWS KMS and assign them to be used in the supported AWS services when creating encrypted resources as well as use them directly within your own applications. AWS KMS can be accessed from the “Encryption Keys” section of the AWS Identity and Access Management (IAM) console for web-based access, and the AWS KMS Command Line Interface or AWS Software Development Kit for programmatic access. Visit the Getting Started page to learn more. ', 'Availability is listed on our global Products and Services by Region\xa0page. '), ('You can perform the following key management functions in AWS KMS:', 'AWS KMS allows you to centrally manage and securely store your keys. You can generate keys in KMS or import them from your key management infrastructure. These keys can be used from within your applications and supported AWS services to protect your data, but the key never leaves KMS AWS. You submit data to AWS KMS to be encrypted, or decrypted, under keys that you control. You set usage policies on these keys that determine which users can use them to encrypt and decrypt data. All requests to use these keys are logged in AWS CloudTrail so you can understand who used which key when. '), ('You can use AWS KMS to help encrypt data locally in your own applications or have it encrypted within a supported AWS service. You can use an AWS SDK with AWS KMS support to do the encryption wherever your applications run. You can also request a supported AWS service to encrypt your data as it is being stored. AWS CloudTrail provides access logs to allow you to audit how your keys were used in either situation. ', 'AWS Key Management Service is seamlessly integrated with several other AWS services to make encrypting data in those services as easy as checking a box and selecting the master key you want to use. See the Product Details page for the list of AWS services currently integrated with KMS. All use of your keys within integrated services appears in AWS CloudTrail logs. See the AWS KMS Developer’s Guide for more information on how integrated services use AWS KMS. '), ('AWS cloud services integrated with AWS KMS use a method called envelope encryption to protect your data. Envelope encryption is an optimized method for encrypting data that uses two different keys. A data key is generated and used by the AWS service to encrypt each piece of data or resource. The data key is encrypted under a master key that you define in AWS KMS. The encrypted data key is then stored by the AWS service. When you need your data decrypted by the AWS service, the encrypted data key is passed to AWS KMS and decrypted under the master key that was originally encrypted under so the service can then decrypt your data. ', 'While AWS KMS does support sending data less than 4 KB to be encrypted, envelope encryption can offer significant performance benefits. When you encrypt data directly with KMS it must be transferred over the network. Envelope encryption reduces the network load for your application or AWS cloud service. Only the request and fulfillment of the data key through KMS must go over the network. Since the data key is always stored in encrypted form, it is easy and safe to distribute that key where you need it to go without worrying about it being exposed. Encrypted data keys are sent to AWS KMS and decrypted under master keys to ultimately allow you to decrypt your data. The data key is available directly in your application without having to send the entire block of data to AWS KMS and suffer network latency. '), ('You have the option of selecting a specific master key to use when you want an AWS service to encrypt data on your behalf. A default master key specific to each service is created in your account as a convenience the first time you try to create an encrypted resource. This key is managed by AWS KMS but you can always audit its use in AWS CloudTrail. You can alternately create a customer master key in AWS KMS that you can then use in your own applications or from within a supported AWS service. AWS will update the policies on default master keys as needed to enable new features in supported services automatically. AWS does not modify policies on keys you create. ', 'Creating a key in AWS KMS gives you more control than you have with default service master keys. When you create a customer master key, you can choose to use key material generated by KMS on your behalf or import your own key material, define an alias, a description, and opt-in to have the key automatically rotated once per year if it backed by key material generated by KMS. You also can define permissions on the key to control who can use and manage the key. Management and usage activity related to the key is available for audit in AWS CloudTrail. '), ('Yes. You can import a copy of your key from your own key management infrastructure to KMS and use it with any integrated AWS service or from within your own applications.', 'You can use an imported key to get greater control over the creation, lifecycle management, and durability of your key in KMS. Imported keys are designed to help you meet your compliance requirements which may include the ability to generate or maintain a secure copy of the key in your infrastructure, and the ability to delete the imported copy of the key on demand from AWS infrastructure once you no longer need the key.'), ('You can import 256-bit symmetric keys.', 'During the import, your key must be wrapped by a KMS-provided public key using one of the two RSA PKCS#1 schemes. This ensures that your encrypted key can only be decrypted by KMS. '), ('Yes. You can choose to have KMS automatically rotate keys generated by KMS on your behalf every year. Automatic key rotation is not supported for imported keys. If you choose to import keys to KMS, you can manually rotate them whenever you want. ', 'If you choose to have KMS automatically rotate keys generated by KMS on your behalf, you don’t have to re-encrypt your data. AWS KMS keeps previous versions of keys to use for decryption of data encrypted under an old version of a key. All new encryption requests against a key in AWS KMS are encrypted under the newest version of the key.'), ('If you manually rotate your keys, you may have to re-encrypt your data depending on your application’s configuration. \xa0', 'Yes. You can schedule a customer master key and associated metadata that you created in KMS for deletion, with a configurable waiting period from 7 to 30 days. This waiting period allows you to verify the impact of deleting a key on your applications and users that depend on it. The default waiting period is 30 days. You can cancel the deletion during the waiting period. The key cannot be used if it is scheduled for deletion until you cancel the deletion during the waiting period. The key gets deleted at the end of the configurable waiting period if you don’t cancel the deletion. Once a key gets deleted, you can no longer use it. All data protected under a deleted master key is inaccessible.'), ('For customer master keys with imported key material, you can delete the key material without deleting the customer master key id or metadata in two ways. First, you can delete your imported key material on demand without a waiting period. Second, at the time of importing the key material into the customer master key, you may define an expiration time for how long AWS can use your imported key material before it is deleted. You can re-import your key material into the customer master key if you need to use it again. ', 'You can re-import your copy of the key material with a valid expiration period to KMS under the original customer master key so it can be used. '), ('Yes. Once you import your key to a customer master key, you will receive an Amazon CloudWatch Metric every few minutes that counts down the time to expiration of the imported key. You will also receive an Amazon CloudWatch Event once the imported key under your customer master key expires. You can build logic that acts on these metrics or events and automatically re-imports the key with a new expiration period to avoid an availability risk.\xa0', 'Yes. AWS KMS is supported in AWS SDKs, AWS Encryption SDK, and the Amazon S3 Encryption Client to facilitate encryption of data within your own applications wherever they run. AWS SDK in the Java, Ruby, .NET, and PHP platforms support AWS KMS APIs. Visit the Developing on AWS website for more information. '), ('You can create up to 1000 customer master keys per account per region. As both enabled and disabled customer master keys count towards the limit, we recommend deleting disabled keys that you no longer use. Default master keys created on your behalf for use within supported AWS services do not count against this limit. There is no limit to the number of data keys that can be derived using a master key and used in your application or by AWS services to encrypt data on your behalf. You may request a limit increase for customer master keys by visiting the AWS Support Center.  ', 'With AWS KMS, you pay only for what you use, there is no minimum fee. There are no set-up fees or commitments to begin using the service. At the end of the month, your credit card will automatically be charged for that month’s usage.'), ('You are charged for all customer master keys you create, and for API requests made to the service each month above a free tier.', 'For current pricing information, please visit the AWS KMS pricing page.'), ('Yes. With the AWS Free Usage Tier you can get started with AWS KMS for free in all regions. Default master keys created on your behalf are free to store in your account. There is a free tier for usage as well that provides a free number of requests to AWS KMS each month. For current information on pricing, including the free tier, please visit the AWS KMS pricing page.', 'Except as otherwise noted, our prices are exclusive of applicable taxes and duties, including VAT and applicable sales tax.\xa0For customers with a Japanese billing address, use of AWS services is subject to Japanese Consumption Tax. You can learn more here.'), ('AWS KMS enforces usage and management policies that you define. You choose to allow AWS Identity and Access Management (IAM) users and roles from your account or other accounts to use and manage your keys.  ', 'AWS KMS is designed so that no one has access to your master keys. The service is built on systems that are designed to protect your master keys with extensive hardening techniques such as never storing plaintext master keys on disk, not persisting them in memory, and limiting which systems can connect to the device. All access to update software on the service is controlled by a multi-level approval process that is audited and reviewed by an independent group within Amazon. '), ('More details about these security controls can be found in the AWS KMS Cryptographic Details whitepaper. In addition, you can request a copy of the Service Organization Controls (SOC) report available from AWS Compliance\xa0to learn more about security controls AWS uses to protect your data and master keys. ', '\xa0'), ('Yes. KMS has been validated as having the functionality and security controls to help you meet the encryption and key management requirements (primarily referenced in sections 3.5 and 3.6 of the PCI DSS 3.1).', 'For more details on PCI DSS compliant services in AWS, you can read the\xa0PCI DSS FAQs. '), ('', 'You can request that AWS KMS generate data keys that can be returned for use in your own application. The data keys are encrypted under a master key you define in AWS KMS so that you can safely store the encrypted data key along with your encrypted data. Your encrypted data key (and therefore your source data) can only be decrypted by users with permissions to use the original master key used in encrypting the data key.  '), ('Master keys in AWS KMS are 256-bits in length. Data keys can be generated at 128-bit or 256-bit lengths and encrypted under a master key you define. AWS KMS also provides the ability to generate random data of any length you define suitable for cryptographic use. ', 'No. Master keys are created and used only within AWS KMS to help ensure their security, enable your policies to be consistently enforced, and provide a centralized log of their use.  '), ('Keys are only stored and used in the region in which they are created. They cannot be transferred to another region. For example; keys created in the EU-Central (Frankfurt) region are only stored and used within the EU-Central (Frankfurt) region.  ', 'Logs in AWS CloudTrail will show requests on your master keys, including both management requests (e.g. create, rotate, disable, policy edits) and cryptographic requests (e.g. encrypt/decrypt). Turn on AWS CloudTrail in your account to view these logs. '), ('AWS CloudHSM provides you with a FIPS 140-2 Level 3 validated single-tenant HSM in your Amazon Virtual Private Cloud (VPC) to store and use your keys. You have total control over your keys and the application software that uses them with AWS CloudHSM.\xa0In addition, you can use AWS CloudHSM to support a variety of use cases and applications, such as Digital Rights Management (DRM), Public Key Infrastructure (PKI), asymmetric cryptographic functions, document signing, and high-performance in-VPC cryptographic acceleration.', 'AWS KMS allows you to control the encryption keys used by your applications and supported AWS services in multiple regions around the world from a single console. Centralized management of all your keys in AWS KMS lets you enforce who can use your keys, when they get rotated, and who can manage them. AWS KMS integration with AWS CloudTrail gives you the ability to audit the use of your keys to support your regulatory and compliance activities. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/organizations/faqs/': [(' Q: What is AWS Organizations?', 'AWS Organizations offers policy-based management for multiple AWS accounts. With Organizations, you can create groups of accounts and then apply policies to those groups. Organizations enables you to centrally manage policies across multiple accounts, without requiring custom scripts and manual processes.'), ('Q: Which administrative actions does AWS Organizations enable?', 'AWS Organizations enables the following administrative actions:'), ('Q: Which controls does AWS Organizations enable in this release?', 'In this release, you can define and enforce the AWS service actions, such as Amazon EC2 RunInstances, that are available for use in different AWS accounts within an organization.'), ('Q: Do I need to migrate from my Consolidated Billing family to AWS Organizations?', 'No, AWS has migrated Consolidated Billing families to AWS Organizations automatically, with only consolidated billing features enabled. '), ('Q: How do I get started?', 'To get started, you must first decide which of your AWS accounts will become the master account. If you have a Consolidated Billing family, we already converted your Consolidated Billing payer AWS account to be the master account. If you do not have a Consolidated Billing family, you can either create a new AWS account or select an existing one.'), ('Steps for customers using Consolidated Billing', 'You can also use the AWS CLI (for command-line access) or SDKs (for programmatic access) to perform the same steps to create a new organization. '), (' Q: What is an organization?', 'An organization is a collection of AWS accounts that you can organize into a hierarchy and manage centrally.'), ('Q: What is an AWS account?', 'An AWS account is a container for your AWS resources. You create and manage your AWS resources in an AWS account, and the AWS account provides administrative capabilities for access and billing.'), ('Q: What is a master account?', 'A master account is the AWS account you use to create your organization. From the master account, you can create other accounts in your organization, invite and manage invitations for other accounts to join your organization, and remove accounts from your organization. You can also attach policies to entities such as administrative roots, organizational units (OUs), or accounts within your organization. The master account has the role of a payer account and is responsible for paying all charges accrued by the accounts in its organization. You cannot change which account in your organization is the master account.'), ('Q: What is a member account?', 'A member account is an AWS account, other than the master account, that is part of an organization. If you are an administrator of an organization, you can create member accounts in the organization and invite existing accounts to join the organization. You also can apply policies to member accounts. A member account can belong to only one organization at a time.'), ('Q: What is an administrative root?', 'An administrative root is the starting point for organizing your AWS accounts. The administrative root is the top-most container in your organization’s hierarchy. Under this root, you can create OUs to logically group your accounts and organize these OUs into a hierarchy that best matches your business needs.'), ('Q: What is an organizational unit (OU)?', 'An organizational unit (OU) is a group of AWS accounts within an organization. An OU can also contain other OUs enabling you to create a hierarchy. For example, you can group all accounts that belong to the same department into a departmental OU. Similarly, you can group all accounts running production services into a production OU. OUs are useful when you need to apply the same controls to a subset of accounts in your organization. Nesting OUs enables smaller units of management. For example, in a departmental OU, you can group accounts that belong to individual teams in team-level OUs. These OUs inherit the policies from the parent OU in addition to any controls assigned directly to the team-level OU.'), ('Q: What is a policy?', 'A policy is a “document” with one or more statements that define the controls that you want to apply to a group of AWS accounts. In this release, AWS Organizations supports a specific type of policy called a Service Control Policy (SCP). An SCP defines the AWS service actions, such as Amazon EC2 RunInstances, that are available for use in different accounts within an organization. '), (' Q: Can I define and manage my organization regionally?', 'No. All organization entities are globally accessible, similar to how AWS Identity and Access Management (IAM) works today. You do not need to specify a region when you create and manage your organization. Users in your AWS accounts can use AWS services in any geographic region in which that service is available.'), ('Q: Can I change which AWS account is the master account?', 'No. You cannot change which AWS account is the master account. Therefore, you should select your master account carefully.'), ('Q: How do I add an AWS account to my organization?', 'Use one of the following two methods to add an AWS account to your organization:'), ('Method 1: Invite an existing account to join your organization', 'Note: You can invite more than one AWS account by providing a comma-separated list of email addresses or AWS account IDs.'), ('The specified AWS account receives an email inviting it to join your organization. An administrator in the invited AWS account must accept or reject the request using the AWS Organizations console, AWS CLI, or Organizations API. If the administrator accepts your invitation, the account becomes visible in the list of member accounts in your organization. Any applicable policies, such as SCPs, will be enforced automatically in the newly added account. For example, if your organization has an SCP attached to the root of your organization it will directly be enforced on the newly created accounts.', 'Method 2: Create an AWS account in your organization'), ('You can also create an account by using the AWS SDK or AWS CLI. For both methods, after you add the new account, you can move it to an organizational unit (OU). The new account automatically inherits the policies attached to the OU.', 'Q: Can an AWS account be a member of more than one organization?'), ('No. An AWS account can be a member of only one organization at a time.', 'Q: How can I access an AWS account that was created in my organization?'), ('As part of AWS account creation, AWS Organizations creates an IAM role with full administrative permissions in the new account. IAM users and IAM roles with appropriate permissions in the master account can assume this IAM role to gain access to the newly created account.', 'Q: Can I set up multi-factor authentication (MFA) on the AWS account that I create in my organization programmatically?'), ('No. This currently is not supported.', 'Q: Can I move an AWS account that I have created using AWS Organizations to another organization?'), ('Yes. However, you must first remove the account from your organization and make it a standalone account (see below). After making the account standalone, it can then be invited to join another organization.  ', 'Q:\xa0 Can I remove an AWS account that I created using Organizations and make it a standalone account?'), ('Yes. When you create an account in an organization using the AWS Organizations console, API, or CLI commands, AWS does not collect all of the information required of standalone accounts. For each account that you want to make standalone, you need to update this information, which can include: providing contact information, agreeing to the AWS Customer Agreement, providing a valid payment method, and choosing a support plan option. AWS uses the payment method to charge for any billable (not AWS Free Tier) AWS activity that occurs while the account is not attached to an organization. For more information, see Removing a Member Account from Your Organization.', 'Q: How many AWS accounts can I manage in my organization?'), ('This can vary. If you need additional accounts, go to the AWS Support Center and open a support case to request an increase. ', 'Q: How can I remove an AWS member account from an organization?'), ('You can remove a member account by using one of the following two methods. You might have to provide additional information to remove an account that you created using Organizations. If the attempt to remove an account fails, go to the AWS Support Center and ask for help with removing an account. ', 'Method 1: Remove an invited member account by signing in to the master account'), ('Method 2: Remove an invited member account by signing in to the member account', 'Q: How can I create an organizational unit (OU)?'), ('To create an OU, follow these steps:', 'Note: You can rename the OU later.'), ('You now can add AWS accounts to your OU. You can also use the AWS CLI and AWS APIs to create and manage an OU.', 'Q: How can I add a member AWS account to an OU?'), ('Follow these steps to add member accounts to an OU:', 'Alternatively, you can use the AWS CLI and AWS APIs to add AWS accounts to an OU.'), ('Q: Can an AWS account be a member of multiple OUs?', 'No. An AWS account can be a member of only one OU at a time.'), ('Q: Can an OU be a member of multiple OUs?', 'No. An OU can be a member of only one OU at a time.'), ('Q: How many levels can I have in my OU hierarchy?', 'You can nest your OUs five levels deep. Including root and AWS accounts created in the lowest OUs, your hierarchy can be five levels deep.'), (' Q: How can I control who can manage my organization?', 'You control who can manage your organization and its resources in the same way that you manage access to your other AWS resources: you attach IAM policies to IAM users, groups, or roles in the master account. With IAM policies, you can control the following:'), ('Q: Why is there an IAM role defined in every account that I create using AWS Organizations? ', 'This role enables users in the master account to access a new member account. A new member account initially doesn’t have any users or passwords and can be accessed only by using this role. After you use the role to access the member account and create at least one IAM user with administrator permissions in it, you can safely delete the role if you want. For more information about IAM roles and users, see Accessing a Member Account That Has a Master Account Access Role.'), ('Q: Can I grant permission to manage my organization to IAM users in any AWS member account in my organization?', 'Yes. If you want to grant IAM users in a member account permission to manage your entire organization or parts of your organization, you can use IAM roles. You create a role with the appropriate permissions in the master account and allow users or roles in the member account to assume the new role. This is the same cross-account method that you use to grant an IAM user in one account access to a resource (for example, an Amazon DynamoDB table) in another account.'), ('Q: Can an IAM user in a member account sign in to my organization?', 'No. IAM users can sign in only to their associated member account in your organization.'), ('Q: Can an IAM user sign in to an OU in my organization?', 'No. IAM users can sign in only to their associated AWS account in your organization.'), ('Q: Can I control who in my AWS account can accept an invitation to join an organization?', 'Yes. Using IAM permissions, you can grant or deny users in your account the ability to accept or decline invitations to join an organization. The following policy grants access to view and manage invitations in an AWS account: '), ('For more information, see Using Identity-Based Policies (IAM Policies) for AWS Organizations.', ' Q: At what levels of my organization can I apply a policy?'), ('You can attach a policy to the root of your organization (applies to all accounts in your organization), to individual organizational units (OUs), which applies to all accounts in the OU including nested OUs, or to individual accounts.', 'Q: How can I attach a policy?'), ('You can attach a policy in one of two ways:', 'For more information, see Managing Policies.'), ('Q: Are policies inherited through hierarchical connections in my organization?', 'Yes. For example, let’s assume that you have arranged your AWS accounts into OUs according to your application development stages: DEV, TEST, and PROD. Policy P1 is attached to the organization’s root, policy P2 is attached to the DEV OU, and policy P3 is attached to AWS account A1 in the DEV OU. With this setup, P1+P2+P3 all apply to account A1.'), ('For more information, see About Service Control Policies.', 'Q: What types of policies does AWS Organizations support?'), ('Currently, AWS Organizations supports Service Control Policies (SCPs). You can use SCPs to define and enforce the actions that IAM users, groups, and roles can perform in the accounts to which the SCP is applied.', 'Q: What is a Service Control Policy (SCP)?'), ('Service Control Policies (SCPs) allow you to control which AWS service actions are accessible to principals (account root, IAM users, and IAM roles) in the accounts of your organization. An SCP is required but is not the only control that determines which principals in an account can access resources to grant principals in an account access to resources. The effective permission on a principal in an account that has an SCP attached is the intersection of what is allowed explicitly in the SCP and what is allowed explicitly in the permissions attached to the principal. For example, if an SCP applied to an account states that the only actions allowed are Amazon EC2 actions, and the permissions on a principal in the same AWS account allow both EC2 actions and Amazon S3 actions, the principal is able to access only the EC2 actions.', 'Principals in a member account (including the root user for the member account) cannot remove or change SCPs that are applied to that account.'), ('Q: What does an SCP look like?', 'SCPs follow the same rules and grammar as IAM policies, except you can not specify conditions and the resource section must be equal to “*”. You can use an SCP to deny or allow access to AWS service actions.'), ('Whitelist example', 'The following SCP grants access to all EC2 and S3 service actions in the AWS account. All principals (account root, IAM user, and IAM role) in an account with this SCP applied will not be able to access any other actions, no matter which IAM policies are directly assigned to them. Those IAM policies must explicitly grant EC2 or S3 service actions for the principals to access them.'), (' Blacklist example', ' The following SCP allows access to all AWS service actions except the S3 action, PutObject. All principals (account root, IAM user, and IAM role) with appropriate permissions assigned directly to them in an account with this SCP applied can access any action except the S3 PutObject action. '), ('For more examples, see Strategies for Using SCPs.', 'Q: If I attach an empty SCP to an AWS account, does that mean that I allow all AWS service actions in that AWS account?'), ('No. SCPs behave the same way as IAM policies: an empty IAM policy is equivalent to a default DENY. Attaching an empty SCP to an account is equivalent to attaching a policy that explicitly denies all actions.', 'Q: Can I specify resources and principals in an SCP?'), ('No. In the current release, you can specify only AWS services and actions in an SCP. You can specify resources and principals by using IAM permission policies within the AWS account. For more details, see Service Control Policy Syntax.', 'Q: What are the effective permissions if I apply an SCP to my organization and my principals also have IAM policies?'), ('The effective permissions granted to a principal (account root, IAM user, and IAM role) in an AWS account with an SCP applied are the intersection between those allowed by the SCP and the permissions granted to the principal by IAM permission policies. For example, if an IAM user has "Allow": "ec2:* " and "Allow": "sqs:* ", and the SCP attached to the account has "Allow": "ec2:* " and "Allow": "s3:* ", the resultant permission for the IAM user is "Allow": "ec2:* " The principal cannot perform any Amazon SQS (not allowed by the SCP) or S3 actions (not granted by the IAM policy).', 'Q: Can I simulate the effect of an SCP on an AWS account?'), ('Yes, the IAM policy simulator can include the effects of SCPs. You can use the policy simulator in a member account in your organization to understand the effect on individual principals in that account. An administrator in a member account with the appropriate AWS Organizations permissions can see if an SCP is affecting the access for the principals (account root, IAM user, and IAM role) in your member account.', 'For more information, see Service Control Policies.'), ('Q: Can I create and manage an organization without enforcing an SCP?', 'Yes. You decide which policies that you want to enforce. For example, you could create an organization that takes advantage only of the consolidated billing functionality. This allows you to have a single-payer account for all accounts in your organization and automatically receive default tiered-pricing benefits. '), (' Q: What does AWS Organizations cost?', 'AWS Organizations is offered at no additional charge.'), ('Q: Who pays for usage incurred by users under an AWS member account in my organization?', 'The owner of the master account is responsible for paying for all usage, data, and resources used by the accounts in the organization.'), ('Q: How does AWS Organizations compare with Consolidated Billing?', 'The features of Consolidated Billing are now part of AWS Organizations. Organizations enables you to consolidate payment for multiple AWS accounts within your company by designating a single-payer account. For more information, see Consolidated Billing and AWS Organizations.'), ('Q: Will my bill reflect the organizational unit structure that I created in my organization?', 'No. For now, your bill will not reflect the structure that you have defined in your organization. You can use cost allocation tags in individual AWS accounts to categorize and track your AWS costs, and this allocation will be visible in the consolidated bill for your organization. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/shield/faqs/': [('Q. What is AWS Shield?', 'AWS Shield is a managed service that provides protection against DDoS attacks for web applications running on AWS. AWS Shield Standard is available to all AWS customers at no additional cost. AWS Shield Advanced is an optional paid service available to AWS Business Support and AWS Enterprise Support customers. AWS Shield Advanced provides additional protections against larger and more sophisticated attacks for your applications running on Elastic Load Balancing (ELB), Amazon CloudFront and Route 53.'), ('Q. What is AWS Shield Standard? ', 'AWS Shield Standard provides protection for all AWS customers against common and most frequently occurring Infrastructure (layer 3 and 4) attacks like SYN/UDP Floods, Reflection attacks, and others to support high availability of your applications on AWS.'), ('Q. What is AWS Shield Advanced?', 'AWS Shield Advanced provides enhanced protections for your applications running on Elastic Load Balancing (ELB), Amazon CloudFront and Route 53 against larger and more sophisticated attacks. AWS Shield Advanced is available to AWS Business Support and AWS Enterprise Support customers. AWS Shield Advanced protection provides always-on, flow-based monitoring of network traffic and active application monitoring to provide near real-time notifications of DDoS attacks. AWS Shield Advanced also gives customers highly flexible controls over attack mitigations to take actions instantly. Customers can also engage the DDoS Response Team (DRT) 24X7 to manage and mitigate their application layer DDoS attacks. The DDoS cost protection feature of AWS Shield Advanced protects your AWS bill against higher fees due to Elastic Load Balancing (ELB), Amazon CloudFront and Amazon Route 53 usage spikes during a DDoS attack.'), ('Q. What is DDoS cost protection?', 'AWS Shield Advanced includes DDoS cost protection, a safeguard from scaling charges as a result of a DDoS attack that causes usage spikes on Elastic Load Balancing (ELB), Amazon CloudFront or Amazon Route 53. If any of these services scale up in response to a DDoS attack, you can request credits via the regular AWS Support channel.'), ('Q. Can I use AWS Shield to protect web sites not hosted in AWS?', 'Yes, AWS Shield is integrated with Amazon CloudFront, which supports custom origins outside of AWS.'), ('Q. Can I use IPv6 with all AWS Shield features?', 'Yes. All of AWS Shield’s detection and mitigations work with IPv6 and IPv4 without any discernable changes to performance, scalability or availability of the service.'), ('Q. Are there any pre-requisites to activate AWS Shield Advanced?', 'Yes. The AWS Account you want to subscribe for AWS Shield Advanced must have AWS Business Support or AWS Enterprise Support. See AWS Support website for more details on support plans.'), ('Q. How can I test AWS Shield?', 'AWS Acceptable Use Policy describes permitted and prohibited behavior on AWS and includes descriptions of prohibited security violations and network abuse. However, because penetration testing and other simulated events are frequently indistinguishable from these activities, we have established a policy for customers to request permission to conduct penetration tests and vulnerability scans to or originating from the AWS environment. Visit our Penetration testing page to request permissions.'), ('Q. In which AWS regions is AWS Shield Standard available? \xa0', 'AWS Shield Standard is available on all AWS services in every AWS Region and AWS edge location worldwide.'), ('Please refer to Regional Products and Services for details of AWS Shield Standard availability by region.', 'Q. In which AWS regions is AWS Shield Advanced available? '), ('AWS Shield Advanced is available globally on all Amazon CloudFront and Amazon Route 53 edge locations worldwide. You can protect your web applications hosted anywhere in the world by deploying Amazon CloudFront in front of your application. Your origin servers can be Amazon S3, Amazon EC2, Elastic Load Balancing, or a custom server outside of AWS. You can also enable AWS Shield Advanced directly on Elastic Load Balancing in the following AWS Regions - Northern Virginia,\xa0Northern California, Oregon, Ireland, and Tokyo.', 'Please refer to Regional Products and Services for details of AWS Shield Advanced availability by region.'), ('Q. is AWS Shield HIPAA eligible?', 'Yes, AWS has expanded its HIPAA compliance program to include AWS Shield as a HIPAA eligible service. If you have an executed Business Associate Agreement (BAA) with AWS, you can use AWS Shield to safeguard your web applications running on AWS from Distributed Denial of Service (DDoS) attacks. For more information, see HIPAA Compliance.'), ('Q. What types of attacks can AWS Shield help me stop?', 'AWS Shield helps protects your website from all types of DDoS attacks including Infrastructure layer attacks (like UDP floods), State exhaustion attacks (like TCP SYN floods), and Application layer attacks (like HTTP GET or POST floods). See the AWS WAF and AWS Shield Advanced Developer Guide for examples.'), ('Q. What types of attacks can AWS Shield Standard help protect me from?', 'AWS Shield Standard automatically provides protection for web applications running on AWS against the most common, frequently occurring Infrastructure layer attacks like UDP floods, and State exhaustion attacks like TCP SYN floods. Customers can also use AWS WAF to protect against Application layer attacks like HTTP POST or GET floods. Find more details on how to deploy application layer protections in the AWS WAF and AWS Shield Advanced Developer Guide.'), ('Q. How many resources can I enable for AWS Shield Standard protection?', 'There is no limit on the number of resources subject to AWS Shield Standard protection. You can get the full benefits of AWS Shield Standard protections by following the best practices of DDoS resiliency on AWS.'), ('Q. How many resources can I enable for AWS Shield Advanced protection?', 'You can enable up to 100 AWS resources (e.g., load balancers, Amazon CloudFront distributions, Amazon Route 53 delegation sets) for AWS Shield Advanced protection. If you want to enable more than 100, you can request for a limit increase by creating an AWS Support case.'), ('Q. Can I activate AWS Shield Advanced protection via API?', 'Yes. AWS Shield Advanced can be activated via APIs. You can also add or remove AWS resources from AWS Shield Advanced protection via APIs.'), ('Q. How quickly are attacks mitigated?', 'Typically, 99% of infrastructure layer attacks detected by AWS Shield are mitigated in less than 1 second for attacks on Amazon CloudFront and Amazon Route 53, and less than 5 minutes for attacks on Elastic Load Balancing. The remaining 1% of infrastructure attacks are typically mitigated in under 20 minutes. Application layer attacks are mitigated by writing rules on AWS WAF, which are inspected and mitigated inline with incoming traffic.'), ('Q. What tools does AWS Shield Standard provide me to mitigate DDoS attacks?', 'AWS Shield Standard automatically protects your web applications running on AWS against the most common, frequently occurring DDoS attacks. You can get the full benefits of AWS Shield Standard by following the best practices of DDoS resiliency on AWS.'), ('Q. What tools does AWS Shield Advanced provide me to mitigate DDoS attacks?', 'AWS Shield Advanced manages mitigation of layer 3 and layer 4 DDoS attacks. This means that your designated web applications are protected from attacks like UDP Floods, or TCP SYN floods. In addition, for application layer (layer 7) attacks, you can use AWS WAF to apply your own mitigations, or you can engage the 24X7 AWS DDoS Response Team (DRT), who can write rules on your behalf to mitigate Layer 7 DDoS attacks.'), ('Q. How can I contact the AWS DDoS Response Team?', 'You can engage the AWS DDoS Response Team (DRT) via regular AWS support, or contact AWS Support.'), ('Q. How quickly can I engage the AWS DDoS Response Team (DRT)?', 'Response times for DRT depends on the AWS Support plan you are subscribed to. We will make every reasonable effort to respond to your initial request within the corresponding timeframes. See the AWS Support website for more details about AWS Support plans.'), ('Q. Does AWS Shield notify me when attacks happen?', 'Yes. With AWS Shield Advanced you will get notification of DDoS attacks via CloudWatch metrics.'), ('Q. How quickly will I get an attack notifications?', 'Typically, AWS Shield Advanced provides notification of an attack within a few minutes of attack detection.'), ('Q. Can I get a history of all DDoS attacks on my AWS resources?', 'Yes. With AWS Shield Advanced you will be able to see the history of all incidents in the trailing 13 months.'), ('Q. How can I see if my AWS WAF rules are working?', 'AWS WAF includes two different ways to see how your website is being protected: one-minute metrics are available in CloudWatch and Sampled Web Requests are available in the AWS WAF API or management console. These allow you to see which requests were blocked, allowed, or counted and what rule was matched on a given request (i.e., this web request was blocked due to an IP address condition, etc.). For more information see the AWS WAF and AWS Shield Advanced Developer Guide.'), ('Q. How am I charged for AWS Shield Standard?', 'AWS Shield Standard is built into the AWS services that you already use for your web applications. There are no additional costs for AWS Shield Standard. '), (' Q. How am I charged for AWS Shield Advanced?', 'With AWS Shield Advanced, you pay a monthly fee of $3,000 per month. In addition, you also pay for the Data Transfer usage fees for AWS resources enabled for advanced protection. AWS Shield Advanced charges are in addition to standard fees on Elastic Load Balancing (ELB), Amazon CloudFront and Amazon Route 53. Please see the AWS Shield Pricing page for more details.'), (' Q. How can I enable AWS Shield Advanced across multiple AWS Accounts?', ' If your organization has multiple AWS accounts, then you can subscribe multiple AWS Accounts to AWS Shield Advanced. You will pay the monthly fee once as long as the AWS accounts are all under a single consolidated billing, and you own all the AWS accounts and resources in those accounts.'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/waf/faq/': [('1. What is AWS WAF? AWS WAF is a web application firewall that helps protect web applications from attacks by allowing you to configure rules that allow, block, or monitor (count) web requests based on conditions that you define. These conditions include IP addresses, HTTP headers, HTTP body, URI strings, SQL injection and cross-site scripting.', '2. How does AWS WAF block or allow traffic? As the underlying service receives requests for your web sites, it forwards those requests to AWS WAF for inspection against your rules. Once a request meets a condition defined in your rules, AWS WAF instructs the underlying service to either block or allow the request based on the action you define. '), ('3. How does AWS WAF protect my web site or application? AWS WAF is tightly integrated with Amazon CloudFront and the Application Load Balancer (ALB), services that AWS customers commonly use to deliver content for their websites and applications. When you use AWS WAF on Amazon CloudFront, your rules run in all AWS Edge Locations, located around the world close to your end users. This means security doesn’t come at the expense of performance. Blocked requests are stopped before they reach your web servers. When you use AWS WAF on Application Load Balancer, your rules run in region and can be used to protect internet-facing as well as internal load balancers. ', '4. Can I use AWS WAF to protect web sites not hosted in AWS? Yes, AWS WAF is integrated with Amazon CloudFront, which supports custom origins outside of AWS. '), ('5. What types of attacks can AWS WAF help me to stop? AWS WAF helps protects your website from common attack techniques like SQL injection and Cross-Site Scripting (XSS). In addition, you can create rules that can block attacks from specific user-agents, bad bots, or content scrapers. See the AWS WAF Developer Guide for examples.', "6. Can I get a history of all AWS WAF API calls made on my account for security, operational or compliance auditing? Yes. To receive a history of all AWS WAF API calls made on your account, you simply turn on AWS CloudTrail in the CloudTrail's AWS Management Console. For more information, visit AWS CloudTrail home page or visit the AWS WAF Developer Guide."), ('7. Does AWS WAF support IPv6? Yes, support for IPv6 allows the AWS WAF to inspect HTTP/S requests coming from both IPv6 and IPv4 addresses.', '8. Does IPSet match condition for an AWS WAF Rule support IPv6? Yes, you can setup new IPv6 match condition(s) for new and existing WebACLs, as per the documentation.'), ('9.\xa0Can I expect to see IPv6 address appear in the AWS WAF sampled requests where applicable?  Yes. The sampled requests will show the IPv6 address where applicable.', '10. Can I use IPv6 with all AWS WAF features? Yes. You will be able to use all the existing features for traffic both over IPv6 and IPv4 without any discernable changes to performance, scalability or availability of the service.'), ('11.\xa0What services does AWS WAF support?  AWS WAF can be deployed on Amazon CloudFront and the Application Load Balancer (ALB). As part of Amazon CloudFront it can be part of your Content Distribution Network (CDN) protecting your resources and content at the Edge locations and as part of the Application Load Balancer it can protect your origin web servers running behind the ALBs.', '12.\xa0In what Regions is AWS WAF on ALB available in? US East (Northern Virginia), US West (North California), US West (Oregon), Asia Pacific (Tokyo) and EU (Ireland)'), ('13. Is AWS WAF HIPAA eligible?\xa0', 'Yes, AWS has expanded its HIPAA compliance program to include AWS WAF as a HIPAA eligible service. If you have an executed Business Associate Agreement (BAA) with AWS, you can use AWS WAF to protect your web applications from common web exploits. For more information,\xa0see HIPAA Compliance.'), ('14. How does AWS WAF pricng work? Are there any upfront costs?', 'AWS WAF charges based on the number of web access control lists (web ACLs) that you create, the number of rules that you add per web ACL, and the number of web requests that you receive. There are no upfront commitments. AWS WAF charges are in addition to Amazon CloudFront Pricing and/or the Application Load Balancer (ALB) pricing.'), ('15. What is Rate-based Rule in AWS WAF?', 'Rate-based Rules are a new type of Rule that can be configured in AWS WAF. This feature allows you to specify the number of web requests that are allowed by a client IP in a trailing, continuously updated, 5 minute period. If an IP address breaches the configured limit, new requests will be blocked until the request rate falls below the configured threshold.'), ('16. How does a Rate-based rule compare to a regular AWS WAF Rule?', 'Rate-based Rules are similar to regular Rules, with one addition: the ability to configure a rate-based threshold. If, for example, the threshold for the Rate-based Rule is set to (say) 2,000, the rule will block all IPs that have more than 2,000 requests in the last 5 minute interval. Rate-based Rule can also contain any other AWS WAF Condition that a regular rule would?'), ('17. What does the Rate-based Rule cost?', 'A Rate-based Rule costs the same as a regular AWS WAF Rule which is $1 per rule per WebACL per month'), ('18. What are the use cases for the Rate-based Rule?', 'Here are some popular use cases customers can address with Rate-based rules:'), ('19. Are the existing matching conditions compatible with the Rate-base Rule?', 'Yes. Rate-based rules are compatible with existing AWS WAF match conditions. This allows you to further refine your match criteria and limit rate-based mitigations to specific URLs of your website or traffic coming from specific referrers (or user agents) or add other custom match criteria.'), ('20. Can I use Rate-based rule to mitigate Web layer DDoS attacks?', 'Yes. This new rules type is designed to protect you from use cases such web-layer DDoS attacks, brute force login attempts and bad bots.'), ('21. What visibility features does Rate-based Rules offer?', 'Rate-based Rules support all the visibility features currently available on the regular AWS WAF Rules. Additionally, they will get visibility into the IP addresses blocked as a result of the Rate-based Rule.'), ('22. Can I use Rate-based rule to limit access to a certain parts of my Webpage?', 'Yes. Here is an example. Suppose that you want to limit requests to the login page on your website. To do this, you could add the following string match condition to a rate-based rule:'), ('Additionally, you would specify a Rate Limit of, say, 15,000 requests per 5 minutes. Adding this rate-based rule to a web ACL will limit requests to your login page per IP address without affecting the rest of your site.', '23. Can I exempt certain high-traffic source IP ranges from being blacklisted by my Rate-based Rule(s)?'), ('Yes. You can do this by having an IP Whitelist condition within the Rate-base Rule.', '24. How accurate is your GeoIP database?'), ('The accuracy of the IP Address to country lookup database varies by region. Based on recent tests, our overall accuracy for the IP address to country mapping is 99.8%.', '1. What are AWS WAF Managed Rules?'), ('AWS WAF Managed Rules are an easy way to deploy pre-configured rules to protect your applications common threats like application vulnerabilities like OWASP, bots, or Common Vulnerabilities and Exposures (CVE). All Managed Rules are automatically updated by AWS Marketplace security Sellers.', '2. How can I subscribe to Managed Rules?'), ('You can subscribe to a Managed Rule provided by a Marketplace security Seller from the AWS WAF console or from the AWS Marketplace. All subscribed Managed Rules will be available for you to add to an AWS WAF web ACL.', '3. Can I use Managed Rules along with my existing AWS WAF rules?'), ('Yes, you can use Managed Rules along with your custom AWS WAF rules. You can add Managed Rules to your existing AWS WAF web ACL to which you might have already added your own rules.', '4. Does a Managed Rule have multiple AWS WAF rules?'), ('Yes, each Managed Rule could have multiple AWS WAF rules. The number of rules depends on each security seller and their Marketplace product.', '5. Will Managed Rules add to my existing AWS WAF limit on number of rules?'), ('The number of rules inside a Managed Rule does not impact your AWS WAF limits. But each Managed Rule added to your web ACL will count as 1 rule.', '6. How can I disable a Managed Rule?'), ('You can add a Managed Rule to a web ACL or remove it from the web ACL anytime. The Managed Rules are disabled once you disassociate a Managed Rule from any web ACLs.', '7.\xa0How can I test a Managed Rule?'), ('AWS WAF allows you to configure a “count” action for a Managed Rule, which counts the number of web requests that are matched by the rules inside the Managed Rule. You can look at the number of counted web requests to estimate how many of your web requests would be blocked if you enable the Managed Rule.', '1. Can I configure custom error pages? Yes, you can configure CloudFront to present a custom error page when requests are blocked. Please see the CloudFront Developer Guide for more information'), ('2. How long does it take AWS WAF to propagate my rules? After an initial setup, adding or changing to rules typically takes around a minute to propagate worldwide. ', '3. How can I see if my rules are working? AWS WAF includes two different ways to see how your website is being protected: one-minute metrics are available in CloudWatch and Sampled Web Requests are available in the AWS WAF API or management console. These allow you to see which requests were blocked, allowed, or counted and what rule was matched on a given request (i.e., this web request was blocked due to an IP address condition, etc.). For more information see the AWS WAF Developer Guide.'), ('4. How can I test my rules? AWS WAF allows you to configure a “count” action for rules, which counts the number of web requests that meet your rule conditions. You can look at the number of counted web requests to estimate how many of your web requests would be blocked or allowed if you enable the rule.', '5. How long are Real-Time Metrics and Sampled Web Requests stored? Real-Time Metrics are stored in Amazon CloudWatch. Using Amazon CloudWatch you can configure the time period in which you want to expire events. Sampled Web Requests are stored for up to 2 hours.'), ('6. Can AWS WAF inspect HTTPS traffic? Yes. AWS WAF helps protect applications and can inspect web requests transmitted over HTTP or HTTPS.', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/mobile/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/api-gateway/faqs/': [('Q: What is Amazon API Gateway?', 'Amazon API Gateway is a fully managed service that makes it easy for developers to publish, maintain, monitor, and secure APIs at any scale. With a few clicks in the AWS Management Console, you can create an API that acts as a “front door” for applications to access data, business logic, or functionality from your back-end services, such as applications running on Amazon Elastic Compute Cloud (Amazon EC2), code running on AWS Lambda, or any web application. Amazon API Gateway handles all of the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, authorization and access control, monitoring, and API version management. Amazon API Gateway has no minimum fees or startup costs. You pay only for the API calls you receive and the amount of data transferred out.'), ('Q: Why use Amazon API Gateway?', 'Amazon API Gateway provides developers with a simple, flexible, fully managed, pay-as-you-go service that handles all aspects of creating and operating robust APIs for application back ends.\xa0 With Amazon API Gateway, you can launch new services faster and with reduced investment so you can focus on building your core business services.\xa0 Amazon API Gateway was built to help you with several aspects of creating and managing APIs:'), ('1) Metering. API Gateway helps you define plans that meter and restrict third-party developer access to your APIs. You can define a set of plans, configure throttling, and quota limits on a per API key basis. API Gateway automatically meters traffic to your APIs and lets you extract utilization data for each API key.', '2) Security. API Gateway provides you with multiple tools to authorize access to your APIs and control service operation access. Amazon API Gateway allows you to leverage AWS administration and security tools, such as AWS Identity and Access Management (IAM) and Amazon Cognito, to authorize access to your APIs. Amazon API Gateway can verify signed API calls on your behalf using the same methodology AWS uses for its own APIs. Using custom authorizers written as AWS Lambda functions, API Gateway can also help you verify incoming bearer tokens, removing authorization concerns from your backend code.'), ('3) Resiliency. Amazon API Gateway helps you manage traffic with throttling so that backend operations can withstand traffic spikes. Amazon API Gateway also helps you improve the performance of your APIs and the latency your end users experience by caching the output of API calls to avoid calling your backend every time.', '4) Operations Monitoring. After an API is published and in use, API Gateway provides you with a metrics dashboard to monitor calls to your services. The Amazon API Gateway dashboard, through integration with Amazon CloudWatch, provides you with backend performance metrics covering API calls, latency data and error rates. You can enable detailed metrics for each method in your APIs and also receive error, access or debug logs in CloudWatch Logs.'), ('5) Lifecycle Management. After an API has been published, you often need to build and test new versions that enhance or add new functionality. Amazon API Gateway lets you operate multiple API versions and multiple stages for each version simultaneously so that existing applications can continue to call previous versions after new API versions are published.', '6) Designed for Developers. Amazon API Gateway allows you to quickly create APIs and assign static content for their responses to reduce cross-team development effort and time-to-market for your applications. Teams who depend on your APIs can begin development while you build your backend processes.'), ('Q: How do I get started with Amazon API Gateway?', 'You can quickly and easily create a custom API using Amazon API Gateway. For a simple “Hello World” example, follow these steps:'), ('1.\xa0 Go to the Amazon API Gateway console.', '2.\xa0 Select an existing REST API or create a new one by entering a name for the API.'), ('3.\xa0 On the REST API tree view, click “Create Resource”.', '4.\xa0 Choose a name for your resource, such as “cars”.'), ('5. With the new resource selected, click the button to create a new method and select the HTTP verb associated with the method (for example, GET).', '6.\xa0 Select the integration type (for example, HTTP Proxy), and enter the URL the Amazon API Gateway should call.'), ('7.\xa0 Define how requests and responses are transformed using a mapping template, or accept the default settings to pass all of the request and response data through without applying any transformation.', '8.\xa0 Configure the method’s security settings.'), ('9.\xa0 Deploy your new API to a stage.', '10.\xa0From the Stage management page, set up caching and throttling.'), ('11.\xa0On the Client Platforms tab in the Amazon API Gateway console, click the button to download the Android, iOS SDK, or JavaScript library that contains helper methods to call your sayHello operation. The SDK library makes calling your APIs similar to calling a local method. The client SDK automatically handles retries, informing the developer of network or other fault conditions. The SDK library includes the logic necessary to authenticate the client application to your APIs.', '12.\xa0Integrate the downloaded SDK into your mobile application. Write the code to invoke your custom API. For example, to invoke the getCar(int carId) API in an iOS application:'), ('–(void)getSampleCar', '{'), ('NSString *response = [MyServiceClient getCar:1323];', 'NSLog( @”Response was [%@]”, response );'), ('}', '13.\xa0Run your application.'), ('Q: Can I create HTTPS endpoints?', 'Yes, all of the APIs created with Amazon API Gateway expose HTTPS endpoints only. Amazon API Gateway does not support unencrypted (HTTP) endpoints. By default, Amazon API Gateway assigns an internal domain to the API that automatically uses the Amazon API Gateway certificate. When configuring your APIs to run under a custom domain name, you can provide your own certificate for the domain.'), ('Q: What data types can I use with Amazon API Gateway?', 'APIs built on Amazon API Gateway can accept any payloads sent over HTTP. Typical data formats include JSON, XML, query string parameters, and request headers. You can declare any content type for your API’s responses, and then use the transform templates to change the back-end response into your desired format.'), ('Q: With what backends can Amazon API Gateway communicate?', 'Amazon API Gateway can execute AWS Lambda functions in your account, start AWS Step Functions state machines, or call HTTP endpoints hosted on AWS Elastic Beanstalk, Amazon EC2, and also non-AWS hosted HTTP based operations that are accessible via the public Internet.\xa0API Gateway also allows you to specify a mapping template to generate static content to be returned, helping you mock your APIs before the backend is ready. You can also integrate API Gateway with other AWS services directly – for example, you could expose an API method in API Gateway that sends data directly to Amazon Kinesis.\xa0'), ('Q: For which client platforms can Amazon API Gateway generate SDKs?', 'API Gateway generates custom SDKs for mobile app development with Android and iOS, and for web app development with JavaScript. Once an API and its models are defined in API Gateway, you can use the AWS console or the API Gateway APIs to generate and download a client SDK.'), ('Q: In which AWS regions is Amazon API Gateway available?', 'Please refer to Regional Products and Services for details of Amazon API Gateway service availability by region. '), ('Q: What can I manage through the Amazon API Gateway console?', 'Through the Amazon API Gateway console, you can define the REST API and its associated resources and methods, manage the API lifecycle, generate client SDKs and view API metrics. You can also use the API Gateway console to define your APIs’ usage plans, manage developers’ API keys, and configure throttling and quota limits. All of the same actions are available through the API Gateway APIs.'), ('Q: What is a REST API?', 'In Amazon API Gateway, a REST API is a group of resources and methods, or endpoints. REST APIs can be deployed to different stages and cloned to new versions.'), ('Q: What is a resource?', 'A resource is a typed object that is part of your API’s domain. Each resource may have associated a data model, relationships to other resources, and can respond to different methods.You can also define resources as variables to intercept requests to multiple child resources.'), ('Q: What is a method?', 'Each resource within a REST API can support one or more of the standard HTTP methods. You define which verbs should be supported for each resource (GET, POST, PUT, PATCH, DELETE, HEAD, OPTIONS) and their implementation. For example, a GET to the cars resource should return a list of cars. To connect all methods within a resource to a single backend endpoint, API Gateway also supports a special “ANY” method.\xa0'), ('Q: What is an usage plan? Usage plans help you declare plans for third-party developers that restrict access only to certain APIs, define throttling and request quota limits, and associate them with API keys. You can also extract utilization data on an per-API key basis to analyze API usage and generate billing documents. For example, you can create a basic, professional, and enterprise plans – you can configure the basic usage plan to only allow 1,000 requests per day and a maximum of 5 requests per second (RPS).', 'Q: What is the Amazon API Gateway API lifecycle?'), ('With Amazon API Gateway, each REST API can have multiple stages. Stages are meant to help with the development lifecycle of an API -- for example, after you’ve built your APIs and you deploy them to a development stage, or when you are ready for production, you can deploy them to a production stage.', 'Q: What is a stage?'), ('In Amazon API Gateway, stages are similar to tags. They define the path through which the deployment is accessible. For example, you can define a development stage and deploy your cars API to it. The resource will be accessible at https://www.myapi.com/dev/cars. You can also set up custom domain names to point directly to a stage, so that you don’t have to use the additional path parameter. For example, if you pointed myapi.com directly to the development stage, you could access your cars resource at https://www.myapi.com/cars.\xa0Stages can be configured using variables that can be accessed from your API configuration or mapping templates.', 'Q: What are stage variables? Stage variables let you define key/value pairs of configuration values associated with a stage. These values, similarly to environment variables, can be used in your API configuration. For example, you could define the HTTP endpoint for your method integration as a stage variable, and use the variable in your API configuration instead of hardcoding the endpoint – this allows you to use a different endpoint for each stage (e.g. dev, beta, prod) with the same API configuration. Stage variables are also accessible in the mapping templates and can be used to pass configuration parameters to your Lambda or HTTP backend.'), ('Q: What if I mistakenly deployed to a stage?', 'Amazon API Gateway saves the history of your deployments. At any point, using the Amazon API Gateway APIs or the console, you can roll back a stage to a previous deployment.'), ('Q: Can I run multiple versions of the same REST API?', 'Yes. Amazon API Gateway gives you the ability to clone an existing API. When you are ready to start working on the next major version of your API, you will be able to keep working on your version 1 and version 2 APIs simultaneously.'), ('Q: Can I use my Swagger API definitions?', 'Yes. You can use our open source Swagger importer tool to import your Swagger API definitions into Amazon API Gateway. With the Swagger importer tool you can create and deploy new APIs as well as update existing ones. '), ('Q: How do I monetize my APIs on API Gateway? You can monetize your APIs on API Gateway by publishing them as products in AWS Marketplace. You will first need to register as a seller in AWS Marketplace, and submit your usage plans on API Gateway as products. Read here to learn more about API Monetization.', 'Q: How do I document my API on Amazon API Gateway?'), ('API Gateway offers the ability to create, update, and delete documentation associated with each portion of your API, such as methods and resources. You can access documentation-related APIs through the AWS SDKs, CLI, via RESTful calls, or by editing the documentation strings directly in the API Gateway console. Documentation can also be imported as a Swagger file, either as part of the API or separately, allowing you to add or update the documentation without disturbing the API definition. API Gateway conforms to the Open API specification for documentation imported from, or exported to, Swagger files. \xa0', 'Q: How can I avoid creating redundant copies of error messages and other documentation that recurs frequently in my API? In addition to offering standards-conformant API documentation support, API Gateway additionally supports documentation inheritance, making it simple to define a documentation string once and then use it in multiple places. Inheritance simplifies the process of defining API documentation, and can be converted to the standard representation when exporting the API as a Swagger file. '), ('Back To Top >>', 'Q: How do I authorize access to my APIs?'), ('With Amazon API Gateway, you can optionally set your API methods to require authorization. When setting up a method to require authorization you can leverage AWS Signature Version 4 or custom authorizers to support your own bearer token auth strategy.', 'Q: How does AWS Signature Version 4 work?'), ('You can use AWS credentials -- access and secret keys – to sign requests to your service and authorize access like other AWS services. The signing of an Amazon API Gateway API request is managed by the custom API Gateway SDK generated for your service. You can retrieve temporary credentials associated with a role in your AWS account using Amazon Cognito. ', 'Q: What is a custom authorizer?'), ('Custom authorizers are AWS Lambda functions. With custom request authorizers, you will be able to authorize access to APIs using a bearer token auth strategy such as OAuth. When an API is called, API Gateway checks if a custom authorizer is configured, API Gateway then calls the Lambda function with the incoming authorization token. You can use Lambda to implement various authorization strategies (e.g. JWT verification, OAuth provider callout) that return IAM policies which are used to authorize the request. If the policy returned by the authorizer is valid, API Gateway will cache the policy associated with the incoming token for up to 1 hour.', 'Q: Can Amazon API Gateway generate API keys for distribution to third-party developers?'), ('Yes. API Gateway can generate API keys and associate them with an usage plan. Calls received from each API key are monitored and included in the Amazon CloudWatch Logs you can enable for each stage. However, we do not recommend you use API keys for authorization. You should use API keys to monitor usage by third-party developers and leverage a stronger mechanism for authorization, such as signed API calls or OAuth.', 'Q: How can I address or prevent API threats or abuse?'), ('Amazon API Gateway supports throttling settings for each method in your APIs. You can set a standard rate limit and a burst rate limit per second for each method in your REST APIs. Further, Amazon API Gateway automatically protects your backend systems from distributed denial-of-service (DDoS) attacks, whether attacked with counterfeit requests (Layer 7) or SYN floods (Layer 3).', 'Q: Can Amazon API Gateway work within an Amazon VPC?'), ('No. Amazon API Gateway endpoints are always public to the Internet. Proxy requests to backend operations also need to be publicly accessible on the Internet. However, you can generate a client-side SSL certificate in Amazon API Gateway to verify that requests to your backend systems were sent by API Gateway using the public key of the certificate.', 'Q: Can I verify that it is API Gateway calling my backend? Yes. Amazon API Gateway can generate a client-side SSL certificate and make the public key of that certificate available to you. Calls to your backend can be made with the generated certificate, and you can verify calls originating from Amazon API Gateway using the public key of the certificate.'), ('Q: Can I use AWS CloudTrail with Amazon API Gateway?', 'Yes. Amazon API Gateway is integrated with AWS CloudTrail to give you a full auditable history of the changes to your REST APIs. All API calls made to the Amazon API Gateway APIs to create, modify, delete, or deploy REST APIs are logged to CloudTrail in your AWS account.'), ('Back To Top >>', ' Q: How can I monitor my Amazon API Gateway APIs?'), ('Amazon API Gateway logs API calls, latency, and error rates to Amazon CloudWatch in your AWS account. The metrics are also available through the Amazon API Gateway console in a REST API dashboard. API Gateway also meters utilization by third-party developers, the data is available in the API Gateway console and through the APIs.', 'Q: Can I set up alarms on the Amazon API Gateway metrics?'), ('Yes, Amazon API Gateway sends logging information and metrics to Amazon CloudWatch. You can utilize the Amazon CloudWatch console to set up custom alarms.', 'Q: How can I set up metrics for Amazon API Gateway?'), ('By default, Amazon API Gateway monitors traffic at a REST API level. Optionally, you can enable detailed metrics for each method in your REST API from the deployment configuration APIs or console screen. Detailed metrics are also logged to Amazon CloudWatch and will be charged at the CloudWatch rates.', 'Q: Can I determine which version of the API my customers are using?'), ('Yes. Metric details are specified by REST API and stage. Additionally, you can enable metrics for each method in your REST API.', 'Q: Does Amazon API Gateway provide logging support?'), ('Yes. Amazon API Gateway integrates with Amazon CloudWatch Logs. You can optionally enable logging for each stage in your API. For each method in your REST APIs, you can set the verbosity of the logging, and if full request and response data should be logged.', 'Q: How quickly are logs available?'), ('Logs, alarms, error rates and other metrics are stored in Amazon CloudWatch and are available near real time.', 'Back To Top >>'), ('Q: How can I protect my backend systems and applications from traffic spikes?', 'Amazon API Gateway provides throttling at multiple levels including global and by service call. Throttling limits can be set for standard rates and bursts. For example, API owners can set a rate limit of 1,000 requests per second for a specific method in their REST APIs, and also configure Amazon API Gateway to handle a burst of 2,000 requests per second for a few seconds. Amazon API Gateway tracks the number of requests per second. Any requests over the limit will receive a 429 HTTP response. The client SDKs generated by Amazon API Gateway retry calls automatically when met with this response.'), ('Q: Can I throttle individual developers calling my APIs? Yes. With usage plans you can set throttling limits for individual API keys.', 'Q: How does throttling help me?'), ('Throttling ensures that API traffic is controlled to help your backend services maintain performance and availability.', 'Q: At which levels can Amazon API Gateway throttle inbound API traffic?'), ('Throttling rate limits can be set at the method level. You can edit the throttling limits in your method settings through the Amazon API Gateway APIs or in the Amazon API Gateway console.', 'Q: How are throttling rules applied? First. API Gateway checks against your AWS account limit. If the traffic is below the set account limit, API Gateway checks the limit you have set on a stage or method. If the traffic is below the stage limit, then API Gateway applies the usage plans limits you set on a per-API key basis.'), ('Q: Does Amazon API Gateway provide API result caching?', 'Yes. You can add caching to API calls by provisioning an Amazon API Gateway cache and specifying its size in gigabytes. The cache is provisioned for a specific stage of your APIs. This improves performance and reduces the traffic sent to your back end. Cache settings allow you to control the way the cache key is built and the time-to-live (TTL) of the data stored for each method. Amazon API Gateway also exposes management APIs that help you invalidate the cache for each stage.'), ('Q: What happens if a large number of end users try to invoke my API simultaneously?', 'If caching is not enabled and throttling limits have not been applied, then all requests will pass through to your backend service until the account level throttling limits are reached. If throttling limits are in place, then Amazon API Gateway will shed the necessary amount of requests and send only the defined limit to your back-end service. If a cache is configured, then Amazon API Gateway will return a cached response for duplicate requests for a customizable time,\xa0but only if under configured throttling limits. This balance between the backend and client ensures optimal performance of the APIs for the applications that it supports. Requests that are throttled will be automatically retried by the client-side SDKs generated by Amazon API Gateway. By default, Amazon API Gateway does not set any cache on your API methods.'), ('Q: How do APIs scale?', 'Amazon API Gateway acts as a proxy to the backend operations that you have configured. Amazon API Gateway will automatically scale to handle the amount of traffic your API receives. Amazon API Gateway does not arbitrarily limit or throttle invocations to your backend operations and all requests that are not intercepted by throttling and caching settings in the Amazon API Gateway console are sent to your backend operations.'), ('Back To Top >> ', 'Q: How am I charged for using Amazon API Gateway?'), ('Amazon API Gateway rates are $3.50 per million API calls, plus the cost of data transfer out, in gigabytes. If you choose to provision a cache for your API, hourly rates apply. Please see the API Gateway Pricing pages for details on data transfer and caching costs.', 'Q: Who pays for Amazon API Gateway API calls generated by third-party developers?'), ('The API owner is charged for the calls to their APIs on API Gateway.', 'Q: If an API response is served by cached data, is it still considered an API call for billing purposes?'), ('Yes. API calls are counted equally for billing purposes whether the response is handled by your backend operations or the Amazon API Gateway caching operation.', 'Back To Top >> '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/cognito/faqs/': [('Q: What is Amazon Cognito? Amazon Cognito lets you easily add user sign-up and authentication to your mobile and web apps. Amazon Cognito also enables you to authenticate users through an external identity provider and provides temporary security credentials to access your app’s backend resources in AWS or any service behind Amazon API Gateway. Amazon Cognito works with external identity providers that support SAML or OpenID Connect, social identity providers (such as Facebook, Twitter, Amazon) and you can also integrate your own identity provider.', 'In addition, Amazon Cognito enables you to synchronize data across a user’s devices so that their app experience remains consistent when they switch between devices or upgrade to a new device. Your app can save data locally on users’ devices allowing your applications to work even when the devices are offline and then automatically synchronize the data when the device is back online.'), ('With Amazon Cognito, you can focus on creating great app experiences instead of worrying about building, securing, and scaling a solution to handle user management, authentication, and sync across platforms and devices. ', 'Q: Who should use Amazon Cognito? Amazon Cognito is designed for developers who want to add user management and sync functionality to their mobile and web apps. Developers can use Cognito Identity to add sign-up and sign-in to their apps and to enable their users to securely access their app’s resources. Cognito also enables developers to sync data across devices, platforms, and applications. '), ('Q: How do I start using Amazon Cognito? You can easily get started by visiting the AWS Console. If you do not have an Amazon Web Services account, you can create an account when you sign in to the console. Once you have created a user pool for user management or an identity pool for federated identities or sync operations, you can download and integrate the AWS Mobile SDK with your app. Alternatively you can call the Cognito server-side APIs directly, instead of using the SDK. See our developer guide for more information.', 'Q: Does Amazon Cognito expose server-side APIs? Yes. Cognito exposes server-side APIs. You can create your own custom interface to Cognito by calling these APIs directly. The server-side APIs are described in the Developer Guide.'), ('Q: Which platforms does Amazon Cognito support? Support for Cognito is included in the optional AWS Mobile SDK, which is available for iOS, Android, Unity, and Kindle Fire. Cognito is also available in the AWS SDK for JavaScript. Cognito Your User Pools is currently supported in the AWS Mobile SDKs for iOS and Android and in the JavaScript AWS SDK for Cognito. Visit our resource page to download the SDKs.', 'Q: Do I have to use the AWS Mobile SDK? No. Cognito exposes its control and data APIs as web services. You can implement your own client library calling the server-side APIs directly.'), ('\xa0', ' Q: Can I have my own identity provider to support user sign-up and sign-in?'), ('Yes, you can easily and securely add sign-up and sign-in functionality to your apps with Cognito Identity. Your users can sign-up and sign-in using email, phone number, or user name. You can also implement enhanced security features, such as email verification, phone number verification, and multi-factor authentication. Cognito Identity also enables you to customize workflows by, for example, adding app-specific logic to user registration for fraud detection and user validation through AWS Lambda. To learn more, visit our docs.', 'Q: What is a User Pool?'), ('A User Pool is your user directory that you can configure for your web and mobile apps. A User Pool securely stores your users’ profile attributes. You can create and manage a User Pool using the AWS console, AWS CLI, or AWS SDK.', 'Q: What user profile information is supported by Cognito Identity?'), ('Developers can use either standard OpenID Connect-based user profile attributes (such as user name, phone number, address, time zone, etc.) or customize to add app-specific user attributes.', 'Q: Can I enable my application’s users to sign up or sign in with an email address or phone number?'), ('Yes, you can use the aliasing feature to enable your users to sign up or sign in with an email address and a password or a phone number and a password. To learn more, visit our docs.', 'Q: Can I set up password policies?'), ('Yes, you can set up password policies, such as strength of password and character type requirements, when setting up or configuring your user pool.', 'Q: Can I verify the email addresses and phone numbers of my application’s users?'), ('Yes, with Cognito Identity you can require your users’ email addresses and phone numbers to be verified prior to providing them access to your application. During sign-up, a verification code will be sent to the user’s phone number or email address, and the user must input the verification code to complete sign-up and become confirmed.', 'Q: Does Cognito Identity support SMS-based multi-factor authentication (MFA)?'), ('Yes, you can enable the end users of your application to sign in with SMS-based MFA. With SMS-based MFA enabled, your users will be prompted for their password (the first factor—what they know), and for a security code that can only be received on their mobile phone via SMS (the second factor—what they have).', 'Q: Is it possible to customize user sign-up and sign-in workflows?'), ('Yes, you can customize sign-up and sign-in by adding app-specific logic to the user sign-up and sign-in flows using AWS Lambda. For example, you can create AWS Lambda functions to identify fraud or perform additional validations on user data. You are able to trigger developer-provided Lambda functions at pre-registration, at post-confirmation, at pre-authentication, during authentication to customize the challenges, and at post-authentication. You can also use Lambda functions to customize messages sent as part of email or phone number verification and multi-factor authentication.', "Q: Can I remember the devices associated with my application's users in a Cognitio user pool?"), ("Yes, you can opt to remember devices used to access your application, and you associate these remembered devices with your application's users in a Cognito user pool. You can also opt to use remembered devices to supress second factor challenges for your users when you have set up multi-factor authentication.", 'Q: How can I migrate my existing users into an Amazon Cognito user pool?'), ('You can use our import tool to migrate your existing users into an Amazon Cognito user pool. User attribute values are imported from a .csv file, which can be uploaded through the console, our APIs, or CLI. When imported users first sign in, they confirm their account and create a new password with a code sent to their email address or phone. There is no additional cost for using the import tool. To learn more, see the import tool documentation.', 'The import tool does not migrate passwords. If you want to retain your users’ current passwords, you might consider an alternative approach to migrate users one at a time as they sign-in to your app during a transition period. With this approach, your app first tries to sign-in the user with your Cognito user pool. If that user doesn’t exist in the user pool, your app will sign the user in with your existing identity system and temporarily retain the username and password used to do so. After a user successfully signs in with your existing identity system, your app would then use the same username and password to create the user in your Cognito user pool. This approach requires maintaining your existing identity system during the transition period, but after the transition period ends, you can use our import tool to import the remaining users (without their passwords).\xa0'), ('Q: Can I use Cognito Identity to federate identities and secure access to AWS resources? Yes, Cognito Identity enables you to authenticate users through an external identity provider and provides temporary security credentials to access your app’s backend resources in AWS or any service behind Amazon API Gateway. Amazon Cognito works with external identity providers that support SAML or OpenID Connect, social identity providers (such as Facebook, Twitter, Amazon) and you can also integrate your own identity provider. ', 'Q: Which public identity providers can I use with Amazon Cognito Identity? You can use Amazon, Facebook, Twitter, Digits, Google and any other OpenID Connect compatible identity provider.'), ('Q: What is an Identity Pool? Identity pools are the containers that Cognito Identity uses to keep your apps’ federated identities organized. Identity Pool associates federated identities from social identity providers with a unique user specific identifier. Identity Pools do not store any user profiles. An identity pool can be associated with one or many apps. If you use two different identity pools for two apps then the same end user will have a different unique identifier in each Identity Pool.', 'Q: How does the login flow work with public identity providers? Your mobile app authenticates with an Identity Provider (IdP) using the provider’s SDK. Once the end user is authenticated with the IdP, the OAuth or OpenID Connect token or the SAML assertion returned from the IdP is passed by your app to Cognito Identity, which returns a new Cognito ID for the user and a set of temporary, limited-privilege AWS credentials.'), ('Q: Can I register and authenticate my own users? Cognito Identity can integrate with your existing authentication system. With a simple API call you can retrieve a Cognito ID for your end users based on your own unique identifier for your users. Once you have retrieved the Cognito ID and OpenID Token Cognito Identity provides, you can use the Cognito Identity client SDK to access AWS resources and synchronize user data. Cognito Identity is a fully managed identity provider to make it easier for you to implement user sign-up and sign-in for your mobile and web apps.', 'Q: How does Cognito Identity help me control permissions and access AWS services securely? Cognito Identity assigns your users a set of temporary, limited privilege credentials to access your AWS resources so you do not have to use your AWS account credentials. The permissions for each user are controlled through AWS IAM roles that you create. You can define rules to choose the IAM role for each user, or if you are using groups in a Cognito user pool, you can assign IAM roles based on groups. Cognito Identity also allows you to define a separate IAM role with limited permissions for guest users who are not authenticated. In addition, you can use the unique identifier that Cognito generates for your users to control access to specific resources. For example you can create a policy for an S3 bucket that only allows each user access to their own folder within the bucket. '), ('Q: When using public identity providers, does Amazon Cognito Identity store users’ credentials?', 'No, your app communicates directly with the supported public identity provider (Amazon, Facebook, Twitter, Digits, Google, or an Open ID Connect-compliant provider) to authenticate users. Cognito Identity does not receive or store user credentials. Cognito Identity uses the token from the identity provider to obtain a unique identifier for the user and then hashes it using a one-way hash so that the same user can be recognized again in the future without storing the actual user identifier.'), ('Q: Does Cognito Identity receive or store confidential information about my users from the identity providers? No. Cognito Identity does not receive any confidential information (such as email address, friends list, etc.) from the identity providers.', 'Q: Do I still need my own backend authentication systems with Cognito Identity? No. Cognito Identity supports login through Amazon, Facebook, Twitter, Digits, and Google, as well as providing support for unauthenticated users. With Cognito Identity you can support federated authentication, profile data sync store and AWS access token distribution without writing any backend code.'), ('Q: What if I don’t want to force my users to log in? Cognito Identity supports the creation and token vending process for unauthenticated users as well as authenticated users. This removes the friction of an additional login screen in your app, but still enables you to use temporary, limited privilege credentials to access AWS resources.', 'Q: What are unauthenticated users? Unauthenticated users are users who do not authenticate with any identity provider, but instead access your app as a guest. You can define a separate IAM role for these users to provide limited permissions to access your backend resources. '), ('Q: Does Cognito Identity support separate identities for different users on the same device? Yes. Cognito Identity supports separate identities on a single device, such as a family iPad. Each identity is treated separately and you have complete control over how your app logs users in and out and how local and remote app data is stored.', 'Q: How do I store data associated with Cognito Identity? You can programmatically create a data set associated with Cognito Identity and start saving data in the form of key/value pairs. The data is stored both locally on the device and in the Cognito sync store. Cognito can also sync this data across all of the end user’s devices.'), ('Q: Does the number of identities in the Cognito Identity console tell me how many users are using my app? The number of identities in the Cognito Identity console shows you how many identities were created via the Cognito Identity APIs. For Authenticated Identities (those logging in with a login provider such as Facebook or an OpenID Connect provider), each call to Cognito Identity’s GetId API will only ever create a single identity for each user. However, for Unauthenticated identities, each time the client in an app calls the GetId API will generate a new identity. Therefore, if your app calls GetId for unauthenticated identities multiple times for a single user it will appear that a single user has multiple identities. So it is important that you cache the response from GetId when using unauthenticated identities and not call it multiple times per user.', "The Mobile SDK provides the logic to cache the Cognito Identity automatically so you don't have to worry about this. If you're looking for a complete analytics solution for your app, including the ability to track unique users, please look at Amazon Mobile Analytics.  "), ('Q: What is the Amazon Cognito sync store? The Amazon Cognito Sync store is a key/value pair store linked to an Amazon Cognito identity. There is no limit to the number of identities you can create in your identity pools and sync store. Each Amazon Cognito identity within the sync store has its own user information store.', 'Q: Is data saved directly to the Amazon Cognito sync store? No. The optional AWS Mobile SDK saves your data to an SQLite database on the local device, this way the data is always accessible to your app. The data is pushed to the Amazon Cognito sync store by calling the synchronize() method and, if push synchronization is enabled, all other devices linked to an identity are notified of the data change in the sync store via Amazon SNS.'), ('Q: How is data stored in the Amazon Cognito sync store? Data associated with an Amazon Cognito identity are organized as key/value pairs. A key is a label e.g. “MusicVolume”, and a value e.g. “11”. Key/value pairs are grouped and categorized using data sets. Data sets are a logical partition of key/value pairs and the most granular entity used by Amazon Cognito to perform sync operations.', 'Q: What is the maximum size of a user information store within the Amazon Cognito sync store? Each user information store can have a maximum size of 20MB. Each data set within the user information store can contain up to 1MB of data. Within a data set you can have up to 1024 keys.'), ('Q: What kind of data can I store in a data set? Both keys and values within a data set are alphanumeric strings. There is no limit to the length of the strings other than the total amount of values in a dataset cannot exceed 1MB. Binary data can be stored as a base64 encoded string as a value provided it does not exceed the 1MB limit.', 'Q: Why are data sets limited to 1MB? Limiting the data set size to 1MB increases the chances of a synchronization task completing successfully even when bandwidth is limited without lots of retries that consume battery life and data plans.'), ('Q: Are user identities and user information stores shared across developers? No, a user identity and information store is tied to a specific AWS account. If there are multiple apps from different publishers on a particular device that use Amazon Cognito, each app will use the information store created by each publisher.', 'Q: How can I analyze and query the data stored in the Cognito Sync store? With Cognito Streams, you can push sync store data to a Kinesis stream in your AWS account. You can then consume this stream and store the data in a way that makes it easy for you to analyze such as a Amazon Redshift database, an RDS instance you own or even an S3 file. We have published sample Kinesis consumer application to show how to store the updates data in Amazon Redshift.'), ('Q: Why should I use Kinesis stream instead of a database export? By streaming the data to Kinesis you can receive all of the history of changes to your datasets in real-time. This means you receive all the changes an end user makes to a dataset and gives you the flexibility to store this data in a tool of your choice.', 'Q: What if I already have data stored in Cognito? When you enable the Kinesis stream feature you will be able to start a bulk publish. This process asynchronously sends all of the data currently stored in your Cognito sync store to the Kinesis stream you selected.'), ('Q: What is the price of this feature? Cognito pushes the data to a Kinesis stream you own. There is no difference in Cognito’s per-synchronization price if this feature is enabled. You will be charged Kinesis’ standard rates for your shards.', "Q: Can I validate data before it is saved? Amazon Cognito Events allows developers to run an AWS Lambda function in response to important events in Cognito. The Sync Trigger event is an event that occurs when any dataset is synchronized. Developers can write an AWS Lambda function to intercept the synchronization event. The function can evaluate the changes to the underlying Dataset and manipulate the data before it is stored in the cloud and synchronized back to the user's other devices. Alternatively, the AWS Lambda function could fail the sync operation so that the data is not synchronized to the user's other devices."), ('Q: How is data synchronized with Amazon Cognito? You can programmatically trigger the sync of data sets between client devices and the Amazon Cognito sync store by using the synchronize() method in the AWS Mobile SDK. The synchronize() method reads the latest version of the data available in the Amazon Cognito sync store and compares it to the local, cached copy. After comparison, the synchronize() method writes the latest updates as necessary to the local data store and the Amazon Cognito sync store. By default Amazon Cognito maintains the last-written version of the data. You can override this behavior and resolve data conflicts programmatically. In addition, push synchronization allows you to use Amazon Cognito to send a silent push notification to all devices associated with an identity to notify them that new data is available.', "Q: What is a silent push notification? Amazon Cognito uses the Amazon Simple Notification Service (SNS) to send silent push notifications to devices. A silent push notification is a push message that is received by your application on a user's device that will not be seen by the user."), ('Q: How do I use push synchronization? To enable push synchronization you need to declare a platform application using the Amazon SNS page in the AWS Management Console. Then, from the identity pool page in the Amazon Cognito page of the AWS Management Console, you can link the SNS platform application to your Cognito identity pool. Amazon Cognito automatically utilizes the SNS platform application to notify devices of changes.', 'Q: How are conflicts in the synchronization process handled? By default Amazon Cognito maintains the last-written version of the data. You can override this behavior by choosing to respond to a callback from the AWS Mobile SDK which will contain both versions of the data. Your app can then decide which version of the data (the local one or the one in the Amazon Cognito sync store) to keep and save to the Amazon Cognito sync store.  '), ('Q: How much does Cognito Identity cost? With Amazon Cognito, you pay only for what you use. There are no minimum fees and no upfront commitments.', 'If you are using the Cognito Identity to create a User Pool, you pay based on your monthly active users (MAUs) only. A user is counted as a MAU if within a calendar month there is an identity operation related to that user, such as sign-up, sign-in, token refresh, and password change. You are not charged for subsequent sessions or for inactive users with in that calendar month. Separate charges apply for optional use of SMS messaging as described below.'), ('The Your User Pool feature has a free tier of 50,000 MAUs each month. The Cognito Identity free tier does not expire at the end of your 12 month AWS Free Tier term, and it is available to both existing and new AWS customers indefinitely', 'Federated Identities and secure access control for AWS resources are always free with Cognito Identity.'), ('Q: How much does Cognito Sync cost? Sync charges are based on the total amount of data saved in the Amazon Cognito sync store and the number of sync operations performed. A sync operation compares the local data store on a device to the Amazon Cognito sync store in the cloud and synchronizes the two data stores.', 'As part of the AWS Free Tier, eligible AWS customers receive 10 GB of cloud sync store and 1,000,000 sync operations per month for the first 12 months. Outside the Free Tier, Amazon Cognito costs $0.15 for each 10,000 sync operations and $0.15 per GB of sync store per month.'), ('Q: What is a sync operation? When you call the synchronize() method using the AWS Mobile SDK, this counts as a sync operation. If you are calling the server APIs directly, a sync operation is initiated when a new sync session token is emitted and is completed with a successful write or a timeout of the session token. Whether you use the SDK synchronize() method or call the server API’s directly, sync operations are charged at the same rate.', 'Q. What are Monthly Active Users (MAUs)? A user is considered active and counted as a MAU when there is an operation (e.g., sign-in, token refresh, sign-up, or password change) associated with the user during the billing month. Therefore, you are not charged for subsequent operations during the billing month or for inactive users. Typically, your total number of users as well as your number of operations will be significantly larger than your total number of MAUs.'), ('Q. What does it cost to use SMS messages with Cognito? Use of SMS messaging to verify phone numbers, to send codes for forgotten or reset passwords, or for multi-factor authentication is charged separately. See the Worldwide SMS Pricing page for more information.', 'Q: Is Amazon Cognito part of the AWS Free Tier? Yes. As part of the AWS Free Tier, Cognito offers 10GB of sync store and 1,000,000 sync operations in a month for up to the first 12 months of usage. Your user pool for Cognito Identity is free for the first 50,000 MAUs, and we offer volume-based tiers thereafter. The Federated Identities feature for authenticating users and generating unique identifiers is always free with Cognito Identity.'), ('Q: Does every write or read from the app count as a sync operation? No. You decide when to call the synchronize() method. Every write or read from the device is to the local SQlite store. This way you are in complete control of your costs.', 'Q: What does push synchronization cost Cognito utilizes Amazon SNS to send silent push notifications. There is no additional charge for using Cognito for push synchronization, but normal Amazon SNS rates will apply for notifications sent to devices.'), ('Q: What is the cost of using Lambda with Amazon Cognito Events? There is no additional charge for using Cognito Events to trigger Lambda functions, but normal rates for your use of AWS Lambda and other AWS services will apply while your Lambda functions are executing. Please see the AWS Lambda pricing page for details.  ', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/pinpoint/faqs/': [('General', 'Product Details'), ('Analytics', 'Event Details '), ('Amazon Pinpoint Campaigns ', 'Contact Us'), ('Q: What is Amazon Pinpoint?', 'Amazon Pinpoint is AWS’s Digital User Engagement Service that enables AWS customers to effectively communicate with their end users and measure user engagement across multiple channels including email, Text Messaging (SMS) and Mobile Push Notifications.'), ('Amazon Pinpoint also provides tools that enables audience management and segmentation, campaign management, scheduling, template management, A/B testing, analytics and data integration. It captures data to track deliverability as well as usage and messaging analytics covering a range of dimensions including user, channels and custom attributes.', 'Amazon Pinpoint is built on a service-based architecture. Developers can extend their applications and backend services in various ways, including: sending messages directly from their applications via the Amazon Pinpoint channels (Email, SMS and Mobile Push), accessing segmentation data to alter their application behavior for segments of users, create and run campaigns directly from their applications, and access deliverability and analytics data to improve the user engagement of their applications.The system empowers customers to send the right message, to the right audience, at the right time and on the most effective channel. '), ('Q: How will developers benefit from Amazon Pinpoint?', "Amazon Pinpoint offers developers a single API layer, CLI support and client side SDK support to be able to extend the communication channels through which their applications engage users. These channels include: email, SMS Text Messaging and Mobile Push Notifications. Amazon Pinpoint also provides developers with an analytics system that tracks app user behavior and user engagement. With this service, developers can learn how each user prefers to engage and can personalize their end-user's experience to increase the value of the developer's applications."), ('Amazon Pinpoint also helps developers address multiple messaging use-cases such direct or transactional messaging, targeted or campaign messaging and event-based messaging. Integrating and enabling all their end-user engagement channels via Amazon Pinpoint, developers can create a 360-degree view of user engagement across all customer touch points.', 'Q: How will marketers benefit from Amazon Pinpoint?'), ('Amazon Pinpoint allows Marketers to create and execute a unified messaging strategy across all engagement channels relevant to their end-users. Pinpoint includes tools and services to let marketers analyze and engage users directly. The console provides marketers with campaign management tools to create, run and manage multichannel campaigns across their applications, user-base and devices. Campaigns can be scheduled or triggered on user changes and actions. Users and devices can also be grouped through flexibly defined segments which can be used to determine campaign audiences. Marketers can also leverage the multi channel templating support to personalize end-user messaging and campaign optimization features such as A/B testing, holdout testing and message caps. Marketers can also measure messaging effectiveness using Pinpoint analytics to understand the impact on user behavior.', 'Q: How will enterprises benefit from Amazon Pinpoint?'), ('Enterprises can use Amazon Pinpoint as their Digital User Engagement Service. They can free developers from having to individually integrate different communication channels into their applications and instead focus on leveraging Pinpoint to learn how their end-users and customers are engaging with their applications. It enables them to measure and improve their technology investments by measuring how engaged their digital customers are across all functions of their enterprise.', 'Q: Why should I use Amazon Pinpoint to run and manage my campaigns?'), ('Amazon Pinpoint makes it easy to run targeted campaigns and drive user engagement of applications using different channels: email, SMS and mobile push notifications. Amazon Pinpoint helps you understand user behavior, define which users to target, determine which messages to send, schedule the best time to deliver the messages, and then track the results of your campaign.', 'Amazon Pinpoint is built to scale, enabling you to collect and process billions of events per day, and send billions of targeted messages to your users.'), ('Marketers can send targeted messages and calls to action when changes occur in their organizations or in a user’s circumstances, like a new product launch to a change in a user’s locale ', 'Q: If I use another campaign management service how does Amazon Pinpoint help me?'), ('Amazon Pinpoint’s architecture is services based. Companies can choose which services to use and integrate with their existing systems and processes. Amazon Pinpoint’s core services include: engagement analytics, communication channels, deliverability metrics, audience management and segmentation, template management, and campaign management.', 'The platform also supports data integration services to extend Amazon Pinpoint analytics and segmentation data from external data sources such as S3, as well as data exports to feed external marketing systems via Kinesis Event Streams. '), ('Q: How much does Amazon Pinpoint cost?', 'Amazon Pinpoint has no upfront costs, no minimum charges, and no subscription fees. You pay only for what you use. Visit the Amazon Pinpoint pricing page for more details.'), ('Q: Who owns the data in Amazon Pinpoint?', 'Customers own their data in Amazon Pinpoint. Amazon Web Services does not own or monetize the data customers collect, and does not share it with third parties. We may use the data to improve the service, monitor the health of the service, and provide technical support to you. As with any other AWS service, customers are responsible for how they use the tools we provide; this responsibility includes providing any necessary notice or opt-outs to end users and complying with applicable law.'), ('\xa0', 'Q: What services and tools does Amazon Pinpoint provide?'), ('Amazon Pinpoint includes a console designed for marketers and developers to use. The console provides capabilities to configure communication channels, manage audiences and segmentation, manage and run campaigns, create and manage message templates, create and manage engagement schedules and analyze user engagement. Standard analytics includes: active users, user activities, sessions, user retention, campaign efficacy and user channel engagement metrics. You can create custom analytics to integrate custom attributes and drive analytics for sales conversion, funnel reporting, product adoption by segment and any other metric required to support the business.', 'Q: I already use Amazon SNS or Amazon SES. What do I gain by switching to Amazon Pinpoint?'), ("In typical Amazon SNS and Amazon SES use cases, you have to set up your application to manage each message's audience, content, and delivery schedule. These same features are built in to Amazon Pinpoint. With Amazon Pinpoint, you can create message templates, delivery schedules, highly-targeted segments, and full campaigns. \xa0", 'Q: What data does Amazon Pinpoint store without using SDKs and instrumentation?'), ('Amazon Pinpoint can store four different types of data:', 'Configuration Data from which Amazon Pinpoint services are provided their rules of engagement. This includes:'), ('User Data which provides Amazon Pinpoint with endpoint information for sending messages across any channel, device or application. User data is extensible, but includes the following per channel:', 'User data can also include:'), ('User Engagement Data which includes default data per channel as well as custom data attributes when configured. Data per channel includes:', 'External Data can include any user, segmentation and analytics data.'), ('Q: What are the options for capturing custom application events?', 'You can either use the Mobile SDK within your mobile application to send custom events and attributes for Mobile Push Notifications, or use the Amazon Pinpoint REST API to send events programmatically from any application.'), ('Q: Does Amazon Pinpoint support cross-device/application identity management?', 'Yes. This is captured under User ID.'), ('Q: What OS versions does Amazon Pinpoint support for Mobile Push Notifications?', 'The iOS SDK supports apps running on iOS 7.0 and higher. The Android SDK supports apps running on Android 2.3.3 and higher.'), ('Q: For mobile push notifications is data cached when a user’s device is offline?', 'Yes, when using the AWS Mobile SDK, data is cached on the user’s device and is uploaded when a network connection is next established.'), ('Q: Are network channels optimized when sending events via the SDK?', 'Yes, the events are batched, and sent once per minute. You can also specify the transport to send the events: cellular and Wi-Fi, or Wi-Fi only.'), ('\xa0', ' Q: How are metrics calculated for the same user using multiple devices?'), (' A user with the same app on two devices, such as an iPhone and an iPad, is counted as two users.', ' '), (' Q: How is a "session" defined?', ' A session is one use of an app by the user. A session begins when an app is launched (or brought to the foreground), and ends when the app is terminated (or goes to the background). To accommodate for brief interruptions, like a text message, an inactivity period of up to 5 seconds is not counted as a new session. Total daily sessions shows the number of sessions your app has each day. Average sessions per daily active user shows the mean number of sessions per user per day.'), (' ', ' Q: When an app goes to the background does its session end?'), (' Yes, the session ends. When the app comes to the foreground, a new session begins.', ' '), (' Q: How are daily and weekly retention defined?', ' Daily retention is measured by determining the number of users that first used your app on a specific day, came back and used your app in the next 7 days (7-day retention), fourteen days (14-day retention), and thirty days (30-day retention). '), (' ', ' Q: How is sticky factor calculated in the User Engagement tab?'), (' Sticky factor is calculated by dividing DAU by MAU. It is the fraction of monthly users using the app on a particular day. For example, if an app has 100K DAU and 300K MAU its sticky factor is .33. A high sticky factor can indicate strong engagement, appeal, and potential monetization opportunities.', ' '), (' Q: What are demographics in Amazon Pinpoint?', ' The Demographics tab provides a breakdown of the device attributes for your app users. You can also see custom attributes that you define.'), ('Q: What are Events?', 'Custom events are defined entirely by you. They help track user actions specific to your app or game. The Events tab provides a view of how often custom events occur. Custom events can be filtered based on attributes and their associated values.'), ('You create custom events by naming them, such as "Item Bought" or "Button Pressed", and then adding context by specifying attributes (for qualitative measure) and metrics (for quantitative measure). For example, if your business goal is to track purchases of items from within the app, you can use "Item Bought" as a custom event, "Item XYZ" as an attribute, and "Item Price" as the metric. The custom events report enables you to search and filter for each attribute or metric. For example, you can find how often "Item XYZ" was purchased or how often “Item Price” was $1.99. You can also review the weighted average of metric values (per session) and track minimum, maximum, or average metric values. As a best practice, we recommend that custom event names be broad and attribute names be specific.', 'Q: What are the benefits of using custom events?'), ('Custom events help you understand user actions specific to your app. A game developer might want to understand both how often a level is completed and how much health each player has left at the end of that level. With custom events, you can create an event called "level_complete", with "add_level" as an attribute, and "health" as an attribute value. Each time a level is completed, you can record a "level_complete" event with the name of the level and the player\'s health. By reviewing the data in the Events tab, you might discover that level 3 is too easy because players always finish with maximum health. You could then adjust the level\'s difficulty to better challenge and engage players, which might improve retention.', 'Q: Are there limits for using custom events in my app?'), ('You can have up to 1,500 unique custom event types per app and up to 40 attributes and metrics per custom event.\xa0For more information on these and other limits affecting custom events, see the Amazon Pinpoint documentation.', 'Q: What are segments?'), ('Segments are defined with usage attributes. These attributes include usage criteria (such as when the app was last used), device attributes (such as app version, platform, and country), and custom attributes that you define. You use these attributes to define a subset of users from within your total user base. Segments can also be a static list of pre-defined users.', 'Q: What are custom attributes?'), ('Amazon Pinpoint provides 40 custom attributes. You can use these to customize your segmentation for your unique use cases. Each custom attribute can store up to 50 values.', 'Q: How do I create segments?'), ('To create a segment, you can build a segment or import a segment.', 'By building a segment, you can define a segment with criteria for usage, device attributes, and custom attributes.'), ('By importing a segment, you can import a static list of users from a CSV or a JSON file that is stored in Amazon S3.', 'Q: What are campaigns?'), ('Campaigns are targeted push notification messages sent to a subset of users on a predefined schedule. You can use targeted push notification campaigns to increase app user engagement and retention. You can create push notification campaigns for use cases such as welcoming new customers, informing customers of new features, and sharing offers and deals with customers.', 'Q: What is a standard campaign?'), ('Standard campaigns define a target audience, the message to be sent, and a schedule for sending the message. You can also reuse previously defined segments or define a new segment while you create a campaign. For every scheduled instance of a campaign, Amazon Pinpoint recalculates the current audience size based on segment filters defined.', 'Q: What is an A/B test campaign?'), ('A/B campaigns are campaigns with more than one treatment. Each treatment differs from the other based on the message or the sending schedule.', 'Q: What are silent push notifications and in-app notifications? How do I use them?'), ('Silent and in-app notifications are messages delivered to the device that are not displayed in the notifications center of the user’s device. These messages have a header that enables developers to manage app configuration or create an in-app message center for their apps.', 'Q: What metrics can I track for standard campaigns?'), ('For standard campaigns, you can track messages sent, messages delivered, direct app opens, sessions per user, purchases per user, delivery rate, open rate, user devices messaged, and campaign sessions by time of day.', 'Q: What are my scheduling options for campaigns?'), ('Campaigns can be scheduled to run one time immediately or at a time you designate in the future. They can also be scheduled with multiple runs – hourly, daily, weekly, or monthly. Just set up a start date, start time, specify whether you want to deliver on local time, set an end date, and set a time to define your recurring campaigns.', 'Q: How does local time delivery work for campaign scheduling?'), ('Local time delivery enables you to create campaigns and deliver messages to your users in their local time. Local time delivery can be set up by choosing the local time option and then selecting the time zone to start your first send. ', ' Q: What is two-way text messaging?'), (' Two-way text messaging enables customers of Amazon Pinpoint to receive text messages from their users. When a user sends a text message to a customer’s leased number, Amazon Pinpoint passes the text message to the customer, and the customer can use this message to trigger an appropriate response. Depending on the country and the local telecommunication regulation requirements, the customer can use long codes (10-digit phone numbers) and short codes (5 to 6-digit phone numbers).', ' To receive text messages from their users, the customer enables two-way text messaging in the Amazon Pinpoint console and selects an Amazon SNS topic to receive the text messages. Amazon Pinpoint provides the telephone number of the user and the customer’s message ID if the text message was sent to the customer as a reply. '), ('Q: What are the advantages of two-way text messaging?', "The use of two-way text messaging enables many additional use cases for customers of Amazon Pinpoint to be able to engage with their users, especially for transactional situations where a customer can alert the user to information and the user can respond and the customer can initiate additional workflows or other processes. For example, in a healthcare scenario, a pharmacy could send a text message to a user that their prescription is due for a refill. The user can respond to have the prescription fulfilled or not, and then the customer can take appropriate action based on the response, such as initiating the re-fill at the user's designated pharmacy pick up location and then informing the user when the prescription is ready for pickup. "), (' Q: Why do you require a dedicated number for two-way text messaging?', ' Receiving text messages from the same company through multiple numbers makes it hard for users to associate a number with a single business with which they regularly interact. A dedicated number makes it easier for users to participate in two-way text messaging. '), (' Additionally, Amazon Pinpoint delivers text messages using numbers that are shared by multiple customers. Since these numbers are not exclusive to a sender, it is not possible to accurately route the text message to an appropriate customer when a cellular subscriber texts a number that is owned by Amazon Pinpoint. Because of these reasons, Amazon Pinpoint requires companies to lease a dedicated number for two-way communication. ', ' Q: How can a customer disable two-way text messaging?'), (' Customers can disable two-way text messaging from the console, and from that point forward, they will stop to receive incoming text messages from their users. ', ' Q: Can customers create automated responses for certain keywords?'), (' Yes, customers with leased phone numbers (long codes and short codes) can create keywords and add responses that the users will receive from the Amazon Pinpoint console. When a user sends a text message that matches the customer’s keyword, Amazon Pinpoint sends the corresponding response to the user. Additionally, customers can customize default HELP and STOP messages.', ' \xa0'), ('Q: My question isn’t answered in this FAQ. How can I reach Amazon for help?', 'Please email us for further help, or visit the Amazon Pinpoint forum.'), ('Q: How do I make a new feature request or provide feedback on this product?', 'Please let us know on the Amazon Pinpoint forum.'), ('Q: I have a question about pricing.', 'Please email us.'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/device-farm/faq/': [('AWS Device Farm allows developers to increase application quality, time to market, and customer satisfaction by testing and interacting with real Android and iOS devices in the AWS Cloud. Developers can upload their app and test scripts and run automated tests in parallel across 100s of real devices, getting results, screenshots, video, and performance data in minutes. They can also debug and reproduce customer issues by swiping, gesturing, and interacting with a device through their web browser.\xa0', '\xa0'), ('AWS Device Farm is designed for developers, QA teams, and customer support representatives who are building, testing, and supporting mobile apps to increase the quality of their apps. Application quality is increasingly important, and also getting complex due to the number of device models, variations in firmware and OS versions, carrier and manufacturer customizations, and dependencies on remote services and other apps. AWS Device Farm accelerates the development process by executing tests on multiple devices, giving developers, QA and support professionals the ability to perform automated tests and manual tasks like reproducing customer issues, exploratory testing of new functionality, and executing manual test plans. AWS Device Farm also offers significant savings by eliminating the need for internal device labs, lab managers, and automation infrastructure development. ', '\xa0'), ('AWS Device Farm supports native and hybrid Android, iOS, and web apps, and cross-platform apps including those created with PhoneGap, Titanium, Xamarin, Unity, and other frameworks.', 'AWS Device Farm tests are run on real, non-rooted devices. The devices are a mixture of OEM and carrier-branded devices. '), ('Please see our getting started guide. ', 'AWS Device Farm works on Internet Explorer 9 or later and the latest versions of Chrome, Firefox, and Safari.  '), ('Your web applications will be tested in Chrome on Android and Safari on iOS.  ', 'AWS Device Farm supports files up to 4 GB. '), ('No instrumentation or source code is required to use the built-in tests. Android apps can be submitted as is. iOS apps should be built with “iOS Device” as the target instead of a simulator. ', 'Apps and files you upload are automatically removed after 30 days. Test results, screenshots, and videos are stored for 15 months. You can also choose to delete files and results at any time through the AWS Device Farm console or API. '), ('After test execution completes, we perform a series of cleanup tasks on each device, including uninstallation of your app. If we cannot verify uninstallation of your app or any of the other cleanup steps, the device will be removed and will no longer be available.', 'While we continue to add additional cleanup steps and improve the cleanup process, it is possible for data to persist between sessions in some cases, especially if you make use of the device system outside the context of your app. For this reason, and because AWS Device Farm captures video and logs of activity taking place during your use of each device, it is recommended that you avoid providing or entering sensitive information such as account info (E.g., Google Account, Apple ID), personal information, and other security-sensitive details during your automated test and remote access sessions. '), ('On iOS, we replace the embedded provisioning profile with a wildcard profile and resign the app. If you provide it, we will add auxiliary data to the application package before installation so the data will be present in your app’s sandbox. Resigning the iOS app results in the removal of certain entitlements. This includes App Group, Associated Domains, Game Center, HealthKit, HomeKit, Wireless Accessory Configuration, In-App Purchase, Inter-App Audio, Apple Pay, Push Notifications, and VPN Configuration & Control.', 'On Android, we resign the app. This may break functionality that depends on the app signature, such as the Google Maps Android API. It may also trigger anti-piracy and anti-tamper detection available from products such as DexGuard. For built-in tests, we may modify the manifest to include permissions required to capture and save screenshots.  '), (' This feature allows developers to access their private fleet devices via their local host machines the same way they debug with real devices connected directly to the machines. On top of the ability for customers to perform the same tasks they do with real devices on Android Studio and Xcode today. Device Farm direct device access gives user the wide range selection of devices and OS versions. To learn more about private devices, please contact us.', '  '), ('Yes.', 'Yes. You can down load the client software from one of the following locations.'), ('Windows: https://s3-us-west-2.amazonaws.com/prod-us-west-2-system-resources/AWSDeviceFarmClient/AWS_Device_Farm.exe', 'MacOS: https://s3-us-west-2.amazonaws.com/prod-us-west-2-system-resources/AWSDeviceFarmClient/AWS_Device_Farm.dmg'), ('For the full instructions for installation please read this documentation. ', '\xa0'), ('\xa0', 'Yes. '), (' No, at the moment, this feature is available for private fleets on AWS Device Farm. To get more information on private fleets: https://aws.amazon.com/device-farm/pricing/#privateDevices. ', 'Yes. '), (' Once you connect to Devices, you can run any framework of your choice.', 'For the detail setup guide, please click here[insert production link]. To learn more about private devices, please contact us.'), ('\xa0', 'AWS Device Farm has a large (and growing) selection of Android, iOS, and Fire OS devices. We add popular new devices as they are released by manufacturers. We also add new devices as new OS versions are released. See the list of available devices. '), ('We currently have international devices from India. We use market data and customer feedback to continuously update the fleet. If you would like to see a device that isn’t in our fleet, please let us know.', 'For Automated Testing, devices are selected through a collection called a device pool. Some curated device pools are provided automatically, but you can create your own pools, too. During execution, tests will be run against all devices in the specified pool that are compatible with your application and tests. For Remote Access, you select the desired device based on make, model, carrier variant, and operating system version. You can then optionally upload apps and other data as well as configure other device settings. Device Farm then locates an available device matching your request and displays the device’s display in your browser. You can then interact with the device and capture screenshots and video.'), ('\xa0', 'Yes, test devices will have a number of apps pre-installed by the device manufacturer or carrier. '), ('Yes. All devices have a WiFi connection with Internet access. If your systems are internal (that is, behind a corporate firewall), you can whitelist the IP range 54.244.50.32-54.244.50.63. All device traffic will come from those IPs. ', 'While you can\'t test actual carrier connections, you can simulate connection types and conditions using the network shaping functionality. When scheduling a run, you can select a curated network profile like "3G" or "Lossy LTE," or you can create your own, controlling parameters like throughput, jitter, and loss. All WiFi traffic from the device will be shaped and manipulated for the duration of your tests according to the profile you choose. You can also simulate dynamic environments by changing network parameters from your test scripts. '), ('No, devices do not have carrier connections and cannot make phone calls or send SMS messages. ', 'Yes, you can use the device cameras, both front- and rear-facing. Due to the way the devices are mounted, images and videos may look dark and blurry. '), ('The built-in compatibility test suite allows you to install, uninstall, launch, and run Fuzz on the app. ', 'Fuzz will perform fuzz testing on your UI immediately after launch. It streams random user input (touches, swipes, keyboard input) in a rapid fashion to your app. You can configure the number of events, the delay between events, and the seed used to randomize events. Using the same seed across test runs will result in the same sequence of events. '), ('For testing iOS, Android, and FireOS apps, we currently support Appium Java JUnit, Appium Java TestNG, Appium Python, Calabash, Instrumentation (Including JUnit, Espresso, Robotium, and any instrumentation-based tests), UI Automation, UI Automator, and XCTest (Including XCUI and KIF). For more information and updated list, visit our documentation. ', 'You can run tests written in Appium Java JUnit, Appium Java TestNG, or Appium Python.  '), ('We’re always evaluating frameworks to support. Please contact us. ', 'If you use one of the supported automation frameworks, you are in full control and can decide when to take screenshots. Those screenshots are included in your reports automatically. '), ('Yes, Google Play Services is installed on devices that support it. The services are updated as new versions become available. ', 'No, devices do not have an active Google account.  '), ('AWS Device Farm supports frameworks like Espresso and Robotium that have record and playback scripting tools. ', 'No, AWS Device Farm will automatically replace a provisioning profile and resign your app so it can be deployed on our devices.  '), ('No, but you can download the logs and symbolicate the stack traces locally. ', 'Yes, if you use ProGuard. If you use DexGuard with anti-piracy measures, we are unable to re-sign the app and run tests against it. '), ('Although devices have access to the Internet, we make no guarantee that ads will be displayed. We recommend that you remove ads from the builds tested on AWS Device Farm. ', 'Yes. If you’re using a client-server framework like Calabash, Appium, or UI Automation, you can access the Internet and execute limited shell commands from the host.\xa0'), ('You can provide a .zip archive up to 4 GB in size. On Android, it will be extracted to the root of external memory; on iOS, to your app’s sandbox. For Android expansion files (OBB), we will automatically place the file into the location appropriate to the OS version. For more information, see the Developer Guide. ', 'Yes, you can select multiple apps and the order in which to install them. These dependent apps will be installed before your tests begin. '), ('Yes, in order to test your upgrade flow, you can upload and install an old version of your app before the new version is installed and tested. ', 'Yes, you can supply latitude and longitude coordinates that will be used to override a device’s GPS. '), ('Yes, you can provide a locale (for example, “en_US”) to override the default locale setting on a device. ', 'Tests are immediately queued for execution and usually start within minutes. If one or more devices are not available, test execution for those devices will remain queued until they become available. Testing on the other devices in your test run will continue. '), ('The maximum time allowed is 60 minutes. If you need a longer timeout, please contact us. ', 'Yes. We have a plug-in for the Jenkins continuous integration environment and a Gradle plugin compatible with Android Studio. AWS Device Farm also provides programmatic support for all console features, including setting up a test and downloading test results through an API. For more information, see the AWS Device Farm API Reference. In addition to the API, you can access AWS Device Farm from the AWS SDKs. '), ('AWS Device Farm test reports contain pass/fail information, crash reports, test logs, device logs, screenshots, videos, and performance data. Reports include both detailed per-device data and high-level results like the number of occurrences of a given error. Remote Access results contain logs and a video of the session. ', 'AWS Device Farm reports include complete logcat (Android) and device logs (iOS), as well as logs from the device host and specified test framework. '), ("If you write data to logcat (Android) or the device log (iOS), those log entries will be included in the report. AWS Device Farm does not collect any non-standard logs or other artifacts, although you may transfer files via your test script using the device's or device host's Internet connection. ", 'Pricing is based on device minutes, which are determined by the duration of tests on each selected device. AWS Device Farm comes with a free trial of 1000 device minutes.* After that, customers are charged $0.17 per device minute. As your testing needs grow, you can opt for an unmetered testing plan, which allows unlimited testing for a flat monthly fee of $250 per device. '), ('Your first 1000 device minutes are provided free of charge.* This is a one-time trial and does not renew. Once your trial allocation is depleted, you will be billed at the standard rate of $0.17 per device minute. ', 'A device minute is the billing unit. Device minutes are a measurement of the time it takes (in minutes) to install, execute, and uninstall your app and tests on every device you have selected for your test run. The unit price is constant regardless of the device, test, or application type. Device minutes are only billed for tests that complete without any device or system errors. Similarly, for Remote Access sessions, device minutes are measured from the time it takes to prepare a device to your specification to completely removing any apps and data you placed on the device. '), ('You can dynamically grow and shrink your usage according to your business needs without any upper limits or up-front commitments. ', 'Unmetered plans allow unlimited testing and remote access starting at $250 per month. Unmetered pricing is based on the number of device slots you purchase for each usage type (i.e. automated test or remote access) and device family (i.e. Android or iOS) and are priced at $250 per slot per month. Device slots correspond to concurrency.'), ('For instance, if you purchase ten automated test Android device slots and schedule a run on 100 Android devices, Device Farm will execute your tests on up to ten devices at a time until all tests are completed on your selected devices. Purchasing more slots would enable you to get your results faster. Regardless of how many tests or remote access sessions you have in a month, you are billed at the flat rate of $250 per device slot per month.\xa0You can cancel your subscription for one or more device slots at any time and the cancellation will take effect at your next renewal date (the day of the month that you purchased your first active device slot). To learn more, see our docs. ', 'You can add device slots at any time and they will be available to you immediately. You can also cancel your subscription for one or more device slots at any time and the cancellation will take effect at your next renewal date (the day of the month that you purchased your first active device slot). '), ('Yes. When creating a run, you can choose to make use of your unmetered device slots or use metered device minutes instead. Because concurrency is not limited on metered billing, this gives you the flexibility of running tests faster than would otherwise happen using your device slots. ', 'A private device is a physical instance of a phone or tablet that is exclusive to your account. Private devices can have custom, static configurations and run custom OS images. Each device is deployed on your behalf and removed at the end of your subscription. '), ('Each private device under your account is considered a private device subscription. The monthly subscription price is tiered on the cost of the device and starts at $200/month. After the minimum subscription period, you can choose to cancel your subscription at any time. Please contact us for more information. ', 'Yes. When selecting devices for a test run or remote access session you will see your private devices as well as public devices. You can also create device pools comprised of both private and public devices. For more information about private devices, please contact us. '), ('* For a limited time, get a one-time trial of 1000 free device minutes instead of the standard 250 device minutes.', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/mobileanalytics/faqs/': [('General', 'Product Details'), ('Report and Metrics Details', 'Custom Event Details '), ('Auto Export ', 'Contact Us'), ('Q: What is Amazon Mobile Analytics?', ''), ('Amazon Mobile Analytics is a service that lets you easily collect, visualize, and understand app usage data at scale. Many mobile app analytics solutions deliver usage data several hours after the events occur. Amazon Mobile Analytics is designed to deliver usage reports within 60 minutes of receiving data from an app so that you can act on the data more quickly.', ''), ('Amazon Mobile Analytics is built to scale with your app, allowing you to collect and process billions of events per day from millions of users. It’s easy to get started with Amazon Mobile Analytics. You simply add the optional AWS Mobile SDK to your app and publish the app using your existing distribution mechanism (such as the iTunes Store, Google Play, or Amazon Appstore), and you can start accessing reports in the AWS Management Console. Amazon Mobile Analytics automatically starts to collect metrics on active users, sessions, and retention, and you can add reporting on in-app revenue or any custom event you choose.', ''), ('Amazon Mobile Analytics helps you spend more time on creating great apps rather than the undifferentiated heavy lifting of setting up and managing an analytics system.', 'Amazon Mobile Analytics is included in the AWS Mobile SDK, which supports iOS, Android, Fire OS, and Unity, or you can use the Amazon Mobile Analytics REST API directly.\xa0 Amazon Mobile Analytics is included in the&nbsp;AWS Mobile SDK, which supports iOS, Android, Fire OS, and Unity, or you can use the Amazon Mobile Analytics REST API directly. You can also use the Amazon Mobile Analytics SDK for Javascript to integrate with your JavaScript enabled apps.'), ('', 'Amazon Mobile Analytics is free for up to 100 million events per month (an event corresponds to activity in your app such as the start of a session or an in-app purchase).'), ('Amazon Mobile Analytics automatically calculates and updates the following metrics as data is received:', 'These metrics are provided via six reporting tabs in the AWS Management Console: Overview, Active Users, Sessions, Retention, Revenue, and Custom Events.'), ('', "Q: How can I use Amazon Mobile Analytics' reporting tabs to better understand user engagement?"), ('You can use the AWS Management Console to view graphical reports for your app, or download data in CSV format. Available reports and the metrics they provide for your app are listed below:', ''), ('Overview: Daily Active Users (DAU), Monthly Active Users (MAU), New Users, Sticky Factor, Total Daily Sessions, 1-Day Retention, Average Revenue Per Daily Active User (ARPDAU), Paying Daily Active Users, and Average Revenue Per Paid Daily Active User (ARPPDAU).', ''), ('Active Users: Daily Active Users (DAU), Monthly Active Users (MAU), New Users, and Sticky Factor.', ''), ('Sessions: Total Sessions (number of time your app was used on a particular day) and Average Number of Sessions Per Daily Active User (DAU).', ''), ('Revenue: Paying Daily Active Users, Average Revenue Per Daily Active User (ARPDAU), and Average Revenue Per Paid Daily Active User (ARPPDAU), Paying Monthly Active Users, Average Revenue Per Monthly Active User (ARPMAU), and Average Revenue Per Paid Monthly Active User (ARPPMAU).', ''), ('Retention: Daily retention (includes 1-day, 3-day, and 7-day retention) and weekly retention (includes 1-week, 2-week, and 3-week retention) for new users.', ''), ('Custom Events: Custom events specific to your app that you define (such as when users tap a button, or each time a player finishes a level).', ''), ('Q: How much does Amazon Mobile Analytics cost?', ''), ('Amazon Mobile Analytics has no upfront costs, no minimum charges or subscription fees. You pay only for what you use.', ''), ('Amazon Mobile Analytics offers a free tier of 100 million free events per month. Beyond the free tier, it costs $1.00 per million events per month.', ''), ('Events are sent to Amazon Mobile Analytics from your app via the AWS Mobile SDK or the REST API. There are three types of events: system events (e.g. the start or end of a session), in-app purchase events, and custom events (e.g. a specific action in your app such a user completing a level in a game, or a user viewing a particular screen). When you use the AWS Mobile SDK, for each app session the SDK automatically sends 2 system events (recording the start and end of a user’s session with your app). Beyond these 2 system events, the total amount of events sent by your app to the Amazon Mobile Analytics service during each session is determined by the inclusion of in-app revenue tracking events, or custom events you integrate into your app, and how many times those events are triggered. You can find more information on event types in the Amazon Mobile Analytics Documentation.', ''), ('Q: How often are reports updated?', ''), ('Amazon Mobile Analytics is designed to deliver usage reports within 60 minutes of receiving data from an app.', ''), ('Q: Which platforms does Amazon Mobile Analytics support?', ''), ('Amazon Mobile Analytics is included in the AWS Mobile SDK, which supports iOS, Android, Fire OS, and Unity. Additionally, you can use the Amazon Mobile Analytics REST API to collect app usage data programmatically.\xa0 You can use the Amazon Mobile Analytics SDK for Javascript to integrate with your JavaScript enabled apps.', ''), ('', 'Q: Who owns the data I collect?'), ('', 'Amazon does not own or monetize the data you collect, and does not share it with third parties. We may use the data to provide and improve the service, monitor the health of the service, and provide technical support to you. As with any other AWS service, you are responsible for how you use the tools we provide; that includes providing any necessary notice or opt-outs to end users and complying with applicable law.'), ('', 'Q: Do I have to integrate the AWS Mobile SDK with my app to use Amazon Mobile Analytics?'), ('No. You can use the Amazon Mobile Analytics REST API to send events programmatically.', 'Q: Do I need to use Amazon Cognito to use the Amazon Mobile Analytics service?'), ('', 'No. You can initialize Amazon Mobile Analytics using AWS IAM accounts. However, we recommend using Amazon Cognito for security best practices. Detailed documentation for both methods can be found here.'), ('', 'Q: Can I combine or split data between the iOS and Android version of my app?'), ('', 'Yes, the Amazon Mobile Analytics Reports feature a filter to split iOS, Android, and Fire OS data. Or, you can view all platforms combined.'), ('', 'Q: What OS versions does Amazon Mobile Analytics support?'), ('The iOS SDK supports apps running on iOS 7.0 and higher, Android apps running on Android 2.3.3 and higher, and apps built using Unity 4.0 or higher. The Amazon Mobile Analytics JavaScript SDK is supported in all modern browsers and JavaScript based app frameworks such as AppGyver (supersonic), Appcelerator, Ionic, Famo.us and Intel XDK. Note that the Amazon Mobile Analytics SDK for Javascript depends on the AWS SDK for Javascript. The REST API can be used on any platform that supports REST.', 'Q: Can I download Amazon Mobile Analytics Reports?'), ('', 'Yes, reports can be downloaded in CSV format.'), ('', 'Q: What time zone are the reports displayed in?'), ('', 'Reports are displayed in UTC time.'), ('', 'Q: Is data cached when a user’s device is offline?'), ('', 'Yes, when using the AWS Mobile SDK, data is cached on the user’s device and is uploaded when a network connection is next established.'), ('', 'Q: Is use of the network channel optimized when sending events?'), ('', 'Yes, the events are batched, and sent once per minute. You can also specify the transport to send the events: cellular and WiFi, or WiFi only.'), ('Q: What AWS Regions is the Amazon Mobile Analytics service available in?', 'Currently, Amazon Mobile Analytics is available in the AWS US East (N. Virginia) Region.'), ('', ''), ('', ''), ('Q: How are metrics calculated for the same user using multiple devices?', 'A user with the same app on two devices, such as an iPhone and an iPad, will be counted as two users.'), ('Q: How is a "Session" defined?', 'A Session is one use of an app by the user. A Session begins when an app is launched (or brought to the foreground), and ends when the app is terminated (or goes to the background). In order to accommodate for brief interruptions, like a text message, an inactivity period of up to 5 seconds is not counted as a new Session. Total Daily Sessions shows the number of sessions your app has each day. Average Sessions per Daily Active User shows the mean number of sessions per user per day.'), ('Q: When an app goes to the background does its session end?', 'Yes, the session ends. When the app comes to the foreground a new session begins.'), ('Q: How are Daily and Weekly Retention defined?', 'Daily Retention is measured by determining the number of users that first used your app on a specific day, come back and use your app on the next day (1-Day Retention), the third day (3-Day Retention), and the seventh day (7-Day Retention). Weekly Retention is measured by determining how many of the devices that first used your app on a specific day come back and use your app during days 1-7 (1-Week Retention), days 8-14 (2-Week Retention), and days 15-21 (3-Week Retention).'), ("Retention data takes 3 weeks to fully populate. For any given date X, retention data for N days is only available if the current date is after X + N days. For example, if today is October 10th, 1-Day Retention data is available for October 9th, 3-Day Retention for October 7th, and so on. For Weekly Retention, the information displayed can be for a partial week. If you are looking at 2-Week Retention and it's only the 10th day, days 8, 9, and (part of) 10 are available, so the 2-Week Retention is incomplete. Incomplete series are noted via the tooltip appears when hovering over data on the Retention chart.", 'Q: How is Sticky Factor calculated in the Active Users tab?'), ('Sticky Factor is calculated by dividing DAU by MAU. It is the fraction of monthly users using the app on any particular day. For example, if an app has 100K DAU and 300K MAU its Sticky Factor is .33. A high Sticky Factor can indicate strong engagement, appeal, and monetization.', 'Q: How are Daily and Monthly Revenue calculated for in-app items?'), ('Average Revenue Per Daily Active User (ARPDAU) is the total of your in-app gross revenue for a given day divided by the number of Daily Active Users (DAU). Average Revenue Per Paying Daily Active User (ARPPDAU) is the total of your in-app gross revenue for a given day divided by the number of paying Daily Active Users (DAU).', 'Average Revenue Per Monthly Active User (ARPMAU) is the total of your in-app gross revenue for a given month divided by the number of Monthly Active Users (MAU). Average Revenue Per Paying Monthly Active User (ARPPMAU) is the total of your in-app gross revenue for a given month divided by the number of paying Monthly Active Users (MAU).'), ('These metrics are provided for informational purposes only and may not reflect actual revenue. They include gross revenue for in-app items only (as sent to Amazon Mobile Analytics by you) and do not take into account taxes, product returns, reimbursements, subscriptions or revenue from the purchase of the app. All amounts are converted to U.S. dollars.', 'Detailed revenue reporting documentation is available for iOS, Android, and Fire OS. '), ('Q: What are Custom Events?', 'Custom Events are events defined entirely by you. They help track user actions specific to your app or game. The Custom Events Report provides a view of how often custom events occur and can be filtered based on Custom Event Attributes and their associated values.'), ('You create Custom Events by naming them, such as "Item Bought" or "Button Pressed." You can add context to Custom Events by specifying Attributes (for qualitative measure) and/or Metrics (for quantitative measure). For example, if your business goal is to track purchases of in-app items, you can use "Item Bought" as a Custom Event, "Item XYZ" as an Attribute and "Item Price" as the Metric. The Custom Events Report allows you to search and filter for each Attribute or Metric. For example, you can find how often "Item XYZ" was purchased or how often an Item Price was $1.99. You can also review the weighted average of Metric values (per session) and track minimum, maximum, or average Metric values.', 'Detailed Custom Event documentation is available for iOS, Android, and Fire OS.'), ('As a best practice, we recommend that Custom Event names be broad and Attributes be specific. In the above example, using "Item Bought" instead of "Item XYZ" as the Custom Event name helps in preventing the report from having too many distinct Custom Event names that are hard to read and aggregate.', 'Q: What are the benefits of using Custom Events?'), ('Custom Events help you understand user actions specific to your app. A game developer may want to understand both how often a level is completed and how much health each player has left at the end of that level. With custom events, you can create an event called "level_complete" and "add_level" as an attribute and "health" as an attribute value. Then each time a level is completed you can record a "level_complete" event with the name of the level and the player\'s health. By reviewing the data via the Custom Events Dashboard you may discover that level 3 is too easy as players always finish with maximum health. You could then adjust the level\'s difficulty to better challenge and engage players to improve retention.', 'Q: Are there any limits for using Custom Events in my app?'), ('You can have up to 1,500 unique Custom Event Types per app and up to 40 Attributes and Metrics per Custom Event. For more information on these and other limits affecting custom events, see docs.', 'Q: How do I remove an app from the Mobile Analytics reports?'), ('Please email us and the team will remove it for you.', 'Q: Why should I use the Auto Export feature?'), ('The Auto Export feature in Amazon Mobile Analytics allows you to regularly export raw event data received from your app to your Amazon Simple Storage Service (S3) bucket and into your Amazon Redshift cluster (which is created by Amazon Mobile Analytics as part of an AWS CloudFormation stack). You can also use event data in Amazon S3 with other data analytics tools such as Amazon Elastic MapReduce (EMR) or other Extract, Transform and Load (ETL) software, or your own data warehouse.', 'Once the event data is loaded into an Amazon Redshift cluster, you can analyze and dive deep into your app data by running SQL queries or by using one of the Amazon Redshift partners to view your data. For example, you can analyze how your users behave differently across multiple devices that they own, track the effectiveness of an in-app promotion across different app versions, or analyze retention rates across users in different countries or languages.'), ('Q: Do I pay an additional cost for using the Auto Export feature?', 'The price of the Amazon Mobile Analytics service remains the same. Amazon Mobile Analytics has a free tier of 100 million events per month per account, and costs just $1 per million events processed after the free tier. If you have enabled the Auto Export feature for Amazon S3, you pay for the costs associated with the storage of your events in your Amazon S3 bucket. If you have enabled Auto Export to Amazon Redshift, you will also pay for an Amazon Redshift cluster (a single node dw2.large cluster), an Amazon Elastic Compute Cloud (EC2)(t2.micro) instance to load data from your Amazon S3 bucket to your Amazon Redshift cluster, and optionally for Amazon CloudWatch resources (if enabled when configuring the Auto Export to Amazon Redshift feature). Free tier pricing information for Amazon Redshift and Amazon EC2 can be found here. For a detailed pricing example, please visit our pricing page.'), ('Q: Which destinations can I export data to?', 'With the Auto Export feature, you can export your app event data to your Amazon S3 bucket, and to your Amazon Redshift cluster. Exporting to S3 allows you to load the raw data into your own data warehouse, process it with an analytics service such as Amazon EMR, or simply archive it for future use. Exporting your data to Amazon Redshift allows you to analyze your raw events data with SQL queries. When you export to your Amazon Redshift cluster, data is also placed into your S3 bucket so that the original raw events are always available if required.'), ('Q: How does my app data get exported to Amazon Redshift?', 'Amazon Mobile Analytics creates an AWS\xa0CloudFormation\xa0stack consisting of an Amazon Redshift cluster and an EC2 instance. The EC2 instance connects to the Amazon Redshift cluster every hour to load events from your Amazon S3 bucket.'), ('Q: What should I do after configuring the Auto Export to Amazon Redshift?', 'Amazon Mobile Analytics uses AWS\xa0CloudFormation\xa0to set up a new stack consisting of an Amazon Redshift cluster, and an Amazon EC2 instance. It takes about 15 minutes for CloudFormation to complete this one time setup. Once the stack is created, the EC2 instance will begin loading any events that are in your Amazon S3 bucket into your Amazon Redshift cluster. You can access your Amazon Redshift cluster using a SQL query analyzer such as\xa0SQL Workbench, or 3rd party visualization tools such as Tableau. For a list of tools that can help you make the most of Amazon Redshift, click\xa0here.'), ('Q: Can I use my existing Amazon S3 bucket or Amazon Redshift cluster?', 'Yes. You can specify the S3 bucket for exporting the raw events. If you want to export your app data to your existing Amazon Redshift cluster, please refer to this doc: Exporting to an Existing Redshift Cluster'), ('Q: What is the frequency of the data exported?', 'Once the Auto Export feature is enabled, raw events from your app are exported to your Amazon S3 bucket within 60 minutes of being sent to the Amazon Mobile Analytics service. The data in your Amazon S3 bucket is imported into Amazon Redshift every hour. This means that it can take up to 2 hours for new events to be loaded into your Amazon Redshift cluster.'), ('Q: What is the format of the data exported?', 'See the documentation for the JSON schema of app events in Amazon S3 and the table schema of app events in Amazon Redshift.'), ('Q: Can I add custom events to the data exported?', 'Yes. All events are exported, including custom events. You can specify the custom event attributes and metrics in the Auto Export configuration wizard.'), ('Q: Can I stop exporting data?', 'Yes, you can start and stop exporting data for each or all of your apps using the App Management page in the Amazon Mobile Analytics console. Please note that by stopping the data export, only the new events that are recorded will not be exported to your Amazon S3 bucket or your Amazon Redshift cluster. If you want to delete the previously exported data and stop new charges, delete the “MobileAnalyticsAutoExportToRedshift…” stack using the AWS CloudFormation console and delete the Amazon S3 bucket used for storing these events from the Amazon S3 console.'), ('Q: Can I start exporting data to Amazon S3 now and then start exporting to Amazon Redshift later?', 'Yes, when you enable Auto Export to Amazon Redshift, all of your app event data that is stored in the Amazon S3 bucket that you specify is loaded into Amazon Redshift.'), ('Q: I’m already using Auto Export to Amazon S3. When can I start exporting events to my Amazon Redshift cluster?', 'You can start Exporting to Amazon Redshift immediately. Simply go to the App Management page in the Amazon Mobile Analytics console to enable Auto Export to Amazon Redshift.'), ('Q: I have a large app with billions of events being sent every day. Does this feature scale to meet my needs?', 'Yes. Amazon Mobile Analytics is designed to collect, process, and export events at scale. Amazon Redshift is a petabyte-scale data warehouse service. You can update your Amazon Redshift cluster in the Amazon Redshift console at any time to make use of more nodes.'), ('Q: Do my Amazon S3 bucket and Amazon Redshift Cluster have to be in the same region as Amazon Mobile Analytics (US-East-1)?', 'Amazon Mobile Analytics requires that your Amazon S3 bucket be located in US East-1. By default, Amazon Mobile Analytics will create an Amazon Redshift cluster and EC2 instance located in US East-1 as well. Please contact us if you want to setup an Amazon Redshift cluster in a different region. Data transfer charges between your Amazon S3 bucket in US-East-1 and the location of your Amazon Redshift cluster will apply.'), ('Q: Once I have my data in Amazon Redshift, how do I get started with analysis?', 'You can access your Amazon Redshift cluster using a SQL query analyzer such as SQL Workbench, or 3rd party visualization tools such as Tableau. For a list of tools that can help you make the best of Amazon Redshift, click here. Our documentation has SQL queries to help you get started.'), ('Q: Where do I go to get my connection string for my Amazon Redshift cluster?', 'Visit the Amazon Redshift console to get your connection information. See the Amazon Redshift documentation for additional help to connect to your Amazon Redshift Cluster.'), ('Q: What level of access can I provide to connect to Amazon Redshift?', 'The Amazon Redshift master user provides full unrestricted access to your Amazon Redshift cluster and can also be used to create additional Amazon Redshift users. The “eventreader” user provides read-only access to your app event data. The passwords for these users are specified when configuring the Auto Export to Amazon Redshift feature in the Amazon Mobile Analytics console.'), ('Q: Can I build custom dashboards for my app with this feature?', 'Yes. You can leverage 3rd party visualization tools such as Tableau to build custom dynamic dashboards. There are several\xa0tools that can help you make the best of Amazon Redshift.'), ('Q: My question isn’t answered in this FAQ. How can I reach Amazon for help?', 'Please email us for further help, follow us on our blog, or visit the Amazon Mobile Analytics forum.'), ('Q: How do I make a new feature request or provide feedback on this product?', 'Please let us know on the Amazon Mobile Analytics forum.'), ('Q: I have a question about Pricing.', 'Please email us. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/step-functions/faqs/': [('Q:\xa0What is AWS Step Functions?', 'AWS Step Functions is a fully managed service that makes it easy to coordinate the components of distributed applications and microservices using visual workflows. Building applications from individual components that each perform a discrete function lets you scale and change applications quickly. Step Functions is a reliable way to coordinate components and step through the functions of your application. Step Functions provides a graphical console to arrange and visualize the components of your application as a series of steps. This makes it simple to build and run multi-step applications. Step Functions automatically triggers and tracks each step, and retries when there are errors, so your application executes in order and as expected. Step Functions logs the state of each step, so when things do go wrong, you can diagnose and debug problems quickly. You can change and add steps without even writing code, so you can easily evolve your application and innovate faster.'), ('AWS Step Functions manages the operations and underlying infrastructure for you to help ensure your application is available at any scale.', 'Q: What are the benefits of designing my application using service orchestration to coordinate tasks?'), ('Breaking an application into service components (or steps) ensures that the failure of one component does not bring the whole system down, that each component scales independently, and that components may be updated without requiring the entire system to be redeployed after each change. The coordination of service components involves managing execution dependencies, scheduling, and concurrency in accordance with the logical flow of the application. In such an application, developers may use service orchestration to do this and to handle failures.', 'Q: What are some use cases that can be solved with AWS Step Functions?'), ('AWS Step Functions helps with any computational problem or business process that can be subdivided into a series of steps. Common use cases include:', 'Q: How does AWS Step Functions work?'), ('With AWS Step Functions, you define your application as a state machine, a series of steps that together capture the behavior of the app. States in the state machine may be tasks, sequential steps, parallel steps, branching paths (choice), and/or timers (wait). Tasks are units of work, and this work may be performed by AWS Lambda functions, Amazon EC2 instances of any type, containers, or on premises servers—anything that can communicate with the Step Functions API may be assigned a task. The visual console automatically graphs each state in the order of execution, making it easy to design multi-step applications. The console highlights the real-time status of each step and provides a detailed history of every execution. Step Functions operates and scales the steps of your application and underlying compute for you to ensure your application executes reliably under increasing demand.', 'Q: When should I use AWS Step Functions vs Amazon SQS?'), ('You should consider AWS Step Functions when you need to coordinate service components in the development of highly scalable and auditable applications. You should consider using Amazon Simple Queue Service (SQS), when you need a reliable, highly scalable, hosted queue for sending, storing, and receiving messages between services. Step Functions keeps track of all tasks and events in an application. Amazon SQS requires you to implement your own application-level tracking, especially if your application uses multiple queues. The Step Functions Console and visibility APIs provide an application-centric view that lets you search for executions, drill down into an execution’s details, and administer executions. Amazon SQS requires implementing such additional functionality. Step Functions offers several features that facilitate application development, such as passing data between tasks and flexibility in distributing tasks. Amazon SQS requires you to implement some application-level functionality. While you can use Amazon SQS to build basic workflows to coordinate your distributed application, you can get this facility out-of-the-box with Step Functions, alongside other application-level capabilities.', 'Q: When should I use AWS Step Functions vs AWS Batch?'), ('AWS Batch is a service that makes it easy to run batch computing workflows of any scale in the AWS cloud. You should use AWS Step Functions when you would like to build a distributed application as a series of steps, including sequential, parallel and/or branching logic (choices). You can use Batch to run jobs in your application and can use Step Functions to submit multiple Batch jobs with interdependencies. Use Batch when you would like automatic management of compute infrastructure in order to scale to the amount of batch processing required.', 'Q: When should I use AWS Step Functions vs Amazon Simple Workflow Service (SWF)?'), ('You should consider using AWS Step Functions for all your new applications, since it provides a more productive and agile approach to coordinating application components using visual workflows. If you require external signals to intervene in your processes, or you would like to launch child processes that return a result to a parent, then you should consider Amazon Simple Workflow Service (SWF). With Amazon SWF, instead of writing state machines in declarative JSON, you write a decider program to separate activity steps from decision steps. This provides you complete control over your orchestration logic, but increases the complexity of developing applications. You may write decider programs in the programming language of your choice, or you may use the Flow framework to use programming constructs that structure asynchronous interactions for you.', 'Q: What will happen to the existing Amazon Simple Workflow Service (SWF)?'), ('AWS will continue to provide Amazon Simple Workflow (SWF) and to support all Amazon SWF customers.', 'Q: How does AWS Step Functions work with other AWS services?'), (' AWS Step Functions works with several other AWS services, including AWS CloudFormation, AWS Lambda, Amazon EC2, Amazon EC2 Container Service (ECS), Amazon API Gateway, Amazon CloudWatch, AWS CloudTrail, and Auto Scaling.', ' The following are examples of some things you can do using various AWS services:'), (' ', 'Q: How does AWS Step Functions work with AWS Lambda?'), ('You can use AWS Lambda functions to perform tasks within your state machine. AWS Step Function passes input to the specified Lambda function, and then waits for the Lambda function to return a result. With Lambda, you can create tasks without provisioning or managing servers, in all languages supported by Lambda. To learn more about using Step Functions with Lambda, see our Step Functions documentation.', 'Q: How does AWS Step Functions work with Amazon EC2 and other compute resources?'), ('All work in your state machine is done by tasks. A task may be an Activity, which can consist of any code in any language. Activities can be hosted on Amazon EC2, Amazon ECS, mobile devices—basically any computer that can communicate with the AWS Step Functions API. Activities long-poll Step Functions using API calls to request work, receive input data, do the work, and return a result.', 'Q: How does AWS Step Functions work with Amazon API Gateway?'), ('Amazon API Gateway is a fully-managed service that makes it easy for developers to publish, maintain, monitor, and secure APIs at any scale. With just a few clicks in the AWS Management Console, you can associate your Step Functions APIs with methods in your API Gateway API, so that, when an HTTPS request is sent to an API method that you defined, API Gateway invokes your Step Functions API actions. ', 'You can use an Amazon API Gateway API to start Step Functions state machines that coordinate the components of a distributed backend application. You can also integrate human activity tasks into the steps of your application, such as an approval requests and responses. You can even make serverless asynchronous calls to the APIs of services that your application uses.'), ('Amazon API Gateway handles all of the tasks involved in accepting and processing hundreds of thousands of concurrent API calls, including traffic management, authorization and access control, monitoring, and API version management.', ' Q: How Does AWS Step Functions work with Amazon CloudWatch?'), (' Amazon CloudWatch is a monitoring service for AWS services and applications that you run on AWS. Amazon CloudWatch collects and track metrics, sets alarms, and automatically reacts to changes in AWS Step Functions.', ' The following are examples of things you can do with Amazon CloudWatch and AWS Step Functions:'), (' ', ' '), ('Q: Can I use AWS Step Functions with my on-premises resources?', 'Yes. AWS Step Functions applications can combine workers running in the datacenter with workers that run in the cloud. The workers in the datacenter continue to run as usual, along with any cloud-based workers.'), ('Q:\xa0How do I get started with AWS Step Functions?', 'To start using AWS Step Functions, go to the AWS Step Functions detail page and click the “Get Started for Free” button. If you do not have an Amazon Web Service account, you will be prompted to create one. After signing up, you can run a sample walkthrough in the AWS Step Functions Console which takes you through the steps of creating a state machine. Go to AWS Step Functions from the AWS Management Console. Next select the “Hello World” blueprint and add a “HelloWorld” Lambda function. You can now preview and run your state machine. To start using AWS Step Functions in your applications, please refer to the AWS Step Functions documentation.'), ('Q: What language does AWS Step Functions use?', 'You may use any programming language to write an Activity, as long as you can communicate with AWS Step Functions using web service APIs. For convenience, you may use an AWS SDK in the language of your choosing. AWS Lambda supports code written in Node.js (JavaScript), Python, and Java (Java 8 compatible), and C# (using the .NET Core runtime). State machines are defined in JSON using Amazon States Language.'), ('Q:\xa0How do I authenticate users?', 'AWS Step Functions is integrated with AWS Identity and Access Management (IAM). IAM policies can be used to control access to the Step Functions APIs. '), ('Q: How am I charged for using AWS Step Functions?', 'With AWS Step Functions you pay only for the transition from one step of your application workflow to the next, called a state transition. Billing is metered by state transition, regardless of how long each state persists (up to one year), making it cost-effective and easy to scale automatically from a few executions per day to tens of millions per month. Please see the AWS Step Functions pricing page for details. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/appstream/faqs/': [('Q: What is Amazon AppStream 2.0?', 'Amazon AppStream 2.0 is a fully managed application streaming service that provides users instant access to their desktop applications from anywhere, on any connected device. Amazon AppStream 2.0 simplifies application management, improves security, and reduces costs by moving a company’s applications from their users’ physical devices to the AWS Cloud. The Amazon AppStream 2.0 streaming protocol provides users a responsive, fluid performance that is almost indistinguishable from a natively installed application. With Amazon AppStream 2.0, organizations can realize increased flexibility, improved scalability, and the agility to support a broad range of compute and storage requirements for their applications.'), ("Q: What's the difference between the original Amazon AppStream and Amazon AppStream 2.0?", 'Amazon AppStream 2.0 is the next generation desktop application streaming service from AWS. Amazon AppStream\xa0was an SDK-base service that customers could use to set up their own streaming service with DIY engineering. Amazon AppStream 2.0 provides a fully managed streaming service with no DIY effort. Amazon AppStream 2.0 offers a greater range of instance types, streams desktop applications to HTML5 browsers with no plugins required, simplifies application lifecycle management, and allows your apps to access services in your VPC.'), ('Q: Can I continue to use the original Amazon AppStream service?', 'No. You cannot use the original Amazon AppStream service. Amazon AppStream 2.0 offers a greater range of instance types, streams desktop applications to HTML5 browsers with no plugins required, simplifies application lifecycle management, and allows your apps to access services in your VPC. '), ('Q: What are the benefits of streaming over rendering content locally?', 'Interactively streaming your application from the cloud provides several benefits:\xa0'), ('Instant-on: Streaming your application with Amazon AppStream 2.0 lets your users start using your application immediately, when using an image builder or Always-On fleet, without the delays associated with large file downloads and time-consuming installations.', 'Remove device constraints: You can leverage the compute power of AWS to deliver experiences that wouldn’t normally be possible due to the GPU, CPU, memory, or physical storage constraints of local devices.'), ('Multi-platform support: You can take your existing applications and start streaming them to browsers on any device without any modifications.', "Easy updates: Because your application is centrally managed by Amazon AppStream 2.0, updating your application is as simple as providing a new version of your application to Amazon AppStream 2.0. That's all you need to do to immediately upgrade all your users, without any action on their part."), ('Improved security: Unlike traditional boxed software and digital downloads, where your application is available for theft or reverse engineering, Amazon AppStream 2.0 stores and executes your application securely in AWS data centers, and only provides an interactive pixel stream to users.', 'Q: Do some applications work better with Amazon AppStream 2.0 than others?'), ('Many types of applications work well as streaming applications, including CAD, CAM, CAE, 3D modeling, simulation, games, video and photo-editing software, medical imaging, and life sciences applications. These applications benefit most from streaming because the application runs on the vast computational resources of AWS, yet your users can interact with the application using low-powered devices, with very little noticeable change in application performance.', 'Q: Does Amazon AppStream 2.0 support microphones?'), ('Yes. Amazon AppStream 2.0 supports most analog and USB microphones, including built-in microphones.', 'Q: How do users enable audio input in an Amazon AppStream 2.0 streaming session?'), ('Users enable audio input from the Amazon AppStream 2.0 toolbar by selecting the Settings\xa0icon and selecting Enable Microphone.', 'Q: What browser support audio-input in an Amazon AppStream 2.0 session?'), ('Most popular HTML5 compliant browsers support audio-input in Amazon AppStream 2.0 session, including Chrome, Edge, and Firefox. Microsoft Internet Explorer 11 (IE11) does not support audio-input, and the microphone option will not appear on the Amazon AppStream 2.0 toolbar in streaming sessions running in IE11.', 'Q: Does Amazon AppStream 2.0 support a 3D mouse?'), ('Amazon AppStream 2.0 does not currently support 3D mouse.', 'Q: What does a user need to access applications streamed from Amazon AppStream 2.0?'), ('A user needs to have applications set up by an administrator, a modern web browser that can support HTML5, a broadband Internet connection with at least 1 Mbps capability, and outbound access to the Internet via HTTPS (443).', 'Q: Can my Amazon AppStream 2.0 applications run offline?'), ('No. Amazon AppStream 2.0 requires a sustained Internet connection to access your applications.Q: Can my Amazon AppStream 2.0 applications run offline?', 'Q: What does Amazon AppStream 2.0 manage on my behalf?'), ('Streaming resources: Amazon AppStream 2.0 launches and manages AWS resources to host your application, deploys your application on those resources, and scales your application to meet client demand.', 'Simplified app management: Amazon AppStream 2.0 delivers the latest version of an application instantly to users, and eliminates the pain of patching and updating applications on every end-user device. Because your application is centrally managed by Amazon AppStream 2.0, updating your application is as simple as providing a new version of your application to Amazon AppStream 2.0. Applications can be assigned to users dynamically and removed instantly at any time, improving business flexibility and reducing costs.'), ('Q: Can I use tags to categorize AppStream 2.0 resources? ', 'Yes. you can assign tags to manage and track the following Amazon AppStream 2.0 resources: Image builders, images, fleets, and stacks. AWS enables you to assign metadata to your AWS resources in the form of tags. Tags let you categorize your AppStream 2.0 resources so you can easily identify their purpose and track costs accordingly. For example, you can use tags to identify all resources used by a particular department, project, application, vendor, or use case. Then, you can use AWS Cost Explorer to identify trends, pinpoint cost drivers, and detect anomalies in your account.  You can assign or remove tags using the AppStream 2.0 management console, command line interface, or API. Tags have a key and a corresponding value, and you can assign up to 50 tags per AppStream 2.0 resource. '), ('Q: What is Amazon AppStream 2.0 Try It Now?', 'Amazon AppStream 2.0 Try It Now is a low-friction, setup-free trial experience for the Amazon AppStream 2.0 service. Try It Now allows any AWS customer to instantly launch and interact with popular desktop applications from their browser.'), ('Q: What do I need to start using Try It Now?', 'You need an AWS account and a broadband Internet connection with at least 1 Mbps bandwidth to use Try It Now. You also need a browser capable of supporting HTML5.'), ('Q: Will I be charged for using Try It Now?', 'You won’t be charged any AWS fees for using Try It Now. However, you may incur other fees such as Internet or broadband charges to connect to the Try It Now experience.'), ('Q: What applications can I use with Try It Now?', 'Try It Now includes popular productivity, design, engineering, and software development applications running on Amazon AppStream 2.0 for you to try. To see the full list of available applications, go to the Try It Now catalog page after signing in with your AWS account.'), ('Q: How long can I stream applications via Try It Now?', 'You can stream the applications included in Try It Now for up to 30 minutes. At the end of 30 minutes, your streaming session is automatically terminated and any unsaved data will be deleted.'), ('Q: Can I save files within Try It Now?', 'You can save files to your Amazon AppStream 2.0 session storage and download them to your client device before your streaming session ends. Your files are not saved when you disconnect from your Try It Now session, or when your session ends, and any unsaved data will be deleted. '), ('Q: Can I submit an application to be included in Try It Now?', 'Yes. You can submit a request to include your application in Try It Now. After your request is received, AWS usually reviews the request and responds within 10 business days. '), ('Q: How do I get started with Amazon AppStream 2.0?', 'You can begin using Amazon AppStream 2.0 by visiting the AWS Management Console, or by using the AWS SDK. You can access the Getting Started guide here.\xa0'), ('Q: What resources do I need to set up to stream my applications using Amazon AppStream 2.0?', 'You need to create an Amazon AppStream 2.0 stack in your AWS account to start streaming applications to your users. A stack includes a fleet of Amazon AppStream 2.0 instances that executes and streams applications to end users. Each instance is launched using an Amazon AppStream 2.0 image containing your applications, and uses an instance type that you select for your fleet. To learn more about Amazon AppStream 2.0 resources, please visit this page.'), ('Q: How do I create an Amazon AppStream 2.0 image to import my applications?', 'You can create an Amazon AppStream 2.0 image using Image Builder via the AWS Management Console. Image Builder allows you to install and test your applications just as you would with any Windows desktop, and then create an image. You can complete all the install, test, and creation steps for the image without leaving the console.'), ('Q: What instance types are available to use with my Amazon AppStream 2.0 fleet?', 'Amazon AppStream 2.0 provides a menu of instance types for configuring a fleet or an image builder. You can select the instance type that best matches your applications and end-user requirements. You can choose from General Purpose, Compute Optimized, Memory Optimized, Graphics Design, Graphics Desktop, or Graphics Pro instance families.'), ('Q: Can I change an instance type after creating a fleet?', 'Yes. You can change your instance type after you have created a fleet. To change the instance type, you will need to stop the fleet, edit the instance type, and then start the fleet again. For more information, see Set up AppStream 2.0 Stacks and Fleets.'), ('Q: Can I connect Amazon AppStream 2.0 instances to my VPC?', 'Yes. You can choose the VPCs to which your Amazon AppStream 2.0 instances (fleet and image builders) connect. When you create your fleet, or launch Image Builder, you can specify one or more subnets in your VPC. If you have a VPC with a VPN connection to your on-premises network, then Amazon AppStream 2.0 instances in your fleet can communicate with your on-premises network. You retain the usual control you have over network access within your VPC, using all the normal configuration options such as security groups, network access control lists, and routing tables.\xa0For more information about creating a VPC and working with subnets, see\xa0Working with VPCs and Subnets.'), ('Q: How can I create images with my own applications?', 'You can use Amazon AppStream 2.0 Image Builder to create images with your own applications. To learn more, please visit the tutorial found on this page.'), ('Q: With which operating system do my apps need to be compatible?', 'Amazon AppStream 2.0 streams applications that can run on Windows Server 2012 R2 64-bit. You can add support for 32-bit applications by using the WoW64 extensions. If your application has other dependencies, such as the .NET framework, include those dependencies in your application installer.'), ('Q: Can I install anti-virus software on my Amazon AppStream 2.0 image to secure my applications?', 'You can install any tools, including anti-virus programs on your AppStream 2.0 image. However, you need to ensure that these applications do not block access to the AppStream 2.0 service. We recommend testing your applications before publishing them to your users.'), ('Q: Can I customize the operating system using group policies?', 'Any changes that are made to the image using Image Builder through local group policies will be reflected in your AppStream 2.0 images. Any customizations outside of local group policies are not currently supported.'), ('Q: How will my Amazon AppStream 2.0 images be updated with updates from the AppStream 2.0 service?', 'AppStream 2.0 regularly releases base images that include Microsoft Windows operating system updates and AppStream 2.0 agent updates. The AppStream 2.0 agent software runs on your streaming instances and enables your users to stream applications. When you create a new image, the Always use latest agent version\xa0option is selected by default. When this option is selected, any new image builder or fleet instance that is launched from your image will always use the latest AppStream 2.0 agent version. If you deselect this option, your image will use the agent version you selected when you launched the image builder. Windows operating system updates are released only through base images. To keep your operating system updated in your images, you need to rebuild your images using the latest AWS base image.  Q: How will my Amazon AppStream 2.0 images be updated with Windows updates from Microsoft?'), ('You will need to create new AppStream 2.0 images to apply Windows updates. To do this, you can create a new image builder instance from an existing image, apply Microsoft updates, and create a new image. Existing streaming instances will be replaced with instances launched from the new image within 16 hours or immediately after users have disconnected from them, whichever is earlier. You can immediately replace all the instances in the fleet with instances launched from the latest image by stopping the fleet, changing the image used, and starting it again.', 'Q: How do I update my applications in an existing image?'), ('To update applications on the image, or to add new applications, launch Image Builder using an existing image, update your applications and create a new image. Existing streaming instances will be replaced with instances launched from the new image within 16 hours or immediately after users have disconnected from them, whichever is earlier. You can immediately replace all the instances in the fleet with instances launched from the latest image by stopping the fleet, changing the image used, and starting it again.', 'Q: Can I connect my Amazon AppStream 2.0 applications to my existing resources, such as a licensing server?'), ('Yes. Amazon AppStream 2.0 allows you to launch streaming instances (fleets and image builders) in your VPC, which means you can control access to your existing resources from your AppStream 2.0 applications.\xa0For more information, see\xa0Network Settings for Fleet and Image Builder Instances.', 'Q: Does Amazon AppStream 2.0 offer GPU-accelerated instances?'), ('Yes. Amazon AppStream 2.0 offers Graphics Design, Graphics Desktop and Graphics Pro instance families.', 'Graphics Design instances are ideal for delivering applications such as Adobe Premiere Pro, Autodesk Revit, and Siemens NX that rely on hardware acceleration of DirectX, OpenGL, or OpenCL. Powered by AMD FirePro S7150x2 Server GPUs and equipped with AMD Multiuser GPU technology, instances start from 2 vCPU, 7.5 GiB system memory, and 1 GiB graphics memory, to 16 vCPUs, 61 GiB system memory, and 8 GiB graphics memory.'), ('The Graphics Desktop instance family offers a single instance type with an NVIDIA GPU based on K520 with 1,536 CUDA cores, 8 vCPUs, 15 GiB system memory, and 4 GiB graphics memory. This instance type is ideal for running desktop graphics applications such as Siemens NX, SolidWorks, ESRI ArcGIS, and other applications that use DirectX, OpenGL, OpenCL, and CUDA. The Graphics Desktop family is a powerful yet economical choice, with pricing that starts at tens-of-cents per hour.', "The Graphics Pro instance family offers three different instance types to support the most demanding graphics applications. Powered by NVIDIA Tesla M60 GPUs with 2048 parallel processing cores, there are three Graphics Pro instances types starting from 16 vCPUs, 122 GiB system memory, and 8 GiB graphics memory, to 64 vCPUs, 488 GiB system memory, and 32 GiB graphics memory. These instance types are ideal for graphic workloads that need a massive amount of parallel processing power for 3D rendering, visualization, and video encoding, including applications such as Petrel from Schlumberger Software, Landmark's DecisionSpace, or MotionDSP's Ikena. For more information on available instance types and pricing, see\xa0Amazon AppStream 2.0 Pricing.\xa0"), ('Q: What is the maximum screen resolution for Amazon AppStream 2.0 Graphics Desktop and Graphics Pro instances?', 'Amazon AppStream 2.0 Graphics Design, Graphics Pro and Graphics Desktop instances support a maximum resolution of 2560x1440. '), ('Q: How many monitors can I use with my Amazon AppStream 2.0 Graphics Desktop and Graphics Pro instances?', 'Currently you can only use a single monitor with your Amazon AppStream 2.0 Graphics Desktop and Graphics Pro instances. '), ('Q: What\xa0types of fleets are available with Amazon AppStream 2.0?', 'Amazon AppStream 2.0 offers two fleet types: Always-On and On-Demand. Always-On fleet instances are in a running state, even if no users are connected. This is best when your users need high availability and instant access to their applications. On-Demand fleets instances don’t start until a user connects to an instance within the fleet. This fleet type is best when your users can wait up to 2 minutes to start their applications, and for streaming applications that have sporadic use.'), ('Q: Can I switch my Amazon AppStream 2.0 Always-On fleet to On-Demand or vice versa?', 'You can only specify the fleet type when you create a new fleet, and you cannot change the fleet type once the fleet has been created. \xa0'), ('Q:\xa0What are the benefits to Always-On and On-Demand fleets for Amazon AppStream 2.0?', 'Always-On fleets are best for when your users need high availability and instant access to their applications. On-Demand fleets instances don’t start until a user connects to an instance within the fleet, and is best for when your users can wait up to 2 minutes to start their applications, and for streaming applications that have sporadic use.'), ('Q: What client operating systems are supported?', 'Amazon AppStream 2.0 can stream your applications to HTML5-capable browsers, including the latest versions of Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Microsoft Edge, on desktop devices, including Windows, Mac, Chromebooks, and Linux PCs.'), ('Q: What server operating system is supported?', 'Amazon AppStream 2.0 supports streaming applications that can execute on the Windows Server 2012 R2, a 64-bit operating system. You can add support for 32-bit applications by using the WoW64 extensions. If your application has other dependencies, such as the .NET framework, include those dependencies in your application installer.'), ('Q: Which AWS regions does Amazon AppStream 2.0 support?', 'Please refer to the AWS Regional Products and Services page for details of Amazon AppStream 2.0 service availability by region'), ('Q: What instance types are available to use with my Amazon AppStream 2.0 fleet?', 'Amazon AppStream 2.0 provides a menu of instance types for configuring a fleet. You can select the instance type that best matches your applications and end-user requirements. You can choose from General Purpose, Compute Optimized, Memory Optimized, Graphics Design, Graphics Desktop, or Graphics Pro instance families. '), ('Q: How does Amazon AppStream 2.0 scale?', 'Amazon AppStream 2.0 uses Fleet Auto Scaling to launch Amazon AppStream 2.0 instances running your application and to adjust the number of servers to match the demand for end-user sessions. Each end-user session runs on a separate instance, and all the apps that are streamed within a session run on the same instance. An instance is used to stream applications for only one user, and is replaced with a new instance at the end of the session.'), ('Q: What scaling policy does Amazon AppStream 2.0 support?', 'Amazon AppStream 2.0 supports fixed and dynamic scaling policies. Use a fixed scaling policy to keep a constant number of Amazon AppStream 2.0 instances and users who can start a streaming session. Use a dynamic scaling policy to scale based on the use of Amazon AppStream 2.0 instances in your environment.'), ('Q: What is an Amazon AppStream 2.0 Fleet Auto Scaling policy?', 'A Fleet Auto Scaling policy is a dynamic scaling policy that allows you to scale the size of your fleet to match the supply of available instances to user demand. You can define scaling policies that adjust the size of your fleet automatically based on a variety of utilization metrics, and optimize the number of running instances to match user demand.'), ('Q: How can I create auto scaling policies for my Amazon AppStream 2.0 fleet?', 'You can create automatic scaling policies from the Fleets tab in the AppStream 2.0 console, or by using the AWS SDK.'), ('Q: Which Amazon AppStream 2.0 CloudWatch metrics can I use to build Fleet Auto Scaling polices?', 'You can use the following metrics to build your Fleet Auto Scaling policies:'), ('• Capacity utilization: you can scale your fleet based on the percentage of instances in your fleet that are being used • Available capacity: you can scale your fleet based on the number of available instances in your fleet • Insufficient capacity error: you can provision new instances when users can’t start streaming sessions due to lack of capacity', 'For more information, please see Fleet Auto Scaling for Amazon AppStream 2.0.'), ('Q: Can my Amazon AppStream 2.0 fleet have more than one associated Fleet Auto Scaling policy?', 'Yes. You can have up to 50 Fleet Auto Scaling policies associated with a single fleet. Each policy allows you to set a single criteria and action for resizing your fleet.\xa0'), ('Q: What is the minimum size I can set for my Amazon AppStream 2.0 fleet when using Fleet Auto Scaling policies?', 'You can set your Fleet Auto Scaling policies to scale in to zero instances. Scaling policies associated with your fleet decrease fleet capacity until it reaches your defined minimum, or the default setting of one if you haven’t set a minimum. For more information, please see Fleet Auto Scaling for Amazon AppStream 2.0.'), ('Q: What is the maximum size I can set for my Amazon AppStream 2.0 fleet when using Fleet Auto Scaling policies?', 'Fleet Auto Scaling policies increase fleet capacity until it reaches your defined maximum size or until service limits apply. For more information, please see Fleet Auto Scaling for Amazon AppStream 2.0. For service limit information, please see Amazon AppStream 2.0 Service Limits.'), ('Q: Are there additional costs for using Fleet Auto Scaling policies with Amazon AppStream 2.0 fleets?', 'There are no charges for using Fleet Auto Scaling policies. However, each CloudWatch alarm that you create and use to trigger scaling policies for your AppStream 2.0 fleets may incur additional CloudWatch charges. For more information, see Amazon CloudWatch Pricing. \xa0'), ('Q:\xa0Does Amazon AppStream 2.0 offer persistent storage so that I can save and access files between sessions?', 'Yes. Users can store and retrieve their files between their application streaming sessions using persistent storage, backed by\xa0Amazon S3. Users can access a home folder on their streaming instance, and save content in this folder for use between streaming sessions. Users can also download and upload files in the home folder directly from their web browser, when connected to a streaming session. All files are stored in an S3 bucket which is automatically created in your AWS account.'), ('Q: How do users access persistent storage from their Amazon AppStream 2.0 sessions?', 'Users can access a home folder during their application streaming session. Any file they save to their home folder will be available for use in the future.'), ('Q: How are files in the home folder persisted?', 'A home folder is created for a user the first time a user launches a streaming session. When connected to the streaming session, each file that is saved by the user to his home folder is synced to Amazon S3. Files are stored as S3 objects within the S3 bucket that is created for your AWS account in the same region. When a user connects to a new session, the home folder, along with all the files saved previously, will be available to open from any application on the streaming instance.'), ('Q: What are the charges for enabling home folders storage for my AppStream 2.0 stacks?', 'There are no additional AppStream 2.0 charges to use this feature. However standard S3 data storage charges will apply when your users save files in their home folder. For more information, see\xa0Amazon S3 Pricing.'), ('Q: How much data can I store in the bucket created for Home Folders?', 'The total volume of data that can be stored within an S3 bucket is unlimited. The largest recommended file size to save in a home folder is 5 gigabytes.'), ('Q: What kind of data can users store in Home Folder?', 'Your users can store any documents, spreadsheets, or other project files they would usually create using a desktop application. However, since the files are individually synced to Amazon S3 on a frequent basis, we recommend not saving large database files or email archive files to your Home Folder.'), ('Q: What are the pre-requisites for using home folders?', 'Before enabling home folders for a stack, you need to create an image from an AppStream 2.0 image published by AWS on or after May 18th 2017. You will also need to enable Internet access from the fleet associated with a stack or configure your Amazon VPC S3 endpoint for AppStream 2.0 access. For more details, please see\xa0Before Enabling Home Folders.'), ('Q: Can users access their home folder files when they are not connected to an application streaming sessions?', 'No. Users cannot access their files when they are not connected to an application streaming session.'), ('Q: Do administrators have access to user content stored in Home Folders?', 'Administrators who can access the Amazon S3 bucket created by Amazon AppStream 2.0 can view and modify content that is part of users’ Home Folders. To restrict administrator access to the S3 bucket containing users’ files, we recommend applying an S3 bucket access policy based on the policy template, please see\xa0Restricting Administrator Access to the Amazon S3 Bucket for Home Folders for more information.'), ('Q: How do I monitor usage of my Amazon AppStream 2.0 fleet resources?', 'There are two ways you can monitor your Amazon AppStream 2.0 fleet. First, the AppStream 2.0 console provides a lightweight, real-time view of the state of your AppStream 2.0 fleet, and offers up to two weeks of historical usage data. Metrics are displayed automatically, and don’t require any setup.'), ('Second, you can access AppStream 2.0 metrics using CloudWatch. The CloudWatch console allows you to specify reporting intervals, create custom dashboards and graphs, and set alarms.', 'To learn more, see Monitoring Amazon AppStream 2.0 Resources.'), ('Q: What information can I get from the Amazon AppStream 2.0 usage metrics?', 'You can see the size of your Amazon AppStream 2.0 fleet, the number of running instances, the number of instances available to accept new connections, and the utilization of your fleet. You can track these metrics over time so that you can optimize your fleet settings to suit your needs.'), ('Using Amazon CloudWatch, you can also set alarms to notify you of changes to your fleet, or when there is insufficient capacity to support your users.', 'For the complete list of available metrics, see Monitoring Amazon AppStream 2.0 Resources.\xa0'), ('Q: Can I create custom Amazon CloudWatch metrics for Amazon AppStream 2.0?', 'Yes, you can create custom metrics for Amazon AppStream 2.0. For more information, see Publish Custom Metrics.'), ('Q: How frequently are Amazon AppStream 2.0 metrics published to Amazon CloudWatch?', 'Amazon AppStream 2.0 sends metrics to Amazon CloudWatch every 1 minute. The metrics are stored in CloudWatch using the standard retention policy. For more information, see Amazon CloudWatch FAQs.'), ('Q: How do I create CloudWatch alarms for Amazon AppStream 2.0?', 'You can create Amazon CloudWatch alarms for Amazon AppStream 2.0 using the CloudWatch console or the CloudWatch APIs.'), ('Q: Are there additional costs for using CloudWatch metrics with Amazon AppStream 2.0?', 'There is no additional charge for viewing CloudWatch metrics for AppStream 2.0. You may incur additional charges for setting up CloudWatch alarms and retrieving metrics via the CloudWatch APIs. For more information, see Amazon CloudWatch Pricing.'), ('Q: Does Amazon AppStream 2.0 offer a set of public APIs?', 'Yes, Amazon AppStream 2.0 includes APIs that you can use to easily integrate and extend the service. The APIs enable you to create, update, and delete Amazon AppStream 2.0 resources, and provide detailed information about resource states. You can create URLs for administrators to connect to their image builders to install applications, and create URLs for users to access their AppStream 2.0 applications. See our API reference for more information'), (' \xa0', 'Q: What streaming protocol does Amazon AppStream 2.0 use?'), ('Amazon AppStream 2.0 uses NICE DCV to stream your applications to your users. NICE DCV is a proprietary protocol used to stream high-quality, application video over varying network conditions. It streams video and audio encoded using standard H.264 over HTTPS. The protocol also captures user input and sends it over HTTPS back to the applications being streamed from the cloud. Network conditions are constantly measured during this process and information is sent back to the encoder on the server. The server dynamically responds by altering the video and audio encoding in real time to produce a high-quality stream for a wide variety of applications and network conditions.', 'Q: What is the maximum network latency recommended while accessing Amazon AppStream 2.0?'), ('While the remoting protocol has a maximum round-trip latency recommendation of 250 ms, the best user experience is achieved at less than 100 ms. If you are located more than 2000 miles from the AWS Regions where Amazon AppStream 2.0 is currently available, you can still use the service, but your experience may be less responsive. The easiest way to check performance is to use the Amazon AppStream 2.0 Try It Now experience. ', 'Q: How do I restrict network access from fleets and image builders launched in my VPC?'), ('Security groups enable you to specify network traffic that is allowed between your streaming instances and resources in your VPC. You can restrict network access by assigning an image builder or fleet to the security groups in your VPC. For more information, refer to Security Group for Your VPC.', 'Q: Can I use existing VPC security groups to secure AppStream 2.0 fleets and image builders?'), ('Yes. You can assign an image builder or fleet to existing security groups in your VPC.', 'Q: How many security groups can I apply to a fleet or image builder?'), ('You can assign an image builder or fleet to up to five security groups.', 'Q: Can I change the security groups to which my fleets are assigned after they have been created?'), ('Yes. You can change the security groups to which your fleets are assigned, so long as they are in the stopped status. ', 'You can also change the rules of a security group in your VPC at any time using the Amazon EC2 console. Note that the new rules will apply to all resources assigned to that security group. For more information, refer to Security Groups for your VPC.'), ('Q: Can I change the security groups to which my image builders are assigned after they have been created?', 'No. You cannot change the security groups to which your fleets are assigned after they have been created. To assign an image builder to a different security groups, you will need to create a new image builder.\xa0'), ('You can also change the rules of a security group in your VPC at any time using the Amazon EC2 console. Note that the new rules will apply to all resources assigned to that security group. For more information, refer to Security Groups for your VPC. ', 'Q: How is the data from my streamed application encrypted to the client?'), ('The streamed video and user inputs are sent over HTTPS and are SSL-encrypted between the Amazon AppStream 2.0 instance executing your applications, and your end users.', 'Q: How do I authenticate users with Amazon AppStream 2.0 applications?'), ('There are three options to authenticate users with Amazon AppStream 2.0: you can use built-in user management, you can build a custom identity, or you can set up federated access using SAML 2.0.', 'When using built-in user management, you can set up and manage your users in the AppStream 2.0 management console from the User Pool tab. To add a new user, all you need is their first and last name, and an e-mail address. To learn more about user management within AppStream 2.0, see\xa0Using the AppStream 2.0 User Pool.'), ('When using federated sign-in to authenticate users, you will set up identity federation using SAML 2.0, which allows you to use your existing user directory to control access to applications available via AppStream 2.0. For details on setting up SAML integration, see the steps outlined here.', 'When building an entitlement service, you should authenticate users either with a custom identity or by using a service such as Login with Amazon. After your custom identity has authenticated a user, it should call into Amazon AppStream 2.0 to create a new streaming URL. AppStream 2.0 returns a URL for the session that can be opened in a browser to start the streaming session. '), ('Q: Can I use Amazon AppStream 2.0 with my existing user directory, including Microsoft Active Directory?', 'Yes. Amazon AppStream 2.0 supports identity federation using SAML 2.0, which allows you to use your existing user directory to manage end user access to your AppStream 2.0 apps. For details on setting up SAML integration, see the steps outlined here. '), ('Q: What type of identity federation does Amazon AppStream 2.0 support?', 'Amazon AppStream 2.0 supports federation using SAML 2.0 (Identity Provider initiated). This type of federated access allows a user to sign in by first authenticating with an identity federation provider, after which they can access their AppStream 2.0 apps. '), ('Q: What are the requirements for setting up identity federation with Amazon AppStream 2.0?', 'To configure identity federation with Amazon AppStream 2.0, you need a SAML 2.0 Identity Provider that links to an existing LDAP-compatible directory, such as Microsoft Active Directory. Microsoft Active Directory Federation Services (ADFS), Ping Identity, Okta, and Shibboleth, are all examples of SAML 2.0 Identity Providers that will work with AppStream 2.0. '), ('Q: Can I control which users access my Amazon AppStream 2.0?', 'Yes. When using built-in user management, you can control which users have access to your Amazon AppStream 2.0 stacks in the User Pool tab of the AppStream 2.0 management console. To learn more about user management within AppStream 2.0, see Using the AppStream 2.0 User Pool.\xa0'), ('When you use SAML 2.0, you can control which users have access to your Amazon AppStream 2.0 stacks by mapping the users in your federation service to the IAM role that has access permissions to the stack. Please refer to the AppStream 2.0 documentation for detailed information and step-by-step guidelines for popular federation services. ', 'Q: Can I enable multi-factor authentication for my users?'), ('Yes. You can enable Multi-Factor Authentication when using federation with SAML 2.0 or when using your own entitlement service. ', 'Q: Can users choose which Amazon AppStream 2.0 stack they want to access during signing-in?'), ('Yes. You can setup every Amazon AppStream 2.0 stack as an entity or a package in your federation service. This allows your users to select which stack they want to access while signing in from your application portal. \xa0', 'Q: Who can access the management console for my Amazon AppStream 2.0 application?'), ('You can use AWS Identity and Access Management (IAM) to add users to your AWS account and grant them access to view and manage your Amazon AppStream 2.0 application. For more information, see “What is IAM?” in the IAM User Guide. ', 'Q: Can I join Amazon AppStream 2.0 image builders to Microsoft Active Directory domains?'), ('Yes, Amazon AppStream 2.0 images can be joined to your Microsoft Active Directory domains. This allows you to apply your existing AD policies to your streaming instances, and provides your users with single sign on access to Intranet sites, file shares, and network printers from within their applications. Your users are authenticated using a SAML 2.0 provider of your choice, and can access applications that require a connection to your AD domain. ', 'Q: What Microsoft Active Directory versions are supported?'), ('Microsoft Active Directory Domain Functional Level Windows Server 2008 R2 and newer are supported by Amazon AppStream 2.0.', 'Q: Which AWS Directory Services directory options are supported by Amazon AppStream 2.0?'), ('Amazon AppStream 2.0 supports AWS Directory Services Microsoft AD. Other options such as AD Connector and Simple AD are not supported. To learn more about AWS Microsoft AD see\xa0What Is AWS Directory Service. ', 'Q: How do I join my Amazon AppStream 2.0 instances to my Microsoft Active Directory domain?'), ('To get started you will need a Microsoft Active Directory domain that is accessible from an Amazon VPC, the credentials of a user with authority to join the domain, and the domain Organizational Unit (OU) you want to join to your fleet. For more information, see Using Active Directory Domains with AppStream 2.0.\xa0', 'Q: Can I use my existing Organization Units (OU) structure with Amazon AppStream 2.0?'), ('Yes, you can use your existing Organizational Unit (OU) structure with Amazon AppStream 2.0. To learn more, see\xa0Using Active Directory Domains with AppStream 2.0.', 'Q: What gets joined to my Microsoft Active Directory domain by Amazon AppStream 2.0?'), ('Amazon AppStream 2.0 will automatically create a unique computer object for every image builder and fleet instance you configure to be joined to your Microsoft Active Directory domain.', 'Q: How can I identify Amazon AppStream 2.0 computer objects in my Microsoft Active Directory domain?'), ('Amazon AppStream 2.0 computer objects are only be created in the Microsoft Active Directory Organization Unit (OU) you specify. The description field indicates that the object is an AppStream 2.0 instance, and to which fleet the object belongs. To learn more, see Using Active Directory Domains with AppStream 2.0.', 'Q: How are computer objects that are created by Amazon AppStream 2.0 deleted from my Microsoft Active Directory domain?'), ('Computer objects created by Amazon AppStream 2.0 that are no longer used will remain in your Active Directory (AD) if the AppStream 2.0 fleet or image builder is deleted, you update a fleet or image builder to a new OU, or select a different AD. To remove unused objects you will have to delete them manually from your AD domain. To learn more, see Using Active Directory Domains with AppStream 2.0.', 'Q: How do I provide users with access to Amazon AppStream 2.0 streaming instances that are joined to a Microsoft Active Directory domain? '), ('To enable user access, you will need to set up federated access using a SAML 2.0 provider of your choice. This allows you to use your existing user directory to control access to streaming applications available via Amazon AppStream 2.0. For details on setting up SAML 2.0 integration, see the steps outlined at Setting Up SAML.', 'Q: Can I connect my users that are managed through User Pools to my Active Directory domain?'), ('No. At this time we do not support User Pools users connecting to domain joined resources. To learn more about User Pools see, Using the AppStream 2.0 User Pool.', 'Q: How much does Amazon AppStream 2.0 cost?'), ('You are charged for the streaming resources in your Amazon AppStream 2.0 environment, and monthly user fees per unique authorized user accessing applications via Amazon AppStream 2.0. You pay for these on-demand, and never have to make any long-term commitments.', 'The streaming resources consist of Amazon AppStream 2.0 instances in your Amazon AppStream 2.0 fleet as well as image builder instances. You have the option to have Always-On and On-Demand fleets. For Always-On fleets you pay for instances in your fleet that are running, even if users are not connected. These instances are billed per hour, and the price per hour is based on the instance type you select. For On-Demand fleets you pay for the instances in your fleet that are running only when a user is connected. These instances are billed per hour, and the price per hour is based on the instance type you select. In an On-Demand fleet If an instance is running but not connected to a user, you pay a nominal hourly On-Demand Stopped Instance fee, which is the same for all instance types within a region. Image builder instances are only available as always on, and you pay for instances that are running, even if users are not connected. The charge for Always-On and On-Demand fleet instances as well as image builder instances includes the cost of the storage volumes used by the Amazon AppStream 2.0 image, and outbound bandwidth used by the streaming protocol.'), ('You can control the number of running instances using fixed or dynamic scaling policies.', 'The monthly user fee is used to pay for the Microsoft Remote Desktop Services Subscriber Access License (RDS SAL). This fee is charged per unique authorized user, and is charged in full (not pro-rated), regardless of when a user first accesses Amazon AppStream 2.0 in that month. Schools, universities, and public institutions may qualify for reduced user fees. Please reference the Microsoft Licensing Terms and Documents for qualification requirements. If you think you may qualify, please contact us. We will review your information and work with you to reduce your Microsoft RDS SAL fee. There is no user fee incurred when using image builder instances. For more details, view the Amazon AppStream 2.0 pricing page.'), ('Q: Can I bring my own licenses and waive the user fees?', 'Yes. If you have Microsoft License Mobility, you may be eligible to bring your own Microsoft RDS CAL licenses and use them with Amazon AppStream 2.0. For users covered with your own licenses, you won’t incur the monthly user fees. For more information about using your existing Microsoft RDS SAL licenses with Amazon AppStream 2.0, please visit this page, or consult with your Microsoft representative.'), ('Q: What are the requirements for schools, universities, and public institutions to reduce their user fee? ', 'Schools, universities, and public institutions may qualify for reduced user fees. Please reference the Microsoft Licensing Terms and Documents\xa0for qualification requirements. If you think you may qualify, please contact us. We will review your information and work with you to reduce your Microsoft RDS SAL fee. There is no user fee incurred when using image builder instances.\xa0'), ('Q: What do I need to provide to qualify as a school, university, or public institution?', "You will need to provide AWS your institution's full legal name, principal office address, and public website URL. AWS will use this information to qualify you for AppStream 2.0's reduced user fees for qualified educational institutions. Please note: The use of Microsoft software is subject to Microsoft’s terms. You are responsible for complying with Microsoft licensing. If you have questions about your licensing or rights to Microsoft software, please consult your legal team, Microsoft, or your Microsoft reseller. You agree that we may provide the information to Microsoft in order to apply educational pricing to your Amazon AppStream 2.0 usage."), ("Q. Does qualification for Amazon AppStream 2.0's reduced RDS SAL user fees affect other AWS cloud services?\xa0", 'No, your user fees are specific to Amazon AppStream 2.0, and do not affect any other AWS cloud services or licenses you have.\xa0'), ('Q: Can I use tags to obtain usage and cost details for Amazon AppStream 2.0 on my AWS monthly billing report?', 'Yes. When you set tags to appear on your monthly Cost Allocation Report, your AWS monthly bill will also include those tags. You can then easily track costs according to your needs. To do this, first assign tags to your Amazon AppStream 2.0 resources by following the steps in Tagging Your AppStream 2.0 Resources. Next, select the tag keys to include in your cost allocation report by following the steps in Setting Up Your Monthly Cost Allocation Report.'), ('Q: Are there any costs associated with tagging Amazon AppStream 2.0 resources?', 'There are no additional costs when using tags with Amazon AppStream 2.0. \xa0'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/workdocs/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/workmail/faqs/': [('Q: What is Amazon WorkMail?', 'Amazon WorkMail is a secure, managed business email and calendar service with support for existing desktop and mobile clients. Amazon WorkMail gives users the ability to seamlessly access their email, contacts, and calendars using Microsoft Outlook, their web browser, or their native iOS and Android email applications. You can integrate Amazon WorkMail with your existing corporate directory and control both the keys that encrypt your data and the location in which your data is stored. '), ('Q: How can I get started using Amazon WorkMail? ', 'To get started with Amazon WorkMail, you will need an AWS account. You can use this account to sign into the AWS Management Console and create an organization, add your domains, and also create users, groups, or resources. Please refer to the Amazon WorkMail documentation for more information on getting started.'), ('Q: What clients can I use to access Amazon WorkMail? ', 'You can access Amazon WorkMail from Microsoft Outlook clients on Windows and Mac OS X, and on mobile devices that support the Microsoft Exchange ActiveSync protocol including iPhone, iPad, Kindle Fire, Fire Phone, Android, Windows Phone, and BlackBerry 10. Additionally, you can use the Apple Mail application on Mac OS X or the Amazon WorkMail web application to securely access Amazon WorkMail using your web browser.'), ('Q: Does Amazon WorkMail support accessibility capabilities?', 'Yes, you can use screen readers and keyboard shortcuts with the Amazon WorkMail web application for easier accessibility; you can learn more about these capabilities on the Working with Accessibility Features documentation page here. In addition, the accessibility capabilities offered in supported desktop and mobile clients (see below for a list) can also be used with Amazon WorkMail. '), ('Q: What is the mailbox storage limit in Amazon WorkMail? ', 'Amazon WorkMail offers a mailbox storage limit of 50 GB per user. '), ('Q: What is the maximum size of email that I can send from Amazon WorkMail? ', 'The maximum size of outgoing and incoming email in Amazon WorkMail is 25 MB. '), ('Q: Can I share my calendar with other users in my organization? ', 'Yes. Amazon WorkMail offers the ability to share your calendar with your co-workers. '), ('Q: Does Amazon WorkMail provide resource booking? ', 'Yes. Amazon WorkMail provides the option to create resource mailboxes such as conference rooms, projectors, and other equipment. The resource mailboxes will allow users to reserve the room or equipment by including the resource in meeting invites.'), ('Q: Does Amazon WorkMail support email archiving? ', 'Email journaling can be enabled to capture and preserve messages in your existing archiving solution.'), ('Q: Can I set up email redirect rules on Amazon WorkMail?', 'Yes, you can configure email redirection rules for Amazon WorkMail mailboxes. You can setup email redirection rules on your desktop email application, such as Microsoft Outlook, or using the Amazon WorkMail web application. You will need to ensure that the Amazon Simple Email Service (Amazon SES) identity policies for your domains are up-to-date to take advantage of email redirection rules. Please visit this page for more information on how to update the Amazon SES identity policy for your domain.'), ('Q: Are there limits on the number of organizations and users I can create when using Amazon WorkMail?', ' No, there are no limits on the number of organizations and users you can create.'), ('Q: Are there limits on the number of messages I can send per user?', ' There are limits only on sending external messages. For example, the number of messages sent to recipients outside your organization. Each user in your organization can send messages to a maximum of 10,000 external recipients per day, and the total external recipients for an AWS account is limited to 100,000 per day. New Amazon WorkMail accounts may start with limits that are lower than the limits described here; please see AWS Service Limits\xa0for more information.'), ('Amazon WorkMail is a business e-mail service and not intended to be used for bulk e-mail services. For bulk e-mail services, please see Amazon Simple Email Service.', 'Q: Are there limits associated with the use of the Amazon WorkMail SMTP gateway?'), ('Yes. To learn more about SMTP limits, please see AWS Service Limits. ', 'Q: Are there limits on the number of messages each user can receive?'), ('There are no limits on the number of messages each user can receive. However, we may queue or reject messages (and send a bounce to the sender) if there is a large volume of incoming email in a short period of time. Please see AWS Service Limits\xa0for more information.', 'Q: Do meeting requests count when evaluating usage against message limits?'), ('All messages that are sent to another user are considered when evaluating these limits. These include e-mails, meeting requests, meeting responses, task requests, as well as all messages that are forwarded or redirected automatically as a result of a rule.', 'Q: What features does the Amazon WorkMail web application provide? '), ('The Amazon WorkMail web application provides users anywhere with access to email, calendar, contacts, and tasks. Users can also access shared calendars, access the global address book, manage their out-of-office replies, and book resources. ', 'Q: Which browsers does the Amazon WorkMail web application work on? '), ('The Amazon WorkMail web application supports the following browsers: Firefox, Chrome, Safari, Edge and Internet Explorer. For more information, please see Log On to the Amazon WorkMail Web Application.\xa0 ', 'Q: In which languages is the Amazon WorkMail web application available? '), ('The Amazon WorkMail web application is currently available in English.', 'Q: Can I use Amazon WorkMail on my mobile device? '), ('Yes. Amazon WorkMail is compatible with most major mobile devices supporting the Microsoft Exchange ActiveSync protocol, including iPad, iPhone, Kindle Fire, Fire Phone, Android, Windows Phone, and BlackBerry 10. ', 'Q: What mobile device policies does Amazon WorkMail support? '), ('Amazon WorkMail gives you the ability to require a PIN or password on your devices, configure the password strength, require a device lock after a number of failed login attempts, require a screen lock for idle timeouts, and require device and storage card encryption. ', 'Q: Does Amazon WorkMail offer the ability to remotely wipe mobile devices?'), ('Yes. Amazon WorkMail offers a remote wipe feature. A remote wipe can be performed by the IT administrator using the AWS Management Console. ', 'Q: Can I use Amazon WorkMail with Microsoft Outlook on Microsoft Windows? '), ('Yes. Amazon WorkMail offers native support for Microsoft Outlook 2007, 2010, 2013, and 2016 on Microsoft Windows. ', 'Q: Do I need any additional software to connect Microsoft Outlook to Amazon WorkMail? '), ('No. Amazon WorkMail offers native support for the most recent versions of Microsoft Outlook and does not require any additional software to connect Microsoft Outlook. ', 'Q: Can I use Amazon WorkMail with Microsoft Outlook on Mac OS X? '), ('Yes. Amazon WorkMail offers native support for Microsoft Outlook 2011 and Microsoft Outlook 2016 on Mac OS X. ', 'Q: Can I use Amazon WorkMail with other clients on Mac OS X?'), ('Yes. Amazon WorkMail offers native support for the Apple Mail and Calendar applications on Mac OS X (10.6 and above).', 'Q: Does the Amazon WorkMail user subscription include a license for Microsoft Outlook? '), ('Amazon WorkMail does not include a license for Microsoft Outlook. To use Microsoft Outlook with Amazon WorkMail, you must have a valid license from Microsoft. ', 'Q: Does Amazon WorkMail support the Click-to-run version of Microsoft Outlook 2010, 2013, and 2016?  '), ('Yes. Amazon WorkMail supports the Click-to-run versions of Microsoft Outlook 2010, 2013, and 2016. ', 'Q: Can I access my Amazon WorkMail mailbox with my existing POP3 or IMAP client applications?'), ('You can access your Amazon WorkMail mailbox with client applications that support the IMAP protocol. Amazon WorkMail currently does not offer support for POP3 email access.', 'Q: When using an IMAP client application, can I access all items in my Amazon WorkMail mailbox?'), ('The IMAP protocol provides access to email, but not to calendar items, contacts, notes, or tasks.', 'Q: When using an IMAP client application, will I be able to see all my email folders?'), ('Yes, any folder which contains email will be visible and accessible using an IMAP client application.', 'Q: How do I send email when using an IMAP email client application?'), ('You can send email by configuring your IMAP email client to use the Amazon WorkMail SMTP gateway. Amazon WorkMail SMTP addresses can be found at AWS Regions and Endpoints.', 'Q. What is the Amazon WorkMail SMTP Gateway?'), ('The Simple Mail Transfer Protocol (SMTP) gateway is an Amazon WorkMail service which allows you to submit email messages for delivery to both internal and external recipients. To learn more, please see Connect your Client IMAP Application.', 'Q. What email client applications can I use to send email using the Amazon WorkMail SMTP gateway?'), ('You can use the Amazon WorkMail SMTP gateway to send email using any email client that supports the SMTP protocol. This includes popular email clients like Microsoft Outlook, Apple Mail or Mozilla Thunderbird.  ', 'Q: Do I need to set up a directory to use Amazon WorkMail?'), ('Each user you add to your Amazon WorkMail organization needs to exist in a directory, but you do not have to provision a directory yourself. You can integrate your existing Microsoft Active Directory with Amazon WorkMail using AWS Directory Service AD Connector or run AWS Directory Service for Microsoft Active Directory Enterprise Edition ("Microsoft AD") so you don’t have to manage users in two places and users can continue to use their existing Microsoft Active Directory credentials. Alternatively, you can have Amazon WorkMail create and manage a Simple AD directory for you and have users in that directory created when you add them to your Amazon WorkMail organization. ', 'Q: How can I integrate with an existing Microsoft Active Directory? '), ("You can integrate with an existing Microsoft Active Directory by setting up an AWS Directory Service AD Connector or Microsoft AD and enabling Amazon WorkMail for this directory. After you've configured this integration, you can choose which users you would like to enable for Amazon WorkMail from a list of users in your existing directory, and users can log in to Amazon WorkMail using their existing Active Directory credentials. ", 'Q: Can I use my existing domain name with Amazon WorkMail? '), ('Yes. You can add your existing domain name to Amazon WorkMail using the AWS Management Console. Before the domain name can be used, you must verify the ownership of the domain name. You can verify the ownership by adding a DNS record to your DNS server. ', 'Q: Can I assign multiple email addresses to a user account? '), ('Yes. You can assign multiple email addresses to a user account using the AWS Management Console. ', 'Q: Can I create distribution groups to deliver email to multiple users? '), ('Yes. You can create new distribution group or enable an existing group from your Microsoft Active Directory using the AWS Management Console. These distribution groups are available in the Global Address Book. Users can also create personal distribution groups using Microsoft Outlook or the Amazon WorkMail web application. ', 'Q: What happens if a user forgets their password to access Amazon WorkMail? '), ('If Amazon WorkMail is integrated with an existing Active Directory domain, then the user would follow the existing lost password process for your existing domain, such as contacting an internal helpdesk. If the account is integrated with a Simple AD directory and a user forgets their password, then the account’s IT administrator can reset the password from the AWS Management Console. ', 'Q: How does an IT administrator remove a user’s access to Amazon WorkMail? '), ('The account’s IT administrator can remove a user’s access to Amazon WorkMail using the AWS Management Console.', 'Q: Does Amazon WorkMail provide a management API? '), ('No. Amazon WorkMail does not currently provide a management API. ', ''), ('Q: Does Amazon WorkMail offer an SDK?', 'Yes. Amazon WorkMail provides an administrative SDK so you can natively integrate WorkMail with your existing services. The SDK enables programmatic user, email group, and meeting room or equipment resource management through API calls. This means your existing IT service management tools, workflows, and third party applications can automate WorkMail migration and management. To learn more, please visit our our API reference. '), ('Q: How can I start using email journaling?', 'Email journaling can be setup from the Amazon WorkMail Management Console under Organization Settings. You can enable email journaling, specify the email address to which journaled emails are sent, and specify the email address to which reports are sent.'), ('Q: Can I apply email journaling to a specific set of actions or users?', 'No. Today email journaling is a global setting that is applied to all inbound and outbound email, and all users.'), ('Q: Does email journaling apply to recipients in the blind carbon copy (BCC) field?', 'Yes. Email sent using BCC recipients is recorded using email journaling.'), ('Q: Will journaling reports show email recipients in the BCC field?', 'For outbound email, journaling reports will contain the details of recipients in the BCC field. For inbound email, the journaling report will only contain of details of recipients in the BCC field if those recipients are in your Amazon WorkMail organization.'), ('Q: Will emails marked as spam be journaled?', 'Yes, they will.'), ('Q: Will emails marked as containing viruses be journaled?', 'No. Emails that contain viruses will be dropped and will not be journaled.'), ('Q: What actions will be taken in case of delivery failures to the journaling destination mailbox?', 'Amazon WorkMail will continue to try to deliver the journaled messages to the journaling destination mailbox for 12 hours. In case of continuous failure, the failure reports will be delivered to the address you specify in the Amazon WorkMail Management Console.'), ('Q: What do journaling failed delivery reports contain?', 'Whenever journaled email fails to be delivered to the primary journaling address, a report is sent to the failed delivery report email address you specify in the Amazon WorkMail Management Console. This report contains information about each journaled message that failed to be delivered, but does not show the contents of the original message.'), ('Q: What is the email address from which journaled emails are sent?', 'Journaled emails are be sent from amazonjournaling@<alias>.awsapps.com where <alias> is your Amazon WorkMail organization name.'), ('Q: Is there an additional cost to using email journaling?', 'No, there is no additional cost to using email journaling.'), ('Q: Which SMTP headers will identify a journaled message by the journaling agent?', '“X-WM-Journal-Report” will be used as the header to identify journaled messages. This header will be signed so that it cannot be mimicked.'), ('Q: Do journaling messages count against the sending limits?', 'No, journaling messages are always sent as long as the user is allowed to send a message. They are not counted against that user’s sending limit. On receiving a message, the journaling message is always sent as long as it can be delivered to a user. '), ('Q: How can I migrate mailboxes from my existing email solution to Amazon WorkMail? ', 'You can migrate your existing mailboxes to Amazon WorkMail using solutions from a preferred Amazon WorkMail migration provider. To see a list of providers, please visit this webpage.\xa0If you’re migrating from Microsoft Exchange Server 2013 or 2010, you can set up interoperability to minimize disruption for your end users.'), ('Q: Does Amazon WorkMail support interoperability with Microsoft Exchange Server?', 'Yes, Amazon WorkMail supports interoperability with Microsoft Exchange Server 2013 and 2010. You can learn about how to set up interoperability here.'), ('Q: What interoperability capabilities does Amazon WorkMail support?', 'Interoperability allows you to use the same corporate domain for all mailboxes on both Microsoft Exchange and Amazon WorkMail. Your users can seamlessly schedule meetings with bi-directional sharing of calendar free-busy information between the two environments, and access user and resource information through a unified global address book. '), ('Q: Which versions of Microsoft Exchange Server are supported with Amazon WorkMail interoperability?', 'Amazon WorkMail offers interoperability support with Microsoft Exchange Server 2013 and 2010.'), ('Q: Are there additional charges to use interoperability features?', 'No. Interoperability features are included in Amazon WorkMail per mailbox pricing.'), ('Q: Can users access Amazon WorkMail using their existing Microsoft Active Directory credentials?', 'Yes, users can connect to Amazon WorkMail using their existing Microsoft Active Directory credentials.'), ('Q: Will mailboxes on Amazon WorkMail use the same domain as mailboxes on my Microsoft Exchange server?', 'Yes. To make this possible, you need to enable email routing between Microsoft Exchange and Amazon WorkMail so that mailboxes on both environments use the same corporate domain. To set up email routing, you can follow the steps outlined here.'), ('Q: Which email platform handles incoming email traffic when interoperability is established?', 'Your on-premises Microsoft Exchange Server handles and processes all incoming email. If you’re using interoperability for migration, you can switch your MX record to point to Amazon WorkMail when your migration is complete.'), ('Q: Can I restrict access to my Microsoft Exchange Server to just my VPC?', 'No, you can’t restrict access to the Exchange Server to your VPC. As of now, the EWS endpoint of your on-premises Microsoft Exchange environment needs to be publicly available. \xa0'), ('Q: Does Amazon WorkMail support bi-directional sharing of calendar free-busy information with Microsoft Exchange?', 'Yes, interoperability provides you bi-directional sharing of calendar free-busy information between your Amazon WorkMail and Microsoft Exchange environments. Please follow the steps here.'), ('Q: How does Amazon WorkMail interact with my on-premises Microsoft Exchange Server to perform bi-directional calendar free-busy lookups?', 'You will need to configure availability settings on Amazon WorkMail and Microsoft Exchange to share calendar free-busy information. Amazon WorkMail uses the EWS URL for your Microsoft Exchange server to perform free-busy lookups. Amazon WorkMail uses an Exchange service account to login to Exchange and read free-busy data of the users in the Microsoft Exchange organization.'), ('For free-busy lookups of Amazon WorkMail users from your Microsoft Exchange Server, Exchange performs an Autodiscover request and connects to the Amazon WorkMail EWS endpoint using an Amazon WorkMail service account. ', 'You can find more information on this here.'), ('Q: Do I need to set up federation on my on-premises Microsoft Exchange server?', 'No, for interoperability support with Amazon WorkMail, you don’t need to set up federation on your Microsoft Exchange server.'), ('Q: Can I also view subject and location in the free-busy details when interoperability is enabled?', 'Yes, to view subject and location information, the service account user needs to have access to this information.'), ('Q: Can an Amazon WorkMail user manage the shared calendar or shared folder of a user on Microsoft Exchange (and vice versa).', 'No, for calendar delegation or accessing shared folders, both users need to be on the same email platform. We recommend migrating users who use calendar and mailbox delegation in the same batch.'), ('Q: How does Amazon WorkMail interact with my on-premises Microsoft Exchange Server to create a unified global address book?', 'Once interoperability support is enabled, Amazon WorkMail performs a synchronization of the address book with your on-premises Active Directory every four hours, using AD Connector. All Microsoft Exchange users, groups, and resources are automatically added to your Amazon WorkMail address book. '), ('Q: Will all Microsoft Exchange Server objects synchronize to the Amazon WorkMail global address book?', "Amazon WorkMail will synchronize users, groups, resources, and contacts that reside in Microsoft Exchange Server. Amazon WorkMail will not synchronize dynamic groups or address lists. When your Microsoft Exchange global address book contains these objects, they won't be available in Amazon WorkMail."), ('Q: Will Amazon WorkMail still synchronize with my Active Directory when interoperability support isn’t enabled?', 'Yes, Amazon WorkMail will still synchronize with your Active Directory when interoperability support is disabled. In this scenario only changes to Amazon WorkMail users and groups are synchronized.'), ('Q: Does the Microsoft Outlook offline address book also contain all my Microsoft Exchange users, and groups, and resources?', 'Yes, the Microsoft Outlook offline address book will contain both Amazon WorkMail Microsoft Exchange users, groups, and resources.'), ('Q: Can my distribution groups contain both Amazon WorkMail and Microsoft Exchange users as members?', 'Yes, you can have both Amazon WorkMail and Microsoft Exchange users as members of distribution groups.'), ('Q: Can I still create new resource in Amazon WorkMail when interoperability support is enabled?', 'No. To create new resources in Amazon WorkMail, you first need to disable interoperability support. Once your new resources have been created, you can then turn interoperability support back on. This is done to ensure resources are synchronized back to your Microsoft Exchange Server.  '), ('Q: What are email flow rules?', 'Amazon WorkMail allows you to use email flow rules to filter inbound email traffic for your Amazon WorkMail organizations, which helps you reduce email from unwanted senders, route suspicious mail to junk folders, and make sure important messages are successfully delivered. Email flow rules can be applied based on specific email addresses, or entire email domains.'), ('Q: What types of email flow rules can I create?', "Email flow rules can be created to filter email based on specific email addresses, or entire email domains. Examples include: • Reject all incoming mail from example.com and its subdomains, generating a bounce message to the sender. • Reject all incoming mail from example.com, except when from myemail@example.com. • Reject all incoming mail from user@example.com. • Bypass the spam check for all incoming email from example.com, delivering the messages instead to users' inbox. • Deliver all messages from example.com to users' junk folders."), ('Q: How can I start using email flow rules?', 'Rules can be set up from the Amazon WorkMail management console by navigating to Organization Settings. You can create, modify, and delete flow rules under the Email Flow Rules tab.'), ('Q: Can I perform filtering based on IP address or range?', 'IP based filtering is already supported by Amazon Simple Email Service. Please see Creating IP Address Filters for Amazon SES Email Receiving\xa0to learn more about IP-based filtering.'), ('Q: What happens if email containing a virus is received from a source specified to bypass spam checks?', 'Amazon WorkMail scans all incoming and outgoing email for spam, malware, and viruses. All email containing viruses is dropped and not delivered, regardless of the configured flow rules.'), ('Q: What happens if email flow rules overlap?', 'If you have email for which multiple email flow rules match, the action of the most specific rule will be applied. For example, a rule for a specific email address will take precedence over a rule for an entire domain. If multiple rules have the same specificity, the most restrictive action will be applied (for example, Drop will take precedence over Bounce). Please see Managing Email Flows\xa0for more information.'), ('Q: Are there limits on the number of rules I can create?', 'Yes. To learn more about limits related to email flow rules, please see AWS Service Limits.'), ('Q: How long does a rule need to take effect?', 'Rules take effect immediately after creation.'), ('Q: Is there any additional charge for defining email flow rules?', 'No, there is no additional charge for using email flow rules. '), ('Q: How is data transmitted to Amazon WorkMail? ', 'All data in transit is encrypted using industry-standard SSL. Our web application, and mobile and desktop clients transmit data to Amazon WorkMail using SSL. '), ('Q: Can I choose the AWS region where my data is stored? ', 'Yes. You choose the AWS region where your organization’s data is stored. Please refer to the Regional Products and Services page for details of Amazon WorkMail availability by region. '), ('Q. How do I decide which AWS region to use? ', 'There are several factors to consider, based on your needs, including whether using a specific AWS region enables you to meet regulatory and compliance requirements. We generally recommend that you set up your Amazon WorkMail organization in the region nearest to where most of your users are located, to reduce data access latencies. '), ('Q: How is Amazon WorkMail protected from malware/viruses? ', 'Amazon WorkMail scans all incoming and outgoing email for spam, malware, and viruses to help protect customers from malicious email. '), ('Q: Does Amazon WorkMail offer support for mobile device policies, to protect data stored on mobile devices? ', 'Yes. Amazon WorkMail gives you the ability to require a PIN or password on your users’ devices, configure the password strength, require a device lock after a number of failed login attempts, require a screen lock for idle timeouts, and require device and storage card encryption. '), ('Q: How can I manage my encryption key used for the data encryption in Amazon WorkMail? ', 'Amazon WorkMail is integrated with Amazon Key Management Service for the encryption of your data. Key management can be performed from the Amazon IAM console. For more information about AWS Key Management Service, please see Amazon AWS Key Management developer guide. '), ('Q: What data is encrypted with my encryption keys? ', 'All email content, attachments, and metadata for a mailbox is encrypted using the customer-managed keys of that user’s organization.'), ('Q: Is my email encrypted when using the IMAP protocol to access my Amazon WorkMail mailbox?', 'Yes. All email communication is encrypted in transit by the secure connections made between the client and the server, and all email stored in Amazon WorkMail is encrypted at rest.  '), ('Q: Does Amazon WorkMail support S/MIME for signing and encrypting email? ', 'Yes. Amazon WorkMail supports S/MIME signing and encryption in the Microsoft Outlook client and certain mobile devices like Apple iPhone and iPad. The Amazon WorkMail web application currently does not support S/MIME signing and encryption. '), ('Q. What compliance certifications does Amazon WorkMail support?', 'Amazon Web Services has achieved the ISO 27001, ISO 27017 and ISO 27018 certifications. Amazon WorkMail regions in US East (N.Virginia), US West (Oregon) and EU (Ireland) are within the scope of the certifications. You can learn more about these certifications on the AWS Cloud Compliance section of the website. '), ('You can also request a copy of the Service Organization Controls (SOC) report available from AWS Compliance to learn more about the security controls AWS uses to protect your data. ', 'Q: How does AWS use my Amazon WorkMail email content?'), ('You own your content in Amazon WorkMail, and you retain full ownership and control of your Amazon WorkMail email. We will not view, use, or move the contents of your Amazon WorkMail account unless authorized by you.', 'Q: How does Amazon WorkMail integrate with Amazon WorkDocs? '), ('Amazon WorkDocs integration offers users the ability to distribute large documents easily from the Amazon WorkMail web application, keep control of sensitive documents distributed by email, and securely save email attachments in Amazon WorkDocs. ', 'Q: How can I start using the Amazon WorkDocs integration? '), ('To use the integration with Amazon WorkDocs, your organization first needs to be activated for Amazon WorkDocs. You can activate Amazon WorkDocs for your organization in the AWS Management Console. After this is done, you can enable Amazon WorkDocs for your users using the Amazon WorkDocs admin panel. After your users are enabled for Amazon WorkDocs, they can start using the Amazon WorkDocs integration in the Amazon WorkMail web application. ', 'If your organization and users are already using Amazon WorkDocs, your users can start using the integration right after they are enabled for Amazon WorkMail.'), ('Q: Can I use Amazon WorkMail without using Amazon WorkDocs? Yes, however you will not be able to use the Amazon WorkDocs integration in the Amazon WorkMail web application. ', 'Q: How does Amazon WorkMail integrate with Amazon Simple Email Service? '), ('Amazon WorkMail uses Amazon Simple Email Service to send all outgoing email. The test mail domain and your production domains are available for management in the Amazon Simple Email Service console. ', 'Q: Will I be charged for outgoing email sent from Amazon WorkMail? '), ('No. You won’t be charged for outgoing email sent from Amazon WorkMail. ', 'Q: Do I need to increase Amazon SES sending limits to use Amazon WorkMail?'), ('No. This is not needed to use with Amazon WorkMail. The SES limits only apply when you are using Amazon SES using the Amazon SES API for sending bulk email from your AWS account.', 'Q: Does Amazon WorkMail integrate with AWS CloudTrail?'), ('Yes. CloudTrail captures API calls from the WorkMail console or from WorkMail API operations. Using the information collected by CloudTrail, you can track requests made to WorkMail, the source IP address from which the requests were made, who made the requests, when they were made, and so on. To learn more about CloudTrail, including how to configure and enable it, see the AWS CloudTrail User Guide. To learn more about logging WorkMail API calls, see Logging Amazon WorkMail API Calls with AWS CloudTrail. ', 'Q: Will I be charged for using AWS CloudTrail with Amazon WorkMail?'), ('There is no additional WorkMail charge to use WorkMail with CloudTrail. There may be charges associated with delivering events using CloudTrail. For details, please see the CloudTrail Pricing', 'Q: How will my business be charged for use of Amazon WorkMail?'), ('There are no upfront fees or commitments to begin using Amazon WorkMail. At the end of the month, you are billed for that month\'s usage. You can view estimated charges for the current billing period by logging into the AWS Management Console and clicking on "Account Activity." You can get started with a free trial of Amazon WorkMail and activate up to 25 user accounts at no charge for the first 30 days. You can use the WorkMail console to get started today. ', 'You are charged for the number of user accounts per month. The number of users billed in a month is based on the average number of active user accounts throughout the month. For every user account, your business is charged a monthly subscription fee. If a user account is deactivated during the month, the monthly subscription fee for that account will be prorated based on the number of active days. For more information on how pricing works, see the pricing page.'), ('Q: Is there a free trial for Amazon WorkMail?', 'Yes. You can activate up to 25 users at no charge for the first 30 days after you sign up for Amazon WorkMail. After this period ends, you are charged for all active users unless you remove them or deregister your Amazon WorkMail account.'), ('Q: Will I be charged for creating or using resources (such as meeting rooms)', 'No. Creating or using of resources within Amazon WorkMail is available free of charge.'), ('Q: Is there an additional charge for using IMAP client applications?', 'No. IMAP access is included in the Amazon WorkMail mailbox pricing. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/workspaces/faqs/': [('Q: What is Amazon WorkSpaces?', 'Amazon WorkSpaces is a managed desktop computing service running on the AWS cloud. Amazon WorkSpaces allows customers to easily provision cloud-based desktops that allow end-users to access the documents, applications and resources they need on supported devices including Windows and Mac computers, Chromebooks, iPads, Fire tablets, Android tablets, and Chrome and Firefox web browsers. With a few clicks in the AWS Management Console, customers can provision a high-quality cloud desktop experience for any number of users at a cost that is competitive with traditional desktops and half the cost of most Virtual Desktop Infrastructure (VDI) solutions.'), ('Q: What is an Amazon WorkSpace?', 'An Amazon WorkSpace is a cloud-based virtual desktop that can act as a replacement for a traditional desktop. A WorkSpace is available as a bundle of compute resources, storage space, and software applications that allow a user to perform day-to-day tasks just like using a traditional desktop. A user can connect to a WorkSpace from any supported device using the free Amazon WorkSpaces client application, or using Chrome or Firefox web browsers. Users will connect using credentials set up by an administrator, or using their existing Active Directory credentials if you’ve chosen to integrate your Amazon WorkSpaces with an existing Active Directory domain. Once the user is connected to a WorkSpace they can perform all the usual tasks they would do on a desktop computer.'), ('Q: How can I get started with Amazon WorkSpaces?', 'To get started with Amazon WorkSpaces, you will need an AWS account. You can use this account to sign into the AWS Management Console and you can then quickly provision Amazon WorkSpaces for yourself and any other users in your organization who might require one. To provision an Amazon WorkSpace, first select a user from your directory. Next, select an Amazon WorkSpaces bundle for the user. The Amazon WorkSpaces bundle specifies the resources you need, which desktop operating system you want to run, and the software applications you want prepackaged. Finally, choose a running mode for their Amazon WorkSpace – pick AlwaysOn if you want to use monthly billing, or AutoStop if you want to use hourly billing. Once your WorkSpace is provisioned, the user will receive an email with instructions for connecting to their WorkSpace. You can use this same process to provision multiple WorkSpaces at the same time. '), ('Q: Which Amazon WorkSpaces bundles are available?', 'You can find the latest information on Amazon WorkSpaces bundles here.'), ('Q: Which versions of Windows are available for use with Amazon WorkSpaces? ', 'Amazon WorkSpaces offers bundles that come with a Windows 7 or Windows 10 desktop experience, powered by Windows Server 2008 R2 and Windows Server 2016 respectively. If your organization is eligible to bring their own Windows Desktop licenses, you can run the Windows 7 or Windows 10 Enterprise operating system on your Amazon WorkSpaces. See below\xa0for more information.'), ('Q: How do I select which desktop experience I want my Amazon WorkSpaces to run?', 'To select the desktop experience you need for your Amazon WorkSpaces, choose the bundle type that best describes your requirements when you launch new WorkSpaces. For the Windows 7 desktop experience, select bundles that include “Windows 7”. For the Windows 10 desktop experience, select bundles that include “Windows 10”.'), ('Q: Can I migrate users from an Amazon WorkSpaces Windows 7 bundle to a Windows 10 bundle?', 'No. To offer existing users a Windows 10 desktop experience, you need to delete their existing Amazon WorkSpace and create a new one using a Windows 10 WorkSpaces bundle. To migrate data and documents, we recommend that you use the sync feature available with Amazon WorkDocs. Note that Amazon WorkDocs comes with 50GB of free storage for every Amazon WorkSpace.'), ('Q: How does a user get started with their Amazon WorkSpace once it has been provisioned?', 'When Amazon WorkSpaces are provisioned, users receive an email providing instructions on where to download the WorkSpaces clients they need, and how to connect to their WorkSpace. If you are not integrating with an existing Active Directory, the user will have the ability to set a password the first time they attempt to connect to their WorkSpace. If the AWS Directory Services AD Connector has been used to integrate with an existing Active Directory domain, users will use their regular Active Directory credentials to log in.'), ('Q: What does a user need to use an Amazon Workspace?', 'A user needs to have an Amazon WorkSpace provisioned for them, and a broadband Internet connection. To use an Amazon WorkSpaces client application to access their WorkSpace, they will need a supported client device (PC, Mac, iPad, Kindle Fire, or Android tablet), and an Internet connection with TCP ports 443 & 4172, and UDP port 4172 open.'), ('Q: Once users connect to their Amazon WorkSpace can they personalize it with their favorite settings?', 'An administrator can control what a user can personalize in their WorkSpace. By default, users can personalize their WorkSpaces with their favorite settings for items such as wallpaper, icons, shortcuts, etc. These settings will be saved and persist until a user changes them. If an administrator wishes to lock down a WorkSpace using tools like Group Policy, this will restrict a user’s ability to personalize their WorkSpaces.'), ('Q: Can users install applications on their Amazon WorkSpace?', 'By default, users are configured as local administrators of their WorkSpaces. Administrators can change this setting and can restrict users’ ability to install applications with a technology such as Group Policy.'), ('Q: Are Amazon WorkSpaces persistent?', 'Yes. Each WorkSpace runs on an individual instance for the user it is assigned to. Applications and users’ documents and settings are persistent.'), ('Q: How is a user’s data backed up?', 'The user volume (D:) on the WorkSpace is backed up every 12 hours. In the case of a WorkSpace failure, AWS can restore this volume from the backup. If Amazon WorkDocs Sync is enabled on a WorkSpace, the folder a user chooses to sync will be continuously backed up and stored in Amazon WorkDocs.'), ('Q: Do users need an AWS account?', 'No. An AWS account is only needed to provision WorkSpaces. To connect to WorkSpaces, users will require only the information provided in the invitation email they will receive when their WorkSpace is provisioned.'), ('Q: If I am located a significant distance from the region where my Amazon WorkSpace is located, will I have a good user experience?', 'If you are located more than 2000 miles from the regions where Amazon WorkSpaces is currently available, you can still use the service, but your experience may be less responsive. The easiest way to check performance is to use the Amazon WorkSpaces Connection Health Check Website. You can also refer to the Regional Products and Services page for details of Amazon WorkSpaces service availability by region.'), ('Q: Does Amazon WorkSpaces offer a set of public APIs?', 'Yes, public APIs are available for creating and managing Amazon WorkSpaces programmatically. APIs are available via the AWS CLI and SDK; you can learn more about the APIs in the documentation.'), ('Q: Do the Amazon WorkSpaces APIs log actions in AWS CloudTrail?', 'Yes. Actions on Amazon WorkSpaces performed via the WorkSpaces APIs will be included in your CloudTrail audit logs.'), ('Q: Is there Resource Permission support with the Amazon WorkSpaces APIs?', 'Yes. You can specify which Amazon WorkSpaces resources users can perform actions on. For details see the documentation.'), ('Q: Do I need to use the AWS Management Console to get started with Amazon WorkSpaces?', 'Yes. The first time set up for Amazon WorkSpaces relies on the AWS Management Console. Once you have created a directory and registered it with the Amazon WorkSpaces service, you can create and manage WorkSpaces using the Amazon WorkSpaces APIs. '), ('Q: What applications are available with Amazon WorkSpaces Windows 7 bundles?', 'Amazon WorkSpaces comes with a default set of applications at no additional cost that include Internet Explorer 11, Firefox, and 7-Zip. You can chose to add “Plus” application bundles to your Windows 7 Amazon WorkSpaces bundles which include Microsoft Office Professional 2010 or 2013, Trend Micro Worry-Free Business Security, and WinZip, for an additional monthly fee. Microsoft Office Professional 2016 is available with bundles that offer the Windows 10 desktop experience.'), ('Q: What applications are available with Amazon WorkSpaces Windows 10 bundles?', 'Amazon WorkSpaces comes with a default set of applications at no additional cost that include Internet Explorer 11, Firefox, and 7-Zip. You can chose to add “Plus” application bundles to your Windows 10 Amazon WorkSpaces bundles which include Microsoft Office Professional 2016, Trend Micro Worry-Free Business Security, and WinZip, for an additional monthly fee. Microsoft Office Professional 2010 and 2013 continue to be available with bundles that offer the Windows 7 desktop experience. \xa0'), ('Q: Can I create custom images for Amazon WorkSpaces?', 'Yes, as an administrator you can create a custom image from a running Amazon WorkSpace. Once you have customized an Amazon WorkSpace with your applications and settings, you can select the WorkSpace in the console and select “Create Image.” This will create an image with your applications and settings. Custom images created from Amazon WorkSpaces Graphics bundles can only be used with Graphics bundles, and custom images created from Value, Standard, Performance, or Power bundles can only be used with those bundles. Most Amazon WorkSpace images are available within 45 minutes. See the custom image documentation for more detail.'), ('Q: How do I launch an Amazon WorkSpace from a custom image?', 'To launch an Amazon WorkSpace from a custom image, you will first need to pair the custom image with a hardware type you want that WorkSpace to use, which results in a bundle. You can then publish this bundle through the console, then select the bundle when launching new WorkSpaces.'), ('Q: What is the difference between a bundle and an image?', 'An image contains only the OS, software and settings. A bundle is a combination of both that image and the hardware from which a WorkSpace can be launched.'), ('Q: How many custom images can I create?', 'As an administrator, you can create as many custom images as you need. Amazon WorkSpaces sets default limits, but you can request an increase in these limits here. To see the default limits for Amazon WorkSpaces, please visit our documentation. '), ('Q: Can I update the image in an existing bundle?', 'Yes. You can update an existing bundle with a new image that contains the same tier of software (for example containing the Plus software) as the original image.'), ('Q: What type of Amazon Elastic Block Store (EBS) volumes does Amazon WorkSpaces offer?', 'All Amazon WorkSpaces launched after 31st January 2017 are built on general purpose solid-state drives (SSD) EBS volumes for both root and user volumes. Amazon WorkSpaces launched prior to 31st January 2017 are configured with EBS magnetic volumes. You can switch your Amazon WorkSpaces using magnetic EBS volumes to SSD EBS volumes by rebuilding them (more information can be found here). You can learn more about SSD EBS volumes here, and magnetic EBS volumes here.'), ('Q: Can I use custom images to launch WorkSpaces with SSD volumes, even if they were created using WorkSpaces with magnetic EBS volumes?', 'Yes. You can use your custom images to launch WorkSpaces with SSD EBS volumes, even if they were created using WorkSpaces with magnetic EBS volumes.'), ('Q: Do I need to provide an AMI build using WorkSpaces with SSD EBS volumes when using my own Windows desktop licenses (BYOL)?', 'No. You can use the AMIs you built as part of the BYOL process without any additional changes. \xa0'), ('Q: How do I deploy applications to my users?', 'You have flexibility in how you deploy the right set of applications to users. First, you choose which image type to build from, either basic or Plus, which determines the default applications that will be in the WorkSpaces. Second, you can install additional software on a WorkSpace and create a custom image which can be used to launch more WorkSpaces. For more detail see the bundle documentation.'), ('Q: Which software can I install on an Amazon WorkSpace?', 'The Amazon WorkSpaces service does not have any technical restrictions on the kind of software that you can install, and any applications that are compatible with the Windows 7 experience provided by Windows Server 2008 R2 should run on your WorkSpaces. We recommend testing any software you would like to deploy on a ‘test’ WorkSpace before delivering it to more users. You are responsible for ensuring that you remain compliant with any licensing restrictions associated with any software you intend to install on a WorkSpace.'), ('Q: Can I increase the size of my Amazon WorSpaces storage volumes? ', 'Yes. You can increase the size of the root and user volumes attached to your WorkSpaces at any time. When you launch new WorkSpaces, you can select a starting size of 80 GB, 175 GB, or your own preferred size, for root volumes, and 10 GB, 50 GB, 100 GB, or your own preferred size, for user volumes. After your WorkSpaces have been launched, you can increase the volumes as necessary, up to 1000 GB each.'), ('Q: Can I decrease the size of storage volumes?', 'No. To ensure that your data is preserved, the volume sizes of either volume cannot be reduced after a WorkSpace is launched. You can launch a Value, Standard, Performance, or Power WorkSpace with a minimum of 80 GB for the root volume and 10 GB for the user volume. You can launch a Graphics WorkSpace with minimum 100 GB for the root volume and 100 GB for the user volume. For more information about configurable storage, see Modifying WorkSpaces.'), ('Q: How do I change the size of my Amazon WorkSpaces storage volumes?', 'You can change the size of your storage volumes via the Amazon WorkSpaces management console, or through the Amazon WorkSpaces API.'), ('Q: Is the storage configuration for a WorkSpace preserved when I rebuild it?', 'Yes, each rebuild preserves your existing storage allocation size.'), ('Q: Can I expand Amazon WorkSpaces magnetic storage volumes?', 'No, configurable storage volumes are only available when using solid state drives (SSD). Any WorkSpaces launched before February 2017 might still use magnetic storage volumes. To switch from magnetic to SSD drives, rebuild your WorkSpaces.'), ('Q: How do custom images affect my root volume size?', 'The root volume size of WorkSpaces launched from a custom image is, by default, the same size as the custom image. For example, if your custom image has a root volume of 100 GB, all WorkSpaces launched from that image also have a root volume size of 100 GB. You can increase your root volume size when you launch your WorkSpace, or any time after that.'), ('Q: Can I expand encrypted volumes?', 'Yes. You can expand encrypted user and root volumes, just like you can for non-encrypted volumes.'), ('Q: Can I access storage volume sizes using the Amazon WorkSpaces API?', 'Yes. The Amazon WorkSpaces API reports both the root and user storage volume sizes via the Describe WorkSpaces API call.'), ('Q: What is the monthly cost for additional storage?', 'For information about pricing, see Amazon WorkSpaces Pricing.\xa0'), ('Q: Can I change my Amazon WorkSpaces bundle without deleting it and creating a new one?', 'Yes. You can switch between Value, Standard, Performance, or Power bundles using the Amazon WorkSpaces management console or the WorkSpaces API. When you switch hardware bundles, your WorkSpaces reboot immediately. When they resume, your operating system, applications, data, and allocated storage on both root and user volumes are all preserved.'), ('For example, you can launch a Standard bundle (2vCPU, 4 GiB), and later expand the volume size on both volumes to 500 GB. You can then switch to the Performance bundle (2vCPU, 7.5 GiB) while preserving your operating system, applications, and data in the expanded volume.', 'Q: How can I track my storage and bundle switch requests?'), ('You can use AWS CloudTrail to track the changes that you have requested.', 'Q: I currently bring my own Windows licenses. Can I expand my storage volumes and switch my WorkSpaces bundles?'), ('Yes. You can take advantage of both these features even if you bring your own Windows desktop licenses. By default, you can only switch WorkSpaces bundles for up to 20% of the total number of your WorkSpaces in a week. To switch more than 20% of your WorkSpaces, contact us.', 'Q: Does a WorkSpace running in AutoStop mode need to be running to apply a change to the bundle type?'), ('No. When you make a change, we start a WorkSpace that isn’t running, apply the bundle change, restart it so that the changes take effect, and then stop it again.', 'For example, you change the bundle type on a stopped Standard (2vCPU, 4 GiB) WorkSpace to Performance. We start your Standard WorkSpace, apply the bundle change, and restart it. Following the restart, your WorkSpace has Performance hardware (2vCPU, 7.5 GiB).'), ('Q: How do I get charged if I change storage size or hardware bundle during a month?', 'For either change, you get charged the monthly price for AlwaysOn and the monthly fee for AutoStop WorkSpaces prorated on a daily basis.'), ('For example, if you increase the volume on the 10th of a month on an AlwaysOn Power WorkSpace with 175 GB, and 100 GB and 200 GB for root and user volumes respectively, you are charged $78 for the Power WorkSpace and $11.6 for 20 days of additional 175 GB at $0.1/GB-month (in US-East-1). Similarly, switching a bundle—for example, from Value to Standard—on the 15th of a month results in 15 days of Value WorkSpaces charge ($12.5 in US-East-1) and 15 days of Standard WorkSpaces charge ($17.5 in US-East-1).', 'Q: How often can I increase volume sizes or change hardware bundle of a WorkSpace?'), ('You can increase volume sizes or change a WorkSpace to a larger hardware bundle once in a 24-hour period. You can also change to a smaller hardware bundle once in a 30-day period.', 'For example, if you increase the root and user volume of a Standard WorkSpace on 5th Dec at 11:00 and change it to Performance WorkSpace at the same time, on 6th Dec at 11:00, you can again increase the root and user volume, and change the hardware bundle. If you change the Performance WorkSpace to a Standard WorkSpace on 6th Dec at 12:00 and want to go to a further smaller bundle (Value), you would be able to make this change on 6th Jan at 12:00.'), ('Q: Does Amazon WorkSpaces offer GPU-enabled cloud desktops?', 'Yes. Amazon WorkSpaces offers Amazon WorkSpaces Graphics bundles, available in English and Japanese.'), ('Q: What are Amazon WorkSpaces Graphics bundles?', 'Amazon WorkSpaces Graphics bundles are Windows Server 2008 R2 based desktops, for a Windows 7 Desktop Experience, or Windows Server 2016 based desktops for a Windows 10 Desktop Experience, and have a full NVIDIA GPU for graphics intensive applications. The Graphics bundle comes with 8vCPUs, 15GiB of RAM, 4GB of video memory, and 100GBs of storage on the user volume and 100 GBs of general purpose persistent root volume.'), ('Q: What kind of GPU is included with Amazon WorkSpaces Graphics bundles?', 'The GPU used in Amazon WorkSpaces Graphics bundles is a high-performance NVIDIA GPU with 1,536 CUDA cores and 4GB of video memory. Each Amazon WorkSpaces Graphics bundle has its own GPU.'), ('Q: When would I use Amazon WorkSpaces Graphics bundles?', 'Amazon WorkSpaces Graphics bundles are designed for engineers and 3D application developers to use as an alternative to expensive graphics-capable workstations. Graphics bundles can be used to run computer-aided design, manufacturing, and engineering software. Additionally, they provide support for OpenGL 4.x, DirectX 10, CUDA, OpenCL, and the GRID SDK for application developers who build 3D capable applications.'), ('Q: Do Amazon WorkSpaces Graphics bundles support a 3D mouse?', 'The Amazon WorkSpaces Graphics bundles do not currently support a 3D mouse.'), ('Q: What kinds of peripherals can I use with my Amazon WorkSpaces Graphics bundles?', 'You can use standard QWERTY and Japanese 106/109 keyboards, and most Bluetooth and USB pointing devices with your Amazon WorkSpaces Graphics bundles. You can expect any peripherals that work with Amazon WorkSpaces Value, Standard, Power, and Performance bundles to also work with Amazon WorkSpaces Graphics bundles.'), ('Q: What is the maximum monitor resolution that I can use with my Amazon WorkSpaces Graphics bundles?', 'Amazon WorkSpaces Graphics bundles support a maximum resolution of 2560x1600, and all VESA compatible resolutions.'), ('Q: How many monitors can I use with my Amazon WorkSpaces Graphics bundles?', 'Currently you can only use a single monitor with your Amazon WorkSpaces Graphics bundles.'), ('Q: In which AWS Regions can I launch Amazon WorkSpaces Graphics bundles?', 'You can launch Graphics bundles in all AWS Regions where Amazon WorkSpaces is available.'), ('Q: Can I create a custom image for my Amazon WorkSpaces Graphics bundles?', 'Yes, you can create a custom image for your Amazon WorkSpaces Graphics bundles. Custom images created from Amazon WorkSpaces Graphics bundles can only be used with Graphics bundles, and custom images created from Value, Standard or Performance bundles can only be used with those bundles.'), ('Q: How do I get started with Amazon WorkSpaces Graphics bundles?', 'You can launch Amazon WorkSpaces Graphics bundles using the Amazon WorkSpaces Management Console, or the Amazon WorkSpaces API. When launching a new Amazon WorkSpace, simply select the Graphics bundle.'), ('Q: Can I enable hybrid IT scenarios with my Amazon WorkSpaces Graphics bundles?', 'Yes. You can integrate your Amazon WorkSpaces Graphics bundles with your on-premises environment just as you would with your existing Amazon WorkSpaces. You can connect your Amazon WorkSpaces Graphics bundles to your on-premises Active Directory using the AWS Directory Service. Once domain-joined to your on-premises Active Directory, you can access files from network file shares, print to network printers, and access intranet web sites and applications.'), ('Q: Which operating systems can I use with Amazon WorkSpaces Graphics bundles?', 'Amazon WorkSpaces Graphics bundles provides users with the Windows 7 desktop experience, running Windows Server 2008 R2. In addition, you can run the Windows 7 Desktop operating system if your organization is eligible to bring their own Windows Desktop license.'), ('Q: How much bandwidth does an Amazon WorkSpaces Graphics bundle consume?', 'Bandwidth used by an Amazon WorkSpaces Graphics bundle depends on the tasks being performed. If there aren’t many changes taking place on the screen, the bandwidth used is generally less than 300 kbps. If there is context switching between multiple windows, or if 3D models are being manipulated, bandwidth use can increase to several megabits per second.'), ('Q: Can I bring my own Windows Desktop licenses for Amazon WorkSpaces Graphics bundles?', 'Yes, you can. Please contact us if this is something you’d like to do.'), ('Q: Can I purchase Amazon WorkSpaces Graphics bundles using the monthly billing option?', 'Yes, you can. Please contact us if this is something you’d like to do. '), ('Q: What are Amazon WorkSpaces Power bundles?', 'Amazon WorkSpaces Power bundles are Windows Server 2008 R2 based desktops, for a Windows 7 Desktop Experience, or Windows Server 2016 based desktops for a Windows 10 Desktop Experience. The Power bundle comes with 4vCPUs, 16GiB of memory, 175GBs of SSD root volume, and 100GBs of SSD user volume.'), ('Q: When would I use Amazon WorkSpaces Power bundles?', 'Amazon WorkSpaces Power bundles are designed for power users such as developers and analysts, who compile code and work with large datasets. If you’re already using the AWS cloud for software development or to store large datasets, Amazon WorkSpaces Power bundles provide a faster end-user experience because your apps stay close to your data.'), ('Q: What is the maximum monitor resolution that I can use with my Amazon WorkSpaces Power bundles?', 'Amazon WorkSpaces Power bundles support a maximum resolution of 4k Ultra HD (3840x2860), and all VESA compatible resolutions, on up to two monitors. When using four monitors, you can use Full HD (1920x1200) resolution. '), ('Q: How many monitors can I use with my Amazon WorkSpaces Power bundles?', 'You can use up to four monitors with your Amazon WorkSpaces Power bundles.'), ('Q: In which AWS Regions can I launch Amazon WorkSpaces Power bundles?', 'You can launch Power bundles in all\xa0AWS Regions\xa0where Amazon WorkSpaces is available.'), ('Q: Can I create a custom image for my Amazon WorkSpaces Power bundles?', 'Yes, you can create a custom image for your Amazon WorkSpaces Power bundles. A Power bundles custom image can only be used with Value, Standard or Performance bundles if the image size is under 80 GB. '), ('Q: How do I get started with Amazon WorkSpaces Power bundles?', 'You can launch Amazon WorkSpaces Power bundles using the Amazon WorkSpaces Management Console, or the Amazon WorkSpaces API. When launching a new Amazon WorkSpace, simply select the Power bundle.'), ('Q: Which operating systems can I use with Amazon WorkSpaces Power bundles?', 'Amazon WorkSpaces Power bundles provide users with a Windows 7 Desktop Experience, running Windows Server 2008 R2, or a Windows 10 Desktop Experience running Windows Server 2016. In addition, you can run the Windows 7 or Windows 10 Desktop operating system if your organization is eligible to bring their own Windows Desktop license. '), (' Q: Can I bring my Windows Desktop licenses to Amazon WorkSpaces?', 'Yes, you can bring your own Windows 7 and Windows 10 Desktop licenses to Amazon WorkSpaces. Amazon WorkSpaces provides you the ability to run on physically dedicated hardware, enabling you to run the Windows 7 or Windows 10 Desktop operating systems on your Amazon WorkSpaces when you are eligible to bring your own licenses.'), ('Q: Can I bring my own Windows Desktop licenses for Amazon WorkSpaces Graphics bundles?', 'Yes, you can. Please contact us if this is something you’d like to do.'), ('Q: What versions of Windows desktop licenses can I bring to Amazon WorkSpaces?', 'If your organization meets the licensing requirements set by Microsoft, you can bring your Windows 7 and Windows 10 Enterprise or Professional licenses to Amazon WorkSpaces. You cannot use Windows OEM licenses for your Amazon WorkSpaces. Please consult with Microsoft if you have any questions about your eligibility to bring your own Windows Desktop licenses.'), ('Q: What benefits are there in bringing my own Windows desktop licenses to Amazon WorkSpaces?', 'By bringing your own Windows Desktop licenses to Amazon WorkSpaces, you will save $4 per Amazon WorkSpace per month when being billed monthly, and you will save money on the hourly usage fee when being billed hourly (see the Amazon WorkSpaces pricing page for more information). Additionally, you can now use a single golden image to manage your physical and virtual desktop deployments.'), ('Q: What are the requirements for bringing my Windows desktop Licenses to Amazon WorkSpaces?', 'You need an active and eligible Microsoft Volume Licensing (VL) agreement with Software Assurance contracts to bring your Windows 7 or Windows 10 Desktop licenses to Amazon WorkSpaces. Please consult with your Microsoft representative to confirm your eligibility in bringing your Windows Desktop licenses to Amazon WorkSpaces.'), ('Q: How do I get started with bringing my Windows desktop licenses to Amazon WorkSpaces?', 'In order to ensure that you have adequate dedicated capacity allocated to your account, please reach out to your AWS account manager or sales representative to get started. Additionally, you can create a Technical Support case with Amazon WorkSpaces to get started with BYOL.'), ('Q: How will I upload my Windows 7 or Windows 10 Desktop image to Amazon WorkSpaces?', 'Please use the VMImport ImportImage function to import your Windows desktop image and create an Amazon Machine Image (AMI). For additional details on importing your Windows desktop image, please consult our documentation here.'), ('Q: How can I launch Amazon WorkSpaces using my Windows 7 or Windows 10 Desktop image?', 'In order for you to launch Amazon WorkSpaces using your Windows 7 or Windows 10 Desktop image, you first have to create a custom bundle with the image you imported. Once the new custom bundle has been created, you can launch WorkSpaces from that bundle through the AWS Management Console or using the WorkSpaces CLI or APIs. You can learn more about launching Amazon WorkSpaces using your own Windows 7 or Windows 10 images here.'), ('Q: How will I activate my Windows 7 or Windows 10 Desktop operating system on Amazon WorkSpaces?', 'You can activate your Windows 7 or Windows 10 Desktop operating system using existing Microsoft activation servers that are hosted in your VPC, or ones that can be reached from the VPC in which Amazon WorkSpaces are launched.'), ('Q: Can I create a new custom image of the Windows 7 or Windows 10 Desktop image uploaded to Amazon WorkSpaces?', 'Yes. You can use the standard Amazon WorkSpaces image management functionality to further customize the Windows 7 or Windows 10 Desktop image and save it as a new Amazon WorkSpace image in your account.'), ('Q: Can I launch Amazon WorkSpaces from a public bundle in the same directory as my Windows 7 or Windows 10 Desktop WorkSpaces?', 'No. Your Windows 7 and Windows 10 Desktop WorkSpaces are launched on physically dedicated hardware to enable you to bring your Windows Desktop licenses to Amazon WorkSpaces. Therefore, WorkSpaces launched in a directory marked for dedicated hardware can only be from a custom bundle that has your own Windows 7 or Windows 10 Desktop image. If you wish to launch WorkSpaces from public bundles to users in the same domain, you can create a new AWS AD Connector directory that points to the same Microsoft Active Directory as your Windows 7 and Windows 10 Desktop WorkSpaces, and launch WorkSpaces in that directory as you normally would through the AWS Management Console or the WorkSpaces SDK and CLI.'), ('Q: Can I bring my Windows desktop licenses to all regions where the Amazon WorkSpaces service is available?', 'Yes. When you communicate with your sales representative or technical support, simply specify the region(s) in which you want to launch Amazon WorkSpaces using your own Windows desktop operating systems.'), ('Q: Would I need to commit to a certain number of Amazon WorkSpaces if I want to bring my own Windows desktop license?', 'Yes, you need to commit to running 200 Amazon WorkSpaces in a region per month on hardware that is dedicated to you.'), ('Q: How long will it take before I can launch Amazon WorkSpaces using my own Windows desktop licenses and image?', 'You should expect to be able to launch Amazon WorkSpaces using your Windows 7 or Windows 10 Desktop operating systems within 4 weeks from when you begin the onboarding process.'), ('Q: Will all of my dedicated Amazon WorkSpaces launch in a single AZ?', 'No. Amazon WorkSpaces launched on dedicated hardware will be balanced across two AZs. You select the AZs for Amazon WorkSpaces when you create the directory in which your Amazon WorkSpaces will be launched, and subsequent launches of Amazon WorkSpaces are automatically load balanced across the AZs selected when you created the directory.'), ('Q: What happens when I terminate Amazon WorkSpaces that are launched on physically dedicated hardware?', 'You can terminate Amazon WorkSpaces when you no longer need them. You will only be billed for the Amazon WorkSpaces that are running.'), ('Q: What happens to Amazon WorkSpaces that are rebuilt or restarted on physically dedicated hardware?', 'Amazon WorkSpaces that are rebuilt or restarted can be placed on any available physical server allocated to your account. A re-start or rebuild of an Amazon WorkSpace can result in that instance being placed on a different physical server that has been allocated to your account. '), ('Q: Is Amazon WorkSpaces HIPAA eligible?', 'Yes. If you have an executed Business Associate Agreement (BAA) with AWS, you can use Amazon WorkSpaces with the AWS accounts associated with your BAA. If you don’t have an executed BAA with AWS,\xa0contact us\xa0and we will put you in touch with a representative from our AWS sales team. For more information, see,\xa0HIPAA Compliance.'), ('Q: Is Amazon WorkSpaces PCI compliant?', 'Yes. Amazon WorkSpaces is PCI compliant and conforms to the Payment Card Industry Data Security Standard (PCI DSS). PCI DSS is a proprietary information security standard administered by the PCI Security Standards Council, which was founded by American Express, Discover Financial Services, JCB International, MasterCard Worldwide and Visa Inc.'), ('PCI DSS applies to all entities that store, process or transmit cardholder data (CHD) and/or sensitive authentication data (SAD) including merchants, processors, acquirers, issuers, and service providers. The PCI DSS is mandated by the card brands and administered by the Payment Card Industry Security Standards Council. For more information, see PCI DSS Compliance.', 'Q: Which credentials should be used to sign in to Amazon WorkSpaces?'), ('Users sign into their WorkSpace using their own unique credentials, which they can create after a WorkSpace has been provisioned for them. If you have integrated the Amazon WorkSpaces service with an existing Active Directory domain, users will sign in with their regular Active Directory credentials. Amazon WorkSpaces also integrates with your existing RADIUS server to enable multi-factor authentication (MFA).', 'Q: Can I control the client devices that access my Amazon WorkSpaces?'), ('Yes. You can restrict access to Amazon WorkSpaces based on the client OS type, and using digital certificates. You can choose to block or allow MacOS, Microsoft Windows, iOS, Android, Chrome OS, zero client, and the WorkSpaces Web Access client.', 'Q: What is a digital certificate?'), ('A digital certificate is a digital form of identity that is valid for a specified period of time, which is used as a credential that provides information about the identity of an entity, as well as other supporting information. A digital certificate is issued by a certificate authority (CA), and the CA guarantees the validity of the information in the certificate.', 'Q: What devices use digital certificates to control access to Amazon WorkSpaces?'), ('Digital certificates can be used to block or allow WorkSpaces access from MacOS and Microsoft Windows client devices.', 'Q: How do I use digital certificates to control access to Amazon WorkSpaces?'), ('To use digital certificates to block or allow access to Amazon WorkSpaces, you upload your root certificates to the WorkSpaces management console and distribute your client certificates to the macOS and Windows devices you want to trust. To distribute your client certificates, use your preferred solution such as Microsoft System Center Configuration Manager (SCCM), or Mobile-Device Management (MDM) software. For more information, see\xa0Restrict WorkSpaces Access to Trusted Devices.', 'Q: How many root certificates can be imported to an Amazon WorkSpaces directory?'), ('For each Amazon WorkSpaces directory, you can import up to two root certificates each for MacOS and Microsoft Windows devices. If two root certificates are imported, WorkSpaces will present both root certificates to the client device, and the client device will use the first certificate that chains up to either root certificate.', 'Q: Can I control client device access to Amazon WorkSpaces without using digital certificates?'), ('Yes. You can control access to Amazon WorkSpaces using the device type only.', 'Q: Can I use digital certificates to control Amazon WorkSpaces access from iOS, Android, Chrome OS, or zero clients?'), ('At this time Amazon WorkSpaces can use digital certificates only with MacOS and Microsoft Windows client devices.', 'Q: What is Multi-Factor Authentication (MFA)?'), ('Multi-Factor Authentication adds an additional layer of security during the authentication process. Users must validate their identity by providing something they know (e.g. password), as well as something they have (e.g. hardware or software generated one-time password (OTP).', 'Q: What delivery methods are supported for MFA?'), ('Amazon supports one time passwords that are delivered via hardware and software tokens. Out of band tokens, such as SMS tokens are not currently supported.', 'Q: Is there support for Google Authenticator and other virtual MFA solutions?'), ('Google Authenticator can be used in conjunction with RADIUS. If you are running a Linux-based RADIUS server, you can configure your RADIUS fleet to use Google Authenticator through a PAM (Pluggable Authentication Module) library. MFA solutions based on the TOTP (Time-based One-time Password) protocol are not currently supported.', 'Q: Which Amazon WorkSpaces client applications support Multi-Factor Authentication (MFA)?'), ('MFA is available for Amazon WorkSpaces client applications on the following platforms - Windows, Mac OS X, Chromebooks, iOS, Fire, Android, and PCoIP Zero Clients. MFA is also supported when using Web Access to access Amazon WorkSpaces through Chrome or Firefox web browsers.  Q: What happens if a user forgets the password to access their Amazon WorkSpace?', 'If either AD Connector or AWS Microsoft AD is used to integrate with an existing Active Directory domain, the user would follow your existing lost password process for your domain, such as contacting an internal helpdesk. If the user is using credentials stored in a directory managed by the WorkSpaces service, they can reset their password by clicking on the “Forgot Password” link in the Amazon WorkSpaces client application. '), ('Q: How will Amazon WorkSpaces be protected from malware and viruses?', 'You can install your choice of anti-virus software on your users’ WorkSpaces. The Plus bundle options offer users access to anti-virus software, and you can find more details on this here. If you choose to install your own anti-virus software, please ensure that it does not block UDP port 4172, as this will prevent users connecting to their WorkSpaces.'), ('Q: How do I remove a user’s access to their Amazon WorkSpace?', 'To remove a user’s access to their WorkSpace, you can disable their account either in the directory managed by the WorkSpaces service, or in an existing Active Directory that you have integrated the WorkSpaces service with.'), ('Q: Does WorkSpaces work with AWS Identity and Access Management (IAM)?', 'Yes. Please see our documentation.'), ('Q: Can I select the Organizational Unit (OU) where computer accounts for my WorkSpaces will be created in my Active Directory?', 'Yes. You can set a default Organizational Unit (OU) in which computer accounts for your WorkSpaces are created in your Active Directory. This OU can be part of the domain to which your users belong, or part of a domain that has a trust relationship with the domain to which your users belong, or part of a child domain in your directory. Please see our documentation for more details.'), ('Q: Can I use Amazon VPC Security groups to limit access to resources (applications, databases) in my network or on the Internet from my WorkSpaces?', 'Yes. You can use Amazon VPC Security groups to limit access to resources in your network or the Internet from your WorkSpaces. You can select a default Amazon VPC Security Group for the WorkSpaces network interfaces in your VPC as part of the directory details on the WorkSpaces console. Please see our documentation for more details. '), ('Q: Does Amazon WorkSpaces support encryption?', 'Yes. Amazon WorkSpaces supports root volume (C: drive) and user volume (D: drive) encryption. Amazon WorkSpaces uses EBS volumes that can be encrypted on creation of a WorkSpace, providing encryption for data stored at rest, disk I/O to the volume, and snapshots created from the volume. Amazon WorkSpaces integrates with the AWS KMS service to allow you to specify the keys you want to use to encrypt the volumes.'), ('Q: Which Amazon WorkSpace bundle types will support encryption?', 'Encryption is supported on all Amazon WorkSpaces hardware and software bundle types. This includes both Windows 7 and Windows 10 desktop experiences, and the Value, Standard, Performance, Power, and Graphics bundles. It also includes all Plus application bundles. Additionally, any custom bundles will also support encryption. '), ('Q: How can I encrypt a new Amazon WorkSpace?', 'When creating a new Amazon WorkSpace from the console or the Amazon WorkSpaces APIs, you will have the option to specify which volume(s) you want encrypted along with a key ARN from your KMS keys for encryption. Note that during the launch of a WorkSpace, you can specify whether you want encryption for the user volume, root volume or both volumes, and the key provided will be used to encrypt the volumes specified.'), ('Q: Can I use different keys to encrypt the root and user volumes of a WorkSpace?', 'The root and user volumes are encrypted using a single key.'), ('Q: Do I need to provide a new KMS key for each WorkSpace that I want to encrypt?', 'You can use the same KMS key to encrypt the volumes of up to 500 Amazon WorkSpaces.'), ('Q: Can Amazon WorkSpaces create a KMS key on my behalf?', 'Amazon WorkSpaces creates a default master key upon your first attempt to launch a WorkSpace through the AWS Management Console. You cannot manage the lifecycle of default master keys. To control the full lifecycle of a key, configure WorkSpaces to use a KMS custom customer master key (CMK). To create a KMS custom CMK, visit the KMS console or use KMS APIs to create your own keys. Note that you can use a default key generated by KMS for your WorkSpaces which will be made available to you on your first attempt to launch Amazon WorkSpaces with encryption through the AWS Management Console.'), ('Q: What are the prerequisites for using KMS keys to encrypt Amazon WorkSpaces?', 'In order to use KMS keys to encrypt Amazon WorkSpaces, the key must not be disabled, and should not have exceeded its limits (learn more about limits here). You also need to have the correct permissions and policies associated with the key to use it for encryption. To learn more about the correct permissions and policies needed on the keys, please refer to our documentation here.'), ('Q: How will I be notified if my KMS key does not meet the pre-requisites outlined above?', 'When you launch a new WorkSpace with the key specified, the WorkSpaces service will verify if the key is valid and eligible to be used for encryption. If the key is not valid, the launch process will fail quickly and notify you of the error associated with the key. Please note that if you change the key settings while the WorkSpace is being created, there is a chance that provisioning will fail and you will be notified of this failure through the AWS Management Console or through the DescribeWorkSpaces API call.'), ('Q: How will I be able to tell which Amazon WorkSpaces are encrypted and which ones are not?', 'You will be able to see if a WorkSpace is encrypted or not from the AWS Management Console or using the Amazon WorkSpaces API. In addition to that, you will also be able to tell which volume(s) on the WorkSpace were encrypted, and the key ARN that was used to encrypt the WorkSpace. For example, the DescribeWorkSpaces API call will return information about which volumes (user and/or root) are encrypted and the key ARN that was used to encrypt the WorkSpace.'), ('Q: Can I enable encryption of volumes on a running Amazon WorkSpace?', 'Encryption of WorkSpaces is only supported during the creation and launch of a WorkSpace.'), ('Q: What happens to a running Amazon WorkSpace when I disable the key in the KMS console?', 'A running WorkSpace will not be impacted if you disable the KMS key that was used to encrypt the user volume of the WorkSpace. Users will be able to login and use the WorkSpace without interruption. However, restarts and rebuilds of WorkSpaces that were encrypted using a KMS key that has been disabled (or the permissions/policies on the key have been modified) will fail. If the key is re-enabled and/or the correct permissions/policies are restored, restarts and rebuilds of the WorkSpace will work again.'), ('Q: Is it possible to disable encryption for a running Amazon WorkSpace?', 'Amazon WorkSpaces does not support disabling encryption for a running WorkSpace. Once a WorkSpace is launched with encryption enabled, it will always remain encrypted.'), ('Q: Will snapshots of an encrypted user volume also be encrypted?', 'Yes. All snapshots of the user volume will be encrypted using the same key that was used to encrypt the user volume of the WorkSpace when it was created. The user volume once encrypted stays encrypted throughout its lifecycle. Please note that Amazon WorkSpaces does not take snapshots of the root volume of a running WorkSpace.'), ('Q: Can I re-build an Amazon WorkSpace that has been encrypted?', 'Yes. Rebuilds of a WorkSpace will work as long as the key that was used to encrypt the WorkSpace is still valid. The WorkSpace volume(s) stay encrypted using the original key after it has been rebuilt.'), ('Q: Can I create a custom image from a WorkSpace that has been encrypted?', 'Creating a custom image from a WorkSpace that is encrypted is not supported.'), ('Q: Will the performance of my WorkSpace be impacted because the volume(s) are encrypted?', 'You can expect a minimum increase in latency on IOPS on encrypted volumes.'), ('Q: Will encryption impact the launch time of an Amazon WorkSpace?', 'The launch time of a WorkSpace that only requires user volume encryption are similar to those of an unencrypted WorkSpace. The launch time of a WorkSpace that requires root volume encrypt will take several more minutes.'), ('Q: Will encryption be supported for BYOL WorkSpaces?', 'Yes. Amazon WorkSpaces will support encryption for BYOL WorkSpaces.'), ('Q: Will I be able to use the same KMS key to encrypt Amazon WorkSpaces in a different region?', 'No. Encrypted resources in one region cannot be used in a different region, because a KMS key belongs to the region in which it was created.'), ('Q: Is there a charge for encrypting volumes on Amazon WorkSpaces?', 'There is no additional charge for encrypting volumes on WorkSpaces, however you will have to pay standard AWS KMS charges for KMS API requests and any custom CMKs that are used to encrypt WorkSpaces. Please see AWS KMS pricing here. Please note that the Amazon WorkSpaces services makes a maximum of five API calls to the KMS service upon launching, restarting or rebuilding a single WorkSpace.'), ('Q: Can I rotate my KMS keys?', 'Yes. You can use KMS to rotate your custom CMKs. You can configure a custom CMK that you create to be automatically rotated by KMS on an annual basis. There is no impact to WorkSpaces encrypted before the CMK rotation, they will work as expected. '), ('Q: What is the Amazon\xa0WorkDocs sync client?', 'The Amazon WorkDocs sync client is a client application that you can install on your Amazon WorkSpace, which continuously, automatically, and securely syncs documents from your Amazon WorkSpace to your Amazon WorkDocs location. You can also install the Amazon WorkDocs sync client on a Mac or PC to sync documents across all desktops they may be using. When an Amazon WorkSpace is launched, users will have a link on their desktop so that they can install the Amazon WorkDocs sync client. The client can be downloaded here.'), ('Q: Can I enable or disable Amazon WorkDocs sync for a user’s Amazon WorkSpace?', 'When you create a directory, or use AD Connector to integrate with an existing Active Directory, you can choose to enable or disable Amazon WorkDocs sync for that directory. Currently you cannot enable or disable Amazon WorkDocs sync on a per-user basis.'), ('Q: How do I synchronize documents between an Amazon WorkSpace and a Mac or Windows PC?', 'To enable synchronization, all you need to do is install the Amazon WorkDocs sync client on your Amazon WorkSpace and PCs you would like to synchronize with. Once you’ve done this, simply select the folders you want to sync.'), ('Q: Is Single Sign-On (SSO) supported?', 'Yes. Single Sign-On (SSO) can be enabled so that when users are signed in to their Amazon WorkSpace they will be automatically signed in to their Amazon WorkDocs sync client, and will not be required to provide credentials when they access the web client from their Amazon WorkSpace. You can enable SSO by visiting the AWS Directory Service area of the AWS Management Console, clicking the directory ID link for your directory and selecting the Apps & Services tab. For more information and detailed setup see our documentation. '), ('Q: What is Amazon WorkSpaces Application Manager? ', 'Amazon WorkSpaces Application Manager (Amazon WAM) offers a fast, flexible, and secure way for you to deploy and manage applications for Amazon WorkSpaces. Amazon WAM accelerates software deployment, upgrades, patching, and retirement by packaging Microsoft Windows desktop applications into virtualized application containers that run as though they are natively installed.'), ('Q: How are Amazon WAM applications delivered to users?', "Amazon WAM delivers desktop apps to users' WorkSpaces as virtualized app containers using a unique cloud delivery technology. The applications execute on a WorkSpace from within the virtualized container and provide performance similar to natively-installed applications."), ('Q: How can I get started with Amazon WAM?', 'To get started with Amazon WAM, select your level of subscription (Lite or Standard,) build an application catalog in the AWS Management Console and assign applications to your Amazon WorkSpaces users. You can build an application catalog using applications for which you own licenses, proprietary applications built in-house, and applications from the AWS Marketplace for Desktop Apps.'), ('After your catalog is available, you can use the AWS Management Console to assign applications from the catalog to your Amazon WorkSpaces users. Applications from the catalog can be made required or optional. Required applications are automatically installed on the appropriate WorkSpaces; optional applications are made available to users for on-demand installation.', 'Q: How do I upload my applications to Amazon WAM?'), ('You can package your applications using the Amazon WAM Studio, validate using the Amazon WAM Player, and then upload your applications to Amazon WAM. For more information, see the Amazon WAM User Guide on packaging and validating.', 'Q: What type of applications can be delivered using Amazon WAM?'), ('Any application compatible with Microsoft Windows 7, Microsoft Windows 8, Microsoft Windows Server 2008 R2, and Microsoft Windows Server 2012 can be delivered to WorkSpaces using Amazon WAM. Both 32-bit and 64-bit applications are supported.', 'Q: Can I track application use with Amazon WAM?'), ('You can track usage for any applications assigned to users.', 'Q: In which AWS regions is Amazon WAM available?'), ('Amazon WAM is currently available in the US East (N. Virginia), US West (Oregon), EU (Ireland), Asia Pacific (Sydney), and Asia Pacific (Singapore) AWS regions.', 'Q: Which Amazon WorkSpaces experiences work with Amazon WAM?'), ('Today you can use Amazon WAM to deploy and manage applications for Amazon WorkSpaces running the Windows 7 desktop experience. Support for Amazon WorkSpaces running the Windows 10 desktop experience will be added at a later time. ', 'Q. Which AWS Directory Service directories does Amazon WAM support?'), ('Amazon WAM can be used with AWS Directory Services AD Connector and Simple AD. Currently WAM cannot be used with AWS Directory Service\xa0Microsoft Active Directory.', 'Q: Do Amazon WorkSpaces need Internet access to use Amazon WAM?'), ('Yes, Amazon WorkSpaces need an Internet connection to receive applications via Amazon WAM.', 'Q: How do I get Amazon WAM on my users’ Amazon WorkSpaces?'), ('Your users can install the Amazon WAM desktop app on their Amazon WorkSpaces via a shortcut located on the desktop by default.', 'Q: How do end users access applications that are assigned using Amazon WAM?'), ("Users can open the Amazon WAM desktop app and see all the applications available to them. You can set up applications to be required or optional. Required applications are automatically installed on user's WorkSpace, and optional applications can be installed via the Amazon WAM desktop app. For more information about the Amazon WAM desktop app, see the Amazon WAM User Guide.", 'Q: How many applications can I add to my Amazon WAM catalog?'), ('There is no limit to the number of applications you can add to your Amazon WAM catalog. However, storage charges apply to applications that you upload to Amazon WAM, after the first 100 GB of storage used for your applications.', 'Q: How many applications can I deliver to each Amazon WorkSpaces user via Amazon WAM?'), ('You can assign up to 50 applications to each Amazon WorkSpaces user.', 'Q: Can I use tags to categorize applications in my Amazon WAM catalogs?'), ('Yes, you can assign tags to applications and service-related charges for WAM by simply tagging your Amazon WorkSpaces. To learn more about assigning tags to your Amazon WorkSpaces, follow the steps listed on this web page: Tagging WorkSpaces.', 'Q: How will I be billed for Amazon WAM?'), ('The Lite plan is available at no cost, and the Standard plan costs $5/user/month for each user enrolled in the WAM Standard plan with one or more applications assigned. There may be a cost for applications from AWS Marketplace for Desktop Applications that users activate.', 'Q: Can I have users on both the Lite and the Standard plans?'), ('No. You can subscribe to either the Lite or Standard plan, and all users will be on the same plan.', 'Q: Can I change my subscription plan during the billing period?'), ('Yes. On the “Subscription plan” page” of the WAM console you can upgrade or downgrade your plan and view the feature details for the two subscription plans. You have the opportunity to view the current usage before confirming the upgrade.', 'Q: What will happen to my applications if I downgrade from the Standard to the Lite plan?'), ('Users will be moved to the most up to date version of applications from AWS Marketplace for Desktop Apps, and will lose access to any applications that you packaged and uploaded to Amazon WAM.', 'Q: Is there a limit for storage of my app packages?'), ('Both the Lite and Standard plans include 100GB of storage for the apps, and S3 charges will apply for additional storage.', 'Q: Can I share an Amazon WAM package with another AWS account?'), ('Yes. Packages created and approved by you within your AWS account can be shared with other AWS accounts in the same region. You can set up package sharing via the Packages tab on the Amazon WAM console by adding package permissions to the AWS account to which you wish to share the package.', 'Q: Can I set limits on the packages that I share with other AWS accounts?'), ('No. At this time, you cannot place any restrictions on packages that are shared.', 'Q: How do I use an Amazon WAM package that is shared with me?'), ('You can use an Amazon WAM package shared with you by creating an application and assigning the application to your users.', 'Q: Can I make any changes to a package that has been shared with my account?'), ('No. A package made available to you by another AWS account cannot be modified.', 'Q: How do I know if I can trust a package that has been shared with my account?'), ('Always verify that your package is shared from a trusted source. Verify the source by validating the AWS account ID and check if it is an account that you trust.', 'Q: Can I delete an Amazon WAM package?'), ('Yes. You can delete an Amazon WAM package that belongs to your account within an AWS region by launching Amazon WAM Studio in your packaging instance. Once you delete a package, all versions of the package will be deleted. Also, you can only delete packages that don’t have apps assigned or have not been shared with another AWS account. If you have an application created, you will first need to delete the application before you can delete the package. If you have shared a package with another AWS account, you will first need to remove sharing of the package before deleting the package.', 'Q: What happens to an Amazon WAM package once it is deleted?'), ('Once an Amazon WAM package is deleted, it will no longer be available from within your account. The package will be fully deleted once any accounts you shared the package with have deleted applications using the package. ', 'Q: What is AWS Marketplace for Desktop Apps? '), ('AWS Marketplace for Desktop Apps is a new category in the AWS Marketplace that can deploy applications to Amazon WorkSpaces through Amazon WAM. The AWS Marketplace for Desktop Apps includes both applications you can purchase on a monthly basis and free apps. You can find applications from developers such as Microsoft, Corel and Foxit and popular open source titles.', 'Q: How do I use desktop applications from AWS Marketplace?'), ('You can subscribe to applications from the AWS Marketplace for Desktop Apps via Amazon WorkSpaces console. Start by selecting the Application Catalog in Amazon WorkSpaces console, browse and add applications from the AWS Marketplace to your application catalog. Once the applications are in your catalog you can assign the applications to your WorkSpaces users. The applications can then be accessed by users via the Amazon WorkSpaces Application Manager (Amazon WAM) desktop app.', 'Q: How will I be charged for applications from the AWS Marketplace for Desktop Apps?'), ('You will be charged the price listed on AWS Marketplace for Desktop Apps for each application on a monthly subscription basis. Software subscriptions are billed monthly, even if they are used on Amazon WorkSpaces set to bill hourly. A subscription is activated and charged the first time a user launches an application and will renew monthly until access to the application is removed for that user. Charges for an application are prorated for the remainder of the first month in which a user launches them. Subsequent months are billed for the entire month. Subscriptions that are removed in the middle of a month will not receive a refund for the remainder of the month.  ', 'Q: How do I unsubscribe from an application?'), ('To unsubscribe from an application, simply remove the users and groups assigned to use the application. Once this is completed, the application will immediately not be available to your users and there will be no new charges for the application in the following month.', 'Q: Can Amazon WorkSpaces end users access the AWS Marketplace for Desktop Apps directly?'), ('No, only the administrator of the WorkSpaces account will see the entire AWS Marketplace in the WorkSpaces console. End users will only see the applications you provisioned for them.', 'Q: Where can I view charges for my application subscriptions from AWS Marketplace for Desktop Apps?'), ('You can view the charges for application subscriptions from AWS Marketplace for Desktop Apps by signing in to the AWS billing console and viewing the AWS Marketplace section in the estimate bill. You can view the applications subscribed, monthly price, and total charge for each application.', 'Q: How do I get support for the applications I use from AWS Marketplace for Desktop Apps?'), ('After subscribing to the application on AWS Marketplace for Desktop Apps, you can select the application details to view support information. Expand the support information to view details on how to obtain support. ', 'Q: Where can I download the Amazon WorkSpaces client application?'), ('A: You can download the Amazon WorkSpaces client application for free on the client download website.', 'Q: Can I use any other client (e.g., an RDP client) with Amazon\xa0WorkSpaces?'), ('No. You can use any of the free clients provided by AWS, which includes client applications for Windows, Mac OS X, Chromebooks, iOS, Fire tablets, and Android tablets, or Chrome or Firefox web browsers, to access your Amazon WorkSpaces. ', 'Q: Which operating systems are supported by the Amazon WorkSpaces client applications?'), ('Amazon WorkSpaces clients are available for the following operating systems:', 'Q: Which tablet devices are supported by the Amazon WorkSpaces client application?'), ('Amazon WorkSpaces clients are available for the following devices:', 'While we expect other popular Android tablets running Android version 4.4 to work correctly with the Amazon WorkSpaces client, there may be some that are not compatible. If you are interested in support for a particular device, please let us know via the Amazon WorkSpaces forum.'), ('Q: Which smartphones are supported by the Amazon WorkSpaces client application?', 'Amazon WorkSpaces clients are available for the following devices:'), ('Samsung Galaxy S8 and S8+ with Samsung DeX Station', 'If you are interested in support for a particular device, please let us know via the Amazon WorkSpaces forum.'), ('Q: What is a PCoIP Zero Client?', 'A PC-over-IP (PCoIP)\xa0Zero Client is a single-purpose hardware device that can enable access to Amazon WorkSpaces. Zero Clients include hardware optimization specifically for the PCoIP protocol, and are designed to require very little administration.'), ('Q: Can I use PCoIP Zero Clients with Amazon WorkSpaces?', 'Yes, Amazon WorkSpaces supports PCoIP Zero Client devices that have the Teradici Tera2 chipset. For a complete list of Zero Clients that are compatible with Amazon WorkSpaces please visit the device finder here (site hosted by Teradici). '), ('Q: Will my Amazon WorkSpace running in AutoStop running mode preserve the state of applications and data when it stops?', 'Yes. Because AutoStop causes your Amazon WorkSpace to stop, the state of your applications and data will be preserved. When you next connect, your Amazon WorkSpace will resume with all open documents and running programs intact.'), ('Q: How do I resume my Amazon WorkSpace after it stops?', 'By logging into your Amazon WorkSpace from the Amazon WorkSpaces client application, the service will automatically restart your Amazon WorkSpace. When you first attempt to log in, the client application will notify you that your Amazon WorKSpace was previously stopped, and that your new session will start once your WorkSpace has resumed. '), ('Q: How long does it take for my Amazon WorkSpace to be available once I attempt to log in?', 'If your Amazon WorkSpace has not yet stopped, your connection is almost instantaneous. If you Amazon WorkSpace has already stopped, in most cases it will be available within sixty to ninety seconds. '), ('Q: Which peripherals can be used with the Amazon WorkSpaces client applications?', 'Amazon WorkSpaces clients support:'), ('Q: What kind of headsets can be used for audio conversations?', 'Most analog and USB headsets will work for audio conversations through WorkSpaces. For USB headsets, you should ensure they show up as a playback device locally on your client computer.'), ('Q: Can I use the built in microphone and speakers for making audio calls?', 'Yes. For the best experience, we recommend using a headset for audio calls. However, you may experience an echo when using the built in microphone and speakers with certain communication applications.'), ('Q: Does Audio-in work with mobile clients such as Android, iOS, and Chromebooks?', 'Audio-in is supported on the Windows, OSX and iOS clients.'), ('Q: How do I enable Audio-in for my WorkSpaces?', 'Audio-in is enabled for all new WorkSpaces launches. For existing WorkSpaces, Audio-in can be enabled with a reboot. Enabling the WorkSpaces Audio-in capability requires local logon access inside your WorkSpace. If you have a Group Policy restricting user local logon in your WorkSpace, we will detect it and not apply the Audio-in update to the WorkSpace. You can remove the Group Policy and the Audio-in capability will be enabled after the next reboot.'), ('Q: Should I update my custom images to take advantage of Audio-in?', 'Yes. We always recommend you refresh your custom images on a regular basis to take advantage of the latest features. WorkSpaces launching from custom images that have not been recently updated may take longer to be available to users. Once a WorkSpace is updated for Audio-In you can use it to create an updated custom image which will include Audio-in support by default.'), ('Q: Does WorkSpaces support devices with high DPI screens?', 'Yes. The Amazon WorkSpaces desktop client application will automatically scale the in-session display to match the DPI settings of the local device. If desired, it is possible to override the automatic settings by manually selecting a DPI configuration within Windows in an Amazon WorkSpace.'), ('Q: How many monitors does Amazon WorkSpaces support?', 'Amazon WorkSpaces supports up to four monitors when accessing your WorkSpace from a Windows or MacOS computer. The Amazon WorkSpaces client application extracts the EDID (extended display identification data) of all attached displays and sends that to Amazon WorkSpaces to find the best compatibility match before initiating a session.'), ('Q: Which Amazon WorkSpaces bundles allow me to use four monitors?', 'You can use four monitors with the Value, Standard, Performance, and Power bundles.\xa0Four monitor support is not available for Graphics bundles.'), ('Q: What is the maximum resolution supported for each monitor?', 'Amazon WorkSpaces supports 4K Ultra HD (3840x2160) resolution on up to two monitors, and Full HD (1920x1200) resolution on up to four monitors.'), ('Q: Which Amazon WorkSpaces bundles support 4K Ultra HD resolution on up to two monitors?', '4K Ultra HD resolutions is available on the Value, Standard, Performance, and Power bundles. 4K Ultra HD resolution is not available for Graphics bundles.'), ('Q: Will my bandwidth usage be higher when I use four monitors, or I use 4k Ultra HD resolution?', 'Yes. The bandwidth requirements for WorkSpaces depends on two factors (a) the number of screens it has to stream to and (b) the amount of pixel changes taking place in each screen.'), ('Q: Can each monitor have a different resolution?', 'Yes. As long as each monitor supports a VESA compatible resolution, Amazon WorkSpaces will be able to adequately stream to monitors of different resolutions attached to the same local device.'), ('Q: Can each monitor have different orientation?', 'Yes. You can have some of your monitors in landscape mode and others in portrait mode to suit your desktop productivity needs.'), ('Q:Will Amazon WorkSpaces remember my monitor settings between sessions?', 'The Fullscreen mode setting will be preserved. If you quit a WorkSpaces session in the fullscreen mode, you will be able to log into the fullscreen mode next time. However, display configurations will not be saved. Every time you initiate a WorkSpaces session, the client application extracts the EDID of uses your local setup configuration and sends that to the WorkSpaces host to deliver an optimal display experience.'), ('Q: What happens when I connect to my WorkSpace from a different desktop?', 'When you connect from a different desktop computer, the display settings of that computer will take precedence to deliver an optimal display experience.'), ('Q: Will the iPad and Android applications support Keyboard/Mouse input?', 'The iPad client supports keyboard input, and the Android client supports both keyboard and mouse input. While we expect most popular keyboard and mouse devices to work correctly, there may be devices that may not be compatible. If you are interested in support for a particular device, please let us know via the Amazon WorkSpaces forum.'), ('Q: Can I access my Amazon WorkSpaces through a web browser?', 'Yes, you can use Amazon WorkSpaces Web Access to log in to your Amazon WorkSpace through Chrome or Firefox web browsers. You do not need to install any software, and you can connect from any network that can access the public Internet. Web Access can be accessed here.'), ('Q: What is Amazon WorkSpaces Web Access?', 'Amazon WorkSpaces Web Access allows you to access your Amazon WorkSpace from Chrome or Firefox running on a computer connected to any network that can access the public Internet. Web Access does not exclude users from using native Amazon WorkSpaces client applications to connect to their WorkSpaces; users can choose between Web Access and native client applications. Web Access is available here.'), ('Q: Which web browsers can I use to access Amazon WorkSpaces Web Access?', 'Amazon WorkSpaces Web Access works with Google Chrome version 53 and higher, and Firefox version 49 and higher, running on Windows, Mac, or Linux. Mobile versions of Chrome and Firefox are not currently supported.'), ('Q: Can I enable Web Access for Non-English based Amazon WorkSpaces?', 'No. Web Access support is only available on WorkSpaces with English based Windows. You can install language packs onto English based WorkSpaces and have Web Access support. However, WorkSpaces with Windows based on other languages will not have Web Access support through you can still use native clients to access those WorkSpaces.'), ('Q: Do I need to install any additional software in order to access my Amazon WorkSpaces through a web browser?', 'No, you do not need to install any programs, add-ins, or plugins in order to access your Amazon WorkSpaces through a supported web browser.'), ('Q: How do I get started using Web Access to log in to my Amazon WorkSpaces?', 'First, your Amazon WorkSpace needs to be enabled for web access. This can be done through the AWS Management Console by your IT administrator. Once this is complete, you can log in using Web Access, which is available here. The first time you log in, you will be asked to enter the registration code that was provided in your welcome email.'), ('Q: How will I know if my Amazon WorkSpace has been enabled for web access?', 'If your Amazon WorkSpace has been set to block web access, you will receive an error message when you attempt to log in, informing you to contact your system administrator to enable web access.'), ('Q. Can I use Web Access to access my Amazon WorkSpaces on any network?', 'Yes. You can use Web Access on any network that can access the public Internet. If you can browse the web, then you can connect to your Amazon WorkSpace.'), ('Q: Which Amazon WorkSpaces bundles can be accessed using Web Access?', 'You can use Web Access to connect to the Value, Standard, Performance, and Power Amazon WorkSpaces bundles running Windows 7 or Windows Server 2008 R2 operating systems. Please note using Web Access to access Amazon WorkSpaces Graphics bundles, or bundles running Windows 10 or Windows Server 2016 operating systems is not currently supported. '), ('Q: Which Amazon WorkSpaces operating systems can be accessed using Web Access?', 'Web Access can be used to connect to Amazon WorkSpaces running Windows 7 or Windows Server 2008 R2.'), ('Q: What local devices can I use when connecting to my Amazon WorkSpace through Chrome or Firefox?', 'You will be able to use your mouse and keyboard as input devices. Local peripheral devices—including printers, USB drives, webcams, and microphones—will not be available. Though clipboard redirection will not work across your local operating system and your Amazon WorkSpace, copy and paste operations within your WorkSpace will work.'), ('Q: In which regions is Web Access available?', 'Amazon WorkSpaces Web Access is available in all regions where you can provision Amazon WorkSpaces. For the complete list, please visit this page.'), ('Q: Do I need to enter a registration code to use Web Access?', 'The first time you log in using Web Access, you will be asked to enter the registration code that was provided in your welcome email. At the moment, Web Access does not offer the ability to store multiple different registration codes.'), ('Q: When using a web browser to access my Amazon WorkSpace, how can I control my session?', 'You can use the connection bar along the top of your browser window to control your session. The connection bar allows you to disconnect, enter and exit full screen mode, and send a “Ctrl-Alt-Del” key sequence to the Amazon WorkSpace. It can be pinned in place, or set to hide automatically.'), ('Q: How do I disconnect from my Amazon WorkSpace when accessing it through a web browser?', 'You can disconnect using the “Disconnect” command in the connection bar, by closing the browser tab, or by quitting the browser program. Web Access does not support reconnecting to your Amazon WorkSpace - you must log in again to reconnect.'), ('Q. Will Amazon WorkSpaces support additional client devices and virtual desktop operating systems?', "We continually review our roadmap to see what features we can add to address our customers' requirements. If there is a client device or virtual desktop operating system that you'd like Amazon WorkSpaces to support, please email us with details of your request."), ('Q: What is the end user experience when Multi-Factor Authentication (MFA) is enabled?', 'Users will be prompted for their Active Directory username and password, followed by their OTP. Once a user passes both Active Directory and RADIUS validation, they will be logged in to their Amazon WorkSpace. To learn more, visit our documentation.'), ('Q: How can I determine the best region to run my Amazon WorkSpaces?', 'The Amazon WorkSpaces Connection Health Check Website compares your connection speed to each Amazon WorkSpaces region and recommends the fastest one.'), ('Q: What languages are supported by Amazon WorkSpaces?', 'Amazon WorkSpaces bundles that provide the Windows 7 and Windows 10 desktop experience currently support English (US) and Japanese. You can also download and install language packs for Windows directly from Microsoft. For more information, visit this page. Amazon WorkSpaces client applications currently support English (US), German, Chinese (Simplified), Japanese, French Canadian, Korean, and Portuguese.'), ('Q: Does the Amazon WorkSpaces service have maintenance windows?', 'Yes. For AlwaysOn (monthly) WorkSpaces the current maintenance window is a four hour period from 00h00 – 04h00 (this time window will be based on the time zone of the AWS region where your Amazon WorkSpaces are located) each Sunday morning. During this time your WorkSpaces may not be available.'), ('For AutoStop (hourly) WorkSpaces with Maintenance mode enabled, the maintenance window is typically from 00h00 to 05h00 everyday starting on the 3rd Monday of the month. The Maintenance window might take up to two weeks.\xa0 WorkSpaces can be maintained on any day in the maintenance window. You can set the Maintenance mode for AutoStop WorkSpaces in the WorkSpaces management console. For more information see\xa0Manage the WorkSpace Running Mode.', 'The maintenance window for WorkSpaces is currently not configurable. '), ('Q: Will my Amazon WorkSpaces require software updates?', 'Your Amazon WorkSpaces provide users with the Windows 7 experience, provided by Windows Server 2008 R2. The underlying OS, and any applications installed in the WorkSpace may need updates.'), ('Q: How will my Amazon WorkSpaces be patched with software updates?', 'You have the ability to control how patching is configured your Amazon WorkSpaces. By default, Windows Update is turned on, but you have the ability to customize these settings, or use an alternative patch management approach if you prefer. Updates are installed at 2am each Sunday.\xa0'), ('Q: What action is needed to receive updates for the Amazon WorkSpaces service?', 'No action is needed on your part. Updates are delivered automatically to your Amazon WorkSpaces during the maintenance window. During the maintenance window, your WorkSpaces may not be available.'), ('Q: Can I turn off the software updates for the Amazon WorkSpaces service?', 'No. The Amazon WorkSpaces service requires these updates to be provided to ensure normal operation of your users’ WorkSpaces.'), ('Q: I don’t want to have Windows Update automatically update my Amazon WorkSpaces. How can I control updates and ensure they are tested in advance?', 'You have full control over the Windows Update configuration in your WorkSpaces, and can use Active Directory Group Policy to configure this to meet your exact requirements. If you would like to have advance notice of patches so you can plan appropriately we recommend you refer to Microsoft Security Bulletin Advance Notification for more information.'), ('Q: How are updates for applications installed in my WorkSpaces provided?', 'For all other applications, updates can be delivered via the automatic update service for each application if one is available. For applications without an automatic update service, you will need to evaluate the software vendor’s recommended updating approach and follow that if necessary.'), ('Q: How can Amazon WorkSpaces be managed?', 'The WorkSpaces Management console lets you provision, reboot, rebuild, and delete WorkSpaces. To manage the underlying OS for the WorkSpaces, you can use standard Microsoft Active Directory tools such as Group Policy to manage the WorkSpaces. In the case when you have integrated WorkSpaces with an existing Active Directory domain, you can manage your WorkSpaces using the same tools and techniques you are using for your existing on-premises desktops. If you have not integrated with an existing Active Directory, you can set up a Directory Administration WorkSpace to perform management tasks. Please see the documentation for more information.'), ('Q: Can I use tags to categorize my Amazon WorkSpaces?', 'Yes, you can assign tags to existing Amazon WorkSpaces, or during the launch of new Amazon WorkSpaces. You can assign up to 50 tags (key/value pairs) to each Amazon WorkSpace using the AWS Management Console, the AWS Command Line Interface, or the Amazon WorkSpaces API. These tags automatically get applied to all Amazon WorkSpaces Application Manager (WAM) applications and WAM-related service charges associated with a WorkSpace. To learn more about assigning tags to your Amazon WorkSpaces, follow the steps listed on this web page: Tagging WorkSpaces.'), ('Q: Can I control whether my users can access Amazon WorkSpaces Web Access?', 'Yes. You can use the AWS Management Console to control whether Amazon WorkSpaces in your directory can be accessed using Web Access, by visit the directory details page. Note: this setting can only be applied to all Amazon WorkSpaces in a directory, not at an individual Amazon WorkSpace level. '), ('Q: What is the difference between rebooting and rebuilding an Amazon WorkSpace?', 'A reboot is just the same as a regular operating system (OS) reboot. A rebuild will retain the user volume on the WorkSpace (D:) but will return the WorkSpace to its original state (any changes made to the system drive (C:) will not be retained).'), ('Q: How do I remove an Amazon WorkSpace I no longer require?', 'To remove a WorkSpace you no longer require, you can “delete” the Workspace. This will remove the underlying instance supporting the WorkSpace and the WorkSpace will no longer exist. Deleting a WorkSpace will also remove any data stored on the volumes attached to the WorkSpace, so please confirm you have saved any data you must keep prior to deleting a WorkSpace.'), ('Q: Can I provide more than one Amazon Workspace per user?', 'No. You can currently only provide one WorkSpace for each user.'), ('Q: How many Amazon WorkSpaces can I launch?', 'You can launch as many Amazon WorkSpaces as you need. Amazon WorkSpaces sets default limits, but you can request an increase in these limits here. To see the default limits for Amazon WorkSpaces, please visit our documentation. '), ('Q: Is there a minimum number of Amazon WorkSpaces or users I must provision?', 'No. There is no minimum requirement.'), ('Q: What is the network bandwidth that I need to use my Amazon WorkSpace?', "The bandwidth needed to use your WorkSpace depends on what you're doing on your WorkSpace. For general office productivity use, we recommend that a bandwidth download speed of between 300Kbps up and 1Mbps. For graphics intensive work we recommend bandwidth download speeds of 3Mbps."), ('Q: What is the maximum network latency recommended while accessing a Workspace?', 'While the remoting protocol has a maximum round trip latency recommendation of 250 ms, the best user experience will be achieved at less than 100 ms.'), ('Q: Does WorkSpaces need any Quality of Service configurations to be updated on my network?', 'If you wish to implement Quality of Service on your network for WorkSpaces traffic, you should prioritize WorkSpaces’ interactive video stream which is comprised of real time traffic on UDP port 4172. If possible, this traffic should be prioritized just after VoIP to provide the best user experience.'), ('Q: Which AWS regions does Amazon WorkSpaces support?', 'Please refer to the Regional Products and Services page for details of Amazon WorkSpaces service availability by region.'), ('Q: Is MFA on Amazon WorkSpaces available in my region?', 'Support for MFA is available in all AWS Regions where Amazon WorkSpaces is offered.'), ('Q: What are the prerequisites for setting up a PCoIP Zero Client?', 'Zero Clients should be updated to firmware version 4.6.0 (or newer). You will need to run the PCoIP Connection Manager to enable the clients to successfully connect to Amazon WorkSpaces. Please consult the Amazon WorkSpaces documentation for a step by step guide on how to properly setup the PCoIP Connection Manager, and for help on how to find and install the necessary firmware required for your Zero Clients'), ('Q: How do I get support with Amazon WorkSpaces?', 'You can get help from AWS Support, and you can also post in the Amazon WorkSpaces Forum. '), ('Q: How does billing work for Amazon WorkSpaces?', 'You can pay for your Amazon WorkSpaces either by the hour, or by the month. You only pay for the WorkSpaces you launch, and there are no upfront fees and no term commitments. The fees for using Amazon WorkSpaces include use of both the infrastructure (compute, storage, and bandwidth for streaming the desktop experience to the user) and the software applications listed in the bundle.'), ('Q: How much does an Amazon WorkSpace cost?', 'Please see our pricing page for the latest information.'), ('Q: Is there a price difference between Amazon WorkSpaces Windows 7 and Windows 10 bundles?', 'No. There is no price difference between Amazon WorkSpaces Windows 7 and Windows 10 bundles. Note, however, that there is an additional charge for the Plus versions of both Windows 7 and Windows 10 bundles. \xa0'), ('Q: Can I pay for my Amazon WorkSpaces by the hour?', 'Yes, you can pay for your Amazon WorkSpaces by the hour. Hourly pricing is available for all WorkSpaces bundles, and in all AWS regions where Amazon WorkSpaces is offered. '), ('Q: How does hourly pricing work for Amazon WorkSpaces?', 'Hourly pricing has two components: an hourly usage fee, and a low monthly fee for fixed infrastructure costs. Hourly usage fees are incurred only while your Amazon WorkSpaces are actively being used, or undergoing routine maintenance. When your Amazon WorkSpaces are not being used, they will automatically stop after a specified period of inactivity, and hourly metering is suspended. When your Amazon WorkSpaces resume, hourly charges begin to accrue again. '), ('Q: How do I get started with hourly billing for my Amazon WorkSpaces?', 'To launch an Amazon WorkSpace to be billed hourly, simply select a user, choose an Amazon WorkSpaces bundle (a configuration of compute resources and storage space), and specify the AutoStop running mode. When your Amazon WorkSpace is created, it will be billed hourly.'), ('Q: What is the difference between monthly pricing and hourly pricing for Amazon WorkSpaces?', 'With monthly billing, you pay a fixed monthly fee for unlimited usage and instant access to a running Amazon WorkSpace at all times. Hourly pricing allows you to pay for your Amazon WorkSpaces by the hour and save money on your AWS bill when your users only need part-time access to their Amazon WorkSpaces. When your Amazon WorkSpaces being billed hourly are not being used, they automatically stop after a specified period of inactivity, and hourly usage metering is suspended. '), ('Q: How do I select hourly billing or monthly billing for my Amazon WorkSpaces?', 'To make hourly billing possible, Amazon WorkSpaces now operates in two running modes – AutoStop and AlwaysOn. The AutoStop running mode allows you to pay for your Amazon WorkSpaces by the hour. The AlwaysOn running mode is used when paying a fixed monthly fee for unlimited usage of your Amazon WorkSpaces. You can easily choose between monthly and hourly billing by selecting the running mode when you launch Amazon WorkSpaces through the AWS Management Console, the Amazon WorkSpaces APIs, or the Amazon WorkSpaces Command Line Interface. You can also switch between running modes for your Amazon WorkSpaces at any time.'), ('Q: When do I incur charges for my Amazon WorkSpace when paying by the hour?', 'Hourly usage fees start accruing as soon as your Amazon WorkSpace is running. Your Amazon WorkSpace may resume in response to a login request from a user, or to perform routine maintenance.'), ('Q: When do I stop incurring charges for my Amazon WorkSpaces when paying by the hour?', 'Hourly usage charges are suspended when your Amazon WorkSpaces stop. AutoStop automatically stops your WorkSpaces a specified period of time after users disconnect, or when scheduled maintenance is completed. The specified time period is configurable and is set to 60 minutes by default. Note that partial hours are billed as a full hour, and the monthly portion of hourly pricing does not suspend when your Amazon WorkSpaces stop. '), ('Q: Can I force hourly charges to suspend sooner?', 'You can manually stop Amazon WorkSpaces from the AWS Management Console, or by using the Amazon WorkSpaces APIs. To stop the monthly fee associated with your hourly Amazon WorkSpaces, you need to remove the Amazon WorkSpaces from your account (note: this also deletes all data stored in those Amazon WorkSpaces). '), ('Q: Can I switch between hourly and monthly billing?', 'Yes, you can switch from hourly to monthly billing for your Amazon WorkSpaces at any time by switching the running mode to AlwaysOn in the AWS Management Console, or through the Amazon WorkSpaces APIs. When you switch, billing immediately changes from hourly to monthly, and you are charged a prorated amount at the monthly rate for the remainder of the month, along with the monthly and hourly usage fees already billed for the month. Your Amazon WorkSpaces will continue to be charged monthly unless you switch the running mode back to AutoStop.'), ('You can switch from monthly to hourly billing by setting the running mode to AutoStop in the AWS Management Console or through the Amazon WorkSpaces APIs. Switching from monthly to hourly billing will take effect the following month as you will have already paid for your Amazon WorkSpaces for that month. Your Amazon WorkSpaces will continue to be charged hourly unless you switch the running mode back to AlwaysOn.', 'Q: If I don’t use my Amazon WorkSpace for the full month, are the fees prorated?'), ('If you’re paying for your Amazon WorkSpaces monthly, your Amazon WorkSpaces are charged for the full month’s usage. If you’re paying hourly (AutoStop running mode), you are charged for the hours during which your Amazon WorkSpaces are running or undergoing maintenance, plus a monthly fee for fixed infrastructure costs. In both cases, the monthly fee is prorated in the first month only.', 'Q: Will I be charged the low monthly fee associated with hourly billing if I don’t use my Amazon WorkSpaces in a given month?'), ('Yes, you will be charged a small monthly fee for the Amazon WorkSpaces bundle you selected. If you’ve chosen an Amazon WorkSpaces Plus bundle, you will be charged for the software subscription as well. You can find the monthly fees for all Amazon WorkSpaces on the pricing page here.', 'Q: How are the Plus software bundles charged when I pay hourly for my Amazon WorkSpaces?'), ('Plus bundles are always charged monthly, even if you’re paying for your Amazon WorkSpaces by the hour. If you selected a Plus bundle when you launched your WorkSpaces, you will incur the listed fee for the Plus software bundle even if you do not use those Amazon WorkSpaces in a particular month.', 'Q: Can I purchase Amazon WorkSpaces Graphics bundles using the monthly billing option?'), ('Yes, you can. Please contact us if this is something you’d like to do. \xa0', 'Q: Will I be able to monitor how many hours my Amazon WorkSpaces have been running?'), ('Yes, you will be able to monitor the total number of hours your Amazon WorkSpaces have been running in a given period of time through the Amazon CloudWatch “UserConnected” metric. ', 'Q: Does Amazon WorkSpaces pricing include bandwidth costs?'), ('Amazon WorkSpaces pricing includes network traffic between the user’s client and their WorkSpace. Web traffic from WorkSpaces (for example, accessing the public Internet, or downloading files) will be charged separately at current AWS bandwidth rates.', 'Q: How will I be charged for Amazon WorkSpaces that I launch that are based on a custom image?'), ('There is no additional charge for Amazon WorkSpaces created from custom images. You will be charged the same as the underlying bundles on which the customized images are based.', 'Q: Can I use custom images for Amazon WorkSpaces that are billed hourly?'), ('Yes. You can launch Amazon WorkSpaces billed hourly from images that you create and upload. There is no additional charge for Amazon WorkSpaces launched from custom images. You will be charged the same as the underlying bundles on which the customized images are based.', 'Q: Is there a charge to use Amazon WorkSpaces client applications?'), ('The Amazon WorkSpaces client applications are provided at no additional cost, and you can install the clients on as many devices as you need to. You can access these here.', 'Q: Is there an additional charge to access Amazon WorkSpaces using Web Access?'), ('There is no additional charge to access Amazon WorkSpaces using Web Access. For Amazon WorkSpaces set to bill hourly, you will keep getting billed for the time you leave a browser tab open with an actively running Amazon WorkSpace.', 'Q: Can I use tags to obtain usage and cost details for Amazon WorkSpaces, Amazon WorkSpaces Application Manager (WAM), and WAM applications on my AWS monthly billing report?'), ('Yes. By setting tags to appear on your monthly Cost Allocation Report, your AWS monthly bill will also include those tags. You can then easily track costs according to your needs. To do this, first assign tags to your Amazon WorkSpaces by following the steps listed on this web page: Tagging WorkSpaces. Next, select the tag keys to include in your cost allocation report by following the steps listed on this web page: Setting Up Your Monthly Cost Allocation Report.', 'Q: Are there any costs associated with tagging Amazon WorkSpaces?'), ('There are no additional costs when using tags with your Amazon WorkSpaces.', 'Q: What does the Amazon WorkSpaces Application Manager (Amazon WAM) cost?'), ('Amazon WAM is available in two versions - lite or standard. The Amazon WAM lite subscription is available at no charge, and the Amazon WAM standard subscription costs $5/user/month. You can learn more about Amazon WAM here.', 'Q: Can I pay for Amazon WAM on an hourly basis?'), ('Amazon WAM is not available for hourly billing. You will still be charged monthly for Amazon WAM usage, even if you’re using Amazon WAM to deliver applications to an Amazon WorkSpace being billed hourly.', 'Q: Do I have to pay to use the Amazon WAM Studio or Amazon WAM Player?'), ('No. There is no additional charge for using the Studio or Player. You will be charged for AWS resources such as the Amazon EC2 instance hours, EBS storage, and bandwidth when using the Studio to package your applications for Amazon WAM.', 'Q: Am I eligible to take advantage of the Amazon WorkSpaces Free Tier offer?'), ('The Amazon WorkSpaces Free Tier offer is available to new or existing AWS customers that have not previously used WorkSpaces. The Free Tier allows you to gain hands-on experience with Amazon WorkSpaces, at no cost, so that you can evaluate the service. ', 'Q: What Amazon WorkSpaces bundles are available as part of the Free Tier?'), ('The Amazon WorkSpaces Free Tier allows you to provision two Standard bundle WorkSpaces. The Standard bundle WorkSpace offers a cloud desktop with 2 vCPUs, 4 GB of memory, and 50 GB of SSD-based storage, and you can choose between a Windows 10 or Windows 7 desktop experience, both powered by Windows Server. As with all bundles, your WorkSpace comes with Internet Explorer 11, Mozilla Firefox, and 7-Zip pre-installed, and access to\xa0Amazon WorkDocs\xa0with 50 GB included storage.', 'Q: What is included with the Amazon WorkSpaces Free Tier?'), ('The WorkSpaces Free Tier includes two Standard bundle Amazon WorkSpaces, for 40 hours of combined use per month, for two calendar months. As with all bundles, your WorkSpace comes with Internet Explorer 11, Mozilla Firefox, and 7-Zip pre-installed, and access to Amazon WorkDocs\xa0with 50 GB included storage. \xa0', 'Q: Can I use any other Amazon WorkSpaces bundles as part of the Free Tier?'), ('The Amazon WorkSpaces Free Tier includes the Standard bundle only. ', 'Q: What is the duration of the Amazon WorkSpaces Free Tier?'), ('The Free Tier offer starts when you launch your first Amazon WorkSpace, and expires at the end of the second calendar month. For example, if you launched your first WorkSpace on the 15th of the month, the Free Tier offer extends to the end of the next month.\xa0', 'Q: If I use less than 40 hours in my first month of Free Tier use, do the remaining hours roll over to the next month?'), ('The Amazon WorkSpaces Free Tier allows you to use a combined total of 40 hours per month. Unused hours expire when the new calendar month starts.', 'Q: What happens if I use my WorkSpaces for more than 40 hours in a calendar month during the Free Tier period?'), ('In the event you exceed 40 hours of use in a month during the Free Tier period, you are billed at the\xa0current hourly rate\xa0for Amazon WorkSpaces.', 'Q: What happens if I convert my Amazon WorkSpaces from AutoStop (hourly billing) to AlwaysOn (monthly billing) before my Free Tier period expires?'), ('To qualify for the Free Tier, your Amazon WorkSpaces need to run in the AutoStop running mode. You can change the running mode of your WorkSpaces to AlwaysOn, but this action converts your WorkSpaces to monthly billing, and your Free Tier period will end. To learn more about how billing works when switching running modes, see the\xa0Amazon WorkSpaces Pricing and Billing FAQ.', 'Q: Hourly billing for Amazon WorkSpaces includes a fee for hours used, and a monthly infrastructure cost. Is the monthly infrastructure cost waived during the Amazon WorkSpaces Free Tier?'), ('The monthly infrastructure fee for Amazon WorkSpaces is waived for Free Tier use, even if you use more than 40 hours in a month. If you do exceed 40 hours in a month, you are billed for your additional usage at the current hourly rate, which is available at\xa0Amazon WorkSpaces Pricing.', 'Q: What happens when my Amazon WorkSpaces Free Tier period ends?'), ('When your Free Tier period ends, your Amazon WorkSpaces convert to Standard bundle WorkSpaces billed at the current hourly rate. In addition, the monthly infrastructure fee will start to apply. For current rates, see\xa0Amazon WorkSpaces Pricing.', 'Q: How can I track my Amazon WorkSpaces Free Tier usage?'), ('To track your Amazon WorkSpaces usage, go to the My Account page in the AWS management console and see your current and past activity by service, and region. You can also download usage reports. For more information, see\xa0Understanding Your Usage with Billing Reports.', 'Q: Can I use an HTTPS proxy to connect to my Amazon WorkSpaces?'), ('Yes, you can configure a WorkSpaces Client app to use an HTTPS proxy. Please see our documentation for more information.', 'Q: Can I connect Amazon WorkSpaces to my VPC?'), ('Yes. The first time you connect to the WorkSpaces Management Console, you can choose an easy ‘getting started’ link that will create a new VPC and two associated subnets for you as well as an Internet Gateway and a directory to contain your users. If you choose to access the console directly, you can choose which of your VPCs your WorkSpaces will connect to. If you have a VPC with a VPN connection back to your on-premises network, then your WorkSpaces will be able to communicate with your on-premises network (you retain the usual control you have over network access within your VPC using all of the normal configuration options such as security groups, network ACLS, and routing tables).', 'Q: Can I connect to my existing Active Directory with my Amazon WorkSpaces?'), ('Yes. You can use AD Connector or AWS Microsoft AD to integrate with your existing on-premises Active Directory. ', 'Q: Will my Amazon WorkSpaces be able to connect to the Internet to browse websites and download applications?'), ('Yes. You have full control over how your Amazon WorkSpaces connect to the Internet based on regular VPC configuration. Depending on what your requirements are you can either deploy a NAT instance for Internet access, assign an Elastic IP Address (EIP) to the Elastic Network Interface (ENI) associated with the WorkSpace, or your WorkSpaces can access the Internet by utilizing the connection back to your on-premises network.', 'Q: Can I use IPv6 addresses in my Amazon WorkSpaces?'), ('Yes. You can use IPv6 addresses for Amazon WorkSpaces Value, Standard, and Power bundles. At this time, IPv6 addresses are not supported in WorkSpaces Performance and Graphics bundles.', 'Q: Can my Amazon WorkSpaces connect to my applications that are running in Amazon EC2 such as a file server?'), ('Yes. Your WorkSpaces can connect to applications such as a fileserver running in Amazon EC2 (both “Classic” and VPC networking environments). All you need to do is ensure appropriate route table entries, security groups and network ACLs are configured so that the WorkSpaces can reach the EC2 resources you would like them to be able to connect to.', 'Q: What are the pre-requisites for using my digital certificates on Amazon WorkSpaces?'), ('To use your certificates to manage which client devices can access Amazon WorkSpaces, you need to distribute your client certificates using your preferred solution such as Microsoft System Center Configuration Manager (SCCM), or a Mobile-Device Management (MDM) software solution to the devices you want to trust. Your root certificates are imported into the WorkSpaces management console. For more information, please see Restrict WorkSpaces Access to Trusted Devices.', 'Q: What are the pre-requisites for enabling MFA on Amazon WorkSpaces?'), ('To enable MFA on WorkSpaces, you will need to configure AD Connector, and have an on-premises RADIUS server(s). Your on-premises network must allow inbound traffic over the default RADIUS server port (1812) from the AD Connector server(s). Additionally, you must ensure that usernames match between Active Directory and your RADIUS server. To learn more, visit our documentation. ', 'Q:\xa0Do I need to set up a directory to use the Amazon WorkSpaces service?'), ('Each user you provision a WorkSpace for needs to exist in a directory, but you do not have to provision a directory yourself. You can either have the WorkSpaces service create and manage a directory for you and have users in that directory created when you provision a WorkSpace. Alternatively, you can integrate WorkSpaces with an existing, on-premises Active Directory so that users can continue to use their existing credentials meaning that they can get seamless applications to existing applications. ', 'Q: If I use a directory that the Amazon WorkSpaces service creates for me, can I configure or customize it?'), ('Yes. Please see our documentation for more details.', 'Q: Can I integrate Amazon WorkSpaces with my existing on-premises Active Directory?'), ('Yes. You can use AD Connector or AWS Microsoft AD to integrate with your existing on-premises Active Directory.', 'Q: How do I integrate Amazon WorkSpaces with my on-premises Microsoft Active Directory?'), ('There are two ways you can integrate Amazon WorkSpaces with your on-premises Microsoft Active Directory (AD): you can set up an interforest trust relationship with your AWS Microsoft AD domain controller, or you can use AD Connector to proxy AD authentication requests.', 'To configure an interforest trust relationship between your on-premises Microsoft AD and your AWS Microsoft AD please see the documentation here. To configure AD Connector, please see the documentation here.'), ('Once a trust is established, you can select the domain where your user accounts reside directly in the Amazon WorkSpaces console, and proceed to provisioning WorkSpaces for your users. Please note that usernames across domains need to be unique per instance of AWS Microsoft AD.', 'Q: There are two options for integrating Amazon WorkSpaces with my on-premises Microsoft Active Directory. Which one should I use?'), ('You can integrate Amazon WorkSpaces with your on-premises Microsoft Active Directory (AD) either by setting up an interforest trust relationship with your AWS Microsoft AD domain controller, or by using AD Connector to proxy AD authentication requests.', 'When using interforest trust, you only need a single trust relationship between your on-premises AD and your AWS Microsoft AD domain controller. You can assign Amazon WorkSpaces to users in any of your on-premises domains, and AWS Microsoft AD automatically discovers and routes authentication requests to the correct domain controller. This option works well when your environment consists of multiple on-premises Microsoft AD domains.'), ('When using AD Connector, a separate AD Connector is required for each of your on-premises Microsoft AD domains with users that will need WorkSpaces assigned to them. Using AD Connector works well for environments with a single on-premises domain, or for proof-of-concept projects.', 'For more information, please visit this page. \xa0'), ('Q: Can I use the Amazon WorkSpaces APIs to create new WorkSpaces for users across domains when I have an interforest trust relationship established with AWS Microsoft AD?', 'Yes. When using the Amazon WorkSpaces API to launch WorkSpaces, you will need to specify the domain name as part of the username, in this format: “NETBIOS\\username” or “corp.example.com\\username”. For more information, please visit this page. \xa0'), ('Q: Can I apply the same Group Policy object settings from my on-premises Microsoft Active Directory to Amazon WorkSpaces?', 'Yes. If you’re using an interforest trust relationship between your on-premises Microsoft AD and your AWS Microsoft AD domain controller, you will need to ensure that your Group Policy object (GPO) settings are replicated across domains before they can be applied to Amazon WorkSpaces. If you are using AD Connector, your GPO settings will be applied to your WorkSpaces much like any other computer in your domain. \xa0'), ('Q: Can I apply Active Directory policies to my Amazon WorkSpaces using the directory that the WorkSpaces service creates for me?', 'Yes. Please see our documentation for more details.'), ('Q: What happens to my directory when I remove all of my Amazon WorkSpaces?', 'You may keep your AWS directory in the cloud and use it to domain join EC2 instances or provide directory users access to the AWS Management Console. You may also delete your directory.'), ('If there are no WorkSpaces being used with your Simple AD or AD Connector for 30 consecutive days, you will be charged for this directory as per the AWS Directory Service pricing terms. If you delete your Simple AD or AD Connector you can always create a new one when you want to start using WorkSpaces again.', 'Q: Which AWS Directory Services support the use of PCoIP Zero Clients?'), ('PCoIP Zero Clients can be used with the AD Connector and Simple AD directory services from AWS. Currently, Zero Clients cannot be used with the AWS Directory Service for Mirosoft Active Directory. \xa0', 'Q:\xa0What does Amazon CloudWatch monitor for Amazon WorkSpaces?'), ('You can use Amazon CloudWatch metrics for Amazon WorkSpaces to review health and connection metrics for individual WorkSpaces and all WorkSpaces belonging to a directory. You can set up CloudWatch alarms on these metrics to be alerted about changes to WorkSpaces health, or about issues your users may have connecting to their WorkSpaces.', 'Q: Will I be able to monitor how many hours my Amazon WorkSpaces have been running?'), ('Yes, you will be able to monitor the total number hours your Amazon WorkSpaces has been running in a given period of time through Amazon CloudWatch “UserConnected” metric. ', 'Q: In what regions can I use Amazon WorkSpaces with CloudWatch metrics?'), ('CloudWatch metrics for Amazon WorkSpaces is supported in all AWS regions in which Amazon WorkSpaces is available.', 'Q: What does it cost?'), ('There is no additional cost for using Basic CloudWatch metrics with WorkSpaces via the CloudWatch console. There may be additional charges for setting up CloudWatch alarms and retrieving CloudWatch metrics via APIs. Please see CloudWatch pricing\xa0for more information.', 'Q: How do I get started?'), ('Basic CloudWatch metrics are enabled by default for all your WorkSpaces. Visit the AWS Management Console to review the metrics and set up alarms.', 'Q: What metrics are supported for the Amazon WorkSpaces client application and PCOIP Zero Clients?'), ('Please see the documentation for more information on Amazon CloudWatch metrics with Amazon WorkSpaces. ', 'Q: What metrics are supported for Amazon WorkSpaces Web Access usage?'), ('The following metrics are currently supported for reporting on Amazon WorkSpaces Web Access usage:', 'Please see the documentation for more information on Amazon CloudWatch metrics with Amazon WorkSpaces.\xa0'), ('Q:\xa0Can I print from my Amazon WorkSpace?', 'Yes, Amazon WorkSpaces supports local printers, network printers, and cloud printing services.'), ('Q: Which printer is set as the default in my Amazon WorkSpace?', 'If you have a local printer configured on the Windows or Mac computer you use to connect to your Amazon WorkSpace, then that printer will be set as the default printer when you connect to your WorkSpace.'), ('Q: How do I print to my local printer?', 'If you have a local printer configured, it will be selected by default. If not, you will need to configure a local printer outside of your WorkSpace. Once this is done, select your local printer from the print menu, and select print.'), ('Q: Why can’t I see my local printer from the printing menu?', 'Most printers are already supported by Amazon WorkSpaces. If your printer is not recognized, you may need to install the appropriate device driver on your WorkSpace.'), ('Q: How do I print to a network printer?', 'Any printer which is on the same network as your Amazon WorkSpace and is supported by Windows Server 2008 R2 can be added as a network printer. Once a network printer is added, it can be selected for printing from within an application.'), ('Q: Can I use my Amazon WorkSpace with a cloud printing service?', 'You can use cloud printing services with your WorkSpace including, but not limited to, Cortado ThinPrint,® and Google Cloud Print.'), ('Q: Can I print from my tablet or Chromebook?', 'The Amazon WorkSpaces clients for tablets and Chromebook support cloud printing services including, but not limited to, Cortado ThinPrint® and Google Cloud Print. Local and network printing are not currently supported. '), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/appstream2/faqs/': [('Q: What is Amazon AppStream 2.0?', 'Amazon AppStream 2.0 is a fully managed application streaming service that provides users instant access to their desktop applications from anywhere, on any connected device. Amazon AppStream 2.0 simplifies application management, improves security, and reduces costs by moving a company’s applications from their users’ physical devices to the AWS Cloud. The Amazon AppStream 2.0 streaming protocol provides users a responsive, fluid performance that is almost indistinguishable from a natively installed application. With Amazon AppStream 2.0, organizations can realize increased flexibility, improved scalability, and the agility to support a broad range of compute and storage requirements for their applications.'), ("Q: What's the difference between the original Amazon AppStream and Amazon AppStream 2.0?", 'Amazon AppStream 2.0 is the next generation desktop application streaming service from AWS. Amazon AppStream\xa0was an SDK-base service that customers could use to set up their own streaming service with DIY engineering. Amazon AppStream 2.0 provides a fully managed streaming service with no DIY effort. Amazon AppStream 2.0 offers a greater range of instance types, streams desktop applications to HTML5 browsers with no plugins required, simplifies application lifecycle management, and allows your apps to access services in your VPC.'), ('Q: Can I continue to use the original Amazon AppStream service?', 'No. You cannot use the original Amazon AppStream service. Amazon AppStream 2.0 offers a greater range of instance types, streams desktop applications to HTML5 browsers with no plugins required, simplifies application lifecycle management, and allows your apps to access services in your VPC. '), ('Q: What are the benefits of streaming over rendering content locally?', 'Interactively streaming your application from the cloud provides several benefits:\xa0'), ('Instant-on: Streaming your application with Amazon AppStream 2.0 lets your users start using your application immediately, when using an image builder or Always-On fleet, without the delays associated with large file downloads and time-consuming installations.', 'Remove device constraints: You can leverage the compute power of AWS to deliver experiences that wouldn’t normally be possible due to the GPU, CPU, memory, or physical storage constraints of local devices.'), ('Multi-platform support: You can take your existing applications and start streaming them to browsers on any device without any modifications.', "Easy updates: Because your application is centrally managed by Amazon AppStream 2.0, updating your application is as simple as providing a new version of your application to Amazon AppStream 2.0. That's all you need to do to immediately upgrade all your users, without any action on their part."), ('Improved security: Unlike traditional boxed software and digital downloads, where your application is available for theft or reverse engineering, Amazon AppStream 2.0 stores and executes your application securely in AWS data centers, and only provides an interactive pixel stream to users.', 'Q: Do some applications work better with Amazon AppStream 2.0 than others?'), ('Many types of applications work well as streaming applications, including CAD, CAM, CAE, 3D modeling, simulation, games, video and photo-editing software, medical imaging, and life sciences applications. These applications benefit most from streaming because the application runs on the vast computational resources of AWS, yet your users can interact with the application using low-powered devices, with very little noticeable change in application performance.', 'Q: Does Amazon AppStream 2.0 support microphones?'), ('Yes. Amazon AppStream 2.0 supports most analog and USB microphones, including built-in microphones.', 'Q: How do users enable audio input in an Amazon AppStream 2.0 streaming session?'), ('Users enable audio input from the Amazon AppStream 2.0 toolbar by selecting the Settings\xa0icon and selecting Enable Microphone.', 'Q: What browser support audio-input in an Amazon AppStream 2.0 session?'), ('Most popular HTML5 compliant browsers support audio-input in Amazon AppStream 2.0 session, including Chrome, Edge, and Firefox. Microsoft Internet Explorer 11 (IE11) does not support audio-input, and the microphone option will not appear on the Amazon AppStream 2.0 toolbar in streaming sessions running in IE11.', 'Q: Does Amazon AppStream 2.0 support a 3D mouse?'), ('Amazon AppStream 2.0 does not currently support 3D mouse.', 'Q: What does a user need to access applications streamed from Amazon AppStream 2.0?'), ('A user needs to have applications set up by an administrator, a modern web browser that can support HTML5, a broadband Internet connection with at least 1 Mbps capability, and outbound access to the Internet via HTTPS (443).', 'Q: Can my Amazon AppStream 2.0 applications run offline?'), ('No. Amazon AppStream 2.0 requires a sustained Internet connection to access your applications.Q: Can my Amazon AppStream 2.0 applications run offline?', 'Q: What does Amazon AppStream 2.0 manage on my behalf?'), ('Streaming resources: Amazon AppStream 2.0 launches and manages AWS resources to host your application, deploys your application on those resources, and scales your application to meet client demand.', 'Simplified app management: Amazon AppStream 2.0 delivers the latest version of an application instantly to users, and eliminates the pain of patching and updating applications on every end-user device. Because your application is centrally managed by Amazon AppStream 2.0, updating your application is as simple as providing a new version of your application to Amazon AppStream 2.0. Applications can be assigned to users dynamically and removed instantly at any time, improving business flexibility and reducing costs.'), ('Q: Can I use tags to categorize AppStream 2.0 resources? ', 'Yes. you can assign tags to manage and track the following Amazon AppStream 2.0 resources: Image builders, images, fleets, and stacks. AWS enables you to assign metadata to your AWS resources in the form of tags. Tags let you categorize your AppStream 2.0 resources so you can easily identify their purpose and track costs accordingly. For example, you can use tags to identify all resources used by a particular department, project, application, vendor, or use case. Then, you can use AWS Cost Explorer to identify trends, pinpoint cost drivers, and detect anomalies in your account.  You can assign or remove tags using the AppStream 2.0 management console, command line interface, or API. Tags have a key and a corresponding value, and you can assign up to 50 tags per AppStream 2.0 resource. '), ('Q: What is Amazon AppStream 2.0 Try It Now?', 'Amazon AppStream 2.0 Try It Now is a low-friction, setup-free trial experience for the Amazon AppStream 2.0 service. Try It Now allows any AWS customer to instantly launch and interact with popular desktop applications from their browser.'), ('Q: What do I need to start using Try It Now?', 'You need an AWS account and a broadband Internet connection with at least 1 Mbps bandwidth to use Try It Now. You also need a browser capable of supporting HTML5.'), ('Q: Will I be charged for using Try It Now?', 'You won’t be charged any AWS fees for using Try It Now. However, you may incur other fees such as Internet or broadband charges to connect to the Try It Now experience.'), ('Q: What applications can I use with Try It Now?', 'Try It Now includes popular productivity, design, engineering, and software development applications running on Amazon AppStream 2.0 for you to try. To see the full list of available applications, go to the Try It Now catalog page after signing in with your AWS account.'), ('Q: How long can I stream applications via Try It Now?', 'You can stream the applications included in Try It Now for up to 30 minutes. At the end of 30 minutes, your streaming session is automatically terminated and any unsaved data will be deleted.'), ('Q: Can I save files within Try It Now?', 'You can save files to your Amazon AppStream 2.0 session storage and download them to your client device before your streaming session ends. Your files are not saved when you disconnect from your Try It Now session, or when your session ends, and any unsaved data will be deleted. '), ('Q: Can I submit an application to be included in Try It Now?', 'Yes. You can submit a request to include your application in Try It Now. After your request is received, AWS usually reviews the request and responds within 10 business days. '), ('Q: How do I get started with Amazon AppStream 2.0?', 'You can begin using Amazon AppStream 2.0 by visiting the AWS Management Console, or by using the AWS SDK. You can access the Getting Started guide here.\xa0'), ('Q: What resources do I need to set up to stream my applications using Amazon AppStream 2.0?', 'You need to create an Amazon AppStream 2.0 stack in your AWS account to start streaming applications to your users. A stack includes a fleet of Amazon AppStream 2.0 instances that executes and streams applications to end users. Each instance is launched using an Amazon AppStream 2.0 image containing your applications, and uses an instance type that you select for your fleet. To learn more about Amazon AppStream 2.0 resources, please visit this page.'), ('Q: How do I create an Amazon AppStream 2.0 image to import my applications?', 'You can create an Amazon AppStream 2.0 image using Image Builder via the AWS Management Console. Image Builder allows you to install and test your applications just as you would with any Windows desktop, and then create an image. You can complete all the install, test, and creation steps for the image without leaving the console.'), ('Q: What instance types are available to use with my Amazon AppStream 2.0 fleet?', 'Amazon AppStream 2.0 provides a menu of instance types for configuring a fleet or an image builder. You can select the instance type that best matches your applications and end-user requirements. You can choose from General Purpose, Compute Optimized, Memory Optimized, Graphics Design, Graphics Desktop, or Graphics Pro instance families.'), ('Q: Can I change an instance type after creating a fleet?', 'Yes. You can change your instance type after you have created a fleet. To change the instance type, you will need to stop the fleet, edit the instance type, and then start the fleet again. For more information, see Set up AppStream 2.0 Stacks and Fleets.'), ('Q: Can I connect Amazon AppStream 2.0 instances to my VPC?', 'Yes. You can choose the VPCs to which your Amazon AppStream 2.0 instances (fleet and image builders) connect. When you create your fleet, or launch Image Builder, you can specify one or more subnets in your VPC. If you have a VPC with a VPN connection to your on-premises network, then Amazon AppStream 2.0 instances in your fleet can communicate with your on-premises network. You retain the usual control you have over network access within your VPC, using all the normal configuration options such as security groups, network access control lists, and routing tables.\xa0For more information about creating a VPC and working with subnets, see\xa0Working with VPCs and Subnets.'), ('Q: How can I create images with my own applications?', 'You can use Amazon AppStream 2.0 Image Builder to create images with your own applications. To learn more, please visit the tutorial found on this page.'), ('Q: With which operating system do my apps need to be compatible?', 'Amazon AppStream 2.0 streams applications that can run on Windows Server 2012 R2 64-bit. You can add support for 32-bit applications by using the WoW64 extensions. If your application has other dependencies, such as the .NET framework, include those dependencies in your application installer.'), ('Q: Can I install anti-virus software on my Amazon AppStream 2.0 image to secure my applications?', 'You can install any tools, including anti-virus programs on your AppStream 2.0 image. However, you need to ensure that these applications do not block access to the AppStream 2.0 service. We recommend testing your applications before publishing them to your users.'), ('Q: Can I customize the operating system using group policies?', 'Any changes that are made to the image using Image Builder through local group policies will be reflected in your AppStream 2.0 images. Any customizations outside of local group policies are not currently supported.'), ('Q: How will my Amazon AppStream 2.0 images be updated with updates from the AppStream 2.0 service?', 'AppStream 2.0 regularly releases base images that include Microsoft Windows operating system updates and AppStream 2.0 agent updates. The AppStream 2.0 agent software runs on your streaming instances and enables your users to stream applications. When you create a new image, the Always use latest agent version\xa0option is selected by default. When this option is selected, any new image builder or fleet instance that is launched from your image will always use the latest AppStream 2.0 agent version. If you deselect this option, your image will use the agent version you selected when you launched the image builder. Windows operating system updates are released only through base images. To keep your operating system updated in your images, you need to rebuild your images using the latest AWS base image.  Q: How will my Amazon AppStream 2.0 images be updated with Windows updates from Microsoft?'), ('You will need to create new AppStream 2.0 images to apply Windows updates. To do this, you can create a new image builder instance from an existing image, apply Microsoft updates, and create a new image. Existing streaming instances will be replaced with instances launched from the new image within 16 hours or immediately after users have disconnected from them, whichever is earlier. You can immediately replace all the instances in the fleet with instances launched from the latest image by stopping the fleet, changing the image used, and starting it again.', 'Q: How do I update my applications in an existing image?'), ('To update applications on the image, or to add new applications, launch Image Builder using an existing image, update your applications and create a new image. Existing streaming instances will be replaced with instances launched from the new image within 16 hours or immediately after users have disconnected from them, whichever is earlier. You can immediately replace all the instances in the fleet with instances launched from the latest image by stopping the fleet, changing the image used, and starting it again.', 'Q: Can I connect my Amazon AppStream 2.0 applications to my existing resources, such as a licensing server?'), ('Yes. Amazon AppStream 2.0 allows you to launch streaming instances (fleets and image builders) in your VPC, which means you can control access to your existing resources from your AppStream 2.0 applications.\xa0For more information, see\xa0Network Settings for Fleet and Image Builder Instances.', 'Q: Does Amazon AppStream 2.0 offer GPU-accelerated instances?'), ('Yes. Amazon AppStream 2.0 offers Graphics Design, Graphics Desktop and Graphics Pro instance families.', 'Graphics Design instances are ideal for delivering applications such as Adobe Premiere Pro, Autodesk Revit, and Siemens NX that rely on hardware acceleration of DirectX, OpenGL, or OpenCL. Powered by AMD FirePro S7150x2 Server GPUs and equipped with AMD Multiuser GPU technology, instances start from 2 vCPU, 7.5 GiB system memory, and 1 GiB graphics memory, to 16 vCPUs, 61 GiB system memory, and 8 GiB graphics memory.'), ('The Graphics Desktop instance family offers a single instance type with an NVIDIA GPU based on K520 with 1,536 CUDA cores, 8 vCPUs, 15 GiB system memory, and 4 GiB graphics memory. This instance type is ideal for running desktop graphics applications such as Siemens NX, SolidWorks, ESRI ArcGIS, and other applications that use DirectX, OpenGL, OpenCL, and CUDA. The Graphics Desktop family is a powerful yet economical choice, with pricing that starts at tens-of-cents per hour.', "The Graphics Pro instance family offers three different instance types to support the most demanding graphics applications. Powered by NVIDIA Tesla M60 GPUs with 2048 parallel processing cores, there are three Graphics Pro instances types starting from 16 vCPUs, 122 GiB system memory, and 8 GiB graphics memory, to 64 vCPUs, 488 GiB system memory, and 32 GiB graphics memory. These instance types are ideal for graphic workloads that need a massive amount of parallel processing power for 3D rendering, visualization, and video encoding, including applications such as Petrel from Schlumberger Software, Landmark's DecisionSpace, or MotionDSP's Ikena. For more information on available instance types and pricing, see\xa0Amazon AppStream 2.0 Pricing.\xa0"), ('Q: What is the maximum screen resolution for Amazon AppStream 2.0 Graphics Desktop and Graphics Pro instances?', 'Amazon AppStream 2.0 Graphics Design, Graphics Pro and Graphics Desktop instances support a maximum resolution of 2560x1440. '), ('Q: How many monitors can I use with my Amazon AppStream 2.0 Graphics Desktop and Graphics Pro instances?', 'Currently you can only use a single monitor with your Amazon AppStream 2.0 Graphics Desktop and Graphics Pro instances. '), ('Q: What\xa0types of fleets are available with Amazon AppStream 2.0?', 'Amazon AppStream 2.0 offers two fleet types: Always-On and On-Demand. Always-On fleet instances are in a running state, even if no users are connected. This is best when your users need high availability and instant access to their applications. On-Demand fleets instances don’t start until a user connects to an instance within the fleet. This fleet type is best when your users can wait up to 2 minutes to start their applications, and for streaming applications that have sporadic use.'), ('Q: Can I switch my Amazon AppStream 2.0 Always-On fleet to On-Demand or vice versa?', 'You can only specify the fleet type when you create a new fleet, and you cannot change the fleet type once the fleet has been created. \xa0'), ('Q:\xa0What are the benefits to Always-On and On-Demand fleets for Amazon AppStream 2.0?', 'Always-On fleets are best for when your users need high availability and instant access to their applications. On-Demand fleets instances don’t start until a user connects to an instance within the fleet, and is best for when your users can wait up to 2 minutes to start their applications, and for streaming applications that have sporadic use.'), ('Q: What client operating systems are supported?', 'Amazon AppStream 2.0 can stream your applications to HTML5-capable browsers, including the latest versions of Google Chrome, Mozilla Firefox, Microsoft Internet Explorer, and Microsoft Edge, on desktop devices, including Windows, Mac, Chromebooks, and Linux PCs.'), ('Q: What server operating system is supported?', 'Amazon AppStream 2.0 supports streaming applications that can execute on the Windows Server 2012 R2, a 64-bit operating system. You can add support for 32-bit applications by using the WoW64 extensions. If your application has other dependencies, such as the .NET framework, include those dependencies in your application installer.'), ('Q: Which AWS regions does Amazon AppStream 2.0 support?', 'Please refer to the AWS Regional Products and Services page for details of Amazon AppStream 2.0 service availability by region'), ('Q: What instance types are available to use with my Amazon AppStream 2.0 fleet?', 'Amazon AppStream 2.0 provides a menu of instance types for configuring a fleet. You can select the instance type that best matches your applications and end-user requirements. You can choose from General Purpose, Compute Optimized, Memory Optimized, Graphics Design, Graphics Desktop, or Graphics Pro instance families. '), ('Q: How does Amazon AppStream 2.0 scale?', 'Amazon AppStream 2.0 uses Fleet Auto Scaling to launch Amazon AppStream 2.0 instances running your application and to adjust the number of servers to match the demand for end-user sessions. Each end-user session runs on a separate instance, and all the apps that are streamed within a session run on the same instance. An instance is used to stream applications for only one user, and is replaced with a new instance at the end of the session.'), ('Q: What scaling policy does Amazon AppStream 2.0 support?', 'Amazon AppStream 2.0 supports fixed and dynamic scaling policies. Use a fixed scaling policy to keep a constant number of Amazon AppStream 2.0 instances and users who can start a streaming session. Use a dynamic scaling policy to scale based on the use of Amazon AppStream 2.0 instances in your environment.'), ('Q: What is an Amazon AppStream 2.0 Fleet Auto Scaling policy?', 'A Fleet Auto Scaling policy is a dynamic scaling policy that allows you to scale the size of your fleet to match the supply of available instances to user demand. You can define scaling policies that adjust the size of your fleet automatically based on a variety of utilization metrics, and optimize the number of running instances to match user demand.'), ('Q: How can I create auto scaling policies for my Amazon AppStream 2.0 fleet?', 'You can create automatic scaling policies from the Fleets tab in the AppStream 2.0 console, or by using the AWS SDK.'), ('Q: Which Amazon AppStream 2.0 CloudWatch metrics can I use to build Fleet Auto Scaling polices?', 'You can use the following metrics to build your Fleet Auto Scaling policies:'), ('• Capacity utilization: you can scale your fleet based on the percentage of instances in your fleet that are being used • Available capacity: you can scale your fleet based on the number of available instances in your fleet • Insufficient capacity error: you can provision new instances when users can’t start streaming sessions due to lack of capacity', 'For more information, please see Fleet Auto Scaling for Amazon AppStream 2.0.'), ('Q: Can my Amazon AppStream 2.0 fleet have more than one associated Fleet Auto Scaling policy?', 'Yes. You can have up to 50 Fleet Auto Scaling policies associated with a single fleet. Each policy allows you to set a single criteria and action for resizing your fleet.\xa0'), ('Q: What is the minimum size I can set for my Amazon AppStream 2.0 fleet when using Fleet Auto Scaling policies?', 'You can set your Fleet Auto Scaling policies to scale in to zero instances. Scaling policies associated with your fleet decrease fleet capacity until it reaches your defined minimum, or the default setting of one if you haven’t set a minimum. For more information, please see Fleet Auto Scaling for Amazon AppStream 2.0.'), ('Q: What is the maximum size I can set for my Amazon AppStream 2.0 fleet when using Fleet Auto Scaling policies?', 'Fleet Auto Scaling policies increase fleet capacity until it reaches your defined maximum size or until service limits apply. For more information, please see Fleet Auto Scaling for Amazon AppStream 2.0. For service limit information, please see Amazon AppStream 2.0 Service Limits.'), ('Q: Are there additional costs for using Fleet Auto Scaling policies with Amazon AppStream 2.0 fleets?', 'There are no charges for using Fleet Auto Scaling policies. However, each CloudWatch alarm that you create and use to trigger scaling policies for your AppStream 2.0 fleets may incur additional CloudWatch charges. For more information, see Amazon CloudWatch Pricing. \xa0'), ('Q:\xa0Does Amazon AppStream 2.0 offer persistent storage so that I can save and access files between sessions?', 'Yes. Users can store and retrieve their files between their application streaming sessions using persistent storage, backed by\xa0Amazon S3. Users can access a home folder on their streaming instance, and save content in this folder for use between streaming sessions. Users can also download and upload files in the home folder directly from their web browser, when connected to a streaming session. All files are stored in an S3 bucket which is automatically created in your AWS account.'), ('Q: How do users access persistent storage from their Amazon AppStream 2.0 sessions?', 'Users can access a home folder during their application streaming session. Any file they save to their home folder will be available for use in the future.'), ('Q: How are files in the home folder persisted?', 'A home folder is created for a user the first time a user launches a streaming session. When connected to the streaming session, each file that is saved by the user to his home folder is synced to Amazon S3. Files are stored as S3 objects within the S3 bucket that is created for your AWS account in the same region. When a user connects to a new session, the home folder, along with all the files saved previously, will be available to open from any application on the streaming instance.'), ('Q: What are the charges for enabling home folders storage for my AppStream 2.0 stacks?', 'There are no additional AppStream 2.0 charges to use this feature. However standard S3 data storage charges will apply when your users save files in their home folder. For more information, see\xa0Amazon S3 Pricing.'), ('Q: How much data can I store in the bucket created for Home Folders?', 'The total volume of data that can be stored within an S3 bucket is unlimited. The largest recommended file size to save in a home folder is 5 gigabytes.'), ('Q: What kind of data can users store in Home Folder?', 'Your users can store any documents, spreadsheets, or other project files they would usually create using a desktop application. However, since the files are individually synced to Amazon S3 on a frequent basis, we recommend not saving large database files or email archive files to your Home Folder.'), ('Q: What are the pre-requisites for using home folders?', 'Before enabling home folders for a stack, you need to create an image from an AppStream 2.0 image published by AWS on or after May 18th 2017. You will also need to enable Internet access from the fleet associated with a stack or configure your Amazon VPC S3 endpoint for AppStream 2.0 access. For more details, please see\xa0Before Enabling Home Folders.'), ('Q: Can users access their home folder files when they are not connected to an application streaming sessions?', 'No. Users cannot access their files when they are not connected to an application streaming session.'), ('Q: Do administrators have access to user content stored in Home Folders?', 'Administrators who can access the Amazon S3 bucket created by Amazon AppStream 2.0 can view and modify content that is part of users’ Home Folders. To restrict administrator access to the S3 bucket containing users’ files, we recommend applying an S3 bucket access policy based on the policy template, please see\xa0Restricting Administrator Access to the Amazon S3 Bucket for Home Folders for more information.'), ('Q: How do I monitor usage of my Amazon AppStream 2.0 fleet resources?', 'There are two ways you can monitor your Amazon AppStream 2.0 fleet. First, the AppStream 2.0 console provides a lightweight, real-time view of the state of your AppStream 2.0 fleet, and offers up to two weeks of historical usage data. Metrics are displayed automatically, and don’t require any setup.'), ('Second, you can access AppStream 2.0 metrics using CloudWatch. The CloudWatch console allows you to specify reporting intervals, create custom dashboards and graphs, and set alarms.', 'To learn more, see Monitoring Amazon AppStream 2.0 Resources.'), ('Q: What information can I get from the Amazon AppStream 2.0 usage metrics?', 'You can see the size of your Amazon AppStream 2.0 fleet, the number of running instances, the number of instances available to accept new connections, and the utilization of your fleet. You can track these metrics over time so that you can optimize your fleet settings to suit your needs.'), ('Using Amazon CloudWatch, you can also set alarms to notify you of changes to your fleet, or when there is insufficient capacity to support your users.', 'For the complete list of available metrics, see Monitoring Amazon AppStream 2.0 Resources.\xa0'), ('Q: Can I create custom Amazon CloudWatch metrics for Amazon AppStream 2.0?', 'Yes, you can create custom metrics for Amazon AppStream 2.0. For more information, see Publish Custom Metrics.'), ('Q: How frequently are Amazon AppStream 2.0 metrics published to Amazon CloudWatch?', 'Amazon AppStream 2.0 sends metrics to Amazon CloudWatch every 1 minute. The metrics are stored in CloudWatch using the standard retention policy. For more information, see Amazon CloudWatch FAQs.'), ('Q: How do I create CloudWatch alarms for Amazon AppStream 2.0?', 'You can create Amazon CloudWatch alarms for Amazon AppStream 2.0 using the CloudWatch console or the CloudWatch APIs.'), ('Q: Are there additional costs for using CloudWatch metrics with Amazon AppStream 2.0?', 'There is no additional charge for viewing CloudWatch metrics for AppStream 2.0. You may incur additional charges for setting up CloudWatch alarms and retrieving metrics via the CloudWatch APIs. For more information, see Amazon CloudWatch Pricing.'), ('Q: Does Amazon AppStream 2.0 offer a set of public APIs?', 'Yes, Amazon AppStream 2.0 includes APIs that you can use to easily integrate and extend the service. The APIs enable you to create, update, and delete Amazon AppStream 2.0 resources, and provide detailed information about resource states. You can create URLs for administrators to connect to their image builders to install applications, and create URLs for users to access their AppStream 2.0 applications. See our API reference for more information'), (' \xa0', 'Q: What streaming protocol does Amazon AppStream 2.0 use?'), ('Amazon AppStream 2.0 uses NICE DCV to stream your applications to your users. NICE DCV is a proprietary protocol used to stream high-quality, application video over varying network conditions. It streams video and audio encoded using standard H.264 over HTTPS. The protocol also captures user input and sends it over HTTPS back to the applications being streamed from the cloud. Network conditions are constantly measured during this process and information is sent back to the encoder on the server. The server dynamically responds by altering the video and audio encoding in real time to produce a high-quality stream for a wide variety of applications and network conditions.', 'Q: What is the maximum network latency recommended while accessing Amazon AppStream 2.0?'), ('While the remoting protocol has a maximum round-trip latency recommendation of 250 ms, the best user experience is achieved at less than 100 ms. If you are located more than 2000 miles from the AWS Regions where Amazon AppStream 2.0 is currently available, you can still use the service, but your experience may be less responsive. The easiest way to check performance is to use the Amazon AppStream 2.0 Try It Now experience. ', 'Q: How do I restrict network access from fleets and image builders launched in my VPC?'), ('Security groups enable you to specify network traffic that is allowed between your streaming instances and resources in your VPC. You can restrict network access by assigning an image builder or fleet to the security groups in your VPC. For more information, refer to Security Group for Your VPC.', 'Q: Can I use existing VPC security groups to secure AppStream 2.0 fleets and image builders?'), ('Yes. You can assign an image builder or fleet to existing security groups in your VPC.', 'Q: How many security groups can I apply to a fleet or image builder?'), ('You can assign an image builder or fleet to up to five security groups.', 'Q: Can I change the security groups to which my fleets are assigned after they have been created?'), ('Yes. You can change the security groups to which your fleets are assigned, so long as they are in the stopped status. ', 'You can also change the rules of a security group in your VPC at any time using the Amazon EC2 console. Note that the new rules will apply to all resources assigned to that security group. For more information, refer to Security Groups for your VPC.'), ('Q: Can I change the security groups to which my image builders are assigned after they have been created?', 'No. You cannot change the security groups to which your fleets are assigned after they have been created. To assign an image builder to a different security groups, you will need to create a new image builder.\xa0'), ('You can also change the rules of a security group in your VPC at any time using the Amazon EC2 console. Note that the new rules will apply to all resources assigned to that security group. For more information, refer to Security Groups for your VPC. ', 'Q: How is the data from my streamed application encrypted to the client?'), ('The streamed video and user inputs are sent over HTTPS and are SSL-encrypted between the Amazon AppStream 2.0 instance executing your applications, and your end users.', 'Q: How do I authenticate users with Amazon AppStream 2.0 applications?'), ('There are three options to authenticate users with Amazon AppStream 2.0: you can use built-in user management, you can build a custom identity, or you can set up federated access using SAML 2.0.', 'When using built-in user management, you can set up and manage your users in the AppStream 2.0 management console from the User Pool tab. To add a new user, all you need is their first and last name, and an e-mail address. To learn more about user management within AppStream 2.0, see\xa0Using the AppStream 2.0 User Pool.'), ('When using federated sign-in to authenticate users, you will set up identity federation using SAML 2.0, which allows you to use your existing user directory to control access to applications available via AppStream 2.0. For details on setting up SAML integration, see the steps outlined here.', 'When building an entitlement service, you should authenticate users either with a custom identity or by using a service such as Login with Amazon. After your custom identity has authenticated a user, it should call into Amazon AppStream 2.0 to create a new streaming URL. AppStream 2.0 returns a URL for the session that can be opened in a browser to start the streaming session. '), ('Q: Can I use Amazon AppStream 2.0 with my existing user directory, including Microsoft Active Directory?', 'Yes. Amazon AppStream 2.0 supports identity federation using SAML 2.0, which allows you to use your existing user directory to manage end user access to your AppStream 2.0 apps. For details on setting up SAML integration, see the steps outlined here. '), ('Q: What type of identity federation does Amazon AppStream 2.0 support?', 'Amazon AppStream 2.0 supports federation using SAML 2.0 (Identity Provider initiated). This type of federated access allows a user to sign in by first authenticating with an identity federation provider, after which they can access their AppStream 2.0 apps. '), ('Q: What are the requirements for setting up identity federation with Amazon AppStream 2.0?', 'To configure identity federation with Amazon AppStream 2.0, you need a SAML 2.0 Identity Provider that links to an existing LDAP-compatible directory, such as Microsoft Active Directory. Microsoft Active Directory Federation Services (ADFS), Ping Identity, Okta, and Shibboleth, are all examples of SAML 2.0 Identity Providers that will work with AppStream 2.0. '), ('Q: Can I control which users access my Amazon AppStream 2.0?', 'Yes. When using built-in user management, you can control which users have access to your Amazon AppStream 2.0 stacks in the User Pool tab of the AppStream 2.0 management console. To learn more about user management within AppStream 2.0, see Using the AppStream 2.0 User Pool.\xa0'), ('When you use SAML 2.0, you can control which users have access to your Amazon AppStream 2.0 stacks by mapping the users in your federation service to the IAM role that has access permissions to the stack. Please refer to the AppStream 2.0 documentation for detailed information and step-by-step guidelines for popular federation services. ', 'Q: Can I enable multi-factor authentication for my users?'), ('Yes. You can enable Multi-Factor Authentication when using federation with SAML 2.0 or when using your own entitlement service. ', 'Q: Can users choose which Amazon AppStream 2.0 stack they want to access during signing-in?'), ('Yes. You can setup every Amazon AppStream 2.0 stack as an entity or a package in your federation service. This allows your users to select which stack they want to access while signing in from your application portal. \xa0', 'Q: Who can access the management console for my Amazon AppStream 2.0 application?'), ('You can use AWS Identity and Access Management (IAM) to add users to your AWS account and grant them access to view and manage your Amazon AppStream 2.0 application. For more information, see “What is IAM?” in the IAM User Guide. ', 'Q: Can I join Amazon AppStream 2.0 image builders to Microsoft Active Directory domains?'), ('Yes, Amazon AppStream 2.0 images can be joined to your Microsoft Active Directory domains. This allows you to apply your existing AD policies to your streaming instances, and provides your users with single sign on access to Intranet sites, file shares, and network printers from within their applications. Your users are authenticated using a SAML 2.0 provider of your choice, and can access applications that require a connection to your AD domain. ', 'Q: What Microsoft Active Directory versions are supported?'), ('Microsoft Active Directory Domain Functional Level Windows Server 2008 R2 and newer are supported by Amazon AppStream 2.0.', 'Q: Which AWS Directory Services directory options are supported by Amazon AppStream 2.0?'), ('Amazon AppStream 2.0 supports AWS Directory Services Microsoft AD. Other options such as AD Connector and Simple AD are not supported. To learn more about AWS Microsoft AD see\xa0What Is AWS Directory Service. ', 'Q: How do I join my Amazon AppStream 2.0 instances to my Microsoft Active Directory domain?'), ('To get started you will need a Microsoft Active Directory domain that is accessible from an Amazon VPC, the credentials of a user with authority to join the domain, and the domain Organizational Unit (OU) you want to join to your fleet. For more information, see Using Active Directory Domains with AppStream 2.0.\xa0', 'Q: Can I use my existing Organization Units (OU) structure with Amazon AppStream 2.0?'), ('Yes, you can use your existing Organizational Unit (OU) structure with Amazon AppStream 2.0. To learn more, see\xa0Using Active Directory Domains with AppStream 2.0.', 'Q: What gets joined to my Microsoft Active Directory domain by Amazon AppStream 2.0?'), ('Amazon AppStream 2.0 will automatically create a unique computer object for every image builder and fleet instance you configure to be joined to your Microsoft Active Directory domain.', 'Q: How can I identify Amazon AppStream 2.0 computer objects in my Microsoft Active Directory domain?'), ('Amazon AppStream 2.0 computer objects are only be created in the Microsoft Active Directory Organization Unit (OU) you specify. The description field indicates that the object is an AppStream 2.0 instance, and to which fleet the object belongs. To learn more, see Using Active Directory Domains with AppStream 2.0.', 'Q: How are computer objects that are created by Amazon AppStream 2.0 deleted from my Microsoft Active Directory domain?'), ('Computer objects created by Amazon AppStream 2.0 that are no longer used will remain in your Active Directory (AD) if the AppStream 2.0 fleet or image builder is deleted, you update a fleet or image builder to a new OU, or select a different AD. To remove unused objects you will have to delete them manually from your AD domain. To learn more, see Using Active Directory Domains with AppStream 2.0.', 'Q: How do I provide users with access to Amazon AppStream 2.0 streaming instances that are joined to a Microsoft Active Directory domain? '), ('To enable user access, you will need to set up federated access using a SAML 2.0 provider of your choice. This allows you to use your existing user directory to control access to streaming applications available via Amazon AppStream 2.0. For details on setting up SAML 2.0 integration, see the steps outlined at Setting Up SAML.', 'Q: Can I connect my users that are managed through User Pools to my Active Directory domain?'), ('No. At this time we do not support User Pools users connecting to domain joined resources. To learn more about User Pools see, Using the AppStream 2.0 User Pool.', 'Q: How much does Amazon AppStream 2.0 cost?'), ('You are charged for the streaming resources in your Amazon AppStream 2.0 environment, and monthly user fees per unique authorized user accessing applications via Amazon AppStream 2.0. You pay for these on-demand, and never have to make any long-term commitments.', 'The streaming resources consist of Amazon AppStream 2.0 instances in your Amazon AppStream 2.0 fleet as well as image builder instances. You have the option to have Always-On and On-Demand fleets. For Always-On fleets you pay for instances in your fleet that are running, even if users are not connected. These instances are billed per hour, and the price per hour is based on the instance type you select. For On-Demand fleets you pay for the instances in your fleet that are running only when a user is connected. These instances are billed per hour, and the price per hour is based on the instance type you select. In an On-Demand fleet If an instance is running but not connected to a user, you pay a nominal hourly On-Demand Stopped Instance fee, which is the same for all instance types within a region. Image builder instances are only available as always on, and you pay for instances that are running, even if users are not connected. The charge for Always-On and On-Demand fleet instances as well as image builder instances includes the cost of the storage volumes used by the Amazon AppStream 2.0 image, and outbound bandwidth used by the streaming protocol.'), ('You can control the number of running instances using fixed or dynamic scaling policies.', 'The monthly user fee is used to pay for the Microsoft Remote Desktop Services Subscriber Access License (RDS SAL). This fee is charged per unique authorized user, and is charged in full (not pro-rated), regardless of when a user first accesses Amazon AppStream 2.0 in that month. Schools, universities, and public institutions may qualify for reduced user fees. Please reference the Microsoft Licensing Terms and Documents for qualification requirements. If you think you may qualify, please contact us. We will review your information and work with you to reduce your Microsoft RDS SAL fee. There is no user fee incurred when using image builder instances. For more details, view the Amazon AppStream 2.0 pricing page.'), ('Q: Can I bring my own licenses and waive the user fees?', 'Yes. If you have Microsoft License Mobility, you may be eligible to bring your own Microsoft RDS CAL licenses and use them with Amazon AppStream 2.0. For users covered with your own licenses, you won’t incur the monthly user fees. For more information about using your existing Microsoft RDS SAL licenses with Amazon AppStream 2.0, please visit this page, or consult with your Microsoft representative.'), ('Q: What are the requirements for schools, universities, and public institutions to reduce their user fee? ', 'Schools, universities, and public institutions may qualify for reduced user fees. Please reference the Microsoft Licensing Terms and Documents\xa0for qualification requirements. If you think you may qualify, please contact us. We will review your information and work with you to reduce your Microsoft RDS SAL fee. There is no user fee incurred when using image builder instances.\xa0'), ('Q: What do I need to provide to qualify as a school, university, or public institution?', "You will need to provide AWS your institution's full legal name, principal office address, and public website URL. AWS will use this information to qualify you for AppStream 2.0's reduced user fees for qualified educational institutions. Please note: The use of Microsoft software is subject to Microsoft’s terms. You are responsible for complying with Microsoft licensing. If you have questions about your licensing or rights to Microsoft software, please consult your legal team, Microsoft, or your Microsoft reseller. You agree that we may provide the information to Microsoft in order to apply educational pricing to your Amazon AppStream 2.0 usage."), ("Q. Does qualification for Amazon AppStream 2.0's reduced RDS SAL user fees affect other AWS cloud services?\xa0", 'No, your user fees are specific to Amazon AppStream 2.0, and do not affect any other AWS cloud services or licenses you have.\xa0'), ('Q: Can I use tags to obtain usage and cost details for Amazon AppStream 2.0 on my AWS monthly billing report?', 'Yes. When you set tags to appear on your monthly Cost Allocation Report, your AWS monthly bill will also include those tags. You can then easily track costs according to your needs. To do this, first assign tags to your Amazon AppStream 2.0 resources by following the steps in Tagging Your AppStream 2.0 Resources. Next, select the tag keys to include in your cost allocation report by following the steps in Setting Up Your Monthly Cost Allocation Report.'), ('Q: Are there any costs associated with tagging Amazon AppStream 2.0 resources?', 'There are no additional costs when using tags with Amazon AppStream 2.0. \xa0'), ('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/iot/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/iot-platform/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/greengrass/faqs/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/iotbutton/faq/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/connect/faqs/': [('Q: What is Amazon Connect?', 'Amazon Connect is a self-service, cloud-based contact center service that makes it easy for any business to deliver better customer service at lower cost.'), ('Q: What else should I know about Amazon Connect?', 'Amazon Connect is based on the same contact center technology used by Amazon customer service associates around the world to power millions of customer conversations. Setting up a cloud-based contact center with Amazon Connect is as easy as a few clicks in the AWS Management Console, and agents can begin taking calls within minutes. There are no up-front payments or long-term commitments and no infrastructure to manage with Amazon Connect. You pay only for the time your customers are connected to the service and for the telephony used. You can get started by visiting the Amazon Connect console.\xa0'), ('Q: Can I really setup Amazon Connect in minutes?', 'Yes. We encourage you to go to the Amazon Connect console\xa0and set up an Amazon Connect Virtual Contact Center now.'), ('Q: In which countries does Amazon Connect offer phone numbers?', 'Amazon Connect offers phone numbers in the US and more than 20 countries worldwide. For more details on available numbers see Amazon Connect Pricing. \xa0'), ('Q: Who should use Amazon Connect?', 'If you’re looking to improve your contact center experience, regardless of size, you can benefit from using Amazon Connect, and the scalable, open, dynamic, and easy, self-service configuration.'), ('Q: Do you have examples of how customers are already using Amazon Connect?', 'Yes. Please see the Amazon Connect website. '), ('Q: How can I try Amazon Connect?', 'Amazon Connect is self-service so you can try before you buy, without talking to sales, completing RFPs, or hiring for consultants or professional services. Simply log in to the AWS Console using your AWS account and set up an Amazon Connect instance.'), ('Q: Is there a free trial for Amazon Connect?', 'Yes. You have access to the following features for free each month for the first 12 months that you use the service:'), ('• 90 minutes per month of Amazon Connect usage • A local direct inward dial (DID) number for the AWS region • 30 minutes per month of local\xa0(to the AWS region) inbound DID calls • 30 minutes per month of local\xa0(to the AWS region) outbound calls • For US regions, a US toll-free number for use per month and 30 minutes per month of US inbound toll-free calls', 'For any additional usage, you will be charged at the published Amazon Connect pricing.'), ('To start your free trial, create an Amazon Connect instance in your AWS account and start using the service.', 'Q: How do I set up an instance of Amazon Connect?'), ('Log in to the AWS Console, launch Amazon Connect, and complete the following steps:', '1. Select a Directory 2. Create an Administrator 3. Select Telephony Options 4. Set a Storage Location 5. Review and Confirm 6. Claim a phone number 7. Place a test call'), ('When you create a user make sure it has admin privileges so you can perform additional configurations.', 'Q: What are the basics for configuring an Amazon Connect instance for my business?'), ('Log in to your Amazon Connect instance as the user you created with admin privileges and configure the following:', '1. Claim a phone number (if you haven’t already done so) 2. Set up hours of operations 3. Create queues which manage how your agents handle contacts 4. Record prompts that will be played to customers 5. Create contact flows to define the experiences your customers will have when they contact you\xa0 6. Create routing profiles so you can configure and prioritize the queues your agents will handle contacts from 7. Add your users and assign them routing profiles and (optional) permissions'), ('Q: What is an Amazon Connect instance?', 'An Amazon Connect instance is a virtual contact center. It is 100% cloud-based and can scale to support any sized business. Note: An Amazon Connect instance is not aligned to an EC2 instance or any other hardware concept.'), ('Q: What is the benefit of being 100% cloud-based?', 'Because Amazon Connect is 100% cloud-based:'), ('• Managers and agents can use it anywhere as long as they have an internet connection and a supported browser. • You don’t need to manage hardware, space, or telephony infrastructure. • You don’t need to plan for scaling up or down. The system is elastic and will grow and shrink as you need.', 'Q: How does Amazon Connect stay available? '), ('Amazon Connect stays available by using multiple Availability Zones in an AWS Region to provide fault tolerance if there is a server failure or Availability Zone outage. Amazon Connect uses multiple, redundant paths to telecom carriers to ensure that calls can continue to be established if there is a failure or circuit issue. In regions where they are available, redundant carriers are used, and we continuously add carriers and paths to ensure that we deliver a high-quality experience. Software updates are performed regularly, and there are no scheduled outages.', 'Q: Is Amazon Connect scalable?'), ('Yes, the technology that powers Amazon Connect has been proven to scale with the needs of Amazon’s award winning customer service. It’s in use by teams ranging from ten to tens of thousands of agents.', 'Q: Which browsers are supported?'), ('Amazon Connect requires WebRTC to enable communications. The following browsers are supported:', 'The version number is listed underneath the Firefox name.'), ('Q: Where is Amazon Connect hosted?', 'You can see where Amazon Cconnect is hosted by visiting AWS Region Table.\xa0'), ('Q: Which languages does Amazon Connect support? ', 'Amazon Connect supports the following eight languages: English, Spanish, French, Brazilian Portuguese, Korean, German, Simplified Chinese, and Japanese. You are provided a localized view when accessing the Amazon Connect management console, as well as your Amazon Connect contact center instances.'), ('Q: Is Amazon Connect PCI DSS compliant?', 'Yes Amazon Connect is certified as Payment Card Industry Data Security Standard (PCI DSS) compliant as of June 30th, 2017. Amazon Web Services (AWS) has successfully completed the 2017-2018 PCI DSS v3.2 assessment. The covered AWS services that are already PCI DSS compliant can be found within AWS Services in Scope by Compliance Program.'), ('AWS being a PCI DSS Compliant Service Provider means that customers who use AWS products and services to store, process or transmit cardholder data can rely on our technology infrastructure as they manage their own PCI DSS compliance certification.', 'Q: How do I access the PCI DSS Compliance Package?'), ('The PCI DSS 3.2 Compliance Package can be downloaded now through AWS Artifact in the AWS Management Console. To download the package:', '1. Sign in to your AWS account.'), ('2. In the list of services under Security, Identity & Compliance, choose Artifact. On the next page, choose PCI DSS Attestation of Compliance (AOC) and Responsibility Summary – Current.', 'Q: Is Amazon Connect HIPAA eligible?'), ('Yes Amazon Connect is HIPAA eligible. If you have an executed Business Associate Agreement (BAA) with Amazon Web Services (AWS), you can now use Amazon Connect to handle contacts containing protected health information (PHI). HIPAA eligibility applies to all AWS Regions where Amazon Connect is available. For more information about HIPAA-eligible services on AWS, see our HIPAA Compliance page. \xa0', 'Q: How do I execute a Business Associate Agreement with Amazon Web Services? '), ('If you don’t have an executed Business Associate Agreement (BAA) with Amazon Web Services (AWS), please contact us and we will put you in touch with an AWS Business Representative.', 'Q: How do I add Amazon Connect users such as agents, managers, and operators?'), ('You can add users from Amazon Connect’s user management page and configure them with appropriate permissions for their role.', 'Q: Can I use an external directory like a Microsoft Active Directory to authenticate users when accessing Amazon Connect?'), ('Yes, you can configure Amazon Connect to authenticate users against your Microsoft Active Directory. The users you add in Amazon Connect must already exist in the directory.', 'Q: Do I have to use an external directory?'), ('No. Amazon Connect can manage users, but note that they won’t be accessible or manageable outside of Amazon Connect’s user experience.', 'Q: Can I use my existing Amazon.com account with Amazon Connect?'), ('No. You must have an Amazon Connect user account or AWS IAM account.', 'Q: Can I access Amazon Connect with an AWS IAM account?'), ('Yes. Start by logging into the AWS Management Console and then choose Amazon Connect from the Services list. Choose the instance you want to launch. You’ll be federated in as a Amazon Connect user and will have all security privileges within your instance. The intent of federated users is to perform tasks such as initial setup or troubleshooting of configuration, not general use.', 'Q: What are the limitations of AWS IAM federated users in Amazon Connect?'), ('You cannot apply permissions to federated IAM users. Federation is not recommended for typical Amazon Connect use cases. It’s recommended that nearly all users, including system operators, administrators, contact center managers, and agents, use an Amazon Connect account.', 'Q: I’m an end user. Where can I learn more about using Amazon Connect?'), ('To learn more about Amazon Connect please see the User Guide.\xa0 ', 'Q: How do end-customers interact with Amazon Connect?'), ('Amazon Connect supports voice interactions for incoming and outgoing PSTN telephony (provided by AMCS LLC). It supports DTMF input, text-to-speech output using Amazon Polly, which can optionally be combined with Amazon Lex for natural language interactions.\xa0', 'Q: How do agents interact with Amazon Connect?'), ('Agents use the Contact Control Panel (CCP) to control their interactions, such as answering calls, dialing out, or setting their status. For agent voice communications, Amazon Connect includes a web-based softphone for incoming and outgoing telephony, or agents can use a traditional telephone service using the PSTN. ', 'Q: Does the softphone offer reliable, high quality voice communications?'), ('Yes, the Amazon Connect softphone leverages WebRTC and the Opus audio codec to enable high quality audio which is highly resilient to packet loss and jitter.', 'Q: Do I need to bring my own telephony provider to use Amazon Connect?'), ('No, Amazon Connect includes all the telecommunication infrastructure you need (provided by AMCS LLC). Just create an Amazon Connect instance and you can start taking and making calls. External telephony providers are not supported.', 'Q: Do I need to reserve or purchase telephony capacity with Amazon Connect?'), ('No, Amazon Connect is designed to scale to your telephony needs.', 'Q: Does Amazon Connect support porting for US phone numbers?'), ('Yes, we support porting for US telephone numbers. Please open an AWS support ticket to request number porting. For more information on our porting process, please see Porting a phone number. \xa0', 'Q: Can I request a number with a specific area code or prefix?'), ('Yes, please open an AWS support ticket to request a number with the area code or prefix you want.\xa0 We will try to accommodate your request. ', 'Q: What is a Contact flow?'), ('Amazon Connect end-customer interactions are enabled via Contact flows. These are similar in concept to Interactive Voice Responder (IVR). Contact flows comprise blocks of functionality such as Play prompt, Branch on customer input, Invoke external functionality, Transfer to queue, Securely take customer sensitive information, or Terminate call. Contact flows determine the automated end-customer experience, and every contact that Amazon Connect handles is processed by at least one Contact flow.', 'Q: What can I do with a Contact flow?'), ('Amazon Connect Contact flows are flexible and extensible. You can use them to play a prompt to a customer, ask a customer a question, make a call to an external data source (a “data dip”), branch to different paths within the Contact flow, and transfer an agent or another Contact flow.', 'Q: Are Contact flows complex?'), ('Most Contact flows are short and straightforward to create or examine. However, you can also construct complex Contact flows to offer many branches and dynamically adapt the customer experience.', 'Q: Can I link Contact flows?'), ('Yes. By doing so you can create smaller, more manageable contacts flows and reuse the same Contact flow functions in multiple end-customer experiences. This provides consistency and allows easy updating from a single point.', 'Q: How do I edit Amazon Connect Contact flows?'), ('Contact flows are based on a simple drag and drop graphical user interface (GUI) in the Amazon Connect console.', 'Q: Is there version control?'), ('Yes. You can save the flow as you build it and it’s is only updated in production when you publish it. You can revert to the most recent published version and also Save as to create a new flow built on a published Contact flow while maintaining the published one.', 'Q: Can Contact flows be imported or exported?'), ("No contact flows can't be imported or exported.", 'Q: Does Amazon Connect offer text-to-speech in Contact flows?'), ('Yes, Amazon Connect has built in text-to-speech leveraging Amazon Polly. You can access all the languages and voices offered by Amazon Polly.', 'Q: Can I customize the pronunciation of text-to-speech in Contact flows?'), ('Simple Speech Markup Language (SSML) can be used within a Contact flow to allow customizability in what is said, and how it is pronounced.', 'Q: How does Amazon Connect work in regions where Amazon Polly is not available?'), ('In regions where Amazon Polly is not available, your text will be sent to Amazon Polly in a different region and returned as speech. This data is encrypted in transit. Note, this may also introduce some delay. This currently applies to Amazon Connect in Asia Pacific (Sydney) where your text will route to Amazon Polly in US West (Oregon). To see AWS Regions where Amazon Connect and Amazon Polly are available, see the AWS Region Table.', 'Q: Can I disable Amazon Connect from sending text requests to Amazon Polly in a different region?'), ('Yes, you can. To do this, you will need to record and upload your prompts instead of using text-to-speech.', 'Q: Can Amazon Connect Contact flows dynamically adapt based on user input, end-customer history or other data or business intelligence?'), ('Yes. Using AWS Lambda you have the flexibility to run code for virtually any type of application or backend service to make “data dips” into your existing systems and adjust the customer experience in real time.', 'Q: How do I use Amazon Lex chatbots with Amazon Connect?'), ('Customer input received through Amazon Lex is enabled in the same Contact flow block (Get Customer Input), that is used to interact with customers using DMTF. Instead of expressing intent via a button press, customers use natural language, and Amazon Lex returns intents and slots to enable a natural interaction that can be personalized on a per-customer basis.', 'Q: How do I incorporate an Amazon Lex chatbot in my contact flows?'), ('Open Amazon Connect management console and select the instance you want to edit from the Instance Alias list. Choose Contact flows in the left of your screen. To integrate Amazon Lex bots in your contact flows, click on the “+Add bot” link.', 'Q: Is Amazon Lex available in all AWS Regions where I can buy Amazon Connect?'), ("No Amazon Lex is not available in all AWS Regions where I can buy Amazon Connect. In those regions where Amazon Lex is not available, you won't be able to use Amazon Lex chatbots in your contact flows. For a list of the supported Amazon Lex AWS regions, please visit the AWS Region Table.", 'Q: How does contact flow logs work?'), ('Amazon Connect now provides you with contact flow logs for real-time details about events in your contact flows. Contact flows are used to define the path a customer takes to resolve their issue. You can view the contact flow logs to understand what is happening during the interaction, and quickly identify areas for improvement in your contact center. To learn more please see Contact Flow Logs.', 'Q: How do I use contact flow logs? '), ('To use contact flow logs, you need to enable them for your Amazon Connect instance. Once enabled, you can add a Set logging behavior block to your contact flow to enable or disable logging within a flow. You can enable contact flow logs when you create a new Amazon Connect instance when you configure Data storage settings. If you already have an Amazon Connect instance, you can enable them in your AWS console under Contact flows settings for your Amazon Connect instance. Once they are enabled, contact flow logs are created and stored on Amazon CloudWatch, a cloud monitoring service, in the same region as your Amazon Connect instance.', 'A log entry is added as each block or process in your contact flow is executed. You can configure Amazon CloudWatch to send alerts in real-time based on your custom criteria. Contact center managers can aggregate data from the contact flow logs to analyze the performance of contact flows to optimize the experience you provide for your customers. To learn more please see Contact Flow Import/Export. '), ('Q: How much does it cost to use contact flow logs?', 'Contact flow logs do not incur additional Amazon Connect charges, and standard rates for Amazon CloudWatch service usage apply for ingestion and storage of the logs. Please see Amazon CloudWatch Pricing for more information.'), ('Q: How does contact flow import/export (beta) work? ', 'When you export a contact flow, the most recently saved version of the flow you currently have open in the contact flow editor is exported as a UTF-8 encoded JSON document. Each block of your contact flow is included in the JSON document as a separate section. To import a contact flow, you just select the file and import it into the contact flow you have open in the contact flow editor. You can import a contact flow that you previously exported or one that was exported from a different Amazon Connect instance. When you import a contact flow, it must be of the same type as the contact flow you have open in the editor. To learn more please see Contact Flow Import/Export.'), ('Q: How do I use contact flow import/export (beta)?', 'You can export a contact flow by selecting Export flow from the contact flow editor drop-down in Amazon Connect. The most recent saved contact flow will download as a text file. You can then import a contact flow by selecting Import flow from the same contact flow editor drop-down and then selecting the contact flow export file you want to import. The contact flow will load the contact flow into the editor for review. To learn more please see Contact Flow Import/Export.'), ('Q: How does outbound contact API work?', 'Amazon Connect allows you to automatically make calls to customers, using the outbound contact API. You can schedule automated calls for appointment reminders or notification calls in response to business events, such as credit card fraud.'), ('Q: How do I use outbound contact API?', 'Enterprise applications like CRM systems can use the outbound contact API when triggered by an event, such as a service outage, to initiate an outbound call using a predetermined contact flow. The contact flow will determine if an agent interaction is required, or if the call is routed to an Amazon Lex chatbot.'), ('Q: How do I sign up for the outbound contact API in the limited preview?', 'To request participation in the outbound contact limited preview, please apply here.'), ('Q: How much does it cost to use outbound contact API?', 'Standard pricing for service usage and associated telephony rates apply for outbound contact API. Please see Amazon Connect Pricing for more information.'), ('Q: Does Amazon Connect support skills-based routing?', 'Yes. Contacts can be routed based on agent skills, availability, and the priority of the contact.'), ('Q: How are required skills associated with a contact in Amazon Connect?', 'A contact is put into a queue which represents which skills are required to service it.'), ('Q: How does Amazon Connect determine which agents can handle a specific contact?', 'Agents are assigned to a Routing profile which includes the queues they have the skills to service.'), ('Q: Can a Routing profile contain multiple queues?', 'Yes. You can assign multiple queues to a Routing profile, so agents with multiple skills can service contacts with different requirements.'), ('Q: Can a single queue be assigned to multiple Routing profiles?', 'Yes. Queues can be assigned to multiple Routing profiles when there are agents with multiple overlapping skill sets.'), ('Q: Can some queues in a Routing profile be prioritized over other queues?', 'Yes. You can configure a Routing profile so certain agents prioritize handling contacts from a specific queue, but can also handle contacts from queues if they don’t have any high priority queues to service. This enlarges the pool of agents, and also ensures that the higher priority queues are serviced.'), ('Q: If two agents are available and have the same skill set, how does Amazon Connect determine which agent to send a contact to?', 'The agent who has been available the longest receives the contact.'), ('Q: Can I adjust the priority of contacts in queue?', 'Yes. You can adjust priority of contacts in the queue using the Set routing priority block in an Amazon Connect Contact flow.'), ('Q: Can an agent be assigned multiple Routing profiles?', 'No, agents can only be assigned to a single Routing profile.'), ('Q: Can I control which contact an agent gets when a queue is assigned to multiple routing profiles?', 'There are multiple options within routing profiles (e.g., Priority, Delay) to fine-tune the logic that determines which contact an agent will get.'), ('Q: What are the benefits of Routing profiles?', 'Routing profiles streamline operations and ensure that agents are treated equally. By assigning the same Routing profile to a group of agents, you can ensure they are all configured in the same way. Changes to a Routing profile affects all agents assigned to that Routing profile. This supports scalability and quick adaptation to real-world situations. '), ('Q: What type of metrics reporting does Amazon Connect support?', 'Amazon Connect offers three metrics experiences:'), ('1. Historical metrics reports: Generate reports to analyze how your contact center has performed over a specified period of time. You can generate granular or aggregated reports pivoted on queues, individual agents, and phone numbers. 2. Real-time metrics reports: Gain insight into how your contact center is performing in real time. You can see reports pivoted on queues, agents, and routing profiles 3. Contact search: View highly detailed individual contact reports with the option to find and play back call recordings.', 'Q: Does Amazon Connect support a wide variety metrics?'), ('Yes, Amazon Connect supports nearly 100 individual metrics across the different report types. You can find a detailed list in the Amazon Connect documentation.', 'Q: Can I save reports in Amazon Connect to be accessed later?'), ('Yes, Historical and Real-time metrics reports can be saved so you can load them later.', 'Q: Can I share reports within my organization?'), ('Yes, reports can be published for all metrics users to access.', 'Q: Can I export my metrics?'), ('Yes, you can export reports to the S3 bucket of your choice in comma separated value (CSV) format. This enables broad compatibility across other analytics and WFM tools.', 'Q: Are my exported metrics encrypted?'), ('Yes. Encryption is enabled by default for all saved reports using Amazon S3 server-side encryption with KMS. Disabling encryption is not recommended.', 'Q: Can I schedule reports to run and be exported at specific times?'), ('Yes, you can schedule reports run hourly, daily, and monthly. The output will be stored in S3.', 'Q: Can I stream my contact metrics in real-time so I can store and analyze them in a data warehouse I choose?'), ('Yes, you can stream Amazon Connect metrics using Amazon Kinesis Streams or Amazon Kinesis Firehose to any supported data repository. You can learn more about Amazon Kinesis here.', 'Q: Can I create a dashboard to view the metrics I’ve defined?'), ('Yes, you can use the comprehensive dashboard to define and monitor the service levels and agent occupancy performance indicators that are most important to you. You can configure the dashboard so that the metrics you care about are always visible. You can configure your dashboard from the home page of your Amazon Connect contact center instance.', 'Q: What is an Amazon Connect dashboard?'), ('The Amazon Connect dashboard tracks real-time performance so that you can quickly monitor the overall health of your contact center. The dashboard provides visibility into important information, which helps you deliver a better customer support experience, and improve the utilization of your agents.', 'Q: How do I configure my Amazon Connect dashboard? '), ('Click the Configure dashboard button to see options for configuring your dashboard. You can change the time range of the dashboard, filter the list of queues, and select the Service Level (SL) metric you want to monitor. You can also fine-tune the performance indicator colors for service level and occupancy metrics.', 'Q: Can I save my Amazon Connect dashboard?'), ('Yes, you can. Configure the dashboard to fit your needs, and click on the down arrow next to the Configure button. From the menu, select Save and name your dashboard. You can access saved dashboards from the Saved Reports page.', 'Q: How do I hide the configuration guide so that I only see the dashboard?'), ('To hide the configuration guide, click the Hide the guide link above the Configuration guide.', 'Q: Is there a report to view when agents log in and log out of Amazon Connect?'), ('Yes, you can now easily view the time stamps and duration for when agents log in and log out of Amazon Connect with the new Login/Logout report. To learn more about the Amazon Connect Login/Logout report, please see the User Guide.', 'Q: How do I generate the Login/Logout report in Amazon Connect?'), ('To generate a Login/Logout report, open the Amazon Connect dashboard, select Metrics and Quality, and then choose Login/Logout report.', 'Q: How does agent event stream work?'), ('You can enable agent event stream to work in Amazon Connect under the Data streaming settings. After you configure your Amazon Kinesis stream, activities will publish every time an agent logs in, logs out, answers a call, or changes their status. To learn more please see Agent Event Streams.', 'Q: What does an agent event stream look like?'), ('Each defined agent event is sent to the Amazon Connect agent event stream as a section in a JSON (JavaScript Object Notation) format document. The section for each event includes various fields about an agent and the event. To learn more please see Agent Event Streams.', 'Q: Is agent event stream different from my existing Amazon Kinesis stream for contact trace records?'), ('Yes, the Amazon Connect agent event stream is a new, separate Kinesis stream.', 'Q: How much does it cost to use agent event streams?'), ('Agent event streams do not incur additional Amazon Connect charges. You may incur charges for Amazon Kinesis usage. Please see Amazon Kinesis Pricing for more information.', 'Q: Does Amazon Connect support call recordings?'), ('Yes. Amazon Connect enables you to store call recordings of customer interactions in Amazon S3. Interactions are not recorded unless an agent is connected. If multiple agents are connected, each will have an associated call recording.', 'Q: What options for call recording does Amazon Connect support?'), ('Call recording is disabled by default, you can enable call recordings of agent / customer interactions, capturing the agent only, customer only, or both the agent and customer. Contact flow interactions are only recorded if an agent is listening to the call as well.', 'Q: Are agents and customers stored on separate, stereo audio channels?'), ('Yes, the agent audio is stored in the right channel. All incoming audio, including the end-customer and any one conferenced in are stored in the left channel.', 'Q: How do I configure call recording settings in Amazon Connect?'), ('You can configure call recording settings in the Set call recording behavior Contact flow block.', 'Q: How do I find and play back call recordings?'), ('You can find individual contacts using the Contact search experience in Amazon Connect metrics. If a call recording is available, and you have the required permissions, you can play it back.', 'Q: Do I have open access to my call recordings outside of Amazon Connect?'), ('Yes. Call recordings are stored in the S3 bucket of your choice enabling access by any user or application with the appropriate permissions.', 'Q: Are call recordings encrypted?'), ('Encryption is enabled by default for all call recordings using Amazon S3 server-side encryption with KMS. Disabling encryption is not recommended.', 'Q: How do I manage my call recordings lifecycle?'), ('Lifecycle management of call recordings should be done using Amazon S3’s lifecycle management tools.\xa0 ', 'Q: Does Amazon Connect work with other AWS services?'), ('Yes. Amazon Connect integrates with several AWS services to provide a richer depth of capabilities and customization, including:', '• Amazon Connect can leverage AWS Directory Services for identity and access management. • Amazon Connect stores any call recordings and exported metrics reports in Amazon S3 buckets you own and control the lifecycle management of. • Amazon Connect can use AWS Lambda to enable data dips, send encrypted customer input and other external integration in Contact flows. • Amazon Connect can stream metrics data to Amazon S3, Amazon Redshift, or external data warehouse solutions with Amazon Kinesis. • Amazon Connect can encrypt contact center related data, such as call recordings and reports, with encryption keys stored with Amazon Key Management Service. • Amazon Connect leverages Amazon Lex for Natural Language Understanding in Contact flows. • Amazon Connect uses Amazon CloudWatch for operational metrics and alarms'), ('Q: Does Amazon Connect integrate with my existing or other third party systems?', 'Yes Amazon Connect is an open platform so it is easy to integrate with existing or other third party systems. Amazon Connect provides out-of-the-box integrations with many popular tools such as customer relationship management (CRM),\xa0Workforce Management (WFM), and Analytics tools.'), ('You can also use Amazon Connect with other AWS services like Amazon S3 and AWS Lambda for storing recorded calls or streaming detailed contact records in real-time to a data warehouse to merge with business intelligence systems for further analysis. Amazon Connect provides an API so you can customize the solution to your needs.\xa0 \xa0', 'Q: Does the Amazon Connect contact control panel (CCP) support the ability to open a specific customer page based on the incoming call data with a CRM?'), ('Yes. The CCP supports an integration library to enable this with leading CRM tools or your own application.', 'Q: Does the Amazon Connect contact control panel (CCP) support click-to-call, the ability to click on a phone number to dial it with a CRM?'), ('Yes. The CCP supports an integration library to enable this with leading CRM tools or your own application.', 'Q: Can I export data from Amazon Connect to third party analytics/reporting packages?'), ('With Amazon Connect you own your data so you can leverage it in the ways that best suit your business, including exporting it to third-party applications and services. Detailed contact data can be exported to data warehouses and Amazon S3 in real time, via Amazon Kinesis Streams or Amazon Kinesis Firehose, and agent and contact data can be exported via automatically at regular intervals.', 'Q: Is there an advantage to leveraging additional AWS Services as opposed to proprietary solutions that are built specifically for a call center?'), ('Yes. AWS has a history of rapid innovation and improving services. For example, using services like Amazon S3 directly for call recordings means that the service is well-documented, has the support of the AWS ecosystem of ISV and consulting partners making it easy to find experts to help if you need it, and you get access to new features (for example lifecycle management tools), as soon as they are released.', 'Q: Is there a broad network of consulting partners should I need their help?'), ('Yes. Consulting partners with knowledge in both AWS Services and Contact Center Services are available to help you with additional support for custom integrations that can integrate to Amazon Connect, including: 1Strategy, Accenture, Aria Solutions, Persistent Systems, Slalom, Solstice, Waterfield Technologies, Voicefoundry, and Wipro. ', 'Q: How much does it cost to use Amazon Connect?'), ('With Amazon Connect, you only pay for what you use. There is a per minute charge for the Amazon Connect service. In addition to the charge for the service, there are also associated telecom charges for public switched telephone network (PSTN) usage. These charges are referred to as “Contact Center Telecommunications” charges on your AWS invoice.', 'Contact Center Telecommunications usage is charged by AMCS LLC and includes the following:'), ('• Telephone numbers that are billed by day, per country, including:  \xa0 \xa0 o Direct Inward Dial (DID), also known as local or toll numbers \xa0 \xa0 o Toll free numbers', '• Telephony usage that is billed per minute, rates vary per country:  \xa0 \xa0 o Inbound to DID number \xa0 \xa0 o Inbound to toll free \xa0 \xa0 o Outbound calling (to either a customer or agent)'), ('Please consult the Amazon Connect pricing page for the latest prices. ', 'Q: How are usage charges calculated?'), ('The Amazon Connect application charge is calculated based on customer contact duration, with a 10-second minimum and per second granularity.', 'For example, if there is an inbound call to your Amazon Connect phone number and the caller is on the line between 18:00:03 and 18:01:09 whether or not connected to your contact center agent, the application charge will be 1.1 minutes multiplied by the published per minute rate.\xa0'), ('The Contact Center Telecommunications charge is calculated based on the aggregate telecom minutes, rounded up to the nearest minute. For example, if a customer calls your Amazon Connect phone number and is on the line for 10 seconds before hanging up, you will be charged for 1 minute of Contact Center Telecommunications. If your agent is configured to receive their calls through PSTN, and your Amazon Connect instance receives an inbound call from a customer with a duration of 2 minutes and 50 seconds, of which 1 minute and 5 seconds were spent with the agent connected, you will be billed for 3 minutes of inbound usage and 2 minutes of outbound telecom usage, as the Amazon Connect instance placed an outbound PSTN call to your agent (rates vary based on the origination/destination of the calls). You are also charged for Contact Center Telecommunications when your agents place outbound calls to customers. ', 'Q: Is there a minimum usage amount per month? '), ('There is no minimum usage amount per month, you only pay for what you use for that month. ', 'Q: Are there any charges for agents or managers or other users of the Amazon Connect service? '), ("Amazon Connect charges are based on your end-customer's use of the system, and when agents place outbound calls.", 'Q: Are there any charges for API access to the system? '), ('No, there are no charges for API access.\xa0', 'Q: Are there any charges for Contact flow or IVR usage? '), ('No, there are no charges for Contact flow or IVR usage. You are, however, charged at the normal rate for any other AWS services which you might use in the IVR, including AWS Lambda and Amazon Lex.\xa0', 'Q: Are there any charges for text to speech with Contact flow or IVR usage?\xa0'), ('No, there are no other charges for text to speech with Contact flow or IVR usage.\xa0', 'Q: Are there any charges for call recordings usage? '), ('No, there are no charges for call regardings. However, you are be charged for the storage capacity you use, whether it is Amazon S3 or any other AWS storage service, to store your call recordings.', 'Q: Are there any charges for telecom trunk provisioning or capacity? '), ('No, you pay only for what you use as you use it. ', 'Q: Do your prices include taxes? '), ('Unless noted, Amazon Connect prices do not include applicable taxes and duties. For more information, please visit AWS Tax Help. \xa0', 'Q: Does Amazon Connect support auditing of configuration changes?'), ('Yes. You can see your configuration change history by choosing View historical changes from the bottom of most routing and user configuration pages.', 'Q: What tools can I use to monitor and set alarms for Amazon Connect operational metrics?'), ('Key operational metrics, queue utilization and concurrent calls, are written to Amazon CloudWatch to enable monitoring and alarms. See the Amazon Connect documentation\xa0for details about which metrics are available in CloudWatch. For more information about Amazon CloudWatch, see the\xa0Amazon CloudWatch.', "Q: Does Amazon Connect's default configuration have service limits?"), ("Yes. Amazon Connect uses service limits in order to ensure the stability of the overall platform and prevent customers from incurring unexpected costs. The default service limits are set to allow customers to run a medium sized contact center. The limits can be raised upon request to accommodate any sized contact center. The technology that powers Amazon Connect has been proven to scale with the needs of Amazon's award winning customer service, with tens of thousands of agents using it at peak times of the year.", 'You can learn more at AWS Service Limits.'), ('Q: How do I get support for Amazon Connect?', 'The answers to most questions about Amazon Connect can be found in the User Guide.\xa0'), ('For additional support options, please see AWS Support.\xa0', 'Amazon Web Services is Hiring.'), ('Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.', '\xa0'), ('Amazon Web Services is an Equal Opportunity Employer.', '\xa0'), ('\xa0', None)], '/lumberyard/faq/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')], '/gamelift/faq/': [('Amazon Web Services is Hiring.', 'Amazon Web Services (AWS) is a dynamic, growing business unit within Amazon.com. We are currently hiring Software Development Engineers, Product Managers, Account Managers, Solutions Architects, Support Engineers, System Engineers, Designers and more. Visit our Careers page or our Developer-specific Careers page to learn more.'), ('\xa0', 'Amazon Web Services is an Equal Opportunity Employer.'), ('\xa0', '\xa0')]}
